This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.idx/
  dev.nix
docs/
  blueprint.md
Hyperliquid/
  repomix-output-AlphaDragon50-TrackLiquidBot.xml
  repomix-output-kukapay-whale-tracker-mcp_tab=readme-ov-file.xml
  repomix-output-oni-giri-hyperliquid-monitor.xml
  repomix-output-wonjaechung-hyperliquid_whale_dashboard.xml
  repomix-output-wonjaechung-hyperliquid_whale_tracker.xml
  repomix-output-wonjaechung-onchain101.xml
public/
  logo.svg
src/
  ai/
    flows/
      summarize-blockchain-data.ts
    dev.ts
    genkit.ts
  app/
    globals.css
    layout.tsx
    page.tsx
  components/
    ui/
      accordion.tsx
      alert-dialog.tsx
      alert.tsx
      avatar.tsx
      badge.tsx
      button.tsx
      calendar.tsx
      card.tsx
      carousel.tsx
      chart.tsx
      checkbox.tsx
      collapsible.tsx
      dialog.tsx
      dropdown-menu.tsx
      form.tsx
      input.tsx
      label.tsx
      menubar.tsx
      popover.tsx
      progress.tsx
      radio-group.tsx
      scroll-area.tsx
      select.tsx
      separator.tsx
      sheet.tsx
      sidebar.tsx
      skeleton.tsx
      slider.tsx
      switch.tsx
      table.tsx
      tabs.tsx
      textarea.tsx
      toast.tsx
      toaster.tsx
      tooltip.tsx
    ai-summarizer.tsx
    api-connection-status.tsx
    auth-modal.tsx
    community-chat.tsx
    dashboard.tsx
    dataset-tables.tsx
    guide.tsx
    hero-animation.tsx
    home-page.tsx
    hyperliquid-tracker.tsx
    leaderboard.tsx
    liquidation-tracker.tsx
    normal-mode-board.tsx
    player-profile.tsx
    ranked-mode-board.tsx
    trading-alerts.tsx
    trading-view-chart.tsx
    user-nav.tsx
    volatility-gauge.tsx
  hooks/
    use-mobile.tsx
    use-toast.ts
  lib/
    utils.ts
  types/
    svg.d.ts
.gitignore
apphosting.yaml
components.json
next.config.ts
package.json
postcss.config.mjs
README.md
tailwind.config.ts
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".idx/dev.nix">
# To learn more about how to use Nix to configure your environment
# see: https://firebase.google.com/docs/studio/customize-workspace
{pkgs}: {
  # Which nixpkgs channel to use.
  channel = "stable-24.11"; # or "unstable"
  # Use https://search.nixos.org/packages to find packages
  packages = [
    pkgs.nodejs_20
    pkgs.zulu
  ];
  # Sets environment variables in the workspace
  env = {};
  # This adds a file watcher to startup the firebase emulators. The emulators will only start if
  # a firebase.json file is written into the user's directory
  services.firebase.emulators = {
    detect = true;
    projectId = "demo-app";
    services = ["auth" "firestore"];
  };
  idx = {
    # Search for the extensions you want on https://open-vsx.org/ and use "publisher.id"
    extensions = [
      # "vscodevim.vim"
    ];
    workspace = {
      onCreate = {
        default.openFiles = [
          "src/app/page.tsx"
        ];
      };
    };
    # Enable previews and customize configuration
    previews = {
      enable = true;
      previews = {
        web = {
          command = ["npm" "run" "dev" "--" "--port" "$PORT" "--hostname" "0.0.0.0"];
          manager = "web";
        };
      };
    };
  };
}
</file>

<file path="docs/blueprint.md">
# **App Name**: DuneChain Explorer

## Core Features:

- Data Parsing: Parse raw blockchain data, making it searchable and filterable for onchain analysis.
- Data Structuring: Organize blockchain data into relational data tables for the most popular EVM chains (such as Ethereum, Polygon, Arbitrum) using a V2 SQL engine.
- AI Data Summarization: Generate natural language summaries of blockchain datasets (blocks, transactions, logs) to make blockchain content understandable by non-experts; use a tool to determine what elements need explanation in each case.
- Smart Contract Decoding: Implement a spellbook to transform decoded calls and events in a GitHub repository so it can generate parsed tables of smart contracts.
- Community Sourced data.: Provide community tables with sourced data to help user perform Onchain analytics.

## Style Guidelines:

- Dark color scheme to evoke a sense of exploration and data-focus.
- Primary color: Deep blue (#2E3192) for a calm and trustworthy feel.
- Background color: Very dark gray (#121212), near black.
- Accent color: Electric purple (#BE0AFF) to add an exciting and hightech touch. Accent purple to also subtly show flow of chain.
- Headline font: 'Space Grotesk' sans-serif for computerized, scientific headlines; classifications include code snippets.
- Body font: 'Inter' sans-serif with a modern, objective look.
- Code font: 'Source Code Pro' monospace for computer code, if and when it appears.
- Use clear, simple icons representing different chains and data types.
- Divide the interface into clear, modular sections for data browsing, AI summarization, and community contributions.
- Use subtle animations, not distracting ones. Consider progress bars for blockchain data processing and loading, as well as smooth transitions for AI summary updates.
</file>

<file path="Hyperliquid/repomix-output-AlphaDragon50-TrackLiquidBot.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
docs/
  privacy.md
  terms.md
LICENSE.md
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="docs/privacy.md">
# TrackLiquid Bot Privacy Policy

_Last updated: May 2025_

TrackLiquid (‚Äúwe‚Äù, ‚Äúus‚Äù) respects your privacy. This policy explains what we collect, why, and your rights.

---

## 1. What We Collect

**User-Provided**  
- Guild ID (Discord server).  
- Wallet addresses you add.  
- Optional aliases.  
- Notification channel setting.

**Automatically Collected**  
- Command usage logs (for debugging and metrics), including on-demand PnL lookups via `/unrealized`.  
- Public on-chain data fetched from the Hyperliquid API.

---

## 2. How We Use It

- To post real-time alerts in your server.  
- To process on-demand unrealized PnL lookups (`/unrealized`).  
- To store your settings (wallets, aliases, notification channel).  
- To improve the bot via anonymized usage metrics.

---

## 3. Data Sharing

- We never sell or share your data with third parties.  
- We only send public, on-chain data to Hyperliquid‚Äôs API for position and price queries.

---

## 4. Retention

- Wallets, aliases, and channel settings are kept until you remove them or uninstall the bot.  
- Logs are temporary and used only for debugging and performance tuning; they are rotated regularly.

---

## 5. Security

- We **don't** collect private keys or other sensitive personal data.  
- All external calls (to Hyperliquid or Discord) use encrypted HTTPS connections.

---

## 6. Your Rights

- Remove any wallet or alias at any time with `/managewallet`.  
- Uninstall the bot from your server to delete all your data.

---

## 7. Changes

We may update this policy as needed; continued use of the bot implies acceptance of any changes.

---

## 8. Contact

- Support Server: https://discord.gg/ZwUmxk2Y3B  
- Email: support@trackliquid.io
</file>

<file path="docs/terms.md">
# TrackLiquid Bot Terms of Service

_Last updated: May 2025_

Welcome to TrackLiquid! These Terms of Service (‚ÄúTerms‚Äù) govern your use of the TrackLiquid Discord bot (the ‚ÄúService‚Äù). By inviting or using the bot, you agree to these Terms.

---

## 1. Definitions

- **Service**: the TrackLiquid Discord bot.  
- **You** or **User**: anyone who uses the Service.  
- **Data**: public on-chain wallet activity fetched from Hyperliquid APIs.

---

## 2. Acceptance

By using TrackLiquid, you accept these Terms in full. If you don't agree, do not add or use the bot.

---

## 3. Service Description

TrackLiquid monitors Hyperliquid perp positions for wallets you register, posting alerts on opens and closes.  
Additional features include:  
- `/openpositions` ‚Äî view current open PERP positions (size, entry price, leverage, P&L).  
- `/unrealized` ‚Äî on-demand unrealized PnL queries for tracked wallets.  

We provide no uptime or accuracy guarantees.

---

## 4. Privacy & Data

We collect only minimal data:

- **Wallets**, **aliases**, and **notification channel**  
- **Public on-chain data** from Hyperliquid  

No private keys or personal data are stored. See our
[Privacy Policy](./privacy.md) for details.

---

## 5. No Financial Advice

The Service is informational only, not financial advice. Always do your own research before trading.

---

## 6. API Usage

Please respect Hyperliquid‚Äôs rate limits. Abuse or excessively frequent requests may lead to temporary blocking.

---

## 7. Disclaimer & Limitation of Liability

- **No warranty**: Service is provided ‚Äúas-is.‚Äù  
- **Limitation**: We are not liable for any losses or damages arising from your use of the bot.

---

## 8. Changes

We may update these Terms at any time; continued use implies your acceptance of any changes.

---

## 9. Contact & License

- **Support Server**: <https://discord.gg/ZwUmxk2Y3B>  
- **Email**: support@trackliquid.io  
- **License**: [MIT](./LICENSE.md)
</file>

<file path="LICENSE.md">
# MIT License

**Copyright (c) 2025 AlphaDragon50**

Permission is hereby granted, **free of charge**, to any person obtaining a copy
of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

> The above copyright notice and this permission notice shall be included in
> all copies or substantial portions of the Software.

---

**The software is provided ‚Äúas is‚Äù, without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software.**
</file>

<file path="README.md">
[![Invite](https://img.shields.io/badge/Invite-TrackLiquid-blue)](https://discord.com/oauth2/authorize?client_id=1366056784049082398&permissions=92160&integration_type=0&scope=bot+applications.commands)
[![Support](https://img.shields.io/badge/Support-Discord-7289DA)](https://discord.gg/ZwUmxk2Y3B)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE.md)

# üì° TrackLiquid ‚Äî Hyperliquid Wallet Tracker

TrackLiquid brings real-time Hyperliquid perp position alerts straight into your Discord server.

---

## üöÄ Quick Start

1. **Invite TrackLiquid**  
   Click your personal invite link and choose a server.

2. **Pick Your Alerts Channel**  
   `/setchannel` ‚Üí select the channel where alerts should post.

3. **Add Wallets to Track (up to 3)**  
   `/addwallet 0x5078c2fbea2...bedb6 [Whale]`  
   *Optional alias helps you read alerts at a glance.*

4. **View Unrealized PnL**  
   `/unrealized` ‚Üí select a tracked wallet to see its current unrealized P&L.

---

## ‚öôÔ∏è Core Commands

| Command           | Description                                                                                   |
|-------------------|-----------------------------------------------------------------------------------------------|
| `/help`           | Show a quick reminder of all available commands.                                              |
| `/addwallet`      | Track a new wallet (with an optional alias). Use up to 3 wallets per server.                  |
| `/listwallets`    | Quickly list your tracked wallets and aliases.                                                |
| `/managewallet`   | View, rename, or remove any tracked wallet (includes ‚ÄúRemove All‚Äù).                           |
| `/openpositions`  | Show current open PERP positions for a tracked wallet (size, entry price, leverage, P&L).    |
| `/unrealized`     | Show unrealized PnL for a tracked wallet.                                                     |
| `/setchannel`     | Choose which channel receives perp notifications (leave blank to clear).                      |
| `/status`         | Display bot uptime and how many wallets you‚Äôre tracking (e.g. `2/3`).                         |

---

## üí° Examples

- **Add a wallet with an (optional) alias**  
  `/addwallet 0xABC...123 MyTradingWallet`  
  <div align="center">
    <img src="./assets/addwallet.prompt.PNG" alt="Add Wallet Prompt" width="300" />
    <img src="./assets/addwallet.embed.PNG"  alt="Add Wallet Confirmation" width="300" />
  </div>

- **List & manage wallets**  
  `/managewallet` ‚Üí choose ‚ÄúMyTradingWallet‚Äù ‚Üí rename, remove, or clear all.  
  <div align="center">
    <img src="./assets/managewallet_panel.PNG" alt="Manage Wallet Panel" width="300" />
    <img src="./assets/managewallet_embed.PNG" alt="Manage Wallet Embed" width="300" />
  </div>

- **Check open positions**  
  `/openpositions` ‚Üí select your wallet ‚Üí see entry price, size, leverage, PnL.  
  <div align="center">
    <img src="./assets/openpositions_embed.PNG" alt="Open Positions Embed" width="300" />
  </div>

- **Check Unrealized PnL**  
  `/unrealized` ‚Üí select your wallet ‚Üí shows current unrealized profit & loss.  
  <div align="center">
    <img src="./assets/unrealized_embed.PNG" alt="Unrealized PnL Embed" width="300" />
  </div>

- **View bot status**  
  `/status` ‚Üí shows uptime and number of tracked wallets (e.g. `2/3`).  
  <div align="center">
    <img src="./assets/status_embed.PNG" alt="Status Embed" width="300" />
  </div>

---

## ü§ù Support

If you hit a snag or have a feature request, join our Support Server:  
üëâ https://discord.gg/ZwUmxk2Y3B

---

¬© 2025 AlphaDragon50 ¬∑ [MIT License](./LICENSE.md)
</file>

</files>
</file>

<file path="Hyperliquid/repomix-output-kukapay-whale-tracker-mcp_tab=readme-ov-file.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitignore
.python-version
Dockerfile
LICENSE
pyproject.toml
README.md
smithery.yaml
whale-tracker.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
__pycache__
.env
.venv
</file>

<file path=".python-version">
3.13
</file>

<file path="Dockerfile">
# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile
# Use official Python 3.13 slim image
FROM python:3.13-slim

# Set working directory
WORKDIR /app

# Copy project metadata and source
COPY pyproject.toml uv.lock whale-tracker.py ./

# Install dependencies
RUN pip install --no-cache-dir . python-dotenv

# Expose no ports since MCP runs over stdio

# Default entrypoint to run the MCP server
ENTRYPOINT ["python", "whale-tracker.py"]
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 kukapay

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="pyproject.toml">
[project]
name = "whale-tracker-mcp"
version = "0.1.0"
description = "A mcp server for tracking cryptocurrency whale transactions using the Whale Alert API"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "httpx>=0.28.1",
    "mcp[cli]>=1.4.0",
]
</file>

<file path="README.md">
# Whale Tracker MCP Server


**A Model Context Protocol (MCP) server for tracking cryptocurrency whale transactions using the Whale Alert API**

[![mit license](https://img.shields.io/badge/license-MIT-blue)](https://opensource.org/license/mit/)
[![python versions](https://img.shields.io/pypi/pyversions/mcp)](https://www.python.org/downloads/)
[![smithery badge](https://smithery.ai/badge/@kukapay/whale-tracker-mcp)](https://smithery.ai/server/@kukapay/whale-tracker-mcp)

<!-- omit in toc -->
## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
  - [Running in Development Mode](#running-in-development-mode)
  - [Integrating with Claude Desktop](#integrating-with-claude-desktop)
  - [Direct Execution](#direct-execution)
- [Examples](#examples)
- [API Key Configuration](#api-key-configuration)
- [License](#license)
- [Acknowledgements](#acknowledgements)


## Overview

The `whale-tracker-mcp` server is a Python-based implementation of the [Model Context Protocol (MCP)](https://modelcontextprotocol.io) that integrates with the [Whale Alert API](https://docs.whale-alert.io/#endpoints). It enables real-time tracking and analysis of large cryptocurrency transactions ("whale" movements) by exposing tools, resources, and prompts to MCP-compatible clients like Claude Desktop.

This server is designed for cryptocurrency enthusiasts, developers, and analysts who want to monitor whale activity directly within their LLM-powered workflows.

## Features

- **Tools**:
  - `get_recent_transactions`: Fetch recent whale transactions with optional filters for blockchain, minimum value, and limit.
  - `get_transaction_details`: Retrieve detailed information about a specific transaction by its ID.
- **Resources**:
  - `whale://transactions/{blockchain}`: Expose recent transactions for a specified blockchain as contextual data.
- **Prompts**:
  - `query_whale_activity`: A reusable template for analyzing whale transaction patterns, optionally filtered by blockchain.
- **Asynchronous API Calls**: Uses `httpx` for efficient, non-blocking requests to the Whale Alert API.
- **Environment Variable Support**: Securely manage your API key via a `.env` file.

## Prerequisites

- **Python**: Version 3.10 or higher.
- **Whale Alert API Key**: Sign up at [whale-alert.io](https://whale-alert.io/) to obtain an API key.
- **MCP Client**: Compatible with MCP clients like Claude Desktop or the MCP Inspector.

## Installation

### Installing via Smithery

To install Whale Tracker for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kukapay/whale-tracker-mcp):

```bash
npx -y @smithery/cli install @kukapay/whale-tracker-mcp --client claude
```

1. **Clone the repository**:
```bash
git clone https://github.com/kukapay/whale-tracker-mcp.git
cd whale-tracker-mcp
```
2. Install dependencies: We recommend using uv for dependency management:
```bash
uv add "mcp[cli]" httpx python-dotenv
```   
Alternatively, use pip:
```bash
pip install mcp httpx python-dotenv
```
3. Set up your API key: Create a .env file in the project root and add your Whale Alert API key:
```
WHALE_ALERT_API_KEY=your_api_key_here
```

## Usage
### Running in Development Mode

Test the server locally with the MCP Inspector:

```bash
mcp dev whale_tracker.py --with-editable .
```

This opens a web interface where you can explore the server's tools, resources, and prompts.

### Integrating with Claude Desktop

Install the server into Claude Desktop for seamless integration:

```bash
mcp install whale_tracker.py --name "WhaleTracker" -f .env
```

- `--name "WhaleTracker"`: Sets a custom name for the server in Claude Desktop.
- `-f .env`: Loads the API key from the .env file.

Restart Claude Desktop after installation. Look for the hammer icon in the input box to confirm the server is loaded, then try commands like:

- "Show me recent whale transactions on Bitcoin."
- "Get details for transaction ID 123456789."
- "Analyze whale activity on Ethereum."

### Direct Execution

Run the server standalone for custom deployments:

```bash
python whale_tracker.py
```

Or use the MCP CLI:

```bash
mcp run whale_tracker.py
```

## Examples

Here‚Äôs how you might interact with the server in Claude Desktop:

### Fetch Recent Transactions:

```text
What are the latest whale transactions on Ethereum with a minimum value of $1,000,000?
```
The server calls `get_recent_transactions` with `blockchain="ethereum"` and `min_value=1000000`.

### Get Transaction Details:

```text
Tell me about transaction ID 123456789.
```

The server uses `get_transaction_details` to fetch and display the transaction data.

### Analyze Whale Activity:

```text
Analyze recent whale transactions on Bitcoin.
```

The `query_whale_activity` prompt triggers an analysis based on the `whale://transactions/bitcoin` resource.

## API Key Configuration

The server requires a Whale Alert API key, which is loaded from the `WHALE_ALERT_API_KEY` environment variable. To configure it:

- Create a .env file:
```text
WHALE_ALERT_API_KEY=your_api_key_here
```
- Ensure `python-dotenv` is installed (included in the dependencies).
- The server will automatically load the key at startup.

Alternatively, pass the key directly when running the server:

```bash
mcp install whale_tracker.py -v WHALE_ALERT_API_KEY=your_api_key_here
```

## License

This project is licensed under the MIT License. See the LICENSE file for details.

## Acknowledgements

- Whale Alert for providing the API to track cryptocurrency whale transactions.
- Model Context Protocol team for the MCP specification and Python SDK.
- httpx for a robust HTTP client library.

Happy whale tracking! üê≥
</file>

<file path="smithery.yaml">
# Smithery configuration file: https://smithery.ai/docs/config#smitheryyaml

startCommand:
  type: stdio
  configSchema:
    # JSON Schema defining the configuration options for the MCP.
    type: object
    required:
      - whaleAlertApiKey
    properties:
      whaleAlertApiKey:
        type: string
        description: Your Whale Alert API key to authenticate requests
  commandFunction:
    # A JS function that produces the CLI command based on the given config to start the MCP on stdio.
    |-
    (config) => ({
      command: "python",
      args: ["whale-tracker.py"],
      env: { WHALE_ALERT_API_KEY: config.whaleAlertApiKey }
    })
  exampleConfig:
    whaleAlertApiKey: YOUR_API_KEY_HERE
</file>

<file path="whale-tracker.py">
import os
from typing import Optional
import httpx
from mcp.server.fastmcp import FastMCP, Context
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
API_KEY = os.getenv("WHALE_ALERT_API_KEY")
BASE_URL = "https://api.whale-alert.io/v1"

if not API_KEY:
    raise ValueError("WHALE_ALERT_API_KEY environment variable is required")

# Initialize the MCP server
mcp = FastMCP("WhaleTracker", dependencies=["httpx"])

# Helper function to make API requests
async def fetch_from_api(endpoint: str, params: dict) -> dict:
    async with httpx.AsyncClient() as client:
        params["api_key"] = API_KEY
        response = await client.get(f"{BASE_URL}/{endpoint}", params=params)
        response.raise_for_status()
        return response.json()

# Tool: Fetch recent whale transactions
@mcp.tool()
async def get_recent_transactions(
    blockchain: Optional[str] = None,
    min_value: Optional[int] = 500000,
    limit: int = 10
) -> str:
    """Fetch recent whale transactions, optionally filtered by blockchain and minimum value (USD)."""
    params = {
        "min_value": min_value,
        "limit": limit
    }
    if blockchain:
        params["blockchain"] = blockchain.lower()

    data = await fetch_from_api("transactions", params)
    if data["result"] != "success":
        return "Error fetching transactions"

    transactions = data["transactions"]
    return "\n".join(
        f"{tx['timestamp']} - {tx['blockchain']} - {tx['amount_usd']} USD "
        f"(Tx ID: {tx['id']})"
        for tx in transactions
    )

# Tool: Get details of a specific transaction
@mcp.tool()
async def get_transaction_details(transaction_id: str) -> str:
    """Fetch details of a specific whale transaction by its ID."""
    params = {"id": transaction_id}
    data = await fetch_from_api("transaction", params)
    if data["result"] != "success":
        return f"Error fetching transaction {transaction_id}"

    tx = data["transaction"]
    return (
        f"Transaction ID: {tx['id']}\n"
        f"Blockchain: {tx['blockchain']}\n"
        f"Timestamp: {tx['timestamp']}\n"
        f"Amount: {tx['amount']} {tx['symbol']} (${tx['amount_usd']} USD)\n"
        f"From: {tx['from'].get('address', 'Unknown')}\n"
        f"To: {tx['to'].get('address', 'Unknown')}"
    )

# Resource: Dynamic transaction data
@mcp.resource("whale://transactions/{blockchain}")
async def get_transactions_by_blockchain(blockchain: str) -> str:
    """Expose recent whale transactions for a specific blockchain as a resource."""
    params = {
        "blockchain": blockchain.lower(),
        "min_value": 500000,
        "limit": 5
    }
    data = await fetch_from_api("transactions", params)
    if data["result"] != "success":
        return f"No transactions found for {blockchain}"

    transactions = data["transactions"]
    return "\n".join(
        f"{tx['timestamp']} - {tx['amount_usd']} USD (Tx ID: {tx['id']})"
        for tx in transactions
    )

# Prompt: Query whale activity
@mcp.prompt()
def query_whale_activity(blockchain: Optional[str] = None) -> str:
    """Generate a prompt to analyze whale activity on a specific blockchain."""
    if blockchain:
        return f"Analyze recent whale transactions on {blockchain}. What patterns do you notice?"
    return "Analyze recent whale transactions across all blockchains. What patterns do you notice?"

# Run the server directly (optional)
if __name__ == "__main__":
    mcp.run()
</file>

</files>
</file>

<file path="Hyperliquid/repomix-output-oni-giri-hyperliquid-monitor.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    publish.yml
src/
  hyperliquid_monitor/
    config.py
    database.py
    monitor.py
    types.py
tests/
  conftest.py
  test_database.py
  test_monitor.py
  test_types.py
.gitignore
LICENSE.md
pyproject.toml
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/publish.yml">
name: Publish to PyPI

on:
  release:
    types: [created]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
    
    - name: Install dependencies
      run: poetry install
    
    - name: Run tests
      run: |
        # Only run unit tests that don't start the monitor
        poetry run pytest tests/test_database.py tests/test_types.py \
                         -v --cov=hyperliquid_monitor --cov-report=term-missing

  publish:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
    
    - name: Configure Poetry
      run: |
        poetry config pypi-token.pypi ${{ secrets.PYPI_TOKEN }}
    
    - name: Build and publish
      run: |
        poetry build
        poetry publish
</file>

<file path="src/hyperliquid_monitor/config.py">
import os
from dotenv import load_dotenv
from hyperliquid_monitor.database import init_database

# Load environment variables
load_dotenv()

# Get addresses from environment
ADDRESSES = [addr.strip() for addr in os.getenv("MONITORED_ADDRESSES", "").split(",") if addr.strip()]

# Initialize database and get path
DB_PATH = init_database(os.getenv("DB_PATH", "trades.db"))
</file>

<file path="src/hyperliquid_monitor/database.py">
import sqlite3
import threading
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

def init_database(db_path: Optional[str] = None) -> str:
    """
    Initialize a new database for the Hyperliquid monitor or validate an existing one.
    
    Args:
        db_path: Optional path to the database. If None, creates a default 'trades.db'
                in the current directory.
    
    Returns:
        str: The absolute path to the initialized database
        
    Raises:
        sqlite3.Error: If there's an error creating or accessing the database
        ValueError: If the provided path is invalid
    """
    if db_path is None:
        db_path = "trades.db"
    
    # Convert to Path object for easier manipulation
    db_path = Path(db_path).resolve()
    
    # Create parent directories if they don't exist
    db_path.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        # Create and test the database connection
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # Create the required tables
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS fills (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME,
            address TEXT,
            coin TEXT,
            side TEXT,
            size REAL,
            price REAL,
            direction TEXT,
            tx_hash TEXT,
            fee REAL,
            fee_token TEXT,
            start_position REAL,
            closed_pnl REAL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        ''')

        cursor.execute('''
        CREATE TABLE IF NOT EXISTS orders (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME,
            address TEXT,
            coin TEXT,
            action TEXT,
            side TEXT,
            size REAL,
            price REAL,
            order_id INTEGER,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # Create indexes for better query performance
        cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_fills_address ON fills(address)
        ''')
        cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_fills_timestamp ON fills(timestamp)
        ''')
        cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_orders_address ON orders(address)
        ''')
        cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_orders_timestamp ON orders(timestamp)
        ''')
        
        conn.commit()
        conn.close()
        
        return str(db_path)
        
    except sqlite3.Error as e:
        raise sqlite3.Error(f"Failed to initialize database at {db_path}: {str(e)}")
    except Exception as e:
        raise ValueError(f"Error creating database at {db_path}: {str(e)}")

class TradeDatabase:
    def __init__(self, db_path: str):
        """Initialize the database connection and create tables if they don't exist."""
        self.db_path = init_database(db_path)  # Use the init_database function
        self._local = threading.local()
        
    @property
    def conn(self) -> sqlite3.Connection:
        if not hasattr(self._local, 'conn'):
            self._local.conn = sqlite3.connect(self.db_path)
        return self._local.conn

    def store_fill(self, fill: Dict) -> None:
        """Store a fill in the database."""
        cursor = self.conn.cursor()
        timestamp = datetime.fromtimestamp(int(fill.get("time", 0)) / 1000)
        
        cursor.execute('''
        INSERT INTO fills (
            timestamp, address, coin, side, size, price, direction, tx_hash, 
            fee, fee_token, start_position, closed_pnl
        )
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            timestamp,
            fill.get("address", "Unknown"),
            fill.get("coin", "Unknown"),
            "BUY" if fill.get("side", "B") == "A" else "SELL",
            float(fill.get("sz", 0)),
            float(fill.get("px", 0)),
            fill.get("dir", "Unknown"),
            fill.get("hash", "Unknown"),
            float(fill.get("fee", 0)),
            fill.get("feeToken", "Unknown"),
            float(fill.get("startPosition", 0)),
            float(fill.get("closedPnl", 0))
        ))
        
        self.conn.commit()

    def store_order(self, order: Dict, action: str) -> None:
        """Store an order in the database."""
        cursor = self.conn.cursor()
        timestamp = datetime.fromtimestamp(int(order.get("time", 0)) / 1000)
        
        # Get the placed or canceled order details
        order_details = order.get("placed", {}) if action == "placed" else order.get("canceled", {})
        
        cursor.execute('''
        INSERT INTO orders (timestamp, address, coin, action, side, size, price, order_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            timestamp,
            order.get("address", "Unknown"),
            order.get("coin", "Unknown"),
            action,
            "BUY" if order_details.get("side", "B") == "A" else "SELL",
            float(order_details.get("sz", 0)),
            float(order_details.get("px", 0)),
            int(order_details.get("oid", 0))
        ))
        
        self.conn.commit()

    def close(self) -> None:
        """Close the database connection."""
        if hasattr(self._local, 'conn'):
            self._local.conn.close()
            delattr(self._local, 'conn')
</file>

<file path="src/hyperliquid_monitor/monitor.py">
import signal
import sys
import threading
from datetime import datetime
from typing import Dict, Any, List, Optional, Union

from hyperliquid.info import Info
from hyperliquid.utils import constants

from hyperliquid_monitor.database import TradeDatabase
from hyperliquid_monitor.types import Trade, TradeCallback

class HyperliquidMonitor:
    def __init__(self, 
                 addresses: List[str], 
                 db_path: Optional[str] = None,
                 callback: Optional[TradeCallback] = None,
                 silent: bool = False):
        """
        Initialize the Hyperliquid monitor.
        
        Args:
            addresses: List of addresses to monitor
            db_path: Optional path to SQLite database. If None, trades won't be stored
            callback: Optional callback function that will be called for each trade
            silent: If True, callback notifications will be suppressed even if callback is provided.
                   Useful for silent database recording. Default is False.
        """
        self.info = Info(constants.MAINNET_API_URL)
        self.addresses = addresses
        self.callback = callback if not silent else None
        self.silent = silent
        self.db = TradeDatabase(db_path) if db_path else None
        self._stop_event = threading.Event()
        self._db_lock = threading.Lock() if db_path else None
        
        if silent and not db_path:
            raise ValueError("Silent mode requires a database path to be specified")
        
    def handle_shutdown(self, signum=None, frame=None):
        """Handle shutdown signals"""
        if self._stop_event.is_set():
            sys.exit(0)
            
        print("\nShutting down gracefully...")
        self._stop_event.set()
        self.cleanup()
        signal.signal(signal.SIGINT, signal.SIG_DFL)
        signal.signal(signal.SIGTERM, signal.SIG_DFL)
        sys.exit(0)
        
    def cleanup(self):
        """Clean up resources"""
        if self.db:
            with self._db_lock:
                self.db.close()
            if not self.silent:
                print("Database connection closed.")

    def create_event_handler(self, address: str):
        """Creates an event handler for a specific address"""
        def handle_event(event: Dict[str, Any]) -> None:
            if self._stop_event.is_set():
                return
                
            if not isinstance(event, dict):
                return
                
            data = event.get("data", {})
            
            # Handle fills
            if "fills" in data:
                for fill in data["fills"]:
                    if not isinstance(fill, dict):
                        continue
                    try:
                        trade = self._process_fill(fill, address)
                        if self.db:
                            with self._db_lock:
                                self.db.store_fill(fill)
                        if self.callback and not self.silent:
                            self.callback(trade)
                    except Exception as e:
                        if not self.silent:
                            print(f"Error processing fill: {e}")
                        
            # Handle order updates        
            if "orderUpdates" in data:
                for update in data["orderUpdates"]:
                    if not isinstance(update, dict):
                        continue
                    try:
                        trades = self._process_order_update(update, address)
                        if self.db:
                            with self._db_lock:
                                if "placed" in update:
                                    self.db.store_order(update, "placed")
                                elif "canceled" in update:
                                    self.db.store_order(update, "canceled")
                        if self.callback and not self.silent:
                            for trade in trades:
                                self.callback(trade)
                    except Exception as e:
                        if not self.silent:
                            print(f"Error processing order update: {e}")
        
        return handle_event

    def _process_fill(self, fill: Dict, address: str) -> Trade:
        """Process fill information and return Trade object"""
        timestamp = datetime.fromtimestamp(int(fill.get("time", 0)) / 1000)
        
        return Trade(
            timestamp=timestamp,
            address=address,
            coin=fill.get("coin", "Unknown"),
            side="BUY" if fill.get("side", "B") == "A" else "SELL",
            size=float(fill.get("sz", 0)),
            price=float(fill.get("px", 0)),
            trade_type="FILL",
            direction=fill.get("dir"),
            tx_hash=fill.get("hash"),
            fee=float(fill.get("fee", 0)),
            fee_token=fill.get("feeToken"),
            start_position=float(fill.get("startPosition", 0)),
            closed_pnl=float(fill.get("closedPnl", 0))
        )
        
    def _process_order_update(self, update: Dict, address: str) -> List[Trade]:
        """Process order update information and return Trade objects"""
        timestamp = datetime.fromtimestamp(int(update.get("time", 0)) / 1000)
        trades = []
        
        if "placed" in update:
            order = update["placed"]
            trades.append(Trade(
                timestamp=timestamp,
                address=address,
                coin=update.get("coin", "Unknown"),
                side="BUY" if order.get("side", "B") == "A" else "SELL",
                size=float(order.get("sz", 0)),
                price=float(order.get("px", 0)),
                trade_type="ORDER_PLACED",
                order_id=int(order.get("oid", 0))
            ))
        elif "canceled" in update:
            order = update["canceled"]
            trades.append(Trade(
                timestamp=timestamp,
                address=address,
                coin=update.get("coin", "Unknown"),
                side="BUY" if order.get("side", "B") == "A" else "SELL",
                size=float(order.get("sz", 0)),
                price=float(order.get("px", 0)),
                trade_type="ORDER_CANCELLED",
                order_id=int(order.get("oid", 0))
            ))
            
        return trades
            
    def start(self) -> None:
        """Start monitoring addresses"""
        if not self.addresses:
            raise ValueError("No addresses configured to monitor")
            
        # Set up signal handlers
        signal.signal(signal.SIGINT, self.handle_shutdown)
        signal.signal(signal.SIGTERM, self.handle_shutdown)
        
        # Subscribe to events for each address
        for address in self.addresses:
            handler = self.create_event_handler(address)
            self.info.subscribe(
                {"type": "userEvents", "user": address},
                handler
            )
            self.info.subscribe(
                {"type": "userFills", "user": address},
                handler
            )
        
        try:
            while not self._stop_event.is_set():
                self._stop_event.wait(1)
        except KeyboardInterrupt:
            self.handle_shutdown()

    def stop(self):
        """Stop the monitor"""
        self._stop_event.set()
        self.cleanup()
</file>

<file path="src/hyperliquid_monitor/types.py">
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, Literal, Callable

TradeType = Literal["FILL", "ORDER_PLACED", "ORDER_CANCELLED"]
TradeSide = Literal["BUY", "SELL"]

@dataclass
class Trade:
    timestamp: datetime
    address: str
    coin: str
    side: TradeSide
    size: float
    price: float
    trade_type: TradeType
    direction: Optional[str] = None
    tx_hash: Optional[str] = None
    fee: Optional[float] = None
    fee_token: Optional[str] = None
    start_position: Optional[float] = None
    closed_pnl: Optional[float] = None
    order_id: Optional[int] = None

    def __post_init__(self):
        """Validate trade data after initialization"""
        if self.side not in ("BUY", "SELL"):
            raise ValueError(f"Invalid side: {self.side}. Must be 'BUY' or 'SELL'")
        
        if self.trade_type not in ("FILL", "ORDER_PLACED", "ORDER_CANCELLED"):
            raise ValueError(
                f"Invalid trade_type: {self.trade_type}. "
                "Must be 'FILL', 'ORDER_PLACED', or 'ORDER_CANCELLED'"
            )

TradeCallback = Callable[[Trade], None]
</file>

<file path="tests/conftest.py">
import os
import tempfile
from datetime import datetime
from typing import Dict
import pytest
from hyperliquid_monitor.types import Trade

@pytest.fixture
def temp_db_path(tmp_path):
    """Create a temporary database path"""
    db_path = tmp_path / "test.db"
    return str(db_path)

@pytest.fixture
def sample_fill_data() -> Dict:
    """Sample fill data for testing"""
    return {
        "coin": "ETH",
        "px": "1850.5",
        "sz": "0.5",
        "side": "A",
        "time": 1699457400000,  # 2023-11-08 15:30:00
        "startPosition": "-10.5",
        "dir": "Open Long",
        "closedPnl": "100.25",
        "hash": "0x123...",
        "oid": 12345,
        "crossed": False,
        "fee": "1.5",
        "tid": 67890,
        "feeToken": "USDC"
    }

@pytest.fixture
def sample_order_data() -> Dict:
    """Sample order data for testing"""
    return {
        "coin": "BTC",
        "time": 1699457400000,  # 2023-11-08 15:30:00
        "placed": {
            "px": "35000.5",
            "sz": "0.1",
            "side": "B",
            "oid": 54321
        }
    }

@pytest.fixture
def sample_trade() -> Trade:
    """Sample trade object for testing"""
    return Trade(
        timestamp=datetime(2023, 11, 8, 15, 30),
        address="0x123...",
        coin="ETH",
        side="BUY",
        size=0.5,
        price=1850.5,
        trade_type="FILL",
        direction="Open Long",
        tx_hash="0x123...",
        fee=1.5,
        fee_token="USDC",
        start_position=-10.5,
        closed_pnl=100.25
    )
</file>

<file path="tests/test_database.py">
import pytest
import os
import threading
from pathlib import Path
from hyperliquid_monitor.database import TradeDatabase, init_database

def test_database_initialization(temp_db_path):
    db = TradeDatabase(temp_db_path)
    assert db is not None
    db.close()

def test_init_database_default():
    db_path = init_database()
    assert os.path.exists(db_path)
    assert db_path.endswith("trades.db")
    os.remove(db_path)  # Cleanup

def test_init_database_custom_path(tmp_path):
    custom_path = tmp_path / "custom" / "path" / "db.sqlite"
    db_path = init_database(str(custom_path))
    assert os.path.exists(db_path)
    assert str(custom_path) == db_path
    assert os.path.exists(custom_path.parent)  # Parent directories should be created

def test_database_tables(temp_db_path):
    db = TradeDatabase(temp_db_path)
    cursor = db.conn.cursor()
    
    # Check fills table
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='fills'
    """)
    assert cursor.fetchone() is not None
    
    # Check orders table
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='orders'
    """)
    assert cursor.fetchone() is not None
    
    # Check indexes
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='index' AND sql IS NOT NULL
    """)
    indexes = [row[0] for row in cursor.fetchall()]
    assert "idx_fills_address" in indexes
    assert "idx_fills_timestamp" in indexes
    assert "idx_orders_address" in indexes
    assert "idx_orders_timestamp" in indexes
    
    db.close()

def test_store_fill(temp_db_path, sample_fill_data):
    db = TradeDatabase(temp_db_path)
    
    # Add address to fill data
    fill_data = {**sample_fill_data, "address": "0x123..."}
    
    # Store the fill
    db.store_fill(fill_data)
    
    # Query the stored fill
    cursor = db.conn.cursor()
    cursor.execute("SELECT * FROM fills")
    row = cursor.fetchone()
    
    assert row is not None
    assert row[2] == "0x123..."  # address
    assert row[3] == "ETH"      # coin
    assert row[4] == "BUY"      # side
    assert float(row[5]) == 0.5  # size
    assert float(row[6]) == 1850.5  # price
    
    db.close()

def test_store_order(temp_db_path, sample_order_data):
    db = TradeDatabase(temp_db_path)
    
    # Add address to order data
    order_data = {**sample_order_data, "address": "0x123..."}
    
    # Store the order
    db.store_order(order_data, "placed")
    
    # Query the stored order
    cursor = db.conn.cursor()
    cursor.execute("SELECT * FROM orders")
    row = cursor.fetchone()
    
    assert row is not None
    assert row[2] == "0x123..."  # address
    assert row[3] == "BTC"      # coin
    assert row[4] == "placed"   # action
    assert row[5] == "SELL"     # side
    assert float(row[6]) == 0.1  # size
    assert float(row[7]) == 35000.5  # price
    assert row[8] == 54321      # order_id
    
    db.close()

def test_database_reuse(temp_db_path, sample_fill_data):
    # First instance
    db1 = TradeDatabase(temp_db_path)
    fill_data = {**sample_fill_data, "address": "0x123..."}
    db1.store_fill(fill_data)
    db1.close()
    
    # Second instance should be able to access the same data
    db2 = TradeDatabase(temp_db_path)
    cursor = db2.conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM fills")
    count = cursor.fetchone()[0]
    assert count == 1
    db2.close()

def test_init_database_invalid_path(tmp_path):
    # Using a file as directory to simulate invalid path
    invalid_file = tmp_path / "file.txt"
    invalid_file.write_text("")  # Create a file
    invalid_path = str(invalid_file / "db.sqlite")  # Try to create DB inside a file
    
    with pytest.raises((ValueError, OSError)):
        init_database(invalid_path)

def test_database_connection_thread_safety(temp_db_path):
    db = TradeDatabase(temp_db_path)
    connections = []
    
    def create_connection():
        conn = db.conn
        connections.append(conn)
    
    # Create connections in different threads
    thread1 = threading.Thread(target=create_connection)
    thread2 = threading.Thread(target=create_connection)
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    # Verify we got different connections
    assert len(connections) == 2
    assert connections[0] != connections[1]
    
    db.close()
</file>

<file path="tests/test_monitor.py">
import pytest
from unittest.mock import Mock, call
from freezegun import freeze_time
from datetime import datetime

from hyperliquid_monitor.monitor import HyperliquidMonitor
from hyperliquid_monitor.types import Trade

def test_monitor_initialization():
    addresses = ["0x123..."]
    monitor = HyperliquidMonitor(addresses)
    assert monitor.addresses == addresses
    assert monitor.db is None
    assert monitor.callback is None
    assert monitor.silent is False

def test_monitor_with_db(temp_db_path):
    addresses = ["0x123..."]
    monitor = HyperliquidMonitor(addresses, db_path=temp_db_path)
    assert monitor.db is not None
    assert monitor.db.db_path == temp_db_path
    assert monitor.silent is False

def test_silent_mode_requires_db():
    addresses = ["0x123..."]
    with pytest.raises(ValueError, match="Silent mode requires a database path"):
        HyperliquidMonitor(addresses, silent=True)

def test_silent_mode_initialization(temp_db_path):
    addresses = ["0x123..."]
    callback = Mock()
    monitor = HyperliquidMonitor(
        addresses, 
        db_path=temp_db_path, 
        callback=callback,
        silent=True
    )
    assert monitor.db is not None
    assert monitor.callback is None  # Callback should be None in silent mode
    assert monitor.silent is True

@freeze_time("2023-11-08 15:30:00")
def test_process_fill(sample_fill_data):
    monitor = HyperliquidMonitor(["0x123..."])
    address = "0x123..."
    
    trade = monitor._process_fill(sample_fill_data, address)
    
    assert isinstance(trade, Trade)
    assert trade.address == address
    assert trade.coin == "ETH"
    assert trade.side == "BUY"  # 'A' should be converted to 'BUY'
    assert trade.size == 0.5
    assert trade.price == 1850.5
    assert trade.trade_type == "FILL"
    assert trade.direction == "Open Long"
    assert abs(trade.closed_pnl - 100.25) < 0.001  # Float comparison

@freeze_time("2023-11-08 15:30:00")
def test_process_order_update(sample_order_data):
    monitor = HyperliquidMonitor(["0x123..."])
    address = "0x123..."
    
    trades = monitor._process_order_update(sample_order_data, address)
    
    assert len(trades) == 1
    trade = trades[0]
    assert isinstance(trade, Trade)
    assert trade.address == address
    assert trade.coin == "BTC"
    assert trade.side == "SELL"  # 'B' should be converted to 'SELL'
    assert trade.size == 0.1
    assert abs(trade.price - 35000.5) < 0.001
    assert trade.trade_type == "ORDER_PLACED"
    assert trade.order_id == 54321

def test_callback_execution(sample_fill_data):
    mock_callback = Mock()
    monitor = HyperliquidMonitor(["0x123..."], callback=mock_callback)
    
    handler = monitor.create_event_handler("0x123...")
    event = {"data": {"fills": [sample_fill_data]}}
    
    handler(event)
    
    assert mock_callback.call_count == 1
    call_args = mock_callback.call_args[0][0]
    assert isinstance(call_args, Trade)
    assert call_args.coin == "ETH"
    assert abs(call_args.size - 0.5) < 0.001

def test_silent_mode_callback_suppression(sample_fill_data, temp_db_path):
    mock_callback = Mock()
    monitor = HyperliquidMonitor(
        ["0x123..."], 
        db_path=temp_db_path,
        callback=mock_callback,
        silent=True
    )
    
    handler = monitor.create_event_handler("0x123...")
    event = {"data": {"fills": [sample_fill_data]}}
    
    handler(event)
    
    # Callback should not be called in silent mode
    assert mock_callback.call_count == 0

def test_stop_monitor():
    monitor = HyperliquidMonitor(["0x123..."])
    assert not monitor._stop_event.is_set()
    
    monitor.stop()
    assert monitor._stop_event.is_set()
</file>

<file path="tests/test_types.py">
from datetime import datetime
import pytest
from hyperliquid_monitor.types import Trade

def test_trade_creation():
    trade = Trade(
        timestamp=datetime(2023, 11, 8, 15, 30),
        address="0x123...",
        coin="ETH",
        side="BUY",
        size=0.5,
        price=1850.5,
        trade_type="FILL"
    )
    
    assert trade.timestamp == datetime(2023, 11, 8, 15, 30)
    assert trade.address == "0x123..."
    assert trade.coin == "ETH"
    assert trade.side == "BUY"
    assert trade.size == 0.5
    assert trade.price == 1850.5
    assert trade.trade_type == "FILL"

def test_trade_optional_fields():
    trade = Trade(
        timestamp=datetime(2023, 11, 8, 15, 30),
        address="0x123...",
        coin="ETH",
        side="BUY",
        size=0.5,
        price=1850.5,
        trade_type="FILL",
        direction="Open Long",
        tx_hash="0x123...",
        fee=1.5,
        fee_token="USDC",
        start_position=-10.5,
        closed_pnl=100.25,
        order_id=12345
    )
    
    assert trade.direction == "Open Long"
    assert trade.tx_hash == "0x123..."
    assert trade.fee == 1.5
    assert trade.fee_token == "USDC"
    assert trade.start_position == -10.5
    assert trade.closed_pnl == 100.25
    assert trade.order_id == 12345

def test_trade_invalid_side():
    with pytest.raises(ValueError, match="Invalid side"):
        Trade(
            timestamp=datetime(2023, 11, 8, 15, 30),
            address="0x123...",
            coin="ETH",
            side="INVALID",  # Should raise ValueError
            size=0.5,
            price=1850.5,
            trade_type="FILL"
        )

def test_trade_invalid_trade_type():
    with pytest.raises(ValueError, match="Invalid trade_type"):
        Trade(
            timestamp=datetime(2023, 11, 8, 15, 30),
            address="0x123...",
            coin="ETH",
            side="BUY",
            size=0.5,
            price=1850.5,
            trade_type="INVALID"  # Should raise ValueError
        )
</file>

<file path=".gitignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Environment
.env
.venv
env/
venv/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Project specific
*.log
*.db
*.db.backup
</file>

<file path="LICENSE.md">
Copyright 2024 Yakitori

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</file>

<file path="pyproject.toml">
[tool.poetry]
name = "hyperliquid-monitor"
version = "0.1.2"
description = "A Hyperliquid trade monitor package"
authors = ["Yakitori"]
readme = "README.md"
license = "MIT"
homepage = "https://github.com/oni-giri/hyperliquid-monitor"
repository = "https://github.com/oni-giri/hyperliquid-monitor"
keywords = ["hyperliquid", "trading", "cryptocurrency", "monitor", "dex"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Office/Business :: Financial :: Investment",
]
packages = [{include = "hyperliquid_monitor", from = "src"}]

[tool.poetry.dependencies]
python = "^3.9"
hyperliquid-python-sdk = "^0.8.0"
python-dotenv = "^1.0.0"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.3"
pytest-mock = "^3.12.0"
pytest-asyncio = "^0.21.1"
pytest-cov = "^4.1.0"
freezegun = "^1.2.2"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=hyperliquid_monitor --cov-report=term-missing"
</file>

<file path="README.md">
![image](./assets/head-image.png)

# Hyperliquid Monitor

A Python package for monitoring trades and orders on Hyperliquid DEX in real-time. This package allows you to track specific addresses and receive notifications when trades are executed or orders are placed/cancelled.

## Features

- Real-time monitoring of trades and orders
- Support for multiple addresses
- Optional SQLite database storage
- Callback system for custom notifications
- Clean shutdown handling
- Proper trade type definitions using dataclasses

## Installation

### Using Poetry (recommended)

```bash
poetry add hyperliquid-monitor
```

### Using pip

```bash
pip install hyperliquid-monitor
```

## Quick Start

### Simple Console Notification

Here's a basic example that monitors an address and prints trades to the console:

```python
from hyperliquid_monitor import HyperliquidMonitor
from hyperliquid_monitor.types import Trade
from datetime import datetime

def print_trade(trade: Trade):
    """Print trade information to console with colors"""
    timestamp = trade.timestamp.strftime('%Y-%m-%d %H:%M:%S')
    
    # Color codes
    GREEN = '\033[92m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    RESET = '\033[0m'
    
    # Choose color based on trade type and side
    color = GREEN if trade.side == "BUY" else RED
    
    print(f"\n{BLUE}[{timestamp}]{RESET} New {trade.trade_type}:")
    print(f"Address: {trade.address}")
    print(f"Coin: {trade.coin}")
    print(f"{color}Side: {trade.side}{RESET}")
    print(f"Size: {trade.size}")
    print(f"Price: {trade.price}")
    
    if trade.trade_type == "FILL":
        print(f"Direction: {trade.direction}")
        if trade.closed_pnl:
            pnl_color = GREEN if trade.closed_pnl > 0 else RED
            print(f"PnL: {pnl_color}{trade.closed_pnl:.2f}{RESET}")
        print(f"Hash: {trade.tx_hash}")

def main():
    # List of addresses to monitor
    addresses = [
        "0x010461C14e146ac35Fe42271BDC1134EE31C703a"  # Example address
    ]

    # Create monitor with console notifications and optional database
    monitor = HyperliquidMonitor(
        addresses=addresses,
        db_path="trades.db",  # Optional: remove to disable database
        callback=print_trade
    )

    try:
        print("Starting monitor... Press Ctrl+C to exit")
        monitor.start()
    except KeyboardInterrupt:
        monitor.stop()

if __name__ == "__main__":
    main()
```

### Trade Object Structure

The `Trade` object contains the following information:

```python
@dataclass
class Trade:
    timestamp: datetime      # When the trade occurred
    address: str            # The address that made the trade
    coin: str              # The traded coin/token
    side: Literal["BUY", "SELL"]  # Trade side
    size: float            # Trade size
    price: float           # Trade price
    trade_type: Literal["FILL", "ORDER_PLACED", "ORDER_CANCELLED"]
    direction: Optional[str] = None  # e.g., "Open Long", "Close Short"
    tx_hash: Optional[str] = None    # Transaction hash for fills
    fee: Optional[float] = None      # Trading fee
    fee_token: Optional[str] = None  # Fee token (e.g., "USDC")
    start_position: Optional[float] = None  # Position size before trade
    closed_pnl: Optional[float] = None     # Realized PnL for closing trades
    order_id: Optional[int] = None         # Order ID for orders
```

## Database Storage

If you provide a `db_path`, trades will be stored in an SQLite database with two tables:

### Fills Table
- timestamp: When the trade occurred
- address: Trader's address
- coin: Traded asset
- side: BUY/SELL
- size: Trade size
- price: Trade price
- direction: Trade direction
- tx_hash: Transaction hash
- fee: Trading fee
- fee_token: Fee token
- start_position: Position before trade
- closed_pnl: Realized PnL

### Orders Table
- timestamp: When the order was placed/cancelled
- address: Trader's address
- coin: Asset
- action: placed/cancelled
- side: BUY/SELL
- size: Order size
- price: Order price
- order_id: Unique order ID

## Database Recording Modes

The monitor supports different modes of operation for recording trades:

### 1. Full Monitoring with Notifications
```python
# Records to database and sends notifications via callback
monitor = HyperliquidMonitor(
    addresses=addresses,
    db_path="trades.db",
    callback=print_trade
)
```

### 2. Silent Database Recording
```python
# Only records to database, no notifications
monitor = HyperliquidMonitor(
    addresses=addresses,
    db_path="trades.db",
    silent=True  # Suppresses all notifications and console output
)
```

### 3. Notification-Only Mode
```python
# Only sends notifications, no database recording
monitor = HyperliquidMonitor(
    addresses=addresses,
    callback=print_trade
)
```

The silent mode is particularly useful for:
- Background monitoring and data collection
- Reducing system resource usage
- Running multiple monitors concurrently
- Long-term trade data accumulation
- Server-side deployments where notifications aren't needed

Note: Silent mode requires a database path to be specified since it's meant for data recording.

## Development

### Setting up the Development Environment

1. Clone the repository:
```bash
git clone https://github.com/your-username/hyperliquid-monitor.git
cd hyperliquid-monitor
```

2. Install poetry if you haven't already:
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

3. Install dependencies:
```bash
poetry install
```

### Running Tests

The package includes a comprehensive test suite using pytest. To run the tests:

```bash
# Run all tests
poetry run pytest

# Run with coverage report
poetry run pytest --cov

# Run specific test file
poetry run pytest tests/test_monitor.py

# Run tests with output
poetry run pytest -v
```

### Test Structure

Tests are organized in the following structure:
```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ conftest.py          # Shared fixtures
‚îú‚îÄ‚îÄ test_monitor.py      # Monitor tests
‚îú‚îÄ‚îÄ test_database.py     # Database tests
‚îî‚îÄ‚îÄ test_types.py        # Type validation tests
```

Key test areas:
- Monitor functionality (subscriptions, event handling)
- Database operations (storage, retrieval)
- Type validation (trade object validation)
- Event processing (fills, orders)

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request. Make sure to:

1. Add tests for any new functionality
2. Update documentation as needed
3. Follow the existing code style
4. Run the test suite before submitting

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

Built on top of the official Hyperliquid Python SDK
</file>

</files>
</file>

<file path="Hyperliquid/repomix-output-wonjaechung-hyperliquid_whale_dashboard.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    scrape.yml
hyperliquid/
  utils/
    __init__.py
    constants.py
  __init__.py
app.py
requirements.txt
scrape_playwright.py
top30_wallets.csv
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/scrape.yml">
name: scrape-hyperliquid

permissions:
  contents: write   # Ïª§Î∞ã/Ìë∏Ïãú Í∂åÌïú

on:
  schedule:
    - cron: '*/5 * * * *'   # Îß§ 5Î∂ÑÎßàÎã§
  workflow_dispatch:       # ÏàòÎèô Ïã§ÌñâÎèÑ Í∞ÄÎä•

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install chromium

      - name: Run scraper
        run: |
          python scrape_playwright.py

      - name: Commit & Push CSV
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add top30_wallets.csv
          git diff --quiet && echo "No changes to commit" || git commit -m "chore: update top30_wallets.csv"
          git push
</file>

<file path="hyperliquid/utils/__init__.py">

</file>

<file path="hyperliquid/utils/constants.py">
# hyperliquid/utils/constants.py

MAINNET_API_URL = "https://api.hyperliquid.xyz"  # ‚Üê replace with the real endpoint
</file>

<file path="hyperliquid/__init__.py">

</file>

<file path="app.py">
# app.py
import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
from hyperliquid.utils import constants
from st_aggrid import AgGrid, GridOptionsBuilder, DataReturnMode, GridUpdateMode


# ‚îÄ‚îÄ Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CSV_PATH = "top30_wallets.csv"
BASE_URL = constants.MAINNET_API_URL


# ‚îÄ‚îÄ HTTP helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def info_http(payload: dict):
    r = requests.post(f"{BASE_URL}/info", json=payload)
    r.raise_for_status()
    return r.json()

def get_portfolio(wallet: str):
    return info_http({"type": "portfolio", "user": wallet})

def get_clearinghouse_state(wallet: str):
    return info_http({"type": "clearinghouseState", "user": wallet})


# ‚îÄ‚îÄ Load leaderboard with Unrealized PnL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data(ttl=600)
def load_leaderboard():
    df = pd.read_csv(CSV_PATH)
    df["Rank"] = df.index + 1
    unrealized = []
    for w in df["Wallet"]:
        try:
            stt = get_clearinghouse_state(w)
            up = sum(float(ap["position"].get("unrealizedPnl") or 0.0)
                     for ap in stt.get("assetPositions", []))
        except:
            up = 0.0
        unrealized.append(up)
    df["Unrealized PnL"] = unrealized
    return df[[
        "Rank","Wallet","Account Value","PNL",
        "ROI","Volume","Unrealized PnL"
    ]]


# ‚îÄ‚îÄ Top-10 summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄv
@st.cache_data(ttl=600)
def compute_top10_summary(wallets):
    periods = [("All-Time","allTime"),("24H","day"),
               ("7D","week"),("30D","month")]
    rows = []
    for label,key in periods:
        pnls,rois = [],[]
        for w in wallets:
            try:
                pf = get_portfolio(w)
                data = next(i[1] for i in pf if i[0]==key)
                hist = data.get("pnlHistory",[])
                delta = (float(hist[-1][1]) - float(hist[0][1])
                         if len(hist)>=2 else 0.0)
                pnls.append(delta)
                if label!="All-Time":
                    av = data.get("accountValueHistory",[])
                    if len(av)>=2:
                        start=float(av[0][1]); rois.append(delta/start if start else 0.0)
            except: pass
        avg_pnl = sum(pnls)/len(pnls) if pnls else 0.0
        if label=="All-Time":
            rows.append({"Period":label,"Avg P&L (USD)":avg_pnl,"Avg ROI (%)":"‚Äî"})
        else:
            avg_roi = sum(rois)/len(rois) if rois else 0.0
            rows.append({"Period":label,"Avg P&L (USD)":avg_pnl,"Avg ROI (%)":avg_roi*100})
    return pd.DataFrame(rows)

st.title("Hyperliquid Whale Dashboard")

# manage search_addr in session_state
if "search_addr" not in st.session_state:
    st.session_state.search_addr = ""
search_input = st.sidebar.text_input(
    "üîé Search Address (hex)",
    value=st.session_state.search_addr,
    key="search_addr"
).strip()

# load leaderboard
df_leader     = load_leaderboard()
top_n         = 10
wallets_top10 = df_leader["Wallet"].head(top_n).tolist()

#
# ‚îÄ‚îÄ Custom Report ÏÑπÏÖò (ÏßÅÏ†ë ÏûÖÎ†•) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#
st.sidebar.markdown("## üìã Custom Report")
raw_text = st.sidebar.text_area(
    "Enter wallet addresses (one per line or comma-separated):",
    height=100
).strip()

if st.sidebar.button("üñ®Ô∏è Generate Report"):
    # parse ÏûÖÎ†•
    custom_wallets = []
    if raw_text:
        custom_wallets = [
            w.strip()
            for part in raw_text.splitlines()
            for w in part.split(",")
            if w.strip()
        ]

    if not custom_wallets:
        st.sidebar.warning("ÌïòÎÇò Ïù¥ÏÉÅÏùò ÏßÄÍ∞ë Ï£ºÏÜåÎ•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
    else:
        # --- 1) Summary ---
        df_cust_summary = compute_top10_summary(custom_wallets)
        st.subheader(f"Custom Report: P&L Summary ({len(custom_wallets)} wallets)")
        st.table(df_cust_summary.style.format({
            "Avg P&L (USD)": "{:,.2f}",
            "Avg ROI (%)":   lambda x: f"{x:.2f}%" if isinstance(x,(int,float)) else x
        }))

        # --- 2) Aggregate Metrics ---
        unrealized_total = 0.0
        coin_counter     = Counter()
        coin_upnls       = defaultdict(float)
        coin_volumes     = defaultdict(float)
        coin_sentiment   = defaultdict(lambda: {"Long":0,"Short":0})

        for w in custom_wallets:
            try:
                state = get_clearinghouse_state(w)
                for ap in state.get("assetPositions", []):
                    p   = ap["position"]
                    amt = float(p.get("szi") or 0.0)
                    upnl= float(p.get("unrealizedPnl") or 0.0)
                    val = float(p.get("positionValue") or 0.0)
                    c   = p.get("coin")

                    unrealized_total += upnl
                    if c:
                        coin_counter[c]  += 1
                        coin_upnls[c]    += upnl
                        coin_volumes[c]  += val
                        side = "Long" if amt>0 else "Short"
                        coin_sentiment[c][side] += 1
            except:
                pass

        popular_coin  = coin_counter.most_common(1)[0][0] if coin_counter else "‚Äî"
        pop_long      = coin_sentiment[popular_coin]["Long"]
        pop_short     = coin_sentiment[popular_coin]["Short"]
        trending_coin = max(coin_volumes, key=coin_volumes.get) if coin_volumes else "‚Äî"
        top_coin, top_upnl     = max(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)
        worst_coin, worst_upnl = min(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)

        st.subheader("Custom Report: Aggregate Metrics")
        st.markdown(f"üí∞ **Unrealized PnL (USD):** ${unrealized_total:,.2f}")
        st.markdown(f"üêã **Popular Whale Position: {popular_coin}** ({pop_long} Long / {pop_short} Short)")
        st.markdown(f"üî• **Trending Coin (by Open Interest):** {trending_coin}")
        st.markdown(f"üèÜ **Top Unrealized PnL Coin:** {top_coin} (+${top_upnl:,.2f})")
        st.markdown(f"‚ö†Ô∏è **Worst Unrealized PnL Coin:** {worst_coin} (${worst_upnl:,.2f})")

        # Avg Entry/Liq table for custom report
        top_coins = [c for c,_ in coin_counter.most_common(10)]
        entries = defaultdict(list)
        liqs    = defaultdict(list)
        for w in custom_wallets:
            try:
                state = get_clearinghouse_state(w)
                for ap in state.get("assetPositions", []):
                    p = ap["position"]
                    c = p.get("coin")
                    if c in top_coins:
                        entries[c].append(float(p.get("entryPx") or 0.0))
                        liqs[c].append(float(p.get("liquidationPx") or 0.0))
            except:
                pass

        rows = []
        for c in top_coins:
            e = sum(entries[c])/len(entries[c]) if entries[c] else 0
            l = sum(liqs[c])/len(liqs[c]) if liqs[c] else 0
            rows.append({"Coin":c, "Avg Entry":e, "Avg Liq":l})
        df_eql = pd.DataFrame(rows)

        st.subheader("Custom Report: Avg Entry & Liq")
        st.table(df_eql.style.format({"Avg Entry":"{:,.2f}", "Avg Liq":"{:,.2f}"}))

        # show back button and stop further rendering
        st.button("‚Üê Back to Leaderboard", on_click=lambda: st.session_state.update({"search_addr": ""}))
        st.stop()
#
# ‚îÄ‚îÄ leaderboard vs individual wallet Î™®Îìú ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#
if search_input == "":
    # Top-10 P&L Summary
    st.markdown(
        "<h2 style='color:#0072C3; font-size:1rem;'>"
        f"Top {top_n} P&L Summary</h2>",
        unsafe_allow_html=True
    )
    df_summary = compute_top10_summary(wallets_top10)
    st.table(df_summary.style.format({
        "Avg P&L (USD)": "{:,.2f}",
        "Avg ROI (%)":   lambda x: f"{x:.2f}%" if isinstance(x,(int,float)) else x
    }))

    # Top-10 Aggregate Metrics (same logic)
    unrealized_total = 0.0
    coin_counter     = Counter()
    coin_upnls       = defaultdict(float)
    coin_volumes     = defaultdict(float)
    coin_sentiment   = defaultdict(lambda: {"Long":0,"Short":0})

    for w in wallets_top10:
        try:
            state = get_clearinghouse_state(w)
            for ap in state.get("assetPositions", []):
                p   = ap["position"]
                amt = float(p.get("szi") or 0.0)
                upnl= float(p.get("unrealizedPnl") or 0.0)
                val = float(p.get("positionValue") or 0.0)
                c   = p.get("coin")

                unrealized_total += upnl
                if c:
                    coin_counter[c]  += 1
                    coin_upnls[c]    += upnl
                    coin_volumes[c]  += val
                    side = "Long" if amt>0 else "Short"
                    coin_sentiment[c][side] += 1
        except:
            pass

    popular_coin  = coin_counter.most_common(1)[0][0] if coin_counter else "‚Äî"
    pop_long      = coin_sentiment[popular_coin]["Long"]
    pop_short     = coin_sentiment[popular_coin]["Short"]
    trending_coin = max(coin_volumes, key=coin_volumes.get) if coin_volumes else "‚Äî"
    top_coin, top_upnl     = max(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)
    worst_coin, worst_upnl = min(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)

    st.markdown(
        "<h2 style='color:#0072C3; font-size:1rem;'>"
        "Top-10 Aggregate Metrics</h2>",
        unsafe_allow_html=True
    )
    st.markdown(f"üí∞ **Unrealized PnL (USD):** ${unrealized_total:,.2f}")
    st.markdown(f"üêã **Popular Whale Position:** {popular_coin} ({pop_long} Long / {pop_short} Short)")
    st.markdown(f"üî• **Trending Coin (by Open Interest):** {trending_coin}")
    st.markdown(f"üèÜ **Top Unrealized PnL Coin:** {top_coin} (+${top_upnl:,.2f})")
    st.markdown(f"‚ö†Ô∏è **Worst Unrealized PnL Coin:** {worst_coin} (${worst_upnl:,.2f})")

    # Avg Entry/Liq table for top-10
    top_coins = [c for c,_ in coin_counter.most_common(10)]
    entries = defaultdict(list)
    liqs    = defaultdict(list)
    for w in wallets_top10:
        try:
            state = get_clearinghouse_state(w)
            for ap in state.get("assetPositions", []):
                p = ap["position"]; c = p.get("coin")
                if c in top_coins:
                    entries[c].append(float(p.get("entryPx") or 0.0))
                    liqs[c].append(float(p.get("liquidationPx") or 0.0))
        except:
            pass
    rows = []
    for c in top_coins:
        e = sum(entries[c])/len(entries[c]) if entries[c] else 0
        l = sum(liqs[c])/len(liqs[c]) if liqs[c] else 0
        rows.append({"Coin":c, "Avg Entry":e, "Avg Liq":l})
    df_eql = pd.DataFrame(rows)

    st.markdown(
        "<h2 style='color:#0072C3; font-size:1rem;'>"
        "Top-10 Avg Entry & Liq</h2>",
        unsafe_allow_html=True
    )
    st.table(df_eql.style.format({"Avg Entry":"{:,.2f}", "Avg Liq":"{:,.2f}"} ))

    st.markdown("---")
    st.markdown("**‚òëÔ∏è Ï≤¥ÌÅ¨Î∞ïÏä§Î•º ÌÅ¥Î¶≠ÌïòÏó¨ ÏßÄÍ∞ëÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.**")

    # Leaderboard Grid
    gb = GridOptionsBuilder.from_dataframe(df_leader)
    gb.configure_selection("multiple", use_checkbox=True)
    gb.configure_column("Rank", width=60)
    gb.configure_column("Wallet", width=250)
    grid_opts = gb.build()

    grid_resp = AgGrid(
        df_leader,
        gridOptions=grid_opts,
        update_mode=GridUpdateMode.SELECTION_CHANGED,
        data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
        fit_columns_on_grid_load=True
    )

    raw = grid_resp.get("selected_rows")
    if isinstance(raw, pd.DataFrame):
        wallets_to_show = raw.to_dict("records")
    elif isinstance(raw, list):
        wallets_to_show = raw
    else:
        wallets_to_show = []

else:
    # individual wallet mode
    def _reset_search():
        st.session_state.search_addr = ""
    st.button("‚Üê Back to Leaderboard", on_click=_reset_search)
    wallets_to_show = [{"Wallet": search_input}]

# ‚îÄ‚îÄ Wallet Details ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
for entry in wallets_to_show:
    wallet = entry["Wallet"]
    st.subheader(f"Address: {wallet}")

    # P&L Chart & Metrics
    try:
        pf       = get_portfolio(wallet)
        all_time = next(i[1] for i in pf if i[0] == "allTime")
        df_pnl   = pd.DataFrame(all_time["pnlHistory"], columns=["time","pnl"])
        df_pnl["pnl"]   = df_pnl["pnl"].astype(float)
        df_pnl["time"]  = pd.to_datetime(df_pnl["time"], unit="ms")

        total = df_pnl["pnl"].iloc[-1]
        now   = df_pnl["time"].iloc[-1]
        def delta(days):
            sl = df_pnl[df_pnl["time"] >= now - pd.Timedelta(days=days)]
            return (sl["pnl"].iloc[-1] - sl["pnl"].iloc[0]) if len(sl)>1 else 0.0

        c1,c2,c3,c4 = st.columns(4)
        c1.metric("Total P&L", f"{total:,.2f}")
        av_d = next(i[1] for i in pf if i[0]=="day")["accountValueHistory"]
        sd   = float(av_d[0][1]) if len(av_d)>=2 else None
        c2.metric("24H P&L", f"{delta(1):,.2f}", delta=f"{delta(1)/sd*100:.2f}%" if sd else None)
        av_w = next(i[1] for i in pf if i[0]=="week")["accountValueHistory"]
        sw   = float(av_w[0][1]) if len(av_w)>=2 else None
        c3.metric("7D P&L", f"{delta(7):,.2f}", delta=f"{delta(7)/sw*100:.2f}%" if sw else None)
        av_m = next(i[1] for i in pf if i[0]=="month")["accountValueHistory"]
        sm   = float(av_m[0][1]) if len(av_m)>=2 else None
        c4.metric("30D P&L", f"{delta(30):,.2f}", delta=f"{delta(30)/sm*100:.2f}%" if sm else None)

        fig, ax = plt.subplots(figsize=(8,3))
        ax.fill_between(df_pnl["time"], df_pnl["pnl"], step="mid", alpha=0.3)
        ax.plot(df_pnl["time"], df_pnl["pnl"], linewidth=2)
        ax.axhline(0, color="gray", linewidth=0.8)
        ax.set_xlabel("Time"); ax.set_ylabel("P&L (USD)")
        plt.xticks(rotation=30)
        st.pyplot(fig)
    except Exception as e:
        st.error(f"Error fetching P&L for {wallet}: {e}")
        continue

    # Positions + CSV export
    try:
        state = get_clearinghouse_state(wallet)
        pos   = []
        for ap in state.get("assetPositions", []):
            p   = ap["position"]
            val = float(p.get("positionValue") or 0.0)
            if val == 0: continue
            amt = float(p.get("szi") or 0.0)
            pnl = float(p.get("unrealizedPnl") or 0.0)
            pos.append({
                "Symbol":         p.get("coin",""),
                "Side":           "Long" if amt>0 else "Short",
                "Leverage":       f"{p['leverage']['value']}X {'Cross' if p['leverage']['type']=='cross' else 'Isolated'}",
                "Value (USD)":    val,
                "Amount":         amt,
                "Entry Price":    float(p.get("entryPx") or 0.0),
                "Unrealised PnL": pnl,
                "Funding Fee":    float((p.get("cumFunding") or {}).get("allTime") or 0.0),
                "Liq. Price":     float(p.get("liquidationPx") or 0.0),
            })
        df_pos = pd.DataFrame(pos)
        if not df_pos.empty:
            st.table(df_pos.style.format({
                "Value (USD)":    "{:,.2f}",
                "Amount":         "{:,.4f}",
                "Entry Price":    "{:,.2f}",
                "Unrealised PnL": "{:,.2f}",
                "Funding Fee":    "{:,.2f}",
                "Liq. Price":     "{:,.2f}"
            }))
            csv = df_pos.to_csv(index=False)
            st.download_button(
                label="üì• Export positions as CSV",
                data=csv,
                file_name=f"{wallet}_positions.csv",
                mime="text/csv"
            )
        else:
            st.info("No active positions.")
    except Exception as e:
        st.error(f"Error fetching positions for {wallet}: {e}")

    st.markdown("---")
</file>

<file path="requirements.txt">
streamlit
pandas
matplotlib
selenium
webdriver-manager
streamlit-aggrid
openai
streamlit-chat
playwright==1.43.0
</file>

<file path="scrape_playwright.py">
# scrape_playwright.py

import asyncio
import pandas as pd
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

async def main():
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-dev-shm-usage"]
        )
        page = await browser.new_page()
        await page.goto("https://app.hyperliquid.xyz/leaderboard", wait_until="networkidle")

        # All-time Î≥¥Í∏∞Î°ú Ï†ÑÌôò
        await page.click("div.variant_black", timeout=30000)
        await page.click("text=All-time", timeout=30000)
        await page.wait_for_selector("table > tbody > tr", timeout=60000)

        # Í∞ÄÏÉÅÌôîÎêú ÌÖåÏù¥Î∏îÏù¥Îùº ÏïÑÎûòÏ≤òÎüº ÌÇ§Î≥¥Îìú Ïä§ÌÅ¨Î°§ÏùÑ Ï∂©Î∂ÑÌûà ÎÇ¥Î†§Ïïº 30Í∞ú ÌñâÏù¥ Î°úÎìúÎê©ÎãàÎã§
        for _ in range(20):
            await page.keyboard.press("PageDown")
            await page.wait_for_timeout(300)

        records = []
        rows_locator = page.locator("table > tbody > tr")
        count = await rows_locator.count()
        total = min(count, 30)
        print(f"üîç Î°úÎìúÎêú Î°úÏö∞: {count}Í∞ú, Í∞ÄÏ†∏Ïò¨ Í∞úÏàò: {total}Í∞ú")

        for i in range(total):
            row = rows_locator.nth(i)
            cols = row.locator("td")
            ccount = await cols.count()

            trader = await cols.nth(1).inner_text() if ccount > 1 else "N/A"
            acct   = await cols.nth(2).inner_text() if ccount > 2 else "N/A"
            pnl    = await cols.nth(3).inner_text() if ccount > 3 else "N/A"
            roi    = await cols.nth(4).inner_text() if ccount > 4 else "N/A"
            vol    = await cols.nth(5).inner_text() if ccount > 5 else "N/A"

            # ÏßÄÍ∞ëÏ£ºÏÜåÎäî ÌÅ¥Î¶≠Ìï¥ÏÑú URL ÎßàÏßÄÎßâ segment Î°ú Ï∂îÏ∂ú
            try:
                await cols.nth(1).click()
                await page.wait_for_load_state("networkidle", timeout=30000)
                wallet = page.url.split("/")[-1]
            except PlaywrightTimeoutError:
                wallet = "N/A"

            await page.go_back(wait_until="networkidle", timeout=30000)
            await page.wait_for_selector("table > tbody > tr", timeout=30000)

            records.append({
                "Trader": trader,
                "Wallet": wallet,
                "Account Value": acct,
                "PNL": pnl,
                "ROI": roi,
                "Volume": vol
            })
            print(f"‚úÖ Row {i+1}: {trader} / {wallet}")

        df = pd.DataFrame(records)
        df.to_csv("top30_wallets.csv", index=False)
        print("‚úÖ Saved top30_wallets.csv")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="top30_wallets.csv">
Trader,Wallet,Account Value,PNL,ROI,Volume
0x77c3...5e45,0x77c3ea550d2da44b120e55071f57a108f8dd5e45,"$383,503,173.15","$191,531,322.95",93.47%,$114.89
thank you jefef,0xfae95f601f3a25ace60d19dbb929f2a5c57e3571,"$129,592,349.99","$132,830,483.88","3,089.41%","$4,655,922.47"
0x9794...333b,0x9794bbbc222b6b93c1417d01aa1ff06d42e5333b,"$125,027,291.46","$106,028,775.17",558.09%,"$26,418,280.98"
0xecb6...2b00,0xecb63caa47c7c4e77f60f1ce858cf28dc2b82b00,"$111,002,630.87","$94,106,370.44",93.23%,"$116,616,733,919.42"
0x20c2...44f5,0x20c2d95a3dfdca9e9ad12794d5fa6fad99da44f5,"$39,946,685.11","$84,218,333.39",81.37%,"$834,677,709.15"
0x5d83...4fb6,0x5d83bb3313240cab65e2e9200d3aaf3520474fb6,"$82,641,759.06","$79,803,886.88","2,812.10%",$0.00
jefe,0x51156f7002c4f74f4956c9e0f2b7bfb6e9dbfac2,"$83,778,381.40","$74,528,986.52",618.38%,"$11,881,334.74"
0x0d44...8c0b,0x0d446c3372a9ba9cddef0eef7a1afab6dc0e8c0b,"$70,355,294.60","$70,330,903.07","117,218.17%",$0.00
0x716b...1d95,0x716bd8d3337972db99995dda5c4b34d954a61d95,"$143,574,644.86","$65,672,743.06",53.27%,$0.00
0xbde2...60b1,0xbde2ddc49a2e6827300faa6afc93d572114a60b1,"$64,504,309.46","$62,253,837.66","2,766.26%","$2,045.92"
</file>

</files>
</file>

<file path="Hyperliquid/repomix-output-wonjaechung-hyperliquid_whale_tracker.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
README.md
whale_tracker.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="README.md">
# hyperliquid_whale_tracker
</file>

<file path="whale_tracker.py">
import asyncio, json, sys, os, csv
from datetime import datetime
from websockets import connect
from hyperliquid.info import Info
from hyperliquid.utils.constants import MAINNET_API_URL


### WS_URL = " " 
THRESHOLD = 10000  # Ï†ÄÏû•Ìï† ÏµúÏÜå Í±∞Îûò Í∏àÏï° (USD)
COINS = ["BTC", "ETH", "SOL"]
CSV_FILE = "whale_logs.csv"

info = Info(MAINNET_API_URL, skip_ws=True)


def safe_float(val):
    try:
        return float(val)
    except (TypeError, ValueError):
        return 0.0


def append_to_csv(row):
    file_exists = os.path.isfile(CSV_FILE)
    with open(CSV_FILE, mode='a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow([
                "Address", "Symbol", "Side",
                "Position (USD)", "Position (Coin)",
                "Entry Price", "Liq. Price", "Margin",
                "Unrealised PnL", "Leverage", "Lev. Type",
                "Trade Price", "Timestamp"
            ])
        writer.writerow(row)


def print_header():
    header = (
        f"{'Address':42s} | {'Symbol':6s} | {'Side':5s} | "
        f"{'Position':>12s} | {'Coin':>10s} | {'Entry Px':>10s} | "
        f"{'Liq. Px':>10s} | {'Margin':>10s} | {'PnL':>10s} | "
        f"{'Lev':>4s} | {'Type':>6s} | {'Trade Px':>10s} | Time"
    )
    print(header)
    print("-" * len(header))

async def whale_tracker():
    async with connect(WS_URL) as ws:
    
        for coin in COINS:
            await ws.send(json.dumps({
                "method": "subscribe",
                "subscription": {"type": "trades", "coin": coin}
            }))
        print(f"üîî Subscribed to trades for: {COINS}\n")
        print_header()


        async for raw in ws:
            try:
                msg = json.loads(raw)
                if msg.get("channel") != "trades":
                    continue

                for t in msg["data"]:
                    price = safe_float(t["px"])
                    size = safe_float(t["sz"])
                    value = price * size
                    symbol = t["coin"]
                    side = t["side"]
                    ts = datetime.fromtimestamp(t["time"] / 1000).strftime("%Y-%m-%d %H:%M")

                    print(f"‚ñ∂ TRADE: {symbol} {side} {size:.4f}@{price:.2f} = ${value:,.2f}")

                    if value < THRESHOLD:
                        continue

                    for user_addr in t.get("users", []):
                        print(f"‚Ä¢ Fetching state for {user_addr} ‚Ä¶", file=sys.stderr)
                        try:
                            us = info.user_state(user_addr)
                            positions = us.get("assetPositions", [])
                        except Exception as e:
                            print(f"‚ùå Error fetching state: {e}", file=sys.stderr)
                            continue

                        for ap in positions:
                            pos = ap.get("position", {})
                            if pos.get("coin") != symbol:
                                continue

        
                            position_usd = safe_float(pos.get("positionValue"))
                            position_coin = safe_float(pos.get("szi"))
                            entry_price = safe_float(pos.get("entryPx"))
                            liq_price = safe_float(pos.get("liquidationPx"))
                            margin_used = safe_float(pos.get("marginUsed"))
                            unreal_pnl = safe_float(pos.get("unrealizedPnl"))
                            leverage = safe_float(pos.get("leverage", {}).get("value"))
                            lev_type = pos.get("leverage", {}).get("type", "unknown")

                        
                            print(
                                f"{user_addr:42s} | {symbol:<6s} | {side:<5s} | "
                                f"{position_usd:12,.2f} | {position_coin:10,.4f} | {entry_price:10,.2f} | "
                                f"{liq_price:10,.2f} | {margin_used:10,.2f} | {unreal_pnl:10,.2f} | "
                                f"{leverage:4.0f} | {lev_type:<6s} | {price:10,.2f} | {ts}"
                            )

                            append_to_csv([
                                user_addr, symbol, side,
                                position_usd, position_coin,
                                entry_price, liq_price, margin_used,
                                unreal_pnl, leverage, lev_type,
                                price, ts
                            ])

            except Exception as e:
                print(f"‚ùå Error while processing trade: {e}", file=sys.stderr)

if __name__ == "__main__":
    asyncio.run(whale_tracker())
</file>

</files>
</file>

<file path="Hyperliquid/repomix-output-wonjaechung-onchain101.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
en/
  ch00/
    ch00-become-chain-analyst.md
  ch01/
    ch01-dune-platform-introduction.md
  ch02/
    ch02-quickstart.md
  ch03/
    ch03-build-first-dashboard.md
  ch04/
    ch04-understanding-tables.md
  ch05/
    ch05-sql-basics-part1.md
  ch06/
    ch06-sql-basics-part2.md
  ch07/
    ch07-practice-build-lens-dashboard-part1.md
  ch08/
    ch08-practice-build-lens-dashboard-part2.md
  ch09/
    ch09-useful-queries-part1.md
  ch10/
    ch10-useful-queries-part2.md
  ch11/
    ch11-useful-queries-part3.md
  ch12/
    ch12-nft-analysis.md
  ch13/
    ch13-lending-analysis.md
  ch14/
    ch14-defi-analysis.md
  ch15/
    ch15-dunesql-introduction.md
  ch16/
    ch16-blockchain-analysis-polygon.md
  ch17/
    ch17-mev-analysis-uniswap.md
  ch18/
    ch18-uniswap-multichain-analysis.md
  ch19/
    ch19-useful-metrics.md
  ch20/
    ch20-network-analysis.md
  ch21/
    ch21-btc-analysis.md
  ch22/
    ch22-how-to-build-spellbook.md
  ch23/
    ch23-how-to-build-app-use-dune-api.md
  eisvogel.tex
  pandock-build-pdf.sh
  readme.md
  SUMMARY.md
zh/
  ch01/
    readme.md
  ch02/
    readme.md
  ch03/
    readme.md
  ch04/
    readme.md
  ch05/
    readme.md
  ch06/
    readme.md
  ch07/
    readme.md
  ch08/
    readme.md
  ch09/
    readme.md
  ch10/
    ch09-useful-queries-part1.md
  ch11/
    ch10-useful-queries-part2.md
  ch12/
    ch11-useful-queries-part3.md
  ch13/
    ch12-nft-analysis.md
  ch14/
    ch13-lending-analysis.md
  ch15/
    ch14-defi-analysis.md
  ch16/
    ch15-dunesql-introduction.md
  ch17/
    ch16-blockchain-analysis-polygon.md
  ch18/
    ch17-mev-analysis-uniswap.md
  ch19/
    ch18-uniswap-multichain-analysis.md
  ch20/
    ch19-useful-metrics.md
  ch21/
    ch20-network-analysis.md
  ch22/
    ch21-btc-analysis.md
  ch23/
    ch22-how-to-build-spellbook.md
  ch24/
    ch23-how-to-build-app-use-dune-api.md
  readme.md
  SUMMARY.md
.gitignore
LICENSE
README.md
SUMMARY.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="en/ch00/ch00-become-chain-analyst.md">
---
# title: ""
# author: []
# date: ""
# subject: "Markdown"
# keywords: [Markdown, Example]
# subtitle: "Aesculeae domus vincemur et Veneris adsuetus lapsum"
lang: "en"
titlepage: true,
titlepage-background: "./assets/bookcover-en.pdf"
...

# 00 Becoming an Onchain Data Analyst #

**TLDR**

- The richness of Onchain data stems from the maturity of blockchain technology and the innovation of projects
- Mastering the perspective of Onchain data helps to reduce information asymmetry and adds an extra layer of protection when navigating the dark forest
- Onchain data truly reflects the flow of value, so the insights gained from analysis are more valuable
- Data analysis provides a quantifiable perspective to support decision-making; analysis is a process, not an end
- Good data analysis comes from data thinking, the ability to abstract things, and requires deepening industry understanding

## What is Onchain Data
Most people, when first introduced to blockchain, get this concept: blockchain is a public, tamper-proof ledger and all transfers as well as transaction records are transparent and trustworthy. However, this is not the only function of blockchain. It is just the initial point of departure from the "peer-to-peer electronic cash system" - that is, the "ledger". With the development of smart contracts, blockchain is actually becoming a large database. The following diagram compares the architecture of traditional web2 and web3 applications: smart contracts replace the backend and blockchain also takes on some of the functions of the database. More and more Onchain projects are emerging and our interactions Onchain are becoming more frequent, such as how much liquidity we added in DeFi protocols, which NFTs we minted, and even which social accounts we follow can be recorded Onchain. All of our interactions with blockchain will be recorded in this database and these records will belong to Onchain data.

![](img/ch00_01.png)

**Onchain data is roughly divided into three categories:**

1. Transaction data.
Such as sending and receiving addresses, transfer amount, address balance, etc.

1. Block data.
For example, timestamps, miner fees, miner rewards, etc.

1. Smart contract code.
That is, the business logic coded on the blockchain.

Onchain data analysis is to extract the desired information from these three types of data for interpretation. 
From the perspective of the data stack, blockchain data products can be divided into data sources, data development tools, and data apps.

![](img/ch00_02.jpg)

Flexible use of various data products will provide us with a new perspective in the crypto world.

Although we always say that Onchain data is public and transparent, it is difficult for us to directly read this data, because a simple swap transaction Onchain may look like this:

![](img/ch00_03.png)

We can see some raw Onchain data in the blockchain browser, but if my question is how much is the UniswapV3 trading volume today, this does not solve my problem!

![](img/ch00_04.png)

The original Onchain data cannot give us the answer, so we need to go through a series of data ingestion processes such as indexing, processing, storage and then aggregate the corresponding data according to the question raised to find an answer.

![](img/ch00_data-process.png)

To start from scratch, we may need to set up our own nodes to receive blockchain data 
and then process it, but this is obviously very time-consuming and laborious. 
Fortunately, there are many data platforms such as Dune, Flipside, Footprint, which after processing, take the original Onchain data obtained by indexing and store it in the data warehouse managed and updated by the respective platform. In other words, the entire blockchain data is made into many relational data tables by these platforms. What we need to do is to select some data we want from the table to build our analysis data. Furthermore, data products such as Nansen, Messari, and DeBank not only organize the data, but also package it according to the needs of the user, convenient for direct use.

|Category | Application Example|
|--------|:---------------:|
|Data Application | Nansen, Messari, DeBank..|
|Data Platform |Dune, FLipside, Footprint.. |
|Data Node | Infura, Quick Node..|

## The Importance of Onchain Data
With the prosperity of the Onchain ecosystem, rich interactive behaviors have brought a huge amount of data. 
This Onchain data corresponds to the flow of value Onchain and in turn the insights derived from the analysis become extremely valuable. Through transparent and truthful Onchain data, we can infer the psychological state and expectations of traders, and even the market as a whole, to help us make more advantageous decisions. It can also provide a beacon of light for us in the dark forest, illuminating the way forward to protect ourselves.

Take the familiar DeFi protocol liquidity mining as an example: you add liquidity to earn rewards, the pool increases depth, users enjoy lower slippage, everyone has a bright future, and you securely lock your money in the contract. One day, the black swan quietly arrives, smart money with insider information immediately retreats, and you are just an ordinary investor; by the time you see the negative news and think about withdrawing, the rewards in your hand are almost worthless, and the severe impermanent loss makes it hard for you to break even.

![](img/ch00_scam.png)

But if you have an Onchain data perspective, you might find: the protocol's TVL suddenly drops and the token's dumping volume on Uniswap surges. In other words, smart people get the news or find something wrong, the liquidity in the pool is getting worse and money is running away, and everyone is bearish on the token and selling like crazy - should I exit now?

Of course, this is just an abstract and simple example, but what I want to convey to you is: ordinary investors in the crypto dark forest are always at a disadvantage in terms of information asymmetry. But Onchain data is transparent and truthful. Why is everyone so obsessed with tracking Nansen's Smart Money? Because people with insider information won't tell you the news, but the information will be reflected in Onchain behavior and recorded truthfully. All we have to do is carefully observe this data world, through capturing Onchain details, to some extent make up for the information gap.

After DeFi summer, we started to care about the TVL of the protocol; Axie exploded, we studied the daily increase in users; NFT rose, we studied the mint number; Ethereum's Gas soared, we observed which project was so hot. Did you notice? Our increasing understanding and sensitivity to Onchain data actually comes from the prosperous development of Onchain activities In other words, the importance of Onchain data comes from the maturity of blockchain technology and the boom of applications. More and more Onchain projects give us enough rich interaction space, at the same time, with the maturity and wide application of SBT and OAT. Everything Onchain becomes possible, which means that the future data will be enough to support every user's full Onchain portrait. By then, we can tell better stories about DID, SocialFi.

## Who Will Do Onchain Data Analysis
For most users, mature data products are enough, 
and a good effect can be achieved by flexibly combining multiple data tools. 
For example, using Nansen to help users track the real-time movements of whales; 
using Token Terminal to view the income of various protocols; 
NFT data monitoring platforms are even more varied.
These "finished" data products, while low-threshold and easy to use, 
also have a bottleneck that cannot meet high customization requirements.

![](img/ch00_07.jpg)

For example, you discover through https://ultrasound.money/ 
that the gas consumption on Ethereum suddenly rises, 
driven by this XEN that you've never heard of. 
You keenly realize that this could be an early opportunity! 
Through a Twitter search, you learn that XEN uses a PoP (Proof of Participation) mining mechanism. 
Participants in XEN mining own all the XEN tokens they mine. 
As the number of participants increases, the difficulty of mining increases and the supply decreases. You want to understand the participation situation of everyone,  since just relying on gas consumption is not enough; you also want to know the number of participants, trends, and how long do participants choose to lock. At the same time, you also find that it seems to have no sybil protection. Pay a gas fee to participate - how many scientists are rushing in? Do I still have any profits? When you analyze this, you urgently need data to support your "rush or not" decision; but because it's early, there's no analysis of it in the data app and the app is also unlikely to monitor and analyze every protocol. This is why, despite the existence of many data products, we still need to be able to write some data analysis ourselves: existing products are difficult to meet customized needs.


![](img/ch00_xen.png)

Through my own data analysis, https://dune.com/sixdegree/xen-crypto-overview, I found out that most people choose short-term pledges, and nearly 70% are new wallets, indicating that they have been exploited by everyone. So I understand that the short-term selling pressure will be very large; if I choose to participate, I will pick the shortest pledge time and sell as soon as possible to see who runs faster. At this point, you have completed the entire process of Onchain data analysis: discover the project, study the project mechanism, abstract the standard for evaluating the project, and finally - perform data processing, visualization, and decision support.






## How to Do Onchain Data Analysis
Although data analysis platforms like Dune have done a lot of sorting work for us, we just need to use SQL-like syntax to extract the parts we need from the data table for construction. Most people's learning path I believe is to rush to "3 Days to Master SQL"; after getting it down, they start to feel lost again and still don't know how to find the thread in the ball of wool. Why is this? The most important thing to learn in data analysis is to cultivate data thinking, and proficiency in programming languages is secondary.

Data analysis provides a quantifiable perspective to ultimately support decision-making - analysis is a process, not an end. The simple steps are to clarify three questions and build data thinking:

**1. What is my purpose?**

Is it to determine whether a coin is a good time to buy now? 
Decide whether to add liquidity to AAVE to earn income? 
Or want to know if it's too late to enter Stepn now?

**2. What is my strategy?**

The strategy for buying coins is to follow Smart money, buy what they buy, enter when they enter, 
exit when they exit; observe if the protocol is operating well, the deposit rate is satisfactory, 
then put the temporarily immobile coins in to earn interest; Stepn is hot recently, 
if the momentum is still up, then I will participate in it.

**3. What data do I need to help me make decisions?**

monitor the holding movements of Smart money addresses and even consider the trading volume and holding distribution of tokens; check the protocol's TVL, outstanding debt amount, capital utilization rate, APR, etc.; consider daily new user numbers, growth trends, daily active user numbers, transaction numbers, player inflow/outflow situation, and the NFT market item sales situation.

- **Three Question before doing data analysis**:
  1. What is my purpose?
  2. What is my strategy?
  3. What data do I need to help me make decisions?


The difficulty of these three questions increases gradually. The first two are easier to answer, but it is difficult to think clearly about the third question, which requires a lot of learning and understanding. This is also the small threshold that distinguishes the level of data analysts. A good analyst should have the following three characteristics:

**1. Understanding and recognition of the track or protocol**

That is, what track is being analyzed? What is the operating mechanism of this project? 
What data will it generate and what does each represent?

**2. The ability to abstract things**

Turn a vague concept into a quantifiable indicator, i.e.

>"Is this DEX protocol good" => "Liquidity" + "Trading Volume" + "Active User Volume" + "Capital Utilization Rate" + "Income Generated by the Protocol"

Then go back to the previous point and find the corresponding data through your understanding of the protocol.

**3. The ability to handle data**

This includes getting data (where does the Onchain data come from), 
processing data (how to find the desired and filter out the irrelevant), 
and data visualization capabilities.

![](img/ch00_support.png)

In general, data analysis is just a tool to support research, so don't analyze for the sake of analysis. This process is first out of your desire to research a certain project, concept, or track, then learn and understand the operating mechanism of the project, abstract the quantitative analysis of the qualitative concept, and finally gather data and visualize.

The most important thing in data analysis is always data thinking. 
As for the last step of doing it yourself, it's just a matter of proficiency, which can be divided into two parts:

- Understanding of blockchain data structure. For example, in EVM chains, 
  only EOA accounts can initiate transactions, but smart contracts can transfer ETH when called. 
  These internal calls are recorded in the `traces` table, 
  so when querying the `transactions` table will miss internal call transactions.
- Mastery of languages such as Python, SQL. Mastering the basic database language, 
  whether it's getting data yourself or using a data platform, can be quite handy.

## Conclusion

There are many online resources or tutorials about Onchain data analysis, 
but they are scattered and of varying quality. Web3 is an open university, 
but it's quite painful to spend a lot of energy looking for suitable textbooks.

Therefore, the Sixdegree team will launch a series of tutorials on "**Mastering Onchain Analytics**". Application-oriented, these will be combined with blockchain data structure and SQL syntax to provide everyone with a set of introductory textbooks to help more people master Onchain data analysis skills and maximize the use of blockchain data characteristics, and in turn to a certain extent eliminate information asymmetry. Build more in the bear market, becoming an Onchain data analyst starts here!

## About Us

SixdegreeLab is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)

## Reference
1. [The Capital Efficiency Era of DeFi](https://blog.hashflow.com/the-capital-efficiency-era-of-defi-d8b3427feae4)
2. [Using Onchain Data for Policy Research: Part 1](https://policy.paradigm.xyz/writing/using-Onchain-data-for-policy-research-part-1)
3. [IOSG: Analysis of the Current Situation and Prospects of Onchain Data Analysis Platform](https://foresightnews.pro/article/detail/8473)
4. [An Introduction to ¬´Onchain¬ª Analysis](https://www.blockstar.ch/post/an-introduction-to-Onchain-analysis)
5. [The Architecture of a Web 3.0 application](https://www.preethikasireddy.com/post/the-architecture-of-a-web-3-0-application)
6. [Sixdegree Dune Dashborads](https://dune.com/sixdegree)
</file>

<file path="en/ch01/ch01-dune-platform-introduction.md">
# 01 Introduction to the Dune Platform #
As mentioned earlier, from the perspective of the data stack, 
blockchain data products can be divided into three categories: 
`data sources`, `data development tools`, and `data apps`. 
Directly accessing data sources is costly and more difficult, 
while data apps are fixed. If we want to analyze data, 
we need a platform that does not require a large amount of development work 
and can access various data. Among these data development tools, 
the most convenient is the Dune platform.

[Dune](https://dune.com/) is an Onchain data analysis platform. 
Users can write SQL statements on the platform, filter out the data they need 
from the blockchain database parsed by Dune, and generate corresponding charts 
to form a dashboard.

All query examples and related queriesn in this tutorial - except for complete data dashboards and third-party account queries - have been tested and passed using the Dune SQL query engine. Dune has announced that it will fully transition to the Dune SQL engine within 2023, so that everyone can directly learn the syntax of Dune SQL.

## Webpage Introduction

After registering on the Dune platform, the main interface of the platform is as follows,
with specific functions:

- **Discover**: show various trends on the platform
  - Dashboard: displays the most followed dashboards. 
    On this page, you can search for keywords of interest in the search box 
    in the upper left corner/right side. This is the most important part.
    You can click on a dashboard to view other people's dashboards.
  - **Queries**: displays the most followed queries. On this page, 
    you can search for keywords of interest in the search box in the 
    upper left corner/right side.
  - Wizards: ranking of users with the highest collection volume on the platform.
  - Teams: ranking of teams with the highest collection volume on the platform.
- **Favorites**:
  - Dashboard: your favorite dashboards, which can be searched in the search box 
    on the right.
  - Queries: your favorite queries, which can be searched in the search box on the right.
- **My Creations**:
  - Dashboard: dashboards you created, which can be searched in the search box 
    on the right. If you have a team, the dashboard can be among different teams.
  - Queries: queries you created, which can be searched in the search box on the right.
  - Contracts: contracts you submitted for parsing, which can be searched 
    in the search box on the right.
- **New Query**: create a new query.
- **Others**:
  - Docs: link to the help documentation.
  - Discord: link to the community discussion group.

![](img/ch01_main-page.png)

## Core Features

### Query

After clicking on `New Query`, you will enter a new interface, 
which consists of three main parts:

- Database Directory: On the left, there is a `data search box` and a `data list`.
  Expanding the data list will reveal each specific table. 
  (Note: The version displayed when you first enter is v1, which is deprecated. 
  Please select `Dune Engine v2(SparkSQL)` from the dropdown.)
  - Raw: Contains the original data tables of various blockchains, 
    mainly including block information (blocks), transaction information (transactions),
    event log information (logs), and traces tables, etc. 
    The currently supported chains include: Ethereum, Polygon, Arbitrum, Solana, Optimism,
    Gnosis Chain, Avalanche.
  - Decoded projects: Directly parsed tables of various projects/contracts. 
    The parsed tables will be clearer and easier to understand. 
    If you are analyzing specific projects, it would be more suitable to use the tables 
    here.
  - Spells: Comprehensive data tables extracted from raw and Decoded projects, 
    such as Dex, NFT, ERC20, etc.
  - Community: Data tables contributed by community users.

- Code Editor: Located in the upper right black area, 
  it is used for writing your own SQL statements. 
  After writing, you can click `Run` in the lower right corner to execute.
- Results & Chart Visualization: Located in the lower right, 
  the query results will be displayed in `Query results`, 
  and you can sequentially create new sub-visualization pages afterwards.

![](img/ch01_query-page.png)

Queries on the platform can be forked, allowing you to copy someone else's query 
to your own account for modification and editing.

**Spellbook**

The spellbook is a very important data table on the Dune platform. It is a series 
of processed data tables contributed by community users. You can contribute your 
own defined data tables on the GitHub 
page [duneanalytics/spellbook](https://github.com/duneanalytics/spellbook). 
The Dune platform will generate corresponding data in the background based on 
this definition. In the frontend page shown above, you can directly use these 
predefined data tables. The definitions and field meanings of these data tables 
can be viewed here: [https://spellbook-docs.dune.com/#!/overview](https://spellbook-docs.dune.com/#!/overview)

At present, hundreds of various tables have been contributed by community users 
in the spellbook, such as nft.trades, dex.trades, tokens.erc20, etc.

![](img/ch01_spellbook.png)

**Parameters**

In the query, you can also set a variable input parameter to change the query conditions,
such as setting different user addresses or setting different time ranges. 
The parameter setting is embedded in the query statement in the form of`'{{parameter name}}'`.

![](img/ch01_query-params.png)

### Visualization

In chart visualization, the Dune platform provides scatter plots, bar charts, 
line charts, pie charts, area charts, counters, and two-dimensional data tables. 
After executing the query and getting the results, you can choose `New visualization` 
to create a new visualization chart. In the chart, you can choose the data fields 
you want to display, and you can immediately get the corresponding visualization chart. 
The chart supports displaying data in multiple dimensions. 
The area below the chart is where you set the chart style, including name, axis format,
color, etc.

![](img/ch01_visualization.png)

### Dashboard

The individual chart visualizations from the previous section can be 
flexibly combined in the dashboard to form an aggregated data indicator board 
with explanations, allowing for a more comprehensive perspective. 
In `Discover`, find `New Dashboard` to create a new dashboard. 
In the dashboard, you can add all the charts generated from queries, 
and you can add text information in markdown format. 
Each visualization widget can be dragged and resized.

![](img/ch01_dashboard.png)

### Dune Related Resources
- Official Resources
  - [Dune Official Documentation](https://dune.com/docs/)
  - [Discord](https://discord.com/invite/ErrzwBz)
  - [Youtube](https://www.youtube.com/channel/UCPrm9d2hLd_YxSExH7oRyAg)
  - [Github Spellbook](https://github.com/duneanalytics/spellbook)
- Community Tutorials
  - [Dune Data Dashboard Zero-Basic Minimalist Entry Guide](https://twitter.com/gm365/status/1525013340459716608)
  - [Dune Entry Guide - Make an NFT Dashboard with Pooly as an Example](https://mirror.xyz/0xa741296A1E9DDc3D6Cf431B73C6225cFb5F6693a/iVzr5bGcGKKCzuvl902P05xo7fxc2qWfqfIHwmCXDI4)
  - [Build Your Dune V1 Analytics Dashboard from 0 to 1 (Basic)](https://mirror.xyz/0xbi.eth/6cbedGOx0GwZdvuxHeyTAgn333jaT34y-2qryvh8Fio)
  - [Build Your Dune V1 Analytics Dashboard from 0 to 1 (Practical)](https://mirror.xyz/0xbi.eth/603BIaKXn7s2_7A84oayY_Fn5XUPh6zDsv2OlQTdzCg)
  - [Build Your Dune V1 Analytics Dashboard from 0 to 1 (Common Table Structures)](https://mirror.xyz/0xbi.eth/uSr336PzXtqMuE_LPBewbJ1CHN2oUs40-TDET2rnkqU)


## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch02/ch02-quickstart.md">
# 02 Quick Start

## Introduction

Our tutorial is heavily focused on practical application, written in conjunction with the scenarios and needs of daily Onchain data analysis. This article will explain the SQL basics you need to understand before starting to create data dashboards. This tutorial is beginner-friendly, primarily aimed at novice users who wish to learn data analysis. We assume that you have no prior experience in writing SQL queries. Users who have SQL experience but are not familiar with the Dune platform can also quickly browse this tutorial. This tutorial mainly includes an introduction to the Dune platform, a quick start to SQL queries, and more. In the next tutorial, we will write queries together, create visual charts, and use these charts to create data dashboards. We believe that as long as you have confidence and follow our tutorial to practice, you can also create high-quality data dashboards, taking the first step towards becoming an Onchain data analyst.

## Introduction to the Dune Platform

[Dune](https://dune.com/) is a powerful blockchain data analysis platform that provides raw blockchain data 
and parsed data in the form of an SQL database. By using SQL queries, we can quickly search 
and extract various blockchain information from Dune's database, then convert it into intuitive visual charts to gain insights.
The data dashboard on Dune is composed of various widgets. These widgets can be visual charts or text boxes generated from query results, and you can also embed images, links, etc. in the text box. 
The query is the main data source of the Dune data panel. We write SQL statements, execute queries, generate visual charts on the result set, and then add the charts to the corresponding data dashboard.

The general process of using Dune to process data can be summarized as: Write SQL queries to display data -> Visualize query results -> Assemble visual charts in the data dashboard -> Adjust and beautify the data dashboard. For the use of the Dune platform, you can check its [official documentation](https://dune.com/docs/).

## Basic Knowledge of Databases

Before we start writing the first SQL query needed for our data dashboard, we need to understand some essential SQL query basics.

### Introduction to Basic Concepts of Databases

**Database**: A database is an ordered collection of structured information or data, a warehouse that organizes, stores, and manages data according to data structures. The Dune platform currently provides multiple databases, each supporting data from different blockchains. This tutorial uses the "v2 Dune SQL" database query engine of the Dune platform. All example queries and referenced example links (except third-party queries) have been updated to Dune SQL.

**Schema**: Multiple schemas can be defined in the same database. For now, we can simply understand the schema as the owner of the data table. The same name data table can exist under different schemas.

**Data Table**: A data table consists of the table name, fields within the table, and the records in the table. The data table is the primary object we access when writing SQL queries. Dune stores data from different blockchains in various data tables under different schemas for our querying purposes. When writing a query using a data table, we use the format `schema_name.table_name` to specify the name of the data table to be used in the query. For instance, `ethereum.transactions` represents the `transactions` table under the `ethereum` schema, i.e., the Ethereum transaction table. The data table name within the same schema must be unique, but data tables with the same name can exist under multiple different schemas simultaneously. For example, both `ethereum.transactions` and `bnb.transactions` tables exist in V2.

**Data Column**: Also known as a field, sometimes simply referred to as a "column", it is the basic unit of data storage in a data table. Each data table contains one or more columns, each storing different types of data. When writing a query, we can return all columns or only return the required data columns. Typically, returning only the minimum required data can enhance the efficiency of the query.

**Data Row**: Also known as a record. Each record includes data from multiple columns defined by the data table. The result of executing an SQL query is one or more records. The record set output by the query is often also referred to as the result set.

### Data Tables Used in This Tutorial

In the SQL query examples in this section, we use the ERC20 token table `tokens.erc20` as an example. The ERC20 token table is an abstract data table (Spells, also known as Abstractions) generated by Dune community users through the Spellbook method. Except for the generation method, the usage of this type of data table is exactly the same as other tables. The ERC20 token table stores information about mainstream tokens compatible with the ERC20 standard on different blockchains that Dune supports for retrieval. For each token, it records the blockchain it belongs to, the token contract address, the number of decimal places supported by the token, and the token symbol information.

The structure of the ERC20 token table `tokens.erc20` is as follows:

| **Column Name**                 | **Data Type**   | **Description**                                    |
| ----------------------- | ------------- | ------------------------------------------ |
| blockchain              | string        | The name of the blockchain to which the token belongs                           |
| contract_address       | string        | The contract address of the token                                |
| decimals                | integer       | The number of decimal places supported by the token                             |
| symbol                  | string        | The symbol of the token                                    |

## Quick Start to SQL Queries

The broad sense of SQL query statement types includes Insert, Delete, Update, Select, and many other types.
The narrow sense of SQL queries mainly refers to data retrieval using Select statements. 
Most of the time, Onchain data analysis only needs to use Select statements to complete the work, 
so we only introduce Select query statements here. In the following content, 
we will alternate the use of Query, Select and other vocabulary, unless otherwise specified,
all refer to the use of Select statements to write Query for data retrieval.

### Write the First Query

The following SQL can query all ERC20 token information:

``` sql
select * from tokens.erc20
limit 10
```

### Introduction to Basic Syntax of Select Query Statements

The structure of a typical SQL query statement is as follows:

``` sql
select {field list}
from {data table}
where {filter condition}
order by {sort field}
limit {return record quantity}
```

The **field list** can list the fields (data columns) that the query needs to return one by one, where multiple fields are separated by English commas. For example, you can specify the field list returned by the query as `contract_address`, `decimals`, `symbol`. You can also use the wildcard `*` to indicate the return of all fields in the data table. If the query uses multiple tables and a certain field exists in these tables at the same time, we need to use the `table_name.field_name` format to specify which table the returned field belongs to.

The **data table** is specified in the format `schema_name.table_name`, for example, `tokens.erc20`. We can use the syntax `as alias_name` to assign an alias to the table, for example: `from tokens.erc20 as t`. In this way, the alias `t` can be used to access the table `tokens.erc20` and its fields in the same query.

The **filter condition** is used to filter the returned data according to the specified conditions. For fields of different data types, the syntax of the applicable filter conditions varies. For string (`varchar`) type fields, conditions such as `=` and `like` can be used for filtering. For date and time (`datetime`) type fields, conditions such as `>=`, `<=`, `between ... and ...` can be used for filtering. When using the `like` condition, the wildcard `%` can be used to match one or more arbitrary characters. Multiple filter conditions can be connected with `and` (meaning that they must all be met) or `or` (meaning that any condition can be met).

The **sort field** is used to specify the basis for sorting the query result set, which is one or more field names, along with optional sort direction indicators (`asc` for ascending, `desc` for descending). Multiple sort fields are separated by English commas. The Order By sort clause also supports specifying the sort field according to the position of the field in the Select clause. For example, `order by 1` means to sort according to the first field in the Select clause (ascending by default).

The **return record quantity** is used to specify (limit) the maximum number of records that the query returns. The blockchain stores massive data, so we usually need to add a limit to the number of returned records to improve the efficiency of the query.

Next, we will give examples to explain how to use the relevant parts of the query. Note that in SQL statements, we can add single-line comment explanations with `--`. We can also use `/*` at the beginning and `*/` at the end to mark multiple lines of content as comment explanations. Comment content will not be executed.

**Specify the returned field list:**

``` sql
-- Specify the columns to be returned one by one
select blockchain, contract_address, decimals, symbol   
from tokens.erc20
limit 10
```

**Add filter conditions:**

``` sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
-- Only return ERC20 token information from the Ethereum blockchain
where blockchain = 'ethereum'   
limit 10
```

**Use multiple filter conditions:**

``` sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
-- Return ERC20 token information from the Ethereum blockchain
where blockchain = 'ethereum'   
    and symbol like 'E%'    -- The token symbol starts with the letter E
```

**Specify sort fields:**

``` sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
where blockchain = 'ethereum'   -- Return ERC20 token information from the Ethereum blockchain
    and symbol like 'E%'    -- The token symbol starts with the letter E
order by symbol asc -- Sort by token symbol in ascending order
```

**Specify multiple sort fields:**

``` sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
where blockchain = 'ethereum'   -- Return ERC20 token information from the Ethereum blockchain
    and symbol like 'E%'    -- The token symbol starts with the letter E
order by decimals desc, symbol asc  -- First sort by the number of decimal places supported by the token in descending order, then sort by the token symbol in ascending order
```

**Use the Limit clause to limit the maximum number of records returned:**

``` sql
select *
from tokens.erc20
limit 10
```

### Some Common Functions and Keywords in Select Queries

#### As to Define Aliases

Aliases can be defined for tables and fields using the "as" clause. Aliases are very useful when the table name (or field name) is long, contains special characters or keywords, or when you need to format the output field name. Aliases are often used in calculated fields, multi-table associations, subqueries, and other scenarios.

``` sql
select t.contract_address as "Token Contract Address",
    t.decimals as "Token Decimal Places",
    t.symbol as "Token Symbol"
from tokens.erc20 as t
limit 10
```
In fact, for more concise writing, the `as` keyword can be omitted when defining aliases. You can directly follow the table name or field name with the alias, separated by a space. The following query is functionally identical to the previous one.

``` sql
-- The as keyword can be omitted when defining aliases
select t.contract_address "Token Contract Address",
    t.decimals "Token Decimal Places",
    t.symbol "Token Symbol"
from tokens.erc20 t
limit 10
```

#### Distinct for Selecting Unique Values

By using the `distinct` keyword, we can filter out the unique values of the fields that appear in the Select clause list. When the Select clause contains multiple fields, the unique combinations of these fields are returned.

``` sql
select distinct blockchain
from tokens.erc20
```

#### Now to Get the Current System Date and Time

Using `now()` can get the current system date and time. We can also use `current_date` to get the current system date, note that no parentheses are needed here.

``` sql
select now(), current_date
```

#### date_trunc to Truncate Dates

In the blockchain, the date and time fields are usually saved in the "year-month-day hour:minute:second" format. If you want to summarize by day, week, month, etc., you can use the `date_trunc()` function to convert the date first. For example: `date_trunc('day', block_time)` converts the value of block_time to a date value represented by "day", `date_trunc('month', block_time)` converts the value of block_time to a date value represented by "month".

``` sql
select now(),
    date_trunc('day', now()) as today,
    date_trunc('month', now()) as current_month
```

#### Interval to Get Time Intervals

Using syntax like `interval '2' day`, we can specify a time interval. It supports various different time interval representations, such as: `'12' hour`, `'7' day`, `'3' month`, `'1' year`, etc. Time intervals are often used to add or subtract a specified interval from a date and time value to get a date range.

``` sql
select now() as right_now, 
    (now() - interval '2' hour) as two_hours_ago, 
    (now() - interval '2' day) as two_days_ago,
    (current_date - interval '1' year) as one_year_ago
```

#### Concat to Connect Strings

We can use the `concat()` function to connect multiple strings together to get a new value. You can also use the more concise concatenation operator `||`.

``` sql
select concat('Hello ', 'world!') as hello_world,
    'Hello' || ' ' || 'world' || '!' as hello_world_again
```

#### Cast to Convert Field Data Types

Some operations in SQL queries require the data types of related fields to be consistent, such as the concat() function requires all parameters to be string `varchar` type. If you need to connect different types of data, you can use the `cast()` function to forcibly convert to the required data type, such as: `cast(25 as string)` converts the number 25 to the string "25". You can also use the `data_type 'value string'` operator to complete the type conversion, such as: `integer '123'` converts the string to a numeric type.

``` sql
select (cast(25 as varchar) || ' users') as user_counts,
    integer '123' as intval,
    timestamp '2023-04-28 20:00:00' as dt_time
```

#### Power to Calculate Exponentiation

ERC20 tokens on the blockchain usually support many decimal places. Ethereum's official token ETH supports 18 decimal places. Due to the limitations of the related programming language, the token amount is usually stored as an integer. When used, it must be converted with the supported decimal places to get the correct amount. The `power()` function, or `pow()`, can be used for exponentiation operations to implement conversions. In Dune V2, you can use a concise form to represent 10 to the power of N, for example `1e18` is equivalent to `power(10, 18)`.

``` sql
select 1.23 * power(10, 18) as raw_amount,
    1230000000000000000 / pow(10, 18) as original_amount,
    7890000 / 1e6 as usd_amount
```

### Advanced Select Queries

#### Group By and Common Aggregate Functions

SQL has some commonly used aggregate functions such as `count()` for counting, `sum()` for summing, `avg()` for averaging, `min()` for finding the minimum, and `max()` for finding the maximum. Apart from aggregating all data in a table, aggregate functions are often used in conjunction with the `group by` clause to group and aggregate statistics based on certain conditions. The syntax for the Group By clause is `group by field_name`, and multiple grouping fields can be specified as `group by field_name1, field_name2`. Similar to the Order By clause, you can also specify the grouping field by its position in the Select clause, which can make our SQL more concise. For example, `group by 1` means grouping by the first field, and `group by 1, 2` means grouping by both the first and second fields. Let's illustrate the usage of common aggregate functions with some examples.

**Count the number of ERC20 token types supported by each blockchain:**

``` sql
select blockchain, count(*) as token_count
from tokens.erc20
group by blockchain
```

**Count the total number, average, minimum, and maximum of token types supported by all blockchains:**

``` sql
-- Here, a subquery is used to demonstrate related functions
select count(*) as blockchain_count,
    sum(token_count) as total_token_count,
    avg(token_count) as average_token_count,
    min(token_count) as min_token_count,
    max(token_count) as max_token_count
from (
    select blockchain, count(*) as token_count
    from tokens.erc20
    group by blockchain
)
```

#### Subqueries (Sub Query)

A subquery is a query nested within another query. The subquery returns a complete dataset for the outer query (also called the parent or main query) to use for further querying. When we need to start from raw data and go through multiple steps of querying, associating, and aggregating to get the desired output, we can use subqueries. By putting the subquery in parentheses and assigning it an alias, we can use the subquery just like any other table.

The previous example used a subquery `from ( subquery statement )`, so no separate example is given here.

#### Joining Multiple Tables (Join)

When we need to take data from related multiple tables, or take different data from the same table and connect them together, we need to use multiple table joins. The basic syntax for multiple table joins is: `from table_a inner join table_b on table_a.field_name = table_b.field_name`. Here, `table_a` and `table_b` can be different tables or the same table, and they can have different aliases.

The following query joins `tokens.erc20` with itself to filter records that exist on both the Ethereum blockchain and the Binance blockchain and have the same token symbol:

``` sql
select a.symbol,
    a.decimals,
    a.blockchain as blockchain_a,
    a.contract_address as contract_address_a,
    b.blockchain as blockchain_b,
    b.contract_address as contract_address_b
from tokens.erc20 a
inner join tokens.erc20 b on a.symbol = b.symbol
where a.blockchain = 'ethereum'
    and b.blockchain = 'bnb'
limit 100
```

#### Union

When we need to merge records from different tables, or merge result sets containing different fields taken from the same table, we can use the `Union` or `Union All` clause. `Union` automatically removes duplicate records in the merged set, while `Union All` does not perform deduplication. For blockchain database tables containing massive data, deduplication can be quite time-consuming, so it is recommended to use `Union All` as much as possible to improve query efficiency.

Because we try to keep things simple for now, the following SQL statement demonstrating union may seem meaningless. But don't worry, this is just to show the syntax. We will have more appropriate examples in the data dashboard section:

``` sql
select contract_address, symbol, decimals
from tokens.erc20
where blockchain = 'ethereum'

union all

select contract_address, symbol, decimals
from tokens.erc20
where blockchain = 'bnb'

limit 100
```

#### Case Statement

With the Case statement, we can generate a different type of value based on the value of a field, usually to make the results more intuitive. For example, the ERC20 token table has a `decimals` field that stores the number of decimal places supported by various tokens. If we want to divide the tokens into high precision, medium precision, low precision, and no precision types based on the supported decimal places, we can use the Case statement for conversion.

``` sql
select (case when decimals >= 10 then 'High precision'
            when decimals >= 5 then 'Middle precision'
            when decimals >= 1 then 'Low precision'
            else 'No precision'
        end) as precision_type,
    count(*) as token_count
from tokens.erc20
group by 1
order by 2 desc
```

#### CTE (Common Table Expressions)

Common Table Expressions, or CTEs, are a good way to execute (and only execute once) a subquery within an SQL statement. The database will execute all WITH clauses and allow you to use their results anywhere in the subsequent query.

The definition of a CTE is `with cte_name as ( sub_query )`, where `sub_query` is a subquery statement. We can also define multiple CTEs in the same Query, separated by commas. Following the order of definition, later CTEs can access and use earlier CTEs. In the "Query 6" in the subsequent data dashboard section, you can see an example of defining multiple CTEs. The previous subquery example is rewritten in CTE format:

``` sql
with blockchain_token_count as (
    select blockchain, count(*) as token_count
    from tokens.erc20
    group by blockchain
)

select count(*) as blockchain_count,
    sum(token_count) as total_token_count,
    avg(token_count) as average_token_count,
    min(token_count) as min_token_count,
    max(token_count) as max_token_count
from blockchain_token_count
```

## Conclusion

Congratulations! You've now familiarized yourself with all the knowledge needed to create your first Dune dashboard. In the next tutorial, we will create a Dune dashboard together.

You can also learn more about the related content through the following links:
- [Dune platform's official documentation](https://dune.com/docs/) (Dune)
- [Dune beginner's guide](https://mirror.xyz/0xa741296A1E9DDc3D6Cf431B73C6225cFb5F6693a/iVzr5bGcGKKCzuvl902P05xo7fxc2qWfqfIHwmCXDI4) (Translated by Louis Wang, a member of SixdegreeLab)
- [Dune Analytics zero-basic minimalist beginner's guide](https://mirror.xyz/gm365.eth/OE_CGx6BjCd-eQ441139sjsa3kTyUsmKVTclgMv09hY) (Written by Dune community user gm365)


## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch03/ch03-build-first-dashboard.md">
# 03 Creating Your First Dashboard

In the previous tutorial, "**Quick Start**" we learned the prerequisites for creating a data dashboard and mastered the basics of writing SQL queries. Now, let's write queries and create a Dune data dashboard together. To help you get started faster, we will create the data dashboard using a specific project as an example. The example of the completed data dashboard can be found here: [https://dune.com/sixdegree/uniswap-v3-pool-tutorial](https://dune.com/sixdegree/uniswap-v3-pool-tutorial).

We won't go into detail about each step of the process. You can learn how to use Dune's Query Editor and Data Dashboard in the official [Dune platform documentation](https://dune.com/docs/).

## Background Knowledge

Before we start creating the dashboard, we need to understand some additional background knowledge. Uniswap is one of the most popular decentralized finance (DeFi) protocols. It is a set of immutable and upgradable smart contracts that collectively create an automated market maker (AMM) protocol. The Uniswap protocol primarily provides peer-to-peer exchange of ERC20 tokens on the Ethereum blockchain. The Uniswap factory contract deploys new smart contracts to create liquidity pools, which pair two ERC20 token assets and set different fees. Liquidity refers to the digital assets stored in Uniswap's liquidity pool contracts, available for traders to trade. Liquidity providers (LPs) are individuals who deposit their ERC20 tokens into a given liquidity pool. LPs receive compensation in the form of trading fees as rewards, while also bearing the risk of price fluctuations. Regular users (swappers) can exchange one ERC20 token they own for another in a liquidity pool, such as exchanging USDC for WETH or vice versa, by paying a small service fee. The Uniswap V3 protocol works as follows: the factory contract creates liquidity pools (including two ERC20 tokens) -> LP users add corresponding assets to the liquidity pools -> other users use the liquidity pools to exchange their held token assets and pay service fees -> LPs receive fee rewards.

Some of these concepts introduced may be unfamiliar to beginners, but there's no need to worry. You don't need to know more about DeFi to successfully complete this tutorial. We're using Uniswap V3 liquidity pools as a case study in the data dashboard we're going to create. The corresponding table is `uniswap_v3_ethereum.Factory_evt_PoolCreated`. Additionally, some queries will utilize the `tokens.erc20` table mentioned in the previous tutorial. Before we start, all you need to know is that you can create many different liquidity pools, each containing two different ERC20 tokens (referred to as a token pair), with a given fee rate. The same token pair (e.g., USDC-WETH) can have multiple liquidity pools with different fee rates.

## Uniswap Liquidity Pool Table

The structure of the liquidity pool table, `uniswap_v3_ethereum.Factory_evt_PoolCreated`, is as follows:

| **Column Name**     | **Data Type** | **Description**                           |
| ------------------- | ------------- | ----------------------------------------- |
| contract_address    | string        | Contract address                          |
| evt_block_number    | long          | Block number                              |
| evt_block_time      | timestamp     | Time the block was mined                   |
| evt_index           | integer       | Index number of the event                  |
| evt_tx_hash         | string        | Unique hash of the event's transaction     |
| fee                 | integer       | Fee rate of the liquidity pool (expressed as "1/1,000,000") |
| pool                | string        | Address of the liquidity pool              |
| tickSpacing         | integer       | Tick spacing                              |
| token0              | string        | Address of the first ERC20 token in the pool  |
| token1              | string        | Address of the second ERC20 token in the pool |

Here is a partial view of the liquidity pool table (displaying only a subset of columns):

![](img/ch03_image_00.png)

## Main Content of the Data Dashboard

Our first Dune data dashboard will include the following queries, each producing one or more visual charts:
- Query 1: Total number of liquidity pools
- Query 2: Number of liquidity pools with different fee rates
- Query 3: Weekly summary of newly created liquidity pools
- Query 4: Daily count of newly created liquidity pools over the last 30 days
- Query 5: Weekly summary of newly created liquidity pools, grouped by fee rate
- Query 6: Statistics on the token with the most liquidity pools
- Query 7: Latest 100 liquidity pool records

## Query 1: Total Number of Liquidity Pools

We can use the COUNT() aggregate function to count the total number of existing pools.

``` sql
SELECT COUNT(*) AS pool_count
FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
```

We suggest copying the code above, creating and saving the query. When saving the query, give it a recognizable name such as "uniswap-pool-count". Of course, you can also directly fork the reference query listed below. The advantage of forking a query is that you can learn more about the details of visual charts.

Reference link to this query in Dune: [https://dune.com/queries/1454941](https://dune.com/queries/1454941)

## Creating a Data Dashboard and Adding Charts

### Creating a Dashboard

First, log in to the [Dune website](https://dune.com/). Then, click on "My Creation" in the top navigation bar, and click "Dashboards" in the bottom section to enter the created data dashboard page: [https://dune.com/browse/dashboards/authored](https://dune.com/browse/dashboards/authored). To create a new data dashboard, click the "New dashboard" button in the right sidebar. In the pop-up dialog, enter a name for the dashboard, and click the "Save and open" button to create the new data dashboard and enter the preview interface. Here, I'm using "Uniswap V3 Pool Tutorial" as the name for this data dashboard.

### Adding Query Charts

A newly created data dashboard has no content and the preview page will display "This dashboard is empty." We can convert the result of the total pool count from the previous step, into a visual chart and add it to the data dashboard. Open the "My Creations" page in a new browser tab: [https://dune.com/browse/queries/authored](https://dune.com/browse/queries/authored), and find the saved "Query 1" query. Click on its name to enter the editing page. Since the query has already been saved and executed, you can click the "New visualization" button to create a new visualization chart. For a single numerical query result, the counter visualization type is usually used. From the "Select visualization type" dropdown list, choose "Counter" and click the "Add Visualization" button. Then, you can give the chart a name and modify the Title value from the default "Counter" to "Total Number of Liquidity Pools". Finally, click "Add to dashboard" in the dialog box, and 
then click the "Add" button next to the corresponding data dashboard to add this counter chart to the data dashboard.

Now we can go back to the data dashboard page. After refreshing the page, you will see the newly added visualization chart. Click the "Edit" button in the upper right corner of the page to edit the data dashboard, including adjusting the size and position of each chart, adding text components, etc. Below is a screenshot of the counter chart for "Total Number of Liquidity Pools" after adjusting the height.

![](img/ch03_image_01.png)

### Adding Text Components

In the data dashboard editing page, you can add text components to the dashboard by clicking the "Add text widget" button. Text components can be used to provide explanations for the core content of the data dashboard or add author information. Text components support Markdown syntax for formatting. Clicking on "Some markdown is supported" in the dialog box will expand to show the supported syntax. Add the necessary text components according to your needs. Here, we won't go into detail on this part.

## Query 2: Number of Liquidity Pools with Different Fee Rates

To count the number of liquidity pools with different fee rates, we can use the FILTER clause. This allows us to count pools with specific fee rates separately and display the results in the same row.

``` sql
SELECT COUNT(*) FILTER (WHERE fee = 100) AS pool_count_100,
    COUNT(*) FILTER (WHERE fee = 500) AS pool_count_500,
    COUNT(*) FILTER (WHERE fee = 3000) AS pool_count_3000,
    COUNT(*) FILTER (WHERE fee = 10000) AS pool_count_10000
FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
```

Reference link to this query in Dune: [https://dune.com/queries/1454947](https://dune.com/queries/1454947)

This query returns four output values. We can add them as separate counter components and name them "Number of 0.01% Pools," "Number of 0.05% Pools," etc. Then, add them to the data dashboard and adjust the size and order of the components in the data dashboard editing page. The display result is shown in the image below:

![](img/ch03_image_02.png)

Alternatively, we can use the GROUP BY clause to group the results and display them in a pie chart.

``` sql
SELECT fee,
    COUNT(*) AS pool_count
FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
GROUP BY 1
```

The fee rate "fee" is a numerical value representing a fee in parts per million (ppm). For example, 3000 represents 3000/1000000, which is "0.30%". To make it more intuitive, we can modify the query to convert the fee rate to a percentage representation.

``` sql
SELECT CONCAT(FORMAT('%,.2f', fee / 1e4), '%') AS fee_tier,
    COUNT(*) AS pool_count
FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
GROUP BY 1
```

Here, `CONCAT(FORMAT('%,.2f', fee / 1e4), '%') AS fee_tier` is used to convert the fee rate to a percentage representation and append the "%" symbol. The result is then output with an alias `fee_tier`. For the specific syntax of the `FORMAT` function, you can refer to the documentation of Trino (Trino is the underlying engine of Dune SQL). Trino documentation link: [https://trino.io/docs/current/functions.html](https://trino.io/docs/current/functions.html).

Reference link to this query in Dune: [https://dune.com/queries/1455127](https://dune.com/queries/1455127)

We can add a pie chart visualization for this query. Click "New visualization" and choose "Pie Chart" from the chart type dropdown list, then click "Add visualization". Modify the title of the chart to "Number of Pools with Different Fee Rates". Select "fee_tier" as the horizontal axis (X Column) and "pool_count" as the vertical axis (Y Column 1) of the chart. Check the "Show data label" option on the left side. Finally, click "Add to dashboard" to add this visualization to the data dashboard. The result will be displayed as shown below:

![](img/ch03_image_03.png)

## Query 3: Weekly Summary of Newly Created Liquidity Pools

To summarize the count of newly created liquidity pools by week, we can use the `date_trunc()` function to convert the creation date of the pools to the start date of each week (Monday), and then use GROUP BY to aggregate the statistics.

``` sql
SELECT block_date, COUNT(pool) AS pool_count
FROM (
    SELECT date_trunc('week', evt_block_time) AS block_date,
        evt_tx_hash,
        pool
    FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
)
GROUP BY 1
ORDER BY 1
```

Reference link to this query in Dune: [https://dune.com/queries/1455311](https://dune.com/queries/1455311)

Data that is grouped by time is suitable for visualizations such as bar charts, area charts, and line charts. Here, we will use a bar chart. Click "New visualization" and choose "Bar Chart" from the chart type dropdown list, then click "Add visualization". Modify the title of the chart to "Weekly Summary of Newly Created Pools". Select "block_date" as the horizontal axis (X Column) and "pool_count" as the vertical axis (Y Column 1) of the chart. Uncheck the "Show chart legend" option on the left side. Finally, click "Add to dashboard" to add this visualization to the data dashboard. The result will be displayed as shown below:

![](img/ch03_image_04.png)


## Query 4: Total Daily Creation of Liquidity Pools in the Last 30 Days

To summarize the daily creation of liquidity pools, we can use a subquery to convert the pool creation dates to days (excluding the time component) using the `date_trunc()` function. Then we can use `GROUP BY` to aggregate and summarize the data. In this case, we will use a Common Table Expression (CTE) for the query. CTEs provide a more intuitive and reusable way of defining queries, improving efficiency and facilitating debugging. Subsequent queries will also use CTEs.

``` sql
WITH pool_details AS (
    SELECT date_trunc('day', evt_block_time) AS block_date, evt_tx_hash, pool
    FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
    WHERE evt_block_time >= NOW() - INTERVAL '29' DAY
)
SELECT block_date, COUNT(pool) AS pool_count
FROM pool_details
GROUP BY 1
ORDER BY 1
```

Reference link for this query on Dune: [https://dune.com/queries/1455382](https://dune.com/queries/1455382)

We can visualize the results using a bar chart. Add a new chart of type "Bar" and modify the title to "Total Daily Creation of Liquidity Pools in the Last 30 Days." Select "block_date" for the X column and "pool_count" for the Y column. Uncheck the "Show chart legend" option on the left and check the "Show data labels" option. Add this visualization chart to the dashboard. The resulting visualization will look like this:

![](img/ch03_image_05.png)


## Query 5: Weekly Summary of Newly Created Liquidity Pools - Grouped by Fee Tiers

To further analyze the newly created liquidity pools, we can group them by fee tiers to compare their popularity during different time periods. This query demonstrates multi-level grouping and stacked bar chart visualization.

``` sql
WITH pool_details AS (
    SELECT date_trunc('week', evt_block_time) AS block_date, fee, evt_tx_hash, pool
    FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
)
SELECT block_date,
    CONCAT(FORMAT('%,.2f', fee / 1e4), '%') AS fee_tier,
    COUNT(pool) AS pool_count
FROM pool_details
GROUP BY 1, 2
ORDER BY 1, 2
```

Reference link for this query on Dune: [https://dune.com/queries/1455535](https://dune.com/queries/1455535)

We can visualize the results using a bar chart. Add a new chart of type "Bar" and modify the title to "Weekly Summary of Newly Created Liquidity Pools - Grouped by Fee Tiers." Select "block_date" for the X column and "pool_count" for the Y column. Additionally, select "fee_tier" in the "Group by" section to enable grouping and stacking of data by fee tiers. Check the "Enable stacking" option on the left to stack data with the same date and fee tier together. Add this visualization chart to the dashboard. The resulting visualization will look like this:

![](img/ch03_image_06.png)


## Query 6: Most Popular Token by Number of Liquidity Pools

To analyze which ERC20 tokens are more popular in Uniswap liquidity pools based on the number of pools associated with them, we can group them by token types.

Each Uniswap liquidity pool consists of two ERC20 tokens (token0 and token1), and based on the alphabetical order of their address hashes, the same ERC20 token may be stored in either token0 or token1. Therefore, in the following query, we use a union operation to get a complete list of liquidity pool details.

Furthermore, the liquidity pools store the contract addresses of ERC20 tokens, which may not be intuitive to display directly. The abstract table `tokens.erc20` generated by the Dune community users' Magic Book provides basic information about ERC20 tokens. By joining this table, we can retrieve the token symbol.

Since Uniswap V3 has over 8,000 liquidity pools involving more than 6,000 different ERC20 tokens, we will focus on the data of the top 100 tokens with the highest number of liquidity pools. The query demonstrates concepts such as multiple CTEs, union, join, and limit.

``` sql
WITH pool_details AS (
    SELECT token0 AS token_address,
        evt_tx_hash, pool
    FROM uniswap_v3_ethereum.Factory_evt_PoolCreated

    UNION ALL

    SELECT token1 AS token_address,
        evt_tx_hash, pool
    FROM uniswap_v3_ethereum.Factory_evt_PoolCreated
),

token_pool_summary AS (
    SELECT token_address,
        COUNT(pool) AS pool_count
    FROM pool_details
    GROUP BY 1
    ORDER BY 2 DESC
    LIMIT 100
)

SELECT t.symbol, p.token_address, p.pool_count
FROM token_pool_summary p
INNER JOIN tokens.erc20 t ON p.token_address = t.contract_address
ORDER BY 3 DESC
```

Reference link for this query on Dune: [https://dune.com/queries/1455706](https://dune.com/queries/1455706)

We can visualize the results using a bar chart. Add a new chart of type "Bar" and modify the title to "Number of Liquidity Pools for Top 100 ERC20 Tokens". Select "symbol" for the X column and "pool_count" for the Y column. To maintain the sorting order (from highest to lowest count), uncheck the "Sort values" option on the right. Although we have limited the data to the top 100 tokens, we can still see significant differences in the number of liquidity pools for different tokens, ranging from over 5,000 to just a few. To make the chart more intuitive, check the "Logarithmic" option on the right to display the data in logarithmic scale. Add this visualization chart to the dashboard. The resulting visualization will look like this:

![](img/ch03_image_07.png)

As the logarithmic scale visually downplays the differences in values, we can also add a "Table" visualization to view the actual numerical values. Continue adding a new visualization chart for this query, select the "Table" chart type. Set the title as "Statistics of the Number of Liquidity Pools for the Top 100 ERC20 Tokens." Adjust the relevant options for the table visualization as needed, and then add it to the dashboard.

![](img/ch03_image_08.png)

You may notice that the table does not return exactly 100 rows of data. This is because some newly appeared tokens may not have been added to the data table in Dune yet.

## Query 7: Latest 100 Liquidity Pool Records

When a project launches a new ERC20 token and supports its listing for trading, Uniswap users may create corresponding liquidity pools to enable exchanges for other users. For example, the XEN token is a recent and notable case.

We can track new trends by querying the latest created liquidity pools. The following query is associated with the `tokens.erc20` table and uses multiple joins with the same table using different aliases to retrieve symbols for different tokens. The query also demonstrates outputting a visualized table, generating hyperlinks using string concatenation, and more.

``` sql
with last_created_pools as (
    select p.evt_block_time,
        t0.symbol as token0_symbol,
        p.token0,
        t1.symbol as token1_symbol,
        p.token1,
        p.fee,
        p.pool,
        p.evt_tx_hash
    from uniswap_v3_ethereum.Factory_evt_PoolCreated p
    inner join tokens.erc20 t0 on p.token0 = t0.contract_address and t0.blockchain = 'ethereum'
    inner join tokens.erc20 t1 on p.token1 = t1.contract_address and t1.blockchain = 'ethereum'
    order by p.evt_block_time desc
    limit 100
)

select evt_block_time,
    token0_symbol || '-' || token1_symbol || ' ' || format('%,.2f', fee / 1e4) || '%' as pool_name,
    '<a href=https://etherscan.io/address/' || cast(pool as varchar) || ' target=_blank>' || cast(pool as varchar) || '</a>' as pool_link,
    token0,
    token1,
    fee,
    evt_tx_hash
from last_created_pools
order by evt_block_time desc
```

Reference link to this query on Dune: [https://dune.com/queries/1455897](https://dune.com/queries/1455897)

We add a visualization chart of type "Table" to the query, set the title as "Latest Created Liquidity Pools List," and adjust the visualization options as desired before adding it to the dashboard.

![](img/ch03_image_09.png)

## Summary

With this, we have completed the creation of the first Dune data dashboard. The complete interface of this dashboard appears as shown in the following image:

![](img/ch03_dashboard.png)

To avoid overwhelming complexity, we have only covered some basic queries, and the resulting charts in the dashboard may not look extremely sophisticated. However, this is not important. What matters more is whether you can use this tutorial as a starting point to embark on your own journey of Onchain data analysis.
After reading this tutorial, I hope you will try it out for yourself. Uniswap was just one example of a DEX, and you can perform similar analyses on any other DEX on different chains. Combining the techniques from the previous lessons, you can explore and compare data from other DEXs or even the same DEX on different chains (such as UniSwap on Ethereum and Optimism). As a blockchain data analyst, your dashboard is your resume, so take it seriously!

## Homework

Based on the tutorial content, create a data dashboard with at least 5 queries for any DEX. The naming format for the dashboard should be "SixdegreeAssignment1-YourName," such as "SixdegreeAssignment1-Spring." This format makes it easier for everyone to learn from each other and helps us monitor the quality of the tutorials. To encourage active participation in creating dashboards, we will keep a record of the completion and quality of the homework. In the future, we will provide rewards, including but not limited to Dune community identities, physical merchandise, free API quotas, POAPs, memberships to various collaborative data products, job recommendations for blockchain data analysis, priority registration for community offline activities, and other incentives from the Sixdegree community.

Keep up the good work! Feel free to share the links to your data dashboards in the Dune WeChat group or Dune's Discord channel.

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch04/ch04-understanding-tables.md">
# 04 Understanding Data Tables

Data platforms like Dune decode and store blockchain data in databases. Data analysts write SQL queries to analyze data from specific tables based on their analysis needs. With more and more blockchain platforms emerging in the market and a variety of projects deployed on different blockchains, it is essential for analysts to quickly locate the corresponding data tables for analysis and understand the meaning and purpose of each field in the tables. This is a crucial skill that every analyst must possess.
Currently, the structure of the basic datasets provided by several data platforms is quite similar. Here, we will focus on explaining the structure of the Dune platform. If you prefer to use other data platforms, you can refer to the corresponding documentation for details. As Dune has officially announced that it will fully switch to the Dune SQL query engine by 2023, we have upgraded all the queries in this tutorial to the Dune SQL version.

## Introduce Dune V2 data tables

There are several types of datasets on Dune:

- **Raw**: stored raw blockchain data, including data tables such as `blocks`, `transactions`, and `traces`. These raw data tables contain the most original Onchain data and can be used for flexible data analysis.
- **Decoded Projects**: stored the decoded calls and events made to smart contracts. For example, tables related to Uniswap V3 and Opensea Seaport. Dune uses the ABI of smart contracts and the interface of standardized token smart contracts (ERC20, ERC721, etc.) to decode data and save the data of each event or method call separately to a data table.
- **Spells**: spells also called Abstractions in Dune V1, is built and maintained by Dune and community through Spellbook GitHub repository, and is compiled using dbt. These data tables are typically more convenient and efficient to use.
- **Community**: this data is provided by selected third party organizations that stream their data directly to Dune. Currently there are two community datasets, `flashbots` and `reservoir`.
- **User Generated Tables**: currently, this function is not available on Dune V2, users can only upload a custom data tables through Spellbook GitHub repository.

On the Query page, we can select or search for the required dataset through the left sidebar. The interface for this section is shown below:

![](img/ch04_5-1.jpg)

The text box in the middle of the image can be used to search for corresponding schemas or data tables. For example, entering `erc721` will filter out all Spells and Decoded projects tables whose names contain this string. The red box above the image is used to select the dataset to be used, "v2 Dune SQL" displayed in it is what we usually refer to as the "Dune SQL engine". Dune will fully transition to the Dune SQL engine in the second half of 2023, so for now, everyone only needs to be familiar with the syntax of Dune SQL.
The red box at the bottom shows several categories of dataset currently supported by the Dune V2 engine. Click on the bold dataset category name will take you to the next level to browse the various data schemas and table names in that category. After that, you can also see a drop-down list with a default option of "All Chains", which can be used to filter the data schemas and tables on specified blockchain. When enter table level, clicking on the table name can expand to view the list of fields in the table.  Clicking the ">>" icon to the right of the table name will insert the table name (in the format of `schema_name.table_name`) into the query editor at the cursor position. While browsing in a hierarchical manner, you can also enter keywords to further search and filter at the current level. Different types of data tables have different levels of depth. The following picture shows an example of browsing decoded data tables.

![](img/ch04_5-2.jpg)

## Raw data

Typical raw data tables in a blockchain include: `Blocks`,`Transactions`,`Traces`,`Logs`,and `Creation_traces`. The naming format for raw data tables is `blockchain_name.table_name`, such as `arbitrum.logs`, `bnb.blocks`, `ethereum.transactions`, `optimism.traces`, etc. Some blockchains may have more or fewer raw data tables. Let's take Ethereum as an example to briefly introduce them.

### ethereum.blocks

A block is the basic component of a blockchain. A block contains multiple transactions. The ethereum.block records information about each generated block, including the block timestamp, block number, block hash, difficulty, gas used, etc. Apart from analyzing the overall blockchain's block generation status, gas usage, etc., we generally don't need to pay close attention to or directly use the block table. The most important information is the block timestamp and block number, which are saved in almost all other data tables under different field names.

### ethereum.transactions

The `ethereum.transactions` table stores the details of every transaction that occurred on the blockchain (including both successful and failed transactions). The structure of the transaction table in Ethereum is shown below:

|  **Column**            |  **Data type**   |  **Description**                                                   |
| -------------------------- | :-----------: | ---------------------------------------------------------------- |
| `block_time`               | _timestamptz_ | The time when the block was mined that includes this transaction |
| `block_number`             | _int8_        | The length of the blockchain in blocks                     |
| `value`                      | _numeric_     | The amount of `[chain_gas_token]` sent in this transaction in `wei`. Note that ERC20 tokens do not show up here |
| `gas_limit`                | _numeric_     | The gas limit in `wei` (ArbGas for Arbitrum) |
| `gas_price`                | _numeric_     | The gas price in `wei`                                    |
| `gas_used`                 | _numeric_     | The gas consumed by the transaction in `wei`              |
| `max_fee_per_gas`          | _numeric_     | The maximum fee per gas the transaction sender is willing to pay total (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |
| `max_priority_fee_per_gas` | _numeric_     | Maximum fee per gas the transaction sender is willing to give to miners to incentivize them to include their transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |
| `priority_fee_per_gas`     | _numeric_     | The priority fee paid out to the miner for this transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |
| `nonce`                    | _numeric_     | The transaction nonce, unique to that wallet               |
| `index`                    | _numeric_     | The transactions index position in the block               |
| `success`                  | _boolean_     | A true/false value that shows if the transaction succeeded |
| `from`                     | _bytea_       | Address of the sender                                      |
| `to`                       | _bytea_       | Address of the receiver. `null` when its a contract creation transaction |
| `block_hash`               | _bytea_       | A unique identifier for that block                         |
| `data`                     | _bytea_       | Can either be empty, a hex encoded message or instructions for a smart contract call |
| `hash`                     | _bytea_       | The hash of the transaction                                |
| `type`                     | _text_        | The type of the transaction: `Legacy`, `AccessList`, or `DynamicFee` |
| `access_list`              | _jsonb_       | A list of addresses and storage keys the transaction intends to access. See [EIP2930](https://eips.ethereum.org/EIPS/eip-2930). Applicable if the transaction is of type `AccessList` or `DynamicFee` |
| `effective_gas_price` | _numeric_      | [Arbitrum and Avalanche C-Chain only] The gas price this transaction paid in `wei` (Arbitrum) or `nanoavax` (Avalanche) |
| `gas_used_for_l1` | _numeric_ | [Arbitrum only] The gas consumed by the L1 resources used for this transaction in ArbGas |
| `l1_gas_used` | _numeric_ | [Optimism only] The costs to send the input `calldata` to L1 |
| `l1_gas_price` | _numeric_ | [Optimism only] The gas price on L1 |
| `l1_fee` | _numeric_ | [Optimism only] The amount in wei paid on L1  |
| `l1_fee_scalar` | _numeric_ | [Optimism only] Variable parameter that makes sure that gas costs on L1 get covered + profits |
| `l1_block_number` | _numeric_ | [Optimism only] The block_number of the block in which this transaction got batch settled on L1 |
| `l1_timestamp` | _numeric_ | [Optimism only] The timestamp of the block in which this transaction got batch settled on L1 |
| `l1_tx_origin` | _numeric_ | [Optimism only] ?? |


The most commonly used fields in the transaction table include `block_time` (or `block_number`), `from`, `to`, `value`, `hash`, `success`,etc. The Dune V2 engine uses a columnar database where data in each table is stored by column. Column-stored tables cannot use indexes in the traditional sense, but rely on metadata with "min/max values" to optimize queries. For numeric or datetime columns, it's easy to calculate min/max values for a set of values. In contrast, for string columns with variable lengths, it's hard to efficiently compute min/max values. This makes string queries less efficient in the V2 engine. So we typically need to combine filters on datetime or numeric columns to improve query performance. As mentioned, the `block_time` and `block_number` fields exist in almost all data tables (under different names), so we should make full use of them for filtering to ensure efficient query execution. You can check [how the Dune V2 query engine works](https://dune.com/docs/query/#changes-in-how-the-database-works) to learn more details.

### ethereum.traces

A transaction can trigger multiple internal calls, and an internal call may further trigger more internal calls. The execution information of these calls is recorded in ethereum.traces. The main fields in this table include `block_time`, `block_number`, `tx_hash`, `success`, `from`, `to`, `value`, `type`,etc.
The `ethereum.traces` has two common use cases:

1. To track transfer details and gas usage of native blockchain tokens. For example, on Ethereum, users may transfer ETH to other address(es) via a smart contract of a DApp. In this case, the `value` field in the `ethereum.transactions` table does not contain the transferred ETH amount. The actual transfer value is only stored in the `value` field of the ethereum.traces table. Also, native tokens are not ERC20 tokens, so their transfer cannot be tracked via ERC20 Transfer events.The gas fees for blockchain transactions are also paid with native tokens. The gas usage data is stored both in the `ethereum.transactions` table and the `ethereum.traces` table. A transaction can have multiple internal calls, which can further trigger more calls. This means the `from`, `to` fields are inconsistent across these calls, implying different accounts paying for gas fees.Therefore, when calculating native token balances like ETH for an address or a group, only the `ethereum.traces` table can give accurate results. Here is an example query to calculate ETH balances for top holders: [ETH top holders' balances](https://dune.com/queries/1001498/1731554)
2. Filter contract addresses. On Ethereum, addresses are divided into two types - Externally Owned Addresses (EOAs) owned by users, and Contract Addresses created by deploying smart contracts.When a new smart contract is deployed, the `type` field in the corresponding `ethereum.traces` record would be `create`. We can use this to identify contract addresses. In Dune V2, the Dune team has extracted the internal calls for contract creations into a separate table `ethereum.creation_traces`. By querying this table directly, we can determine if an address is a contract address.

### ethereum.logs

The `ethereum.logs` stores all the event logs emitted by smart contracts. It is very useful when we need to query and analyze smart contracts that are not decoded or cannot be decoded (due to closed source code etc).In general, we recommend using the decoded data tables first for efficiency and avoiding errors in queries. However, sometimes due to latency (contract not decoded yet) or contracts not supporting decoding, we have to directly access the `ethereum.logs` table for analysis.

The main fields are `block_time`, `block_number`, `tx_hash`, `contract_address`, `topic1`, `topic2`, `topic3`,`topic4`,`data`,etc.There are some points to pay attention to when using:

- `topic1` contains the hashed signature of the event method. We can filter logs by `contract_address` and topic1` to get all logs for a specific event of a contract.
- `topic2`, `topic3`, `topic4` store indexed event parameters (topics). Each event can have up to 3 indexed topic parameters. If there are less than 3 indexed params, the remaining topic fields will not contain any value. For each specific event, the values saved in these topic params are different. We can check the logs shown on blockchain explorers like EtherScan to match and confirm what each topic param represents. Or we can also check the source code of the smart contract to understand the definitions of the event parameters.
- `data` stores the hexadecimal encoded combination of unindexed event parameters , in string format starting with `0x`. Each parameter takes up 64 characters, with 0-padding on the left if less than 64 bits. When we need to decode the data, we should split it into groups of 64 characters starting from the 3rd character, based on this structure. Then we can further process each group to convert into the actual data types (address, number, string etc.)

Here is a sample query that decode the ethereum.logs table directly: https://dune.com/queries/1510688. You can copy a tx_hash value from the query results and visit Etherscan, then switch to the "Logs" tab for comparison. Below is an example screenshot from Etherscan:
![](img/ch04_5-4.jpg)


## Decoded Projects

The decoded project tables make up the largest group of data tables. When a smart contract is submitted to Dune for decoding, Dune generates a dedicated table for each method call and event in the contract.In Dune's query editor sidebar, these decoded project tables are displayed hierarchically as:

```
category name -> project name (namespace) -> contract name -> function name / event name

-- Sample
Decoded projects -> uniswap_v3 -> Factory -> PoolCreated
```

The naming convention for decoded project tables is:

Events: `projectname_blockchain.contractName_evt_eventName`

Function calls: `projectname_blockchain.contractName_call_functionName`

For example, for the PoolCreated event of Uniswap V3:
The table name would be `uniswap_v3_ethereum.Factory_evt_PoolCreated`

A very useful method is to query the `ethereum.contracts` spell table to check if a contract you want has already been decoded. This table stores records of all decoded contracts.

If the query returns a result, you can use the methods described earlier to quickly browse or search for the contract's decoded tables in the editor sidebar.
If no result is returned, it means the contract has not yet been decoded. You can submit it to Dune for decoding: [Submit New Contract](https://dune.com/contracts/new?__cf_chl_rt_tk=U.qtXIi0RjaP8DToW1_sJG9luDEv4_HiZ9JleGrNyNw-1690016370-0-gaNycGzNFvs)
You can submit any valid contract address, as long as it is a decodable smart contract (Dune can auto extract the ABI or you provide it).
We have created a dashboard where you can directly [check if a contract is decoded](https://dune.com/sixdegree/decoded-projects-contracts-check)

## Spells

The Spellbook is a community-driven data transformation layer project on Dune. Spells can be used to build advanced abstract tables for common use cases like NFT trades. The Spellbook automates building and maintaining these tables, with data quality checks.

Anyone in the Dune community can contribute spells to the Spellbook by submitting PRs on GitHub, which requires basic knowledge of Git and GitHub. If you want to contribute, check the Dune Spellbook docs for details.

The Dune community is very active and has created many useful spells. Many have been widely used in our daily data analysis. Here, we will introduce some of the important spells

### The prices tables (prices.usd, prices.usd_latest)

The `prices.usd` table contains per-minute historical USD prices for major ERC20 tokens on each blockchain.When aggregating or comparing multiple tokens, we typically join with the prices table to convert everything to USD amounts first before summarizing or comparing.The price information table currently provides major ERC20 token price information for Ethereum, BNB, Solana and other chains, accurate to every minute.To get daily or hourly average prices, you can calculate the average price per day/hour.Here are two sample queries demonstrating different approaches to get daily prices for multiple tokens:

- [get daily average price](https://dune.com/queries/1507164)
- [get daily last minute price record](https://dune.com/queries/1506944)

price.usd_latest provides the latest price for the relevant ERC20 token

### The DeFi trade table(dex.trades, dex_aggregator.trades)

The `dex.trades` table provides trade data across major DEXs. Since there are many DeFi projects, the Dune community is continuously expanding the data sources. Currently integrated DEXs include Uniswap, Sushiswap, Curve, Airswap, Clipper, Shibaswap, Swapr, Defiswap, DFX, Pancakeswap, Dodo and more.The `dex.trades` table consolidates data across projects. Each project also has its own specific spell table, like `uniswap.trades`, `curvefi_ethereum.trades` etc. If analyzing a single project, its dedicated spell table is preferable.

The `dex_aggregator.trades` table contains trade records from DEX aggregators. These aggregators route trades to DEXs for execution, organize these records separately to avoid double-count with `dex.trades`.As of this writing, it currently only has data for Cow Protocol.

### The tokens table (tokens.erc20,tokens.nft)

The tokens tables currently mainly include:`tokens.erc20` and `tokens.nft`

The `tokens.erc20` table records definition info like contract address, symbol, decimals for major ERC20 tokens.

The `tokens.nft` table records basic info for NFT collections. It relies on community PRs to update so may have latency or missing data.

Since blockchain data stores amounts as raw integers without decimals, we need to join the `tokens.erc20` decimals to properly convert values.

### The ERC token tables (erc20_ethereum.evt_Transfer, erc721_ethereum.evt_Transfer,etc)

The ERC token tables contain decoded Approval and Transfer events for different token standards like ERC20, ERC721 (NFT), ERC1155 etc.We can use these spell tables when we want to analyze token transfer details, balances, etc for an address or group of addresses.

### The ENS tables (ens.view_registrations,etc)

The ENS tables contain data about ENS domains, including:ENS domain registrations,Reverse resolution records,ENS domain update,etc.

### The labels tables

The labels tables are a collection of spell tables from various sources that associate wallet/contract addresses to text labels. The data sources include ENS domains, Safe wallets, NFT projects, decoded contract addresses, etc. We can use the built-in Dune function `get_labels()` in our queries to display addresses using intuitive, more readable labels instead of raw addresses.

### The balance tables(balances_ethereum.erc20_latest,etc)

The balances tables contain hourly, daily, and latest token balances for addresses across ERC standards like ERC20, ERC721 (NFT), ERC1155. We can use these tables when we want to look up latest balances or track balance changes over time for addresses

### The NFT trade tables

The NFT trades tables contain transaction data from major NFT marketplaces like OpenSea, MagicEden, LooksRare, X2Y2, SudoSwap, Foundation, ArchipelagoCryptopunks,Element,SuperRare,Zora,Blur,and more.Similar to DeFi, each platform has its own dedicated spell table, like `opensea.trades`. When analyzing a single marketplace, its dedicated table is preferable.

### Other spell tables

In addition to the tables mentioned above, there are many other spell tables created by the Dune community. New spell tables are continually added over time.

To learn more, you can check the [Dune Spellbook documentation](https://spellbook-docs.dune.com/#!/overview)

## Community and User generated tables

As mentioned previously, the two main community-sourced datasets currently on Dune are `flashbots` and `reservoir`.The Dune documentation provides introductions to these tables:

[Dune Community-source tables](https://dune.com/docs/data-tables/community/)

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch05/ch05-sql-basics-part1.md">
# 05 SQL Basics (I)

## Basic Concepts

### 1. What is a data warehouse?

Simply put, a data warehouse is a structured storage of data for statistical purposes. The storage carrier is [**data tables**].  A series of [**data tables**] grouped together for one or multiple subjects is called a data warehouse. Note: the data here can be result data (e.g. daily trading volume of a trading pair on Uniswap since its launch) It can also be process data (every transaction record of a trading pair on Uniswap since launch: who initiated it, trading A for B, transaction time, tx_hash, amount, etc.).

**2. What is SQL?**

Let's say you want some crispy Nestle chocolate bars, but you can't go out right now. So you ask someone to run the errand for you: "I need a box of chocolate bars, the brand is Nestle". The errand runner goes to the supermarket, buys the chocolate and delivers it to your home.
Similarly, SQL is like the sentence you spoke, Dune Analytics is the errand runner. It allows you to converse with the data warehouse and retrieve data from it. The most basic structure or syntax of SQL has 3 components, almost all SQL will contain these 3 parts:

**select**: Which fields to retrieve?

**from**: From which table to retrieve?

**where**: What are the criteria?

**3. What does a data table look like?**

You can think of a table as an Excel sheet, with each sheet containing different data. Take `ethereum.transactions` (Ethereum transaction records) as an example:

![](img/ch05_query-page.png)

There are some commonly used fields in tables:

- **block_time**: Timestamp when the transaction was mined
- **block_number**: Block height where the transaction was mined
- **value**: Amount of ETH transferred (need to divide by power(10,18) for decimal precision)
- **from**: Wallet address where the ETH was sent from
- **to**: Wallet address where the ETH was sent to
- **hash**: Transaction hash of this transaction
- **success**: Whether the transaction succeeded

## Common Syntax and Use Cases

### 1. Basic Structure, Operators, Sorting

**Case 1**: I want to see when Sun's wallet (0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296) had large ETH transfers (>1000 ETH) since January 2022, and the specific amounts transferred.

#### SQL

``` sql
select -- Select fields to query, separate multiple fields with commas
    block_time
    ,"from"
    ,"to"
    ,hash
    ,value /power(10,18) as value -- Convert value to decimal by dividing by power(10,18), 18 is Ethereum's precision
from ethereum.transactions -- Get data from ethereum.transactions table
where block_time > date('2022-01-01') -- Limit block_time to be after Jan 1, 2022
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296 -- Limit to Sun's wallet
and value /power(10,18) >1000 -- Limit ETH transfer value > 1000
order by block_time -- Sort by block_time in ascending order,desc for descending order
```

![](img/ch05_query-page2.png)

#### Dune Query URL

[https://dune.com/queries/1523799](https://dune.com/queries/1523799)

#### Syntax Explanation

- SELECT
  - SELECT followed by fields to query, separate multiple fields with commas
- FROM
  - FROM followed by source table
- WHERE
  - WHERE followed by filters on the data
- Operators: and / or
  - Use operators to connect multiple filters
    - and: intersection of multiple filters
    - or: union of multiple filters
- Sorting: order by [fieldA], sort in ascending order by fieldA, add desc at the end for descending order
- Power calculation: used to convert Value precision, syntax is Power(Number, Power), where Number is base and Power is exponent
- Change case of strings
  - lower(): convert string to lowercase
  - upper(): convert string to uppercase

### 2. Aggregate Functions

**Case 2**: the table contains detailed data. I don't want to see the specifics, I just want to understand the overview through some aggregated stats.

#### SQL

``` sql
select
    sum( value /power(10,18) ) as value -- Sum the value field
    ,max( value /power(10,18) ) as max_value -- Get max value
    ,min( value /power(10,18) )  as min_value -- Get min value
    ,count( hash ) as tx_count -- Count number of rows
    ,count( distinct to ) as tx_to_address_count -- Count number of rows for qualifying data (dedupe by to address)
from ethereum.transactions -- Get data from ethereum.transactions table
where block_time > date('2022-01-01') -- Limit block_time to be after Jan 1, 2022
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
and value /power(10,18) > 1000 -- Limit ETH transfer value > 1000
```

![](img/ch05_query-page3.png)

#### Dune Query URL

[https://dune.com/queries/1525555](https://dune.com/queries/1525555)

#### Syntax Explanation

- Aggregate functions
  - count(): count, number of rows; add distinct inside () for dedupe
  - sum(): sum
  - min(): minimum
  - max(): maximum
  - avg(): average

### 3. Date/Time Functions, Aggregation by Groups

**Case 3**: I don't want to just see a single number, I want to see trends broken down by hour/day/week.

#### 3.1 Convert timestamp to hour/day/week format for further aggregated analysis

##### SQL

``` sql
-- Convert seconds-level timestamp to day/hour/minute (for further aggregation by day or hour)

select -- Select fields to query, separate multiple fields with commas
    block_time -- Timestamp of when the transaction happened
    ,date_trunc('hour',block_time) as stat_hour -- Convert to hour
    ,date_trunc('day',block_time) as stat_date -- Convert to day
    ,date_trunc('week',block_time) as stat_week -- Convert to week
    ,"from"
    ,"to"
    ,hash
    ,value /power(10,18) as value -- Convert value by dividing by power(10,18), 18 is Ethereum's precision
from ethereum.transactions -- Get data from ethereum.transactions table
where block_time > date('2021-01-01') -- Limit block_time to be after Jan 1, 2021
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
and value /power(10,18) >1000 -- Limit ETH transfer value > 1000
order by block_time -- Sort by block_time ascending, add desc at end for descending
```

![](img/ch05_query-page4.png)

##### Dune Query URL

[https://dune.com/queries/1527740](https://dune.com/queries/1527740)

##### Syntax Explanation

- DATE_TRUNC('datepart', timestamp)
  - Timestamp truncation function
  - Returns different results based on datepart parameter:
    - minute: Truncate timestamp to minute
    - hour: Truncate timestamp to hour
    - day: Truncate timestamp to day
    - week: Truncate timestamp to Monday of the week
    - year: Truncate timestamp to first day of the year

#### 3.2 Aggregate by groups using group by + sum based on the processed time fields from before

##### SQL

``` sql
select
    date_trunc('day',block_time) as stat_date
    ,sum( value /power(10,18) ) as value -- Sum the value field for qualifying data
from ethereum.transactions -- Get data from ethereum.transactions table
where block_time > date('2022-01-01') -- Limit block_time to be after Jan 1, 2022
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
and value /power(10,18) > 1000 -- Limit ETH transfer value > 1000
group by 1
order by 1
```

![](img/ch05_query-page5.png)

##### Dune Query URL

[https://dune.com/queries/1525668](https://dune.com/queries/1525668)

##### Syntax Explanation

- Aggregation by groups (`group by`):
  The syntax for aggregation by groups is `group by`. As the name suggests, it groups first then aggregates, and needs to be used together with aggregate functions.

![](img/ch05_group-by-case.png)

Let's say the table above shows household expenses (3 people) for the first 2 months of 2020. If you just use `sum`, you would only get the total of 12900. If you want to get the 2 types of aggregated data on the right, you need to use group by (group by `Person` or group by `Month`).

### 4. Join, Subquery

**Case 4**: I want to look at Sun's transfers behavior from the perspective of USD value of ETH transferred out.

#### 4.1 The transfers show ETH's amount and I want to see the USD value for each transfer

##### SQL

``` sql
select
     block_time
     ,transactions_info.stat_minute  as stat_minute
    ,"from"
    ,"to"
    ,hash
    ,eth_amount -- Convert value by dividing by power(10,18), 18 is Ethereum's precision
    ,price
    ,eth_amount * price as usd_value
from
(
    select -- Select fields to query, separate multiple fields with commas
        block_time
        ,date_trunc('minute',block_time) as stat_minute -- Truncate block_time to minute as the primary key
        ,"from"
        ,"to"
        ,hash
        ,value /power(10,18) as eth_amount -- Convert value by dividing by power(10,18), 18 is Ethereum's precision
    from ethereum.transactions -- Get data from ethereum.transactions table
    where block_time > date('2022-01-01') -- Limit block_time to be after Jan 1, 2022
    and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
    and value /power(10,18) >1000 -- Limit ETH transfer value > 1000
    order by block_time -- Sort by block_time ascending, add desc at end for descending
) transactions_info
left join -- Join transactions_info with price_info, using left join
(
    -- prices.usd table contains minute-level price data
    select
        minute as stat_minute
        ,price
    from prices.usd
    where blockchain = 'ethereum' -- Get Ethereum prices
    and symbol = 'WETH' -- Get WETH data
) price_info on transactions_info.stat_minute = price_info.stat_minute -- Join with stat_minute field
```

![](img/ch05_leftjoin.png)

##### Dune Query URL

[https://dune.com/queries/1528027](https://dune.com/queries/1528027)

##### Syntax Explanation

- Join query
  - In most cases, the data we need is not in the same table. For example, the transactions table only contains transaction data, not price data. If we want to calculate the USD value of transactions, we need to join these two tables.
  - A join query can be understood as combining two tables based on some condition to form a virtual table. You can then easily process this virtual table.
- A join query has two components:
  - Join method (join, left join, right join, cross join, full join)
  - Join condition (on)
- The most commonly used are join and left join. Take these two examples to explain the specific usage

![](img/ch05_query-2.png)

```
- join: Joins two tables based on the join condition (on), taking the intersection
  - Table A and Table B are joined on Name, the intersection is Xiaoming and  Xiaohong. Since join takes the intersection, the final result will only have Xiaoming and Xiaohong
  - All records from both tables that meet the criteria need to be joined. Because Table B has 2 records for Xiaoming, the joined result will also have 2 records for Xiaoming
  - left join: Takes the left table as primary and joins the right table on the join condition (on), filling with null if no join is found
  - Table A and Table B are joined on Name. Since the left table is primary, even though Xiaolan and Xiaoqing from the left table have no matching join records in the right table, Xiaolan and Xiaoqing will still appear in the result, with the right table portion filled with null.
```

#### 4.2 Aggregate the detailed data from 4.1 by day, without too many levels of nested SQL

##### SQL

``` sql
with transactions_info as -- Create subquery named transactions_info
(
    select
         block_time
         ,transactions_info.stat_minute  as stat_minute
        ,"from"
        ,"to"
        ,hash
        ,eth_amount -- Convert value by dividing by power(10,18), 18 is Ethereum's precision
        ,price
        ,eth_amount* price as usd_value
    from
    (
        select -- Select fields to query, separate multiple fields with commas
            block_time
            ,date_trunc('minute',block_time) as stat_minute -- Truncate block_time to minute
            ,"from"
            ,"to"
            ,hash
            ,value /power(10,18) as eth_amount -- Convert value by dividing by power(10,18), 18 is Ethereum's precision
        from ethereum.transactions -- Get data from ethereum.transactions table
        where block_time > date('2022-01-01') -- Limit block_time to be after Jan 1, 2022
            and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
            and value /power(10,18) >1000 -- Limit ETH transfer value > 1000
        order by block_time -- Sort by block_time ascending, add desc at end for descending
    ) transactions_info
    left join -- Join transactions_info with price_info, using left join
    (
        -- prices.usd table contains minute-level price data
        select
            minute as stat_minute
            ,price
        from prices.usd
        where blockchain = 'ethereum' -- Get Ethereum prices
            and symbol = 'WETH' -- Get WETH data
    ) price_info on transactions_info.stat_minute = price_info.stat_minute -- Join key is stat_minute
)

select date_trunc('day',block_time) as stat_date
    ,sum(eth_amount) as eth_amount
    ,sum(usd_value) as usd_value
from transactions_info -- Get data from 'virtual table' transactions_info
group by 1
order by 1
```

![](img/ch05_query-page-1.png)

##### Dune Query URL

[https://dune.com/queries/1528564](https://dune.com/queries/1528564)

##### Syntax Explanation

- Subquery (with as)
  - with as can be used to construct a subquery, turning the result of some SQL into a 'virtual table' (similar to a view or subquery). The subsequent SQL can then directly retrieve data from this 'virtual table'.
  - Through with as, the readability of SQL logic can be improved, and multiple nestings can also be avoided.

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch06/ch06-sql-basics-part2.md">
# 06 SQL Basics (II)

In the "SQL syntax (I)" section, we covered the fundamentals of SQL,including SQL query statement infrastructure syntax, datetime, group by, with as and join.Next, we continue to introduce some common fundamentals of SQL.

## Commonly used Date functions and Interval

In the context of blockchain, data is recorded and stored in the order of transaction occurrences. When conducting daily data analysis, it is often necessary to perform statistical operations on data within specific time periods. In the previous section, we introduced the `date_trunc()` function, which allows us to truncate date values at specified intervals such as days, weeks, or hours. Furthermore, there are several commonly used functions and their respective usage.

### 1.Now() and Current_Date() functions

The `now()` function is used to get the date and time of the current system.Note that it is internally stored with hour, minute and second values, but Dune's query editor only displays "hour:minute" by default.When we want to correlate the date field with the `minute` field in the `prices.usd` table, we must first intercept by minute.Otherwise,the correct price record may not be associated.

The  `current_date()` function is used to get the current date (without the hours, minutes and seconds part).When filtering data by date and time, we often need to combine these functions and use relevant date functions to obtain the exact date or time. The `current_date()` function is equivalent to using `date_trunc('day', now())`, which extracts the day value from the result of `now()`. You can also omit the parentheses of `current_date()` and write it as `current_date` directly.

``` sql
select now() -- current datetime
    ,current_date() -- current date
    ,current_date   -- current date
    ,date_trunc('day', now()) -- same as current_date
```
    
### 2.DateAdd(), Date_Add(), Date_Sub() and DateDiff() functions

The `dateadd(unit, value, expr)` function  adds a datetime unit to a date expression. Here the "date and time units" using constants, commonly used are HOUR, DAY, WEEK, MONTH and so on.The value can be a negative number, which means that the corresponding date and time unit is subtracted from the following expression.It is also because a negative number can be used to indicate the subtraction of a datetime interval that the `datesub()` function is not needed and indeed not available.

The `date_add(startDate, numDays)` function adds or subtracts the specified number of days to a date expression and returns another date.Parameter numDays for a positive number of days after the specified date to return to the `startDate`, for a negative number of days before the specified date to return.The function `date_sub (startDate, numDays)`is similar, but the meaning of the opposite, a negative number indicates the date after the return, and a positive number indicates the previous date.

The function `datediff(endDate, startDate)` returns the number of days between two date expressions.If `endDate` is after `startDate`, it returns a positive value, before it returns a negative value.

The SQL example is as follows:

``` sql
select date_add('MONTH', 2, current_date) -- Add 2 months to current date
    ,date_add('HOUR', 12, now()) -- Add 12 hours to current date
    ,date_add('DAY', -2, current_date) -- Subtract 2 days to current date 
    ,date_add('DAY', 2, current_date) -- Add 2 days to current date
    ,date_add('DAY', -5, current_date) -- Subtract 5 days to current date 
    ,date_diff('DAY', date('2022-11-22'), date('2022-11-25')) -- the difference between two date, return negtivate value
    ,date_diff('DAY', date('2022-11-25'), date('2022-11-22'))  -- the difference between two date, return positive value
```

### 3.INTERVAL type

Interval is a datatype that represents an interval of time in specified datetime units. The time interval represented by Interval is very convenient to use, avoiding being troubled by the previous date functions with similar names and similar functions.

``` sql
select now() - interval '2' hour -- 2 hours ago
    ,current_date - interval '7' day -- 7 days ago
    ,now() + interval '1' month -- 1 month after now
```

For a description of more date-time related functions, see [Date and time functions and operators](https://trino.io/docs/current/functions/datetime.html)
<a id="jump_8"></a>

## Conditional expressions Case, If

When conditional logic needs to be applied, the `case` statement can be used. The general syntax for the CASE statement is `CASE {WHEN cond1 THEN res1} [...] [ELSE def] END`. This statement allows an expression to be evaluated under multiple conditions and returns the value corresponding to the first condition that evaluates to True. If none of the conditions are satisfied, the value specified after `else` is returned. The `else` part is optional, and if omitted, NULL is returned.

We have used the CASE statement many times in the "Lens Practice Case: Creator Profile Domain Name Analysis" section. Some of the code excerpts are as follows:

``` sql
-- ...skip some code...

profiles_summary as (
    select (
            case
                when length(short_name) >= 20 then 20 -- if the length of profile name greater than 20, then set to 20
                else length(short_name) -- if the length of profile name less than 20, use the original length
            end) as name_length, -- rename case column to a new name
        handle_type,
        count(*) as name_count
    from profile_created
    group by 1, 2
),

profiles_total as (
    select count(*) as total_profile_count,
        sum(case
                when handle_type = 'Pure Digits' then 1 -- if the handle_type equal to 'Pure Digits', return 1
                else 0  -- else return 0
            end
        ) as pure_digit_profile_count,
        sum(case 
                when handle_type = 'Pure Letters' then 1 
                else 0  
            end
        ) as pure_letter_profile_count
    from profile_created
)

-- ...skip some code...
```

As you can see, through the CASE statement we can flexibly convert the data according to actual needs to facilitate subsequent statistical summary.

Related links for the above example query:

- Query:[https://dune.com/queries/1535541](https://dune.com/queries/1535541)
- Description: [Lens Creator Profile Domain Name Analysis](https://sixdegreelab.gitbook.io/mastering-chain-analytics/ru-men-jiao-cheng/06_pratical_case_lens_protocol)

The function `if(cond, expr1, expr2)` returns one of two expressions, depending on whether the condition evaluates to true or false. If the condition evaluates to a true value, the first expression is returned, and if it evaluates to a false value, the second expression is returned.

``` sql
select if(1 < 2, 'a', 'b') -- if the condition result is true, return 'a', else return 'b'
    ,if('a' = 'A', 'case-insensitive', 'case-sensitive') 
 ```

## Common functions for string processing

1. Substring() function

When there are certain situations where we have to work with the original data table `transactions` or `logs` and decode the `data` therein, we need to extract part of the string from it first, and then carry out the targeted conversion process, at this time we need to use the Substring function. The syntax of the Substring function is `substring( expr, pos [, len])` or `substring (expr FROM pos [FOR len] ] )`, that in the expression `expr`, starting from the position `pos`, intercept `len` characters and return. If `len` is omitted, the string is intercepted until the end of the string.

2. Concat() Function and the || Operator

The function `concat(expr1, expr2 [, ...])` strings multiple expressions together. ) concatenates multiple expressions together and is often used to link strings. The operator `||` has the same function as Concat.

``` sql
select concat('a', ' ', 'b', ' c') -- concat multi string
    , 'a' || ' ' || 'b' || ' c' -- same as concat
```

3. Right() function

"The `right(str, len)` function retrieves `len` characters from the right side of the string `str`. In our case, the original data table, like `logs`, contains connected groups of 64 characters stored in the `data`.For the contract address or user address, it is represented by 40 characters.  When saving, it will be filled with `0` on the left to make up the 64-bit length. When extracting the address, we need to retrieve the 40 rightmost characters and add the '0x' prefix to restore it to the correct address format.

Note that in Dune SQL, directly using the `right()` function may return a syntax error, which can be solved by putting the function name in double quotes, that is, using `"right"()`. Since this method is cumbersome, you can leverage the substring function with a negative start position parameter to perform the right-side extraction with ease.

The following is a comprehensive example of using the above functions. This example decodes the cross-chain to Arbitrum records from the `logs` table, using several methods comprehensively:

``` sql
select date_trunc('day', block_time) as block_date, --truncate a timestamp to day
    concat('0x', "right"(substring(cast(data as varchar), 3 + 64 * 2, 64), 40)) as address, -- Extract the third part of the data column and convert it into an address, starting from the third character, each 64 characters as a group.
    concat('0x', "right"(substring(cast(data as varchar), 3 + 64 * 3, 64), 40)) as token, -- Extract part 4 of data and convert it to address
    concat('0x', substring(substring(cast(data as varchar), 3 + 64 * 3, 64), -40, 40)) as same_token, -- Extract part 4 of data and convert it to address
    substring(cast(data as varchar), 3 + 64 * 4, 64) as hex_amount, -- Extract part 5 of data column
    bytearray_to_uint256(bytearray_substring(data, 1 + 32 * 4, 32)) as amount, -- Extract part 5 of data column and convert it to decimal
    tx_hash
from ethereum.logs
where contract_address = 0x5427fefa711eff984124bfbb1ab6fbf5e3da1820   -- Celer Network: cBridge V2 
    and topic0 = 0x89d8051e597ab4178a863a5190407b98abfeff406aa8db90c59af76612e58f01  -- Send
    and substring(cast(data as varchar), 3 + 64 * 5, 64) = '000000000000000000000000000000000000000000000000000000000000a4b1'   -- 42161
    and substring(cast(data as varchar), 3 + 64 * 3, 64) = '000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc2' -- WETH
    and block_time >= now() - interval '30' day
limit 10
```

Related links for the example query above:

- Query:[https://dune.com/queries/1647016](https://dune.com/queries/1647016)
- Description: [String Functions and Operators](https://trino.io/docs/current/functions/string.html)

## Window function

The combination of multiple rows of data becomes a window (Window). A function that operates on a set of rows in a window and calculates the return value for each row based on the set of rows is called a window function.Window functions prove invaluable for various processing tasks, such as computing moving averages, cumulative statistics, or accessing the value of a row based on its relative position within the current row's window.The common syntax format of a window function is as follows:"

``` sql
function OVER window_spec
```

Among them, `function` can be a ranking window function, an analysis window function or an aggregation function. `Over` is a fixed keyword that must be used. There are two possible changes in the `window_spec` part: partition by `partition_feild order by order_field` or `order by order_field`, respectively indicating partition first and then sort and direct sort without partition. Except for the case where all rows are treated as the same group, the grouping function must be used with `order by`.

1. LEAD(), LAG() functions

The Lead() function returns the value of the specified expression from subsequent rows within the partition. Its syntax is `lead(expr [, offset [, default] ] )`. The Lag() function returns the value of the specified expression from the preceding row in the partition. These two functions are very useful when we need to compare the value of a column in the result set with the value of the same column in the previous or next row (of course, values can also be taken at intervals of multiple rows).

Our previous tutorial described a query to count the number of new pools added daily to Uniswap V3 for the last 30 days. Its SQL is:

``` sql
with pool_details as (
    select date_trunc('day', evt_block_time) as block_date, evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
    where evt_block_time >= now() - interval '29' day
)

select block_date, count(pool) as pool_count
from pool_details
group by 1
order by 1
```

If we want to add a curve to show the change in the number of new fund pools every day based on the current bar chart, we can use the Lag() function to calculate the change value of each day compared to the previous day, and then visualize it. In order to keep the logic clear, we added a CTE, and the modified SQL is as follows:

``` sql
with pool_details as (
    select date_trunc('day', evt_block_time) as block_date, evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
    where evt_block_time >= now() - interval '29' day
),

pool_summary as (
    select block_date,
        count(pool) as pool_count
    from pool_details
    group by 1
    order by 1
)

select block_date,
    pool_count,
    lag(pool_count, 1) over (order by block_date) as pool_count_previous, -- use the lag function to get previous day
    pool_count - (lag(pool_count, 1) over (order by block_date)) as pool_count_diff -- Subtract to get the change value
from pool_summary
order by block_date
```

Add `pool_count_diff` to the visualisation chart (using the right hand axis and choosing Line for the graph type) as shown below:

![](img/ch06_part_2_01.png)

The Lead() function proves to be a valuable tool when we wish to perform "forward" comparisons of data across various rows. For example, we previously prpesented a query that identified the creator accounts with the highest post counts in the Lens instance. Now, we shall refine this query to retrieve the top 50 accounts with the highest post counts. With this refined dataset, we can delve into comparing the differences in the number of posts among these top accounts. Specifically, we will examine the variance between the first and second positions, the second and third positions, and so on.The key part of the query code is as follows:

``` sql
with post_data as (
    -- To obtain the detailed data of the original post, please refer to the Dune SQL link
),

top_post_profiles as (
    select profile_id,
        count(*) as post_count
    from post_data
    group by 1
    order by 2 desc
    limit 50
)

select row_number() over (order by post_count desc) as rank_id, -- Generate consecutive numbers to indicate ranking
    profile_id,
    post_count,
    lead(post_count, 1) over (order by post_count desc) as post_count_next, -- Get the post data of the next line
    post_count - (lead(post_count, 1) over (order by post_count desc)) as post_count_diff -- Calculate the difference between the number of posts in the current row and the next row
from top_post_profiles
order by post_count desc
```
The query results are shown in the figure below, where we can see that there are very small differences in the number of posts between some accounts:

![](img/ch06_part_2_02.png)

Full SQL reference link:
- [https://dune.com/queries/1647422](https://dune.com/queries/1647422)

2. Row_Number() function

Row_Number() is a powerful window function of the ranking type, primarily used to assign distinct row numbers based on a specified sorting method. These row numbers start from 1 and increment consecutively. In a previous example, we employed Row_Number() with the syntax `row_number() over (order by post_count desc) as rank_id` to generate row numbers representing the ranking of our data, so we won't delve into another example here.If combined with the `partition by` partition clause, Row_Number() will start numbering from 1 within each partition. Using this feature, we can use it to implement some advanced screening. For example, we have a group of Token addresses, and we need to calculate and return their average price in the last 1 hour.Due to potential delays in data from sources like Dune, filtering by the "hour" value of the current system date may not always yield the desired price data. To ensure accuracy, a more cautious approach is to widen the time range and then filter out the most recent record for each Token. This way, even if the data is delayed by several hours, our queries will continue to function correctly.To achieve this, we can utilize the Row_Number() function along with the `partition by` clause. The process involves generating row numbers for each partition, and then filtering out the required data based on these row numbers.

``` sql
with latest_token_price as (
    select date_trunc('hour', minute) as price_date, -- group by hour
        contract_address,
        symbol,
        decimals,
        avg(price) as price -- Calculate average price
    from prices.usd
    where contract_address in (
        0xdac17f958d2ee523a2206206994597c13d831ec7,
        0x2260fac5e5542a773aa44fbcfedf7c193bc2c599,
        0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,
        0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48,
        0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9
    )
    and minute > now() - interval '1' day -- Fetch data within the last day to make sure it works well even if the data is delayed
    group by 1, 2, 3, 4
),

latest_token_price_row_num as (
    select  price_date,
        contract_address,
        symbol,
        decimals,
        price,
        row_number() over (partition by contract_address order by price_date desc) as row_num -- Generate row numbers by contract_address
    from latest_token_price
)

select contract_address,
    symbol,
    decimals,
    price
from latest_token_price_row_num
where row_num = 1 -- Filter out the latest average price of each token by row number 1
```

The above query results are shown in the figure below:

![](img/ch06_part_2_03.png)

Full SQL reference link:
- [https://dune.com/queries/1647482](https://dune.com/queries/1647482)

More complete information on window functions:
- [Window functions](https://trino.io/docs/current/functions/window.html)

## Array_agg() function

If you want to combine a certain column of each row of data in the query result set, you can use the array_agg() function. If you want to merge multiple columns of data together (imagine exporting the query results as CSV), you can consider using the string concatenation method described above to combine multiple columns of data into one column, and then apply the array_agg() function. Here is a simple example:

``` sql
select array_agg(contract_address) from
(
    select contract_address 
    from ethereum.logs
    where block_time >= current_date
    limit 10
) t
```

## Summary

Each database has dozens or even hundreds of built-in functions, and what we introduce here is only a small part of the commonly used functions. If you want to become a proficient data analyst, we highly recommend reading and understanding the usage of each of the built-in functions here:[Trino functions](https://trino.io/docs/current/functions.html).

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch07/ch07-practice-build-lens-dashboard-part1.md">
# 07 Practice - Build Lens Dashboard (I)

In order to let everyone get started with data analysis as soon as possible, we will put some theoretical content in the subsequent part of the tutorial, and the first half will explain more about some content that can be combined with practice. In this section, let's make a data dashboard for the Lens Protocol project.

## What is the Lens Protocol?

The introduction from the [Lens website](https://docs.lens.xyz/docs/what-is-lens) is as follows: Lens Protocol (Lens Protocol, Lens for short) is a Web3 social graph ecosystem on the Polygon blockchain. It is designed to allow creators to own their connections to the community, forming a fully composable, user-owned social graph. The protocol was built with modularity in mind from the start, allowing new features to be added and bugs fixed, while ensuring the immutability of user-owned content and social connections. Lens aims to solve some of the major problems in existing social media networks. The Web2 network all reads data from its proprietary centralized database. Users' profiles, friendships, and content are locked into specific networks, and ownership of them rests with the network operator. Networks compete with each other for user attention, becoming a zero-sum game. Lens rectifies this by being an open social graph owned by the user and accessible by any application. Since users own their data, they can bring it to any application built on top of the Lens protocol. As the true owners of their content, creators no longer need to worry about losing their content, audiences, and revenue streams based on sudden changes in individual platform algorithms and policies. Furthermore, the far-reaching impact of Lens extends to the entire ecosystem. Each application utilizing the Lens protocol contributes to the collective advancement, transforming what used to be a zero-sum game into a collaborative and synergistic endeavor.

The following roles (entities) are involved in the Lens protocol: personal Profile, Publication, Comment, Mirror, Collect, Follow. At the same time, there are three types of NFTs in the protocol, namely: Profile NFT, Follow NFT, and Collect NFT.

Typical usage scenarios on Lens include:

- Creators register to create their Profile and mint their exclusive ProfileNFT. You can set a personalized name (Profile Handle Name, which can be simply compared to a domain name, that is, "Lens domain name"). At the same time, you can set the URL of the account avatar picture and the rules when you are followed (by setting special rules, you can generate revenue, for example, you can set that users need to pay a certain fee to follow the Profile). Currently only addresses on the allow list can create profile accounts.
- Creators publish Publications, including Posts, Mirrors, Comments, etc.
- In the relevant operation steps, 3 different types of NFTs are respectively minted and transferred to different user addresses.

## The main analysis content of the Lens Protocol

For a project like Lens, we can analyze its overview as a whole, or conduct data analysis from different angles and for different types of roles. Here is an overview of some of the things that can be analyzed:
- Total number of users, total number of creators, proportion of creators, etc.
- Total number of publications, total number of comments, total number of mirrors, total number of followers, total number of favorites, etc.
- User-related analysis: the number of new users per day, the number of new creators per day, the number of active users per day, the number of active creators, the trend of overall user activity, etc.
- Analysis of the personalized domain names of Lens accounts: the number of domain name registrations, the registration status of different types of domain names (pure numbers, pure letters, different lengths), etc.
- Creator activity analysis: number of publications released, number of times followed, number of times mirrored, most popular creators, etc.
- Related analysis of publications: number of published content, growth trend, number of followers, number of favorites, most popular publications, etc.
- Related analysis of followers: the number of followers and their changing trends, cost analysis of followers, users who follow creators the most, etc.
- Related analysis of favorites: daily number of favorites, popular favorites, etc.
- Creator's income analysis: income generated through attention, other income, etc.
- Relevant analysis from the perspective of NFT: daily casting quantity, costs involved (focus on fees), etc.

There is a wealth of content that can be analysed. In this dashboard, we only use some of the contents as a case. Please try to analyze other content separately.

## Data Table introduction

On the [deployed smart contract](https://docs.lens.xyz/docs/deployed-contract-addresses) page of the official Lens document, it is prompted to use the smart contract LensHub Proxy (LensHub Proxy) as the main contract for interaction. Except for a small number of NFT-related queries that need to use the data table under the smart contract FollowNFT, we basically focus on the decoded table under the smart contract LensHub. The figure below lists part of the data table under this smart contract.

![](img/ch07_image_01.png)

As mentioned in the previous tutorial, there are two types of decoded smart contract data tables: event log table (Event Log) and function call table (Function Call). The two types of tables are named in the format: `projectname_blockchain.contractName_evt_eventName` and :`projectname_blockchain.contractName_call_functionName` respectively. Browsing the list of tables under the LensHub contract, we can see the following main data tables:
- collect/collectWithSig
- comment/commentWithSig
- createProfile
- follow/followWithSig
- mirror/mirrorWithSig
- post/postWithSig
- Transfer

Except for the Transfer table, which is an event table, the remaining tables mentioned are function call tables. The data table with the `WithSig` suffix signifies operations performed through signature authorization. This allows the use of API or enables other authorized parties to perform specific operations on behalf of a user. It is important to aggregate data from related tables when analyzing types such as post tables in order to gain a comprehensive understanding.

In the provided list, there are several other data tables with different methods. These tables are all generated under the LensHub smart contract, and they interact with the LensHub address, specifically `0xdb46d1dc155634fbc732f92e853b10b288ad5a1d`. To analyze the overall user data of Lens, it is recommended to query the polygon.transactions original table to extract data associated with this contract address. This will provide a complete dataset for analysis purposes.

## Overview analysis of Lens Protocol

By looking at [the LensHub smart contract creation transaction details](https://polygonscan.com/tx/0xca69b18b7e2daf4695c6d614e263d6aa9bdee44bee91bee7e0e6e5e5e4262fca), we can see that the smart contract was deployed on May 16, 2022. When we query raw data tables such as the polygon.transactions raw table, by setting date and time filter conditions, query execution performance can be greatly improved.

### Total number of transactions and total number of users
As mentioned earlier, the most accurate data source for querying the number of users is the original `polygon.transactions table`. We can use the following query to query the current number of transactions and the total number of users of Lens. We directly query all transaction records sent to the LensHub smart contract, and use the `distinct` keyword to count the number of independent user addresses. Since we know the creation date of the smart contract, we use this date as a filter condition to optimize the query performance.

``` sql
select count(*) as transaction_count,
    count(distinct "from") as user_count    -- count unique users
from polygon.transactions
where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
    and block_time >= date('2022-05-16')  -- contract creation date
```

Create a new query using the SQL code above, run the query to get the results and save the Query. Then add two `Counter` types to the visualisation chart with the titles set to "Lens Total Transactions" and "Lens Total Users". Lens Total Users".

Reference link for this query on Dune:[https://dune.com/queries/1533678](https://dune.com/queries/1533678)

Now we can add visualization charts to the dashboard. Since this is our first query, we can create a new dashboard in the Add Visualization to Dashboard popup dialog. Switch to the first Counter, click the "Add to dashboard" button, in the dialog box, click the "New dashboard" button at the bottom, enter the name of the data dashboard, and click the "Save dashboard" button to create a blank data dashboard. I use "Lens Protocol Ecosystem Analysis" here as the name of the board. After saving, we can see the newly created data dashboard in the list, and click the "Add" button on the right to add the current Counter to the data dashboard. Switching to another Counter after closing the dialog will also add it to the newly created data dashboard.

At this point, we can click the "My Creations" link at the head of the Dune website, and then select the "Dashboards" Tab to switch to the data dashboard list. Click the name of our newly created board to enter the preview interface of the board. We can see the two Counter type visualizations we just added. Here, by clicking the "Edit" button to enter the edit mode, you can adjust the size and position of the chart accordingly, and you can click the "" button to add text components to explain or beautify the data dashboard. The figure below is an example of the interface of the adjusted data dashboard.

![](img/ch07_image_02.png)

The link to our newly created data dashboard is:[Lens Protocol Ecosystem Analysis](https://dune.com/sixdegree/lens-protocol-ecosystem-analysis)

### Number of transactions and unique users by day

To analyze the growth trend of the Lens protocol in terms of activity, we can create a query that counts the number of transactions and the number of active user addresses per day by date. By adding the `block_time` field to the query and using the `date_trunc()` function to convert it into a date (excluding the numerical part of the hour, minute, and second), combined with the `group by` query clause, we can count the daily data. The query code is shown below:

``` sql
select date_trunc('day', block_time) as block_date,
    count(*) as transaction_count,
    count(distinct "from") as user_count
from polygon.transactions
where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
    and block_time >= date('2022-05-16')  -- contract creation date
group by 1
order by 1
```

Save the query and add two visual charts of `Bar Chart` type, select `transaction_count` and `user_count` for `Y column 1`, and set the titles of the visual charts as "Lens Daily Transactions" and "Lens Daily Users" respectively. Add them to the data dashboard. The result is shown in the figure below:

![](img/ch07_image_03.png)

Often when querying statistics by date, we can summarise the relevant data by date, calculate the cumulative value and add it to the same visual chart as the daily data to have a more intuitive understanding of the overall trend of data growth. This is easily achieved by using the `sum() over ()` window function. In order to keep the logic simple and easy to understand, we always prefer to use CTEs to break down complex query logic into multiple steps. Modify the above query as:

``` sql
with daily_count as (
    select date_trunc('day', block_time) as block_date,
        count(*) as transaction_count,
        count(distinct "from") as user_count
    from polygon.transactions
    where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
        and block_time >= date('2022-05-16')  -- contract creation date
    group by 1
    order by 1
)

select block_date,
    transaction_count,
    user_count,
    sum(transaction_count) over (order by block_date) as accumulate_transaction_count,
    sum(user_count) over (order by block_date) as accumulate_user_count
from daily_count
order by block_date
```

Once the query is executed, we can adjust the two visualisation charts we added earlier. Select `accumulate_transaction_count` and `accumulate_user_count` under `Y column 2` respectively to add them as a second indicator value to the chart. The default charts do not display well because the cumulative values are often not in the same order of magnitude as the daily values. We can do this by selecting the "Enable right y-axis" option, and then setting the newly added second column to use the right axis, and modifying its "Chart Type" to " Area" (or "Line", "Scatter"), so that the chart will look better.

In order to compare the number of daily transactions with the number of daily active users, we can add another visualisation with the title "Lens Daily Transactions VS Users", and select the transaction_count and user_count columns on the Y-axis. count columns on the Y-axis. Again, since the two values are not in the same order of magnitude, we enable the right axis, set user_count to use the right axis, and choose the chart type "Line". This chart is also added to the Data Kanban board. Looking at this chart, we can see that in a few days at the beginning of November 2022, Lens saw a new peak in daily transactions, but the increase in the number of daily active users was not as pronounced.

It is important to note that because the same user may have used Lens on different days, when we aggregate data from multiple days, the cumulative number of users does not represent the actual total number of unique users, but rather is greater than the actual total number of users. If we need to count the number of new unique users per day and their total number, we can first obtain the earliest transaction records of each user, and then use the same method to aggregate statistics by day. We will not expand on the details here, please try it yourself. In addition, if you want to weekly, monthly statistics, just Fork this query, modify the `date_trunc ()` function for the first parameter "week" or "month" can be achieved. For comparison, we Forked and modified a query for monthly statistics, and only added the "" to the DataWatcher.

Once the adjustment is complete, the charts in dashoboard will automatically update to the latest display, as shown in the figure below.

![](img/ch07_image_04.png)

Reference links for the above two queries on Dune:
- [https://dune.com/queries/1534604](https://dune.com/queries/1534604)
- [https://dune.com/queries/1534774](https://dune.com/queries/1534774)

## Creator profile data analysis

Lens creator profile accounts are currently limited to users within the licence whitelist to create, and the data for creating profiles is stored in the `createProfile` table. Using the following query, we can calculate the number of profiles that have been created so far.

``` sql
select count(*) as profile_count
from lens_polygon.LensHub_call_createProfile
where call_success = true   -- Only count success calls
```

Create a visualisation chart of the Counter type with the Title set to "Total Profiles" and add it to the data dashboard.

We are also interested in how creator profiles change and grow over time. Use the following query to see how profiles are created on a daily and monthly basis.

``` sql
with daily_profile_count as (
    select date_trunc('day', call_block_time) as block_date,
        count(*) as profile_count
    from lens_polygon.LensHub_call_createProfile
    where call_success = true
    group by 1
    order by 1
)

select block_date,
    profile_count,
    sum(profile_count) over (order by block_date) as accumulate_profile_count
from daily_profile_count
order by block_date
```

Create and add visualization charts to the dashboard in a similar way. The display is shown in the figure below:

![](img/ch07_image_05.png)

Reference links for the above two queries on Dune:
- [https://dune.com/queries/1534486](https://dune.com/queries/1534486)
- [https://dune.com/queries/1534927](https://dune.com/queries/1534927)
- [https://dune.com/queries/1534950](https://dune.com/queries/1534950)

## Creator profile domain analysis

Lens is committed to building a social graph ecosystem, where each creator can set a personalised name (Profile Handle Name) for their account, which is what is usually referred to as a Lens domain name. Similar to other domain name systems such as ENS, we will pay attention to the registration status of some short domain names, plain numeric domain names, etc., and the number of domain names of different character lengths that have been registered, and other information. In the `createProfile` table, the field `vars` saves a json object in string format, which includes the user's personalised domain name. In Dune V2, we can directly access the value of the elements in the json string using the `:` sign, for example, using `vars:handle` to get the domain name information.

Using the following SQL, we can get the details of a registered Lens domain name:
``` sql
select json_value(vars, 'lax $.to') as user_address,
    json_value(vars, 'lax $.handle')  as handle_name,
    replace(json_value(vars, 'lax $.handle') , '.lens', '') as short_handle_name,
    call_block_time,
    output_0 as profile_id,
    call_tx_hash
from lens_polygon.LensHub_call_createProfile
where call_success = true
```

In order to count the number of Lens domains of different lengths and types (purely numeric, purely alphabetic, mixed) as well as the total number of registered domains under each type, we can put the above query into a CTE. The advantage of using a CTE is that it simplifies the logic (you can debug and test each CTE separately in order). At the same time, once the CTE is defined, it can be used multiple times in subsequent SQL scripts for the same query, which is very convenient. Given that the query for the total number of registered domain names and the corresponding number of registered domain names with different character lengths is based on the above query, we can put them together in the same query. Because the aforementioned statistics need to distinguish the type of domain name, we added a field `handle_type` to represent the type of domain name in this query. The modified query code is as follows:

``` sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        (case when regexp_like(replace(json_value(vars, 'lax $.handle'), '.lens', ''), '^[0-9]+$') then 'Pure Digits'
            when regexp_like(replace(json_value(vars, 'lax $.handle'), '.lens', ''), '^[a-z]+$') then 'Pure Letters'
            else 'Mixed'
        end) as handle_type,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
),

profiles_summary as (
    select (case when length(short_name) >= 20 then 20 else length(short_name) end) as name_length,
        handle_type,
        count(*) as name_count
    from profile_created
    group by 1, 2
),

profiles_total as (
    select count(*) as total_profile_count,
        sum(case when handle_type = 'Pure Digits' then 1 else 0 end) as pure_digit_profile_count,
        sum(case when handle_type = 'Pure Letters' then 1 else 0 end) as pure_letter_profile_count
    from profile_created
)

select cast(name_length as varchar) || ' Chars' as name_length_type,
    handle_type,
    name_count,
    total_profile_count,
    pure_digit_profile_count,
    pure_letter_profile_count
from profiles_summary
join profiles_total on true
order by handle_type, name_length
```

The modified query code is relatively complicated and can be interpreted as follows:
1. CTE `profile_created` extracts the profile's domain name information and the user address to which the domain belongs by using the ":" notation to extract the domain name information and user address from the json string saved in the `vars` field. Since the saved domain name includes a `.lens` suffix, we use the `replace()` method to remove the suffix and name the new field `short_name` to make it easier to calculate the character length of the domain name later. Further, we use a CASE statement in conjunction with the regular expression matching operator `rlike` to determine whether the domain name consists of pure numbers or pure letters, and assign a string name value to the field named `handle_type`. see [rlike operator](https://docs.databricks.com/sql/language-manual/functions/rlike.html) for more information on regular expression matching.
2. CTE `profiles_summary` performs summary queries based on `profile_created`. We first use the `length()` function to calculate the character length of each domain name. Because there are a small number of exceptionally long domains, we use a CASE statement to treat domains longer than 20 characters uniformly as 20. We then perform `group by` summary statistics based on the domain name length `name_length` and `handle_type` to calculate the number of various domain names.
3. In CTE `profiles_total`, we count the total number of domain names, the number of purely numeric domain names, and the number of purely alphabetic domain names.
4. Finally, we associate the two CTEs `profiles_summary` and `profiles_total` together to output the final query results. Since `profiles_total` has only one row of data, we can directly use `true` as the JOIN condition. In addition, since `name_length` is a numeric type, we convert it to a string type and concatenate it to another string to get a more readable domain length type name. We sort the output by domain type and length.

After the query is executed and saved, we add the following visualization charts to it and add them to the data dashboard:
1. Add two Counters to output the number of purely numeric domain names and the number of purely alphabetic domain names respectively. Since there was already a counter for the total number of domain name registrations before, we can place these two new counter charts on the same row as it.
2. Add a Pie Chart of domain name type distribution, set the Title to "Profiles Handle Name Type Distribution", select the `handle_type field` for "X Column", and select the `name_count` field for "Y Column 1".
3. Add a Pie Chart of domain name length distribution, set the Title to "Profiles Handle Name Length Distribution", select the `name_length_type` field for "X Column", and select the `name_count` field for "Y Column 1".
4. Add a histogram (Bar Chart) of domain name length distribution, set the Title to "Profiles Handle Name Count By Length", select the `name_length_type` field for "X Column", select the `name_count` field for "Y Column 1", and select the `handle_type` field for "Group by". Also uncheck the "Sort values" option, and then check the "Enable stacking" option.
5. Add an area chart (Area Chart) of domain name length distribution, set the Title to "Profile Handle Name Count Percentage By Type", select `the name_length_type` field for "X Column", select the `name_count` field for "Y Column 1", and select the `handle_type` field for "Group by" . Uncheck the "Sort values" option, then check the "Enable stacking" option, and then check the "Normalize to percentage" option.

Add all the above visualization charts to the data dashboard, and adjust the display order, as shown in the following figure:

![](img/ch07_image_06.png)

Reference link for this query on Dune:
- [https://dune.com/queries/1535541](https://dune.com/queries/1535541)

## Registered domain search

In addition to tracking the distribution of registered Lens domains, users are also interested in the details of registered domains. To this end, a search function can be provided that allows users to search for a detailed list of registered domains. Since there are currently about 100,000 Lens accounts registered, we limit the query below to return a maximum of 10,000 search results.

Firstly, we can define a parameter `{{name_contains}}` in the query (Dune uses two curly brackets around the parameter name, and the default parameter type is the string `Text` type). Then use the`like` keyword as well as the `%` wildcard to search for domains with specific characters in the name:

``` sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
)

select call_block_time,
    profile_id,
    handle_name,
    short_name,
    call_tx_hash
from profile_created
where short_name like '%{{name_contains}}%' -- query the name contian the input string
order by call_block_time desc
limit 1000
```

Before the query is executed, the Dune engine will replace the parameter names in the SQL statement with the input parameter values. When we enter "john", the clause `where short_name like '%{{name_contains}}%'` will be replaced by `where short_name like '%john%'`, which means to search for all domain names whose `short_name` contains the string `john`. Note that although the parameter type is a string type, the field will not add single quotes before and after the parameter replacement. Single quotes need to be entered directly into the query, and if you forget to enter them, it will cause a syntax error.

As mentioned earlier, the length of the domain name is also critical, and the shorter the domain name, the more scarce it is. In addition to searching for the characters contained in the domain name, we can add another parameter `{{name_length}}` for domain name length filtering, change its parameter type to a drop-down list type, and fill in the sequence of numbers 5-20 as a parameter value list, one per line value. Because the Lens domain name currently has at least 5 characters, and there are very few domain names exceeding 20 characters, so we choose 5 to 20 as the interval. The parameter settings are shown in the figure below.

![](img/ch07_image_08.png)

After adding the new parameters, we adjust the WHERE clause of the SQL statement as shown below. Its meaning is to search for a list of domain names whose name contains the input keyword and whose character length is equal to the selected length value. Note that although the values of our `name_length` parameter are all numbers, the default type of the List type parameter is a string, so we use the `cast()` function to convert its type to an integer type before comparing.

``` sql
where short_name like '%{{name_contains}}%' -- -- query the name contian the input string
    and length(short_name) = cast('{{name_length}}' as integer) 
```

Similarly, we can add another domain name string pattern parameter `{{name_pattern}}` to filter purely numeric domain names or purely alphabetic domain names. Here also set the parameter to List type, the list includes three options: Any, Pure Digits, Pure Letters. The WHERE clause of the SQL statement is correspondingly modified as shown below. Similar to the previous query, we use a CASE statement to determine the type of the current query domain name. If you query a purely numeric or purely alphabetic domain name, use the corresponding expression. If you query any pattern, use `1 = 1`, which always returns true The equality judgment of the value is equivalent to ignoring this filter condition.

``` sql
where short_name like '%{{name_contains}}%' -- query the name contian the input string
    and length(short_name) = cast('{{name_length}}' as integer) -- length of domain name equal to the select item 
    and (case when '{{name_pattern}}' = 'Pure Digits' then regexp_like(short_name, '^[0-9]+$')
            when '{{name_pattern}}' = 'Pure Letters' then regexp_like(short_name, '^[a-z]+$')
            else 1 = 1
        end)
```

Because we use the `and` connection condition between these search conditions, it means that all conditions must be satisfied at the same time, and such a search has certain limitations. We make appropriate adjustments, and add a default option "0" to the name_length parameter. When a filter is not entered or selected by the user, we ignore it. This makes search queries very flexible. The complete SQL statement is as follows:

``` sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
)

select call_block_time,
    profile_id,
    handle_name,
    short_name,
    '<a href=https://polygonscan.com/tx/' || cast(call_tx_hash as varchar) || ' target=_blank>Polyscan</a>' as link,
    call_tx_hash
from profile_created
where (case when '{{name_contains}}' <> 'keyword' then short_name like '%{{name_contains}}%' else 1 = 1 end)
    and (case when cast('{{name_length}}' as integer) < 5 then 2 = 2
            when cast('{{name_length}}' as integer) >= 20 then length(short_name) >= 20
            else length(short_name) = cast('{{name_length}}' as integer)
        end)
    and (case when '{{name_pattern}}' = 'Pure Digits' then regexp_like(short_name, '^[0-9]+$')
            when '{{name_pattern}}' = 'Pure Letters' then regexp_like(short_name, '^[a-z]+$')
            else 3 = 3
        end)
order by call_block_time desc
limit 1000
```

We add a Table type visualization chart to this query and add it to the data dashboard. When adding a parameter query to the data kanban, all parameters are automatically added to the kanban header. We can enter the edit mode and drag the parameter to its desired position. The rendering after adding the chart to the data dashboard is shown below.

![](img/ch07_image_07.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1535903](https://dune.com/queries/1535903)
- [https://dune.com/queries/1548540](https://dune.com/queries/1548540)
- [https://dune.com/queries/1548574](https://dune.com/queries/1548574)
- [https://dune.com/queries/1548614](https://dune.com/queries/1548614)

## Summary

So far, we have completed the analysis of the basic overview of the Lens protocol, the creator‚Äôs profile, and domain name information, and added a domain name search function. In the previous "Main Analysis Contents of Data Kanban" section, we listed more content that can be analyzed. In the second part of this tutorial, we will continue to analyze the publications, attention, favorites, NFT and other aspects released by the creator. You can also explore and create new queries on your own.

## Homework

Please combine the tutorial content to create your own Lens protocol data dashboard, and try new query analysis by referring to the content prompted in the "Main analysis content of the data dashboard". Please actively practice, create data dashboards and share them with the community. We will record the completion and quality of the homework, and then retroactively provide certain rewards for everyone, including but not limited to Dune community identity, peripheral objects, API free quota, POAP, various cooperative data product members, and blockchain data analysis Job opportunity recommendation, priority registration qualification for community offline activities, and other Sixdegree community incentives, etc.

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch08/ch08-practice-build-lens-dashboard-part2.md">
# 08 Practice - Build Lens Dashboard (II)

In the first part of this tutorial, we introduced the Lens protocol to you, and made a preliminary dashboard for it, analyzing the total number of transactions and total users, the number of transactions and the number of unique users by day, creators Profile data analysis, Lens domain name analysis, registered domain name search and other related content. Let's go ahead and add new queries and visualizations to this dashboard. We will analyze and add the following content: create multiple profiles with the same address, follow data, post data, comment data, collection data, mirror data, comprehensive operation of profiles, and comprehensive operation of regular user addresses.

## Create multiple Profiles with the same address

The Lens protocol allows multiple Profiles to be created for a single address. We can write a query to count the data distribution of addresses with multiple profiles created. In the following query, we first use CTE profile_created to obtain the data details of all created profiles, and then use multiple_profiles_addresses to count the number of profiles created for each address. Finally, we use a CASE statement to return aggregated statistics by sorting each address by the number of profiles created.

``` sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
),

multiple_profiles_addresses as (
    select user_address,
        count(profile_id) as profile_count
    from profile_created
    group by 1
    order by 2 desc
)

select (case when profile_count >= 10 then '10+ Profiles'
            when profile_count >= 3 then '5+ Profiles'
            when profile_count = 2 then '2 Profiles'
            else '1 Profile'
        end) as profile_count_type,
    count(user_address) as user_address_count,
    sum(profile_count) as profile_count
from multiple_profiles_addresses
group by 1
```

When doing this kind of data statistics, we usually also need to get some Counter type statistical values, such as the total number of addresses that have created multiple Profiles, how many Profiles have been created by these addresses, and the proportion of these Profiles in all created Profiles etc. The above CTE subquery code can be shared when querying these data, so we make few changes to it and add two additional CTEs to count the values of these Counter types. Add a visualisation chart for this query and add it to the data dashboard respectively. The display effect is as follows:

![](img/ch08_image_09.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1562662](https://dune.com/queries/1562662)
- [https://dune.com/queries/1553030](https://dune.com/queries/1553030)


## Profile Posts data analysis

### Top posting accounts daily analysis

The creators of Lens have two ways to post (Post). They have been posting directly with their own accounts, and the other is to entrust other accounts or post via API. Post data is stored in the `LensHub_call_post` and `LensHub_call_postWithSig` tables respectively. The content of each topic Post is stored in the field `vars` in the form of a JSON string, including the author's ProfileID, the URL of the post content, and other information. For JSON content in string form, we can use the : operator to access the value. The following query can get some sample data:

``` sql
select call_block_time,
    call_tx_hash,
    output_0 as post_id,
    json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
    json_value(vars, 'lax $.contentURI') as content_url,
    json_value(vars, 'lax $.collectModule') as collection_module,
    json_value(vars, 'lax $.referenceModule') as reference_module,
    vars
from lens_polygon.LensHub_call_post
where call_success = true
limit 10
```

In view of the large number of Profiles posting, we can make a classification and statistics of Profiles with different posting numbers as in the previous analysis of 'creating multiple Profiles at the same address', and also pay attention to the top users, that is, the data of accounts with the most posts. Here we analyze the accounts with the most posts, and compare the number of posts of these accounts with the total number of posts, and output the Counter chart. The complete SQL is as follows:

``` sql
with post_data as (
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module,
    from lens_polygon.LensHub_call_post
    where call_success = true
    
    union all
    
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module,
    from lens_polygon.LensHub_call_postWithSig
    where call_success = true
),

posts_summary as (
    select count(*) as total_post_count,
        count(distinct profile_id) as posted_profile_count
    from post_data
),

top_post_profiles as (
    select profile_id,
        count(*) as post_count
    from post_data
    group by 1
    order by 2 desc
    limit 1000
)

select profile_id,
    post_count,
    sum(post_count) over () as top_profile_post_count,
    total_post_count,
    posted_profile_count,
    cast(sum(post_count) over () as double) / total_post_count * 100 as top_profile_posts_ratio
from top_post_profiles
inner join posts_summary on true
order by 2 desc
```

Interpretation of the above SQL: Since Post data is stored in two tables separately, in CTE `post_data`, we use `union all` to merge the data taken from the two tables together. We use `posts_summary` to count the number of Profiles and the cumulative number of Posts they have posted. In `top_post_profiles`, we follow the data of the 1000 Profiles with the largest number of posts per Profile. Finally, we query `top_post_profiles` and `posts_summary` in association, and output the account data with the most posts and their comparison with the total post data. After the query results are visualized and added to the data dashboard, the display effect is as follows:

![](img/ch08_image_10.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1554541](https://dune.com/queries/1554541)

###  New posts count daily statistics

The daily number of new posts by Lens users is an important indicator for observing the trend of overall activity. We write a query to count the number of daily posts. The `post_data` CTE in this query is exactly the same as before, so we omit its details in the code below. Because we also want to accumulate the number of posts per day and return the cumulative number of posts, we define `post_daily_summary` CTE as an intermediate step to make the SQL code easy to understand. The corresponding SQL is as follows:

``` sql
with post_data as (
    -- Get post data from LensHub_call_post and LensHub_call_postWithSig tables
),

post_daily_summary as (
    select date_trunc('day', call_block_time) as block_date,
        count(*) post_count,
        count(distinct profile_id) as profile_count
    from post_data
    group by 1
)

select block_date,
    post_count,
    profile_count,
    sum(post_count) over (order by block_date) as accumulate_post_count
from post_daily_summary
order by block_date
```

The display after visualising the query results and adding them to the data dashboard is shown below:

[image_11.png](img/image_11.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1555124](https://dune.com/queries/1555124)


###  Top active Profile statistics by posts count 30 days

Similarly, we may be interested in the profiles with the most active postings in the most recent period. To this end, we only need to add date filter conditions to filter the posts in the last 30 days in the aforementioned `post_data` CTE, and then summarize statistics by date. The SQL is as follows:

``` sql
with post_data as (
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module
    from lens_polygon.LensHub_call_post
    where call_success = true
        and call_block_time >= now() - interval '30' day
    
    union all
    
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module
    from lens_polygon.LensHub_call_postWithSig
    where call_success = true
        and call_block_time >= now() - interval '30' day
)

select profile_id,
    count(*) as post_count
from post_data
group by 1
order by 2 desc
limit 100
```

We can add a histogram to display the number of posts of the 100 accounts with the most posts in the past 30 days, and add a Table type chart to output details. The display effect after the relevant chart is added to the data dashboard is as follows:

![](img/ch08_image_12.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1559981](https://dune.com/queries/1559981)


## Profile Comments data analysis

### Top Profiles Comments Count analysis 

Lens comment data is similar to post data, which are stored in the `LensHub_call_comment` and `LensHub_call_commentWithSig` tables according to the source of the data. Based on the current functions of the Lens protocol, users must have created their own Profile to comment on other creators' Posts. In the comment data table, it is tracked by the profile ID of the commenter. At the same time, the number of each creator's post is incremented from 1. That is to say, posts from different creators may have the same number. We need to associate the creator's Profile ID with its Publication ID so as to get a unique number. The SQL is as follows:

``` sql
select call_block_time,
    call_tx_hash,
    output_0 as comment_id, -- comment id
    json_value(vars, 'lax $.profileId') as profile_id_from, -- Profile ID of the comment
    json_value(vars, 'lax $.contentURI') as content_url, -- comment content link
    json_value(vars, 'lax $.pubIdPointed') as publication_id_pointed, -- Commented Publication ID
    json_value(vars, 'lax $.profileIdPointed') as profile_id_pointed, -- Profile ID of Creator who were commented on
    json_value(vars, 'lax $.profileIdPointed') || '-' || json_value(vars, 'lax $.pubIdPointed') as unique_publication_id  -- combine to generate unique id
from lens_polygon.LensHub_call_comment
where call_success = true
limit 10
```

We also obtain the total comment data by defining an additional CTE, so that the Counter chart can be output in the same query, and the comment data of the 1000 accounts with the most comments and the comment data of all accounts can be compared. After the query results are visualized and added to the data dashboard, the display effect is as follows:

![](img/ch08_image_13.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1560028](https://dune.com/queries/1560028)

### Top Publication Comments statistics

Each comment is aimed at a specific object (Publication) (here the author thinks it should be Post, please correct me if there is any misunderstanding). It is of certain value to analyze the Publications that have been commented the most. We write a query to count the top 500 most commented Publications and compare it with all comment data. The SQL is as follows:

``` sql
with comment_data as (
    -- get comment data from LensHub_call_comment and LensHub_call_commentWithSig tables
)

select profile_id_pointed,
    publication_id_pointed,
    unique_publication_id,
    count(*) as comment_count
from comment_data
group by 1, 2, 3
order by 4 desc
limit 500
```

In the same way, we add an additional CTE to obtain the data of all comments, and compare the data of the top 500 most commented Publications with the global data. Add the corresponding visual chart to the data dashboard, the effect is as follows:

![](img/ch08_image_14.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1560578](https://dune.com/queries/1560578)

## Profile Mirrors data analysis

Mirroring data is highly similar to comment data, and users must first create their own Profile to mirror other people's Publications. We write two queries respectively to count the top 1000 account data with the most mirroring operations and the top 500 publication data with the most mirroring operations. Compare them with the overall mirror data as well. The effect after adding the data dashboard is shown in the following figure:

![](img/ch08_image_15.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1561229](https://dune.com/queries/1561229)
- [https://dune.com/queries/1561558](https://dune.com/queries/1561558)


## Profiles Collections data analysis

Lens collection data is also stored in the two tables `LensHub_call_collect` and `LensHub_call_collectWithSig` respectively. Unlike comment or mirror data, collecting a Publication does not require the collector to have his own Lens Profile. That is to say, any address (user) can bookmark Publications under other Profiles. So we need to track the specific collection operation through the address of the collector. What's special is that the collector's address data is not saved in the `LensHub_call_collect` table, but the `LensHub_call_collectWithSig` table has this data. We need to link the `LensHub_call_collect` table to the transactions table to obtain the user address of the current operation collection. The SQL example is as follows:

``` sql
select call_block_time,
    t."from" as collector,
    c.profileId as profile_id,
    c.pubId as publication_id,
    cast(c.profileId as varchar) || '-' || cast(c.pubId as varchar) as unique_publication_id,
    c.output_0 as collection_id
from lens_polygon.LensHub_call_collect c
inner join polygon.transactions t on c.call_tx_hash = t.hash -- join the transaction table to get user address
where call_block_time >= date('2022-05-18') -- filter by Lens Contract deployed date to improve the query speed
    and block_time >= date('2022-05-18')
    and c.call_success = true
limit 10
```

Since the transaction table records are quite large, the query time consumption will increase significantly. A rule of thumb is to avoid joining operations on raw data tables (transactions, logs, traces) as much as possible.

The other parts of the collection data analysis SQL are basically the same as the previous example, so I won't repeat them here. Similarly, we also conduct statistical analysis on the most collected Publications. The display effect after adding the relevant visualisation images to the data dashboard is shown in the following figure:

![](img/ch08_image_16.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1560847](https://dune.com/queries/1560847)
- [https://dune.com/queries/1561009](https://dune.com/queries/1561009)


## Profile Follows data analysis

### Top Profile by followers counts

The follow data of the Lens protocol is still stored in two tables, `LensHub_call_follow` and `LensHub_call_followWithSig` respectively. Any address (user) can follow other Profiles. Similar to favorites, the `LensHub_call_follow` table does not save the addresses of followers, so we also need to get the addresses of users currently operating favorites by associating with the `transactions` table. In addition, there is a special feature of following, that is, multiple profiles can be followed in batches at the same time in one transaction. In the `LensHub_call_follow` table, the followed Profile data is stored in the array type field profileIds, which is relatively easy to handle. In the table `LensHub_call_followWithSig`, it is an array value in JSON string format. An example of the field `vars` is as follows (some contents are omitted):

```json
{"follower":"0xdacc5a4f232406067da52662d62fc75165f21b23","profileIds":[21884,25271,39784],"datas":["0x","0x","0x"],"sig":"..."}
```

Using Dune SQL's JSON functions, you can read array values from JSON strings. We can first use `json_extract()` to extract the required element value from the json string, and then use the `cast()` method to convert it into an array of the specified type. The sample code is as follows:

``` sql
select
json_query(vars, 'lax $.follower') AS follower, -- single value
json_query(vars, 'lax $.profileIds') AS profileIds, -- still string
from_hex(cast(json_extract(vars,'$.follower') as varchar)) as follower2, -- cast to varbinary
cast(json_extract(vars,'$.profileIds') as array(integer)) as profileIds2, -- cast to array
vars
from lens_polygon.LensHub_call_followWithSig
where cardinality(output_0) > 1
limit 10
```

The complete SQL code for reading attention details is as follows:

``` sql
with follow_data as (
    select f.follower, p.profile_id
    from (
        select from_hex(cast(json_extract(vars,'$.follower') as varchar)) as follower, -- cast to varbinary
            cast(json_extract(vars,'$.profileIds') as array(integer)) as profile_ids -- cast to array
        from lens_polygon.LensHub_call_followWithSig
            
        union all
        
        select t."from" as follower,
            cast(f.profileIds as array(integer)) as profile_ids
        from lens_polygon.LensHub_call_follow f
        inner join polygon.transactions t on f.call_tx_hash = t.hash
        where call_block_time >= date('2022-05-18') -- Lens launch date
            and block_time >= date('2022-05-18')
            and call_success = true
    ) f
    cross join unnest(f.profile_ids) as p(profile_id)
)

select * from follow_data
limit 100
```

It's important to note here that we use the `cross join unnest(f.profile_ids) as p(profile_id)` clause to break up the array in the subquery and get the individual ID values that are broken up. Also, since the element type in the lens_polygon.`LensHub_call_follow table` is `uint256`, which is a Dune custom type that we can't use when extracting values from json strings, we use `cast(f.profileIds as array(integer) )` to convert `uint256` to `integer` type.

Similarly, on the basis of the above query, we also add the CTE definition to obtain all the concerned data, so that when obtaining the most concerned proile list, we can compare it with the overall number of concerned. After the query results are visualized and added to the data dashboard, the effect is as follows:

![](img/ch08_image_17.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1554454](https://dune.com/queries/1554454)

### Profile distribution by number of follow range

We see that almost most of the Profiles are followed, and we can use a query to analyze the distribution of the attention of each Profile. The SQL code is as follows:

``` sql
with follow_data as (
    -- Get follow data from table LensHub_call_follow and LensHub_call_followWithSig
),

profile_follower as (
    select profile_id,
        count(follower) as follower_count
    from follow_data
    group by 1
)

select (case when follower_count >= 10000 then '10K+ Followers'
            when follower_count >= 1000 then '1K+ Followers'
            when follower_count >= 100 then '100+ Followers'
            when follower_count >= 50 then '50+ Followers'
            when follower_count >= 10 then '10+ Followers'
            when follower_count >= 5 then '5+ Followers'
            else '1 - 5 Followers'
        end) as follower_count_type,
    count(profile_id) as profile_count
from profile_follower
group by 1
```

Use a Pie chart to visualize the above query results. After adding it to the data dashboard, the display effect is as shown in the figure below:

![](img/ch08_image_18.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1554888](https://dune.com/queries/1554888)

### The number of daily new followers count statistics 

The number of daily new followers of Lens users is also an important indicator for observing changes in overall activity. We write a query to count the number of posts per day. The `follow_data` CTE in this query is exactly the same as before. The query processing method is also highly similar to the statistics of the number of daily posts mentioned above, so the details will not be detailed here. Add a visualization chart to the query result and add it to the data dashboard, the display effect is as follows:

![](img/ch08_image_19.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1555185](https://dune.com/queries/1555185)

## Comprehensive analysis of profile operations

Combining the previous content, it can be seen that creators (users with Profile) can post, comment or mirror the data of other creators, while ordinary users (without creating a Profile) can follow Creators and collections of publications. So we can combine data that creators can manipulate for comprehensive analysis.

We define an `action_data` CTE, and use the method of nested definition CTE to gather related data together. Among them, post_data, comment_data and mirror_data are all exactly the same as the definitions in the previous related queries. We use union all to merge the above data together, and at the same time distribute and specify the corresponding action type to generate a field `action_type` for classification. Then we only need to perform summary statistics according to the classification fields to calculate the number of transactions and the corresponding number of profiles for each operation type. The SQL example is as follows:

``` sql
with action_data as (
    with post_data as (
        -- get post data from relevant tables
    ),
    
    comment_data as (
        -- get comment data from relevant tables
    ),
    
    mirror_data as (
        -- get mirror data from relevant tables
    )
 
    select 'Post' as action_type, * from post_data
    union all
    select 'Mirror' as action_type, * from mirror_data
    union all
    select 'Comment' as action_type, * from comment_data
)

select action_type,
    count(*) as transaction_count,
    count(distinct profile_id) as profile_count
from action_data
group by 1
```

In a similar way, we can create a query that summarizes the daily counts of various operations by date. The sample code is as follows:

```
with action_data as (
    -- same as above query
)

select date_trunc('day', call_block_time) as block_date,
    action_type,
    count(*) as transaction_count
from action_data
group by 1, 2
order by 1, 2
```

Visualize the above query results and add them to the data dashboard, the display effect is as follows:

![](img/ch08_image_20.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1561822](https://dune.com/queries/1561822)
- [https://dune.com/queries/1561898](https://dune.com/queries/1561898)

## Comprehensive analysis of regular user operations

Similar to creators, we can combine follow and collection operations that ordinary users can perform for analysis. We also write two queries to count the overall distribution of operations and the number of operations by date. The `action_data data` in the query also comes from the collection query and follow query introduced earlier. The SQL example is as follows:

``` sql
with action_data as (
    with follow_data as (
        -- get follow data from relevant tables
    ),
    
    collect_data as (
        -- get collect data from relevant tables
    )

    select 'Follow' as action_type, * from follow_data
    union all
    select 'Collect' as action_type, * from collect_data
)
```

Except for the different data sources, these two queries are basically the same as the comprehensive analysis of creator operations. Visualize the query results and add them to the data dashboard, the display effect is as follows:

![](img/ch08_image_21.png)

Reference link for the above query on Dune:
- [https://dune.com/queries/1562000](https://dune.com/queries/1562000)
- [https://dune.com/queries/1562178](https://dune.com/queries/1562178)


## Summary and Homework

Very good! We have completed an overall analysis of the Lens protocol. However, due to space issues, there are still many indicators worthy of analysis that we have not yet covered, including but not limited to: analysis of relevant data of the three NFTs, analysis of the creator‚Äôs income, analysis of the transfer of Profile accounts, etc. This part is left for you to continue to explore.

Please continue to improve your own Lens protocol data dashboard based on the content of the tutorial. You can fork the query in this tutorial to modify it, and make any further extensions according to your own understanding. Please practice actively, create data dashboards and share them with the community. We will record the completion and quality of the homework, and then retroactively provide certain rewards for everyone, including but not limited to Dune community identity, peripheral objects, API free quota, POAP, various cooperative data product members, and blockchain data analysis Job opportunity recommendation, priority registration qualification for community offline activities, and other Sixdegree community incentives, etc.

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch09/ch09-useful-queries-part1.md">
# 09 Useful Queries (I): ERC20 token price queries

In daily data analysis, We usually encounter some common queries, such as tracking the price changes of an ERC20 token, querying the balance of various ERC20 tokens held by a certain address, etc. In the help documentation of the Dune platform, [some helpful data dashboards](https://dune.com/docs/reference/wizard-tools/helpful-dashboards/) and [utility queries](https://dune.com/docs/reference/wizard-tools/utility-queries/) sections give some examples, you can refer to them. In this tutorial, we combine some typical needs that we encounter in our daily life, and sort out some query cases for you.

## Query the latest price of a single ERC20 token

ERC20 tokens are used in a wide variety of blockchain applications. DeFi initiatives facilitate the trading of ERC20 tokens. Other projects reward their backers, early adopters, and development teams through distribution plans and airdrops in exchange for ERC20 tokens. Price data for several ERC20 tokens may be found on sites like [CoinGecko](https://www.coingecko.com/). The 'prices.usd' and 'prices.usd_latest' tables in Dune make it easy for data analysts to retrieve the current market value of the most popular ERC20 tokens on each blockchain. There is a table called [prices.usd](https://dune.com/docs/reference/tables/prices/) that keeps track of the minute-by-minute prices of different ERC20 tokens. To facilitate activities like summarization and comparison while researching ERC20 token-related projects, we may pool the pricing data to convert the quantity of different tokens into the amount stated in US dollars.

**Get the latest price of a single ERC20 token**

The prices in the `prices.usd` table are recorded on a minute-by-minute basis. The retrieval of the most recent record is contingent upon the token's symbol and the corresponding blockchain it is associated with. In the event that a contract address is available, it is also possible to use such contract address for querying purposes. The `usd_latest` database is designed to store the most recent price of each token. Each token is represented by a single row in the table. The below techniques may be used to get the most recent price of an individual token, using WETH as an illustrative instance. In order to enhance query performance, we restrict the retrieval of the most recent portion of the data, since the pricing information is stored in a single record per token each minute, resulting in a substantial number of records for each token. Intermittently, there may exist a specific temporal lag. In the present case, we retrieve the most recent data entry during the preceding six-hour timeframe to ascertain the obtainability of the pricing.

**Use the token value to read the latest price information in the `prices.usd` table:**

``` sql
select * from prices.usd
where symbol = 'WETH'
    and blockchain = 'ethereum'
    and minute >= now() - interval '6' hour
order by minute desc
limit 1
```

**Use the smart contract address of the token to read the latest price in the `prices.usd` table:**

``` sql
select * from prices.usd
where contract_address = 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2   -- WETH
    and minute >= now() - interval '6' hour
order by minute desc
limit 1
```

**Read the latest price information from the tables of `prices.usd_latest`: **

``` sql
select * from prices.usd_latest
where symbol = 'WETH'
    and blockchain = 'ethereum'
```

The query is simpler to read from the `prices.usd_latest` table, but since it is actually a view of the `prices.usd` table, it is slightly less efficient to execute.
reference source code: [prices_usd _latest](https://github.com/dizunalytics/spellbook/blob/main/models/prices_usd.latest.sql)


## Check the latest prices of multiple ERC20 tokens

When we need to read the latest prices of multiple tokens at the same time, the convenience of the `prices.usd_latest` table is reflected. Here we take the latest price query of WETH, WBTC and USDC as an example.


**Read the latest price information for multiple tokens from the `prices.usd_latest` table:**

``` sql
select * from prices.usd_latest
where symbol in ('WETH', 'WBTC', 'USDC')
    and blockchain = 'ethereum'
```

**Read the latest price information for multiple tokens from the `prices.usd` table:**

``` sql
select symbol, decimals, price, minute
from (
    select row_number() over (partition by symbol order by minute desc) as row_num, *
    from prices.usd
    where symbol in ('WETH', 'WBTC', 'USDC')
        and blockchain = 'ethereum'
        and minute >= now() - interval '6' hour
    order by minute desc
) p
where row_num = 1
```

Because we want to read the latest prices of multiple tokens at the same time, we cannot simply use the `limit` clause to limit the number of results to get the desired results. What we actually need to return is to take the first record after each different token is sorted in descending order by the `minute` field. In the above query, we used `row_number() over (partition by symbol order by minute desc) as row_num` to generate a new column. The values in this column are grouped by `symbol` and sorted in descending order by the `minute` field - that is, each different token will generate its own row number sequence value such as 1, 2, 3, 4, etc. We put it into a subquery, and filter the record of `where row_num = 1` in the outer query, which is the latest record of each token. This method seems a little complicated, but similar queries are often used in practical applications, and new columns are generated through the `row_number()` function and then used to filter data.

## Query the daily average price of a single ERC20 token

When we need to query the average price of an ERC20 token every day, we can only use the `prices.usd` table. By setting the date range of the price to be queried (or taking the data of all dates without adding the date range), summarizing by day, and using the `avg()` function to obtain the average value, the price data by day can be obtained. The SQL statement is as follows:

``` sql
select date_trunc('day', minute) as block_date,
    avg(price) as price
from prices.usd
where symbol = 'WETH'
    and blockchain = 'ethereum'
    and minute >= date('2023-01-01')
group by 1
order by 1
```

If we need to return other fields at the same time, we can add them to the SELECT list and add them to the GROUP BY at the same time. This is because, when using the `group by` clause, fields that appear in the SELECT list must also appear in the GROUP BY clause if they are not aggregate functions. The modified SQL statement is as follows:

``` sql
select date_trunc('day', minute) as block_date,
    symbol,
    decimals,
    contract_address,
    avg(price) as price
from prices.usd
where symbol = 'WETH'
    and blockchain = 'ethereum'
    and minute >= date('2023-01-01')
group by 1, 2, 3, 4
order by 1
```

## Query the daily average price of multiple ERC20 tokens

Similarly, we can query the average price of a group of ERC20 tokens every day at the same time, just put the symbol of the token to be queried into the `in ()` conditional clause. The SQL statement is as follows:

``` sql
select date_trunc('day', minute) as block_date,
    symbol,
    decimals,
    contract_address,
    avg(price) as price
from prices.usd
where symbol in ('WETH', 'WBTC', 'USDC')
    and blockchain = 'ethereum'
    and minute >= date('2022-10-01')
group by 1, 2, 3, 4
order by 2, 1   -- Order by symbol first
```

## Calculate price from DeFi swap records

The price data table `prices.usd` on Dune is maintained through spellbook, which does not include price information for all tokens on all supported blockchains. Especially when a new ERC20 token is newly issued and listed on the DEX (such as XEN), Dune's price list will not automatically display this token's data. At this point, we can read the swap data in the DeFi project, such as the Swap data in Uniswap, calculate the exchange price between the corresponding token and USDC (or WETH), and then convert the USDC or WETH price data to get the US dollar price. A sample query is as follows:

``` sql
with xen_price_in_usdc as (
    select date_trunc('hour', evt_block_time) as block_date,
        'XEN' as symbol,
        '0x06450dee7fd2fb8e39061434babcfc05599a6fb8' as contract_address, -- XEN
        18 as decimals,
        avg(amount1 / amount0) / pow(10, (6-18)) as price   --USDC: 6 decimals, XEN: 18 decimals
    from (
        select contract_address,
            abs(amount0) as amount0,
            abs(amount1) as amount1,
            evt_tx_hash,
            evt_block_time
        from uniswap_v3_ethereum.Pair_evt_Swap
        where contract_address = '0x353bb62ed786cdf7624bd4049859182f3c1e9e5d'   -- XEN-USDC 1.00% Pair
            and evt_block_time > '2022-10-07'
            and evt_block_time > now() - interval '30 days'
    ) s
    group by 1, 2, 3, 4
),

usdc_price as (
    select date_trunc('hour', minute) as block_date,
        avg(price) as price
    from prices.usd
    where contract_address = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'   -- USDC
        and minute > '2022-10-07'
        and minute > now() - interval '30 days'
    group by 1
)

select x.block_date,
    x.price * u.price as price_usd
from xen_price_in_usdc x
inner join usdc_price u on x.block_date = u.block_date
order by x.block_date
```

The above query is a practical application in the data dashboard of the XEN Crypto project. The reference link is as follows:
- data dashboard: [XEN Crypto Overview](https://dune.com/sixdegree/xen-crypto-overview)
- Query: [XEN - price trend](https://dune.com/queries/1382200)

## Calculate price from DeFi transaction spells table

If the corresponding DeFi transaction data is already integrated into the `dex.trades` table, it will be easier to use this table to calculate the price. We can divide `amount_usd` by `token_bought_amount` or `token_sold_amount` to get the USD price of the corresponding token. Taking USDC-WETH 0.30% under Uniswap V3 as an example, the SQL statement to calculate the latest price of WETH is as follows:

``` sql
with trade_detail as (
    select block_time,
        tx_hash,
        amount_usd,
        token_bought_amount,
        token_bought_symbol,
        token_sold_amount,
        token_sold_symbol
    from dex.trades
    where project_contract_address = 0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8
        and block_date >= now() - interval '3' day
    order by block_time desc
    limit 1000
)

select avg(
    case when token_bought_symbol = 'WETH' then amount_usd / token_bought_amount
        else amount_usd / token_sold_amount
    end
    ) as price
from trade_detail
```

## Calculate the price of the native token (ETH)

Taking Ethereum as an example, its native token ETH is not an ERC20 token, so there is no price information of ETH itself in the `prices.usd` table. However, WETH tokens (Wrapped ETH) are equivalent to ETH, so we can directly use WETH price data.

## Use price data from other blockchains

There is also a trick that can work around when the token price data of the blockchain we want to analyze cannot be found in `prices.usd`. For example, the Avalanche-C chain also provides transactions of tokens such as USDC, WETH, WBTC, and AAVE, but they have different token addresses compared to the Ethereum chain. If `prices.usd` does not provide the price data of the Avalache-C chain (it should already be supported), we can customize a CTE to map the token addresses on different chains, and then query to obtain the price.

``` sql
with token_mapping_to_ethereum(aave_token_address, ethereum_token_address, token_symbol) as (
    values
    (0xfd086bc7cd5c481dcc9c85ebe478a1c0b69fcbb9, 0xdac17f958d2ee523a2206206994597c13d831ec7, 'USDT'),
    (0x2f2a2543b76a4166549f7aab2e75bef0aefc5b0f, 0x2260fac5e5542a773aa44fbcfedf7c193bc2c599, 'WBTC'),
    (0xd22a58f79e9481d1a88e00c343885a588b34b68b, 0xdb25f211ab05b1c97d595516f45794528a807ad8, 'EURS'),
    (0xff970a61a04b1ca14834a43f5de4533ebddb5cc8, 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48, 'USDC'),
    (0xf97f4df75117a78c1a5a0dbb814af92458539fb4, 0x514910771af9ca656af840dff83e8264ecf986ca, 'LINK'),
    (0x82af49447d8a07e3bd95bd0d56f35241523fbab1, 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2, 'WETH'),
    (0xda10009cbd5d07dd0cecc66161fc93d7c9000da1, 0x6b175474e89094c44da98b954eedeac495271d0f, 'DAI'),
    (0xba5ddd1f9d7f570dc94a51479a000e3bce967196, 0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9, 'AAVE')
),

latest_token_price as (
    select date_trunc('hour', minute) as price_date,
        contract_address,
        symbol,
        decimals,
        avg(price) as price
    from prices.usd
    where contract_address in (
        select ethereum_token_address
        from token_mapping_to_ethereum
    )
    and minute > now() - interval '1' day
    group by 1, 2, 3, 4
),

latest_token_price_row_num as (
    select  price_date,
        contract_address,
        symbol,
        decimals,
        price,
        row_number() over (partition by contract_address order by price_date desc) as row_num
    from latest_token_price
),

current_token_price as (
    select contract_address,
        symbol,
        decimals,
        price
    from latest_token_price_row_num
    where row_num = 1
)

select * from current_token_price
```

Here's an example query: [https://dune.com/queries/1042456](https://dune.com/queries/1042456)


## Calculate price from logs

Tip: the content of this section is relatively complicated. If you find it difficult, you can skip it directly.

A special case is when analyzing a new DeFi project or a blockchain newly supported by Dune. At this point, there is no corresponding `prices.usd` data, the smart contract of the corresponding project has not been submitted for analysis, and the transaction records have not been integrated into the magic table like `dex.trades`. The only thing we can access is the raw data tables such as `transactions` and `logs`. Therefore, we can first find several transaction records, analyze the detailed information of the event log displayed on the blockchain, determine the data type and relative position contained in the `data` value of the event, and then manually analyze the data based on this information to convert the price.

For example, say we need to calculate the price of the $OP token on the Optimism chain, and assuming that all the aforementioned conditions are met, the price must be calculated from the original table of the transaction event log. We first find an exchange transaction record based on the clues provided by the project team (contract address, case hash, etc.): [https://optimistic.etherscan.io/tx/0x1df6dda6a4cffdbc9e477e6682b982ca096ea747019e1c0dacf4aceac3fc532f](https://optimistic.etherscan.io/tx/0x1df6dda6a4cffdbc9e477e6682b982ca096ea747019e1c0dacf4aceac3fc532f). This is a swap transaction, where the `topic1` value of the last `logs` log "0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822" corresponds to "Swap(address,uint256,uint256,uint256,uint256,address)" method. This can be further verified by querying the `decoding.evm_signatures` table (this is because Optimism is an EVM-compatible blockchain that uses the same related functions as Ethereum).

A screenshot of the logs on the blockchain browser is as follows:

![](img/ch09_image_01.png)

The screenshot of evm_signatures signature data query is as follows:

![](img/ch09_image_02.png)

When querying `evm_signatures` in the above figure, we did some processing so that the relevant columns of data are displayed from top to bottom. The corresponding SQL statement is:

``` sql
select 'ID:' as name, cast(id as varchar) as value
from decoding.evm_signatures
where id = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822
union all
select 'Signature:' as name, signature as value
from decoding.evm_signatures
where id = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822
union all
select 'ABI:' as name, abi as value
from decoding.evm_signatures
where id = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822
```

Combining the above relevant information, we can convert the price by analyzing the Swap records in the event log. In the query below, we take the latest 1000 transaction records to calculate the average price. Since the exchange is bidirectional, it may be exchanged from `token0` to `token1` or vice versa, we use a case statement to take out different values accordingly to calculate the transaction price.  In addition, we did not further obtain the price of USDC for conversion. After all, it is a stable currency and its price fluctuates less. When you need more accurate data, you can refer to the previous example to convert through USDC price information.

``` sql
with op_price as (
    select 0x4200000000000000000000000000000000000042 as token_address,
        'OP' as token_symbol,
        18 as decimals,
        avg(
            (case when amount0_in > 0 then amount1_out else amount1_in end) 
            / 
            (case when amount0_in > 0 then amount0_in else amount0_out end)
        ) as price
    from (
        select tx_hash,
            index,
            cast(bytearray_to_uint256(bytearray_substring(data, 1, 32)) as decimal(38, 0)) / 1e18 as amount0_in,
            cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) / 1e6  as amount1_in,
            cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32 * 2, 32)) as decimal(38, 0)) / 1e18  as amount0_out,
            cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32 * 3, 32)) as decimal(38, 0)) / 1e6  as amount1_out
        from optimism.logs
        where block_time >= now() - interval '2' day
            and contract_address = 0x47029bc8f5cbe3b464004e87ef9c9419a48018cd -- OP - USDC Pair
            and topic0 = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822   -- Swap
        order by block_time desc
        limit 1000
    )
)

select * from op_price
```

Here is an actual case: [https://dune.com/queries/1130354](https://dune.com/queries/1130354)

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch10/ch10-useful-queries-part2.md">
# 10 Useful Queries (II): Token holders, total supply, account balance

In the useful queries part1, we mainly explained the different ways of querying the price of ERC20 tokens. Usually we also need to query the number of holders of a certain token, the total supply of tokens (circulation), the account balance of each holder (such as the balance of the account with the most holdings), and other related information. Next, we will introduce this part of the content.

Unlike Bitcoin, which tracks account balances through unspent transaction output (UTXO), EVM-compatible blockchains represented by Ethereum use a model of account balances. Each account address has transfer-in records and transfer-out records for each ERC20 token and the current balance of the account can be obtained by summarizing these transfer-in and transfer-out data. Because the blockchain itself does not hold the current balance of each address, we have perform some calculations to retrieve this data. Dune V2's spells tables `erc20_day`, `erc20_latest` (path: Spells/balances/ethereum/erc20/) and organize and update the latest balance and daily balance of each ERC20 token under each address, which can be used for query. However, according to the test, there are currently two problems with the use of these spells tables: one is that there is only the account balance spells table of the Ethereum chain and it does not support querying data of other chains; the other is that the query performance of these tables is not very satisfactory. So we will not introduce the use of these tables here, you can explore by yourself.

To query the account balance information of a single ERC20 token, first we need to know the contract address of the corresponding token. This can be obtained by querying the `tokens.erc20` table. For example, if we want to query the information of FTT Token, we can execute the following query. From the query results, we can get the contract address of FTT Token: 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9 .

``` sql
select * from tokens.erc20
where symbol = 'FTT'
    and blockchain = 'ethereum'
```

## Query the number of token holders and the total circulation of tokens

As mentioned earlier, whether we want to calculate the balance of a certain token under an account or calculate the balance of all holders of a certain token, we need to combine the transfer-in and transfer-out data together. For the transferred data, we take `to` as the user's addressn and the amount is a positive number. For the transfer data, take `from` as the user address and multiply the amount by `-1` to make it a negative number. Use union all to merge all records together. Use `union all` to merge all records together. The following sample code considers execrestriction:
ution performance issues and deliberately increases the `limit 10` 
``` sql
select * from (
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "to" as address,
        cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9

    union all
    
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9
)
limit 10    -- for performance
```

In the above query, we use `union all` to merge the incoming and outgoing FTT tokens for each account address, and only take 10 samples. Note that we cast the value using `value::decimal(38, 0)` on the `value` field. Since the field is now stored as a string, not doing this would cause some problems in the calculation. The number 38 is currently the largest number of integers supported by Dune's database, and "0" means no decimal places.

The account balance we need to calculate is the summary data, which we can put into a CTE definition based on the preceding query and then perform summary statistics against the CTE. Given that many token holders may have a large number of addresses (tens of thousands or even more), we usually focus on the total number of holders, total circulation, and the portion of addresses with the most holdings. We can also put the query summarized by address into a CTE, which is convenient to do further statistics as needed. Here, we first count the total number of holders and exclude those with a current token balance of 0. The new SQL statement is as follows:

``` sql
with transfer_detail as (
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "to" as address,
        cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9
    
    union all
    
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9
),

address_balance as (
    select address,
        sum(amount) as balance_amount
    from transfer_detail
    group by address
)

select count(*) as holder_count,
    sum(balance_amount / 1e18) as supply_amount
from address_balance
where balance_amount > 0
```
In the above query, we count the account balances by address in the `address_balance` CTE. In the final query we calculate the number of addresses whose current balance is greater than 0 (number of holders) and the sum of all account balances (total in circulation). Since the number of decimal places in the FTT token is `18`, when we calculate `thesupply_amount`, we divide the original amount by `1e18` to convert it to the amount with decimal places. This is the total amount of FTT tokens in circulation. It is important to note that different ERC20 tokens have different decimal places, as returned by the previous query to the `tokens.erc20` table. `1e18` is an equivalent shorthand for `power(10, 18)`, which means finding 10 to the 18th power. Since FTT tokens have more than 20,000 holding addresses, this query is relatively time-consuming and may take several minutes to execute.

The query results are shown in the following figure. Contrast Etherscan's data above [https://etherscan.io/token/0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9](HTTP://https://etherscan.io/token/0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9), the amount of total circulation tokens is essentially consistent, but the number of holders have certain differences. The difference is caused by the criteria used to determine which accounts have very small balances, which can be converted to decimal places when aggregating the balances of each address and ignored when counting the number of holders and total balances in circulation. A rule of thumb is to ignore addresses with balances less than `0.001` or `0.0001`.

![](img/ch10_image_03.png)

An example query: [https://dune.com/queries/1620179](https://dune.com/queries/1620179)

## Query the address holding the most tokens

In the previous Query that queried the number of token holders and the amount in circulation, we have aggregated the current token balance of each holder by address. Therefore, it is easy to query the addresses of the users with the largest number of tokens and their respective holdings. You can either Fork the query to make changes, or you can copy the query code and create a new query. Since we are querying for a single token, we can replace the hard-coded token address with a query parameter `{{token_contract_address}}` and set the contract address of the FTT token above as the default, which gives us the flexibility to query data for any token. The following query returns the 100 addresses with the largest number of tokens:

``` sql
with transfer_detail as (
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "to" as address,
        cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = {{token_contract_address}}
    
    union all
    
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = {{token_contract_address}}
),

address_balance as (
    select address,
        sum(amount / 1e18) as balance_amount
    from transfer_detail
    group by address
)

select address,
    balance_amount
from address_balance
order by 2 desc
limit 100
```

Using the FTT token contract address default parameters, the above query returns the 100 addresses holding the largest number of FTTS. We can visualize a bar chart comparing the amount held by the top 100 holders. Because the amount difference is obvious, we will log the Y-axis data by checking the Logarithmic option. As shown below:

![](img/ch10_image_04.png)

An example query: [https://dune.com/queries/1620917](https://dune.com/queries/1620917)

## Query the distribution of the amount held by different token holders

If we need to know the distribution of balances across all addresses holding an ERC20 token, there are two alternatives: one uses a rule of thumb to set up partitions, which is coarser, may miss some key features, and is not flexible enough to support analysis of many different tokens at the same time. The other way is more accurate, but also more complex. Let's introduce them separately.

**Distribution by rule of thumb:** Because we are looking at ranges of money (and similarly for quantity distributions), we can choose typical ranges of money: over 10,000, between 1,000 and 10,000, between 500 and 1,000, between 100 and 500, between 10 and 100, between 1 and 10, and less than 1. Of course, you can adjust it to meet the demand based on the total issuance of the specific token being analyzed. The query is as follows:

``` sql
with transfer_detail as (
    -- Same as previous sample
),

address_balance as (
    select address,
        sum(amount / 1e18) as balance_amount
    from transfer_detail
    group by address
)

select (case when balance_amount >= 10000 then '>= 10000'
            when balance_amount >= 1000 then '>= 1000'
            when balance_amount >= 500 then '>= 500'
            when balance_amount >= 100 then '>= 100'
            when balance_amount >= 10 then '>= 10'
            when balance_amount >= 1 then '>= 1'
            else '< 1.0'
        end) as amount_area_type,
        (case when balance_amount >= 10000 then 10000
            when balance_amount >= 1000 then 1000
            when balance_amount >= 500 then 500
            when balance_amount >= 100 then 100
            when balance_amount >= 10 then 10
            when balance_amount >= 1 then 1
            else 0
        end) as amount_area_id,
    count(address) as holder_count,
    avg(balance_amount) as average_balance_amount
from address_balance
group by 1, 2
order by 2 desc
```

A pie chart is the best way to visualize the distribution over a small number of specified intervals, but one drawback of using a pie chart is that the data often is not sorted in the order you expect. So in the above query, we also use another CASE statement to output the field `amount_area_id` used for sorting. In addition to the pie chart, we also output a histogram, because histograms support adjusted sorting (the default ordering, which can be unsorted or reversed), which is more intuitive to compare the number of adjacent ranges. In this histogram, we unsort and invert the result set so that the histogram is plotted from smallest to largest. Here is how the visualization looks when added to the data dashboard:

![](img/ch10_image_05.png)

An example query: [https://dune.com/queries/1621478](https://dune.com/queries/1621478)

**Statistical distribution according to logarithmic partition interval: **

A more reasonable statistical distribution is to divide the data into corresponding partition intervals according to certain rules and then count the number of holder addresses belonging to each interval. For situations like token balances that vary wildly (accounts with small balances can have less than one token,and with large balances can have hundreds of millions of tokens), partitioning using logarithms is a relatively viable solution. If the analysis is the price, transaction amount, and other relative changes in a certain period of time is not particularly drastic, the use of the equal division method is also feasible. Specifically, calculate the difference between the maximum value and the minimum value, divide it into N equal parts, each interval is increased by the corresponding value on this basis. Here we use the `log2()` method to find the logarithm. Depending on the specific characteristics of the data you are analyzing, there may be other partitioning methods that are more appropriate.

``` sql
with transfer_detail as (
    -- Same as previous sample
),

address_balance as (
    select address,
        floor(log2(sum(amount / 1e18))) as log_balance_amount,
        sum(amount / 1e18) as balance_amount
    from transfer_detail
    group by address
    having balance_amount >= pow(10, -4)
)

select (case when log_balance_amount <= 0 then 0 else pow(2, log_balance_amount) * 1.0 end) as min_balance_amount,
    count(*) as holder_count
from address_balance
group by 1
order by 1
```

We use `floor(log2(sum(amount / 1e18)))` to log the balance of all holders and round it down to get an integer value. It also calculates the normal balance and using `having balance_amount >= pow(10, -4)` filters out accounts with a balance less than 0.0001. In the query that outputs the final result, we use a CASE statement that treats the value `log_balance_amount >= 0` as 0, indicating that the account balance is between 0 and 2. For any other value, the `pow()` function is used to restore the normal amount of money. In this way, we realize the number of addresses in different amount intervals by logarithmic partitioning. As shown below, We can visualize the query results as a histogram:

![](img/ch10_image_06.png)

An example query: 
- Statistical distribution by log partition: [https://dune.com/queries/1622137](https://dune.com/queries/1622137)
- Statistical distribution according to equal division method: [https://dune.com/queries/1300399](https://dune.com/queries/1300399)

## Query the number of ERC20 token holders over the date

For smart contracts that have already been parsed, in addition to querying the `evt_Transfer` table, we can also directly query the corresponding Decode table. For example, with regard to the the FTT Token we queried earlier, its contract has already been Decoded. Go to the query editor page of Dune, click "Decoded Projects", search for "ftt", and then select "FTT_Token". You should see a table of type `event` called "Transfer" in the list. Click the double arrow symbol on the right to insert the full table name into the query editor window, which is `ftt_ethereum.FTT_Token_evt_Transfer`. The advantage of using Decode tables is that queries read less data and performs better.

Suppose our goal is to track the number of FTT token holders each week, so we need to figure out how many people hold FTT token balances in each week. Let's start with the query code, followed by an explanation:

``` sql
with transfer_detail as (
    select evt_block_time,
        "to" as address,
        cast(value as decimal(38, 0)) as value,
        evt_tx_hash
    from ftt_ethereum.FTT_Token_evt_Transfer
    
    union all
    
    select evt_block_time,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as value,
        evt_tx_hash
    from ftt_ethereum.FTT_Token_evt_Transfer
),

holder_balance_weekly as (
    select date_trunc('week', evt_block_time) as block_date,
        address,
        sum(value/1e18) as balance_amount
    from transfer_detail
    group by 1, 2
),

holder_summary_weekly as (
    select block_date,
        address,
        sum(balance_amount) over (partition by address order by block_date) as balance_amount
    from holder_balance_weekly
    order by 1, 2
),

min_max_date as (
    select min(block_date) as start_date,
        max(block_date) as end_date
    from holder_balance_weekly
),

date_series as (
    SELECT dt.block_date 
    FROM min_max_date as mm
    CROSS JOIN unnest(sequence(date(mm.start_date), date(mm.end_date), interval '7' day)) AS dt(block_date)
),

holder_balance_until_date as (
    select distinct d.block_date,
        w.address,
        -- get the last balance of same address on same date or before (when no date on same date)
        first_value(balance_amount) over (partition by w.address order by w.block_date desc) as last_balance_amount
    from date_series d
    inner join holder_summary_weekly w on w.block_date <= d.block_date
),

holder_count_summary as (
    select block_date,
        count(address) as holder_count,
        sum(last_balance_amount) as balance_amount
    from holder_balance_until_date
    where last_balance_amount > 0
    group by block_date
)

select block_date,
    holder_count,
    balance_amount,
    (holder_count - lag(holder_count, 1) over (order by block_date)) as holder_count_change,
    (balance_amount - lag(balance_amount, 1) over (order by block_date)) as balance_amount_change
from holder_count_summary
order by block_date
```

The instructions are as follows: 
1. CTE `transfer_detail` is basically the same as the previous example, except now we read the data from the `FTT_Token_evt_Transfer` table specific to the FTT token, so there is no additional filter.
2. In the `holder_balance_weekly` CTE, we use `date_trunc(`week`, evt_block_time)` to convert the date to the start of each week, and group the balance change for each address in each week. Note that this is the weekly change, not the actual balance at that time.
3. In `holder_summary_weekly`, we based on the `weekly balance changes`, Use `sum(balance_amount) over (partition by address order by block_date)` to sum the balance of each address up to each date. In this case, you get the actual balance value for the specific date.
4. The CTE `min_max_date` is used to find the start and end dates from the previous CTE. Because we want to count the number of holders for each week, we need to generate a date sequence from this date range.
5. Then we use the start and end dates in `date_series` to generate a sequence of dates with 7-day intervals. This gives the start date of each week between the two dates.
6. Then in `holder_balance_until_date`, we do a relational query using the CTE of the date series and the weekly balance to calculate the accumulated balance at each address up to each date in the `date_series`. Note that `from date_series d inner join holder_summary_weekly w on w.lock_date <= d.lock_date `Here, we used` <= `to match all the records in the` holder_summary_weekly `table that are up to and including the current` date_series` date. That is, for each date value in `date_series`, we will match a batch of records in` holder_summary_weekly `. This operation is somewhat similar to the Cartesian product. Also note that in the SELECT substatement, we're getting a `d.lock_date` instead of a `w.lock_date`, which is crucial for summarizing the data correctly.
7. Then, in `holder_count_summary`, we count the number of addresses with a balance greater than 0 by date, so we get the number of addresses with an FTT Token balance in the account for each date (first day of the week).
8. At the end of the query, we use the `lag()` function to output the daily change in the number of holders and the total balance of all accounts.

We visualize the query results into two charts, and add them to the data dashboard as follows: 

![](img/ch10_image_07.png)

An Example on Dune: [https://dune.com/queries/1625278](https://dune.com/queries/1625278)

## Query the account balance for the specified user address

Based on the previous query example, it can be easily modified to query the balance information for a specific user address or a set of user addresses. We just need to add a filter to filter the `address` records that meet the criteria, so there is no example in this case.

## Querying native token holders (ETH)

ETH is the native token of the Ethereum, not an ERC20 token, and its transaction data is not stored in the `evt_Transfer` table, so it cannot be used to calculate information such as ETH balance and holder in the same way as ERC20 tokens. A smart contract can transfer ETH at the same time as calling a method that supports transfer function, or even when a new smart contract is created (deployed) or when a smart contract self-destructs.Moreover, Ethereum blockchain fuel is also paid in ETH. All of these ETH transfers are recorded in the `ethereum. traces` table, while the `ethereum. transactions` table contains only direct transactions.  Therefore, when calculating the ETH balance or counting the number of holders, we have to use `traces` table.  The implementation is similar to calculating the ERC20 token balance, except for the data source.  Here is a data dashboard created earlier to track the balance of ETH account, and the query demonstrates the implementation.

Reference data dashboard: [ETH Whales Tracking](https://dune.com/springzhang/eth-whales-top-1000-eth-holders)

## Recommended References

The "Tips and Tricks for Query and Visualization in Dune V2 Engine" data dashboard board is a collection of tips and tricks for further reading. The follow-up will continue to supplement and update more skills, welcome to collect.

dashboard address: [Tips and Tricks for Query and Visualization in Dune V2 Engine](https://dune.com/springzhang/tips-and-tricks-for-query-and-visualization-in-v2-engine)

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch11/ch11-useful-queries-part3.md">
# 11 Useful Queries (III): custom data, number sequence, array, JSON, etc

In the first two parts of common queries, we introduced some common query methods such as price query, holder, and holding balance of ERC20 tokens. In this section, we'll look at some other common queries.

##  Custom data table using CTE

Dune V2 does not currently support user-custom tables and views. For some data from external sources or a small amount of manually curated data, we can consider using CTE to generate a custom list of data within the query. It can support custom CTE tables with thousands of rows with only a few fields and that they will execute successfully as long as they do not exceed the maximum size of the Dune query request. There are two ways to customize CTE tables: 

Example of the first syntax: 
``` sql
with raydium_lp_pairs(account_key, pair_name) as (
    values
    ('58oQChx4yWmvKdwLLZzBi4ChoCc2fqCUWBkwMihLYQo2', 'SOL/USDC'),
    ('7XawhbbxtsRcQA8KTkHT9f9nc6d69UwqCDh6U5EEbEmX', 'SOL/USDT'),
    ('AVs9TA4nWDzfPJE9gGVNJMVhcQy3V9PGazuz33BfG2RA', 'RAY/SOL'),
    ('6UmmUiYoBjSrhakAobJw8BvkmJtDVxaeBtbt7rxWo1mg', 'RAY/USDC'),
    ('DVa7Qmb5ct9RCpaU7UTpSaf3GVMYz17vNVU67XpdCRut', 'RAY/USDT'),
    ('GaqgfieVmnmY4ZsZHHA6L5RSVzCGL3sKx4UgHBaYNy8m', 'RAY/SRMSOL'),
    ('6a1CsrpeZubDjEJE9s1CMVheB6HWM5d7m1cj2jkhyXhj', 'STSOL/USDC'),
    ('43UHp4TuwQ7BYsaULN1qfpktmg7GWs9GpR8TDb8ovu9c', 'APEX4/USDC')
)

select * from raydium_lp_pairs
```

Example of the second syntax: 

``` sql
with token_plan as (
    select token_name, hook_amount from (
        values
        ('Token Type','BEP-20 on BNB Chain'),
        ('Total Token Supply','500,000,000 HOOK'),
        ('Private Sale Allocation','100,000,000 HOOK'),
        ('Private Sale Token Price','0.06 USD to 0.12 USD / HOOK'),
        ('Private Sale Amount Raised','~ 6,000,000 USD'),
        ('Binance Launchpad Sale Allocation','25,000,000 HOOK'),
        ('Binance Launchpad Sale Price','0.10 USD / HOOK'),
        ('Binance Launchpad Amount to be Raised','2,500,000 USD'),
        ('Initial Circ. Supply When Listed on Binance','50,000,000 HOOK (10.00%)')
    ) as tbl(token_name, hook_amount)
)

select * from token_plan
```

Of course, with the second syntax, you can omit the CTE definition and use the SELECT query directly if you happen to only need to return this part of the custom data.

Example link to the above query: 
- [https://dune.com/queries/781862](https://dune.com/queries/781862)
- [https://dune.com/queries/1650640](https://dune.com/queries/1650640)

Due to the limitations mentioned earlier, the execution may not succeed when there are too many rows. You will need to duplicate the same CTE code for every query, which is relatively inconvenient. For large amounts of data, multiple times, long-term use, etc., you should still consider generating the spells table by submitting spellbook PR.

## Decode data from the logs

Earlier in calculating the price of ERC20 tokens, we saw an example of calculating the price from logs. Let's look at another example where we need to decode data directly from logs. When the smart contract is not decoded by Dune, or the decode table for the corresponding event is not generated because the ABI data used during decoding is incomplete, we may need to decode the query data directly from the logs. Taking the Lens protocol as an example, we found that in the Lens smart contract source code ([Lens Core](https://github.com/lens-protocol/core)), almost every operation has generated event logs. However, there are only a few event-related tables in Dune's decoded data. Further investigation revealed that the ABI used during decoding was missing the definition of these events. Although we can regenerate or get the Lens team to get the full ABI and submit it to Dune to parse again, the main point here is how to extract data from the undecoded logs.

In the Lens smart contract source code, we see the `FollowNFTTransferred` event definition, [code link](https://github.com/lens-protocol/core/blob/main/contracts/libraries/Events.sol#L347). There is also a `Followed` event in the code, but decoding is complicated by the array argument, so we'll use the previous event as an example. From the event name, we can infer that when a user follows a Lens Profile, a FollowNFT will be generated and transferred to the follower's address. We can  then find a transaction record of interest. Let's look at the logs inside for the following transaction:[https://polygonscan.com/tx/0x30311c3eb32300c8e7e173c20a6d9c279c99d19334be8684038757e92545f8cf](https://polygonscan.com/tx/0x30311c3eb32300c8e7e173c20a6d9c279c99d19334be8684038757e92545f8cf). The transaction Logs page in our browser and switch to the "Logs" TAB, so we can see that there are four event logs in total. In certain instances, the blockchain browser can display the original event name. The Lens transaction we're looking at doesn't show the original name, so how do we know which one corresponds to the `FollowNFTTransferred` event log? Here we can use third-party tools to compare by generating the keccak256 hash of the event definition. [Keccak - 256](https://emn178.github.io/online-tools/keccak_256.html) this page can generate online Keccak - 256 hash value. Let's clean up the definition of the `FollowNFTTransferred` event in the source code to a minified mode (remove parameter names, remove Spaces), Get ` FollowNFTTransferred (uint256 uint256, address, the address, uint256) `, then paste it to Keccak - 256 tool page, The generated hash value for ` 4996ad2257e7db44908136c43128cc10ca988096f67dc6bb0bcee11d151368fb `. (The latest Dune parse table already has the full event table for the Lens project, here is just for example purposes)

![](img/ch11_image_08.png)

Using this hash, we can search Polygonscan's transaction log list to find a match. You can see that the first log entry is exactly what we're looking for.

![](img/ch11_image_09.png)

After finding the corresponding log record, with the event definition, we can easily decode the data:

``` sql
select block_time,
    tx_hash,
    bytearray_to_uint256(topic1) as profile_id, --  the followed Profile ID
    bytearray_to_uint256(topic2) as follower_token_id, -- follower's NFT Token ID
    bytearray_ltrim(bytearray_substring(data, 1, 32)) as from_address2, -- address (out)
    bytearray_ltrim(bytearray_substring(data, 1 + 32, 32)) as to_address2 -- address (in)(address of the follower)
from polygon.logs
where contract_address = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d -- Lens contract address
    and block_time >= date('2022-05-01') -- The Lens contract is deployed after this date, and this condition is used to improve query speed
    and topic0 = 0x4996ad2257e7db44908136c43128cc10ca988096f67dc6bb0bcee11d151368fb   -- Event topic FollowNFTTransferred
limit 10
```

Example link to the above query:
- [https://dune.com/queries/1652759](https://dune.com/queries/1652759)
- [Keccak-256 Tool](https://emn178.github.io/online-tools/keccak_256.html)

## Use sequences of numbers to simplify queries

When studying NFT projects, we may want to analyze the distribution of prices of all transactions for a given NFT project during a certain time period (i.e., how many transactions were recorded in each price range). We typically set the minimum and maximum transaction prices (either by input or by querying the transaction data and handling outliers), divide the range into N ranges, and count the number of transactions in each range. Here is an example of a query that is simple in logic but cumbersome in comparison:

``` sql
-- nft Position cost distribution
-- 0x306b1ea3ecdf94ab739f1910bbda052ed4a9f949 beanz
-- 0xED5AF388653567Af2F388E6224dC7C4b3241C544 azuki
with contract_transfer as (
    select * 
    from nft.trades
    where nft_contract_address = 0xe361f10965542ee57D39043C9c3972B77841F581
        and tx_to != 0x0000000000000000000000000000000000000000
        and amount_original is not null
),

transfer_rn as (
    select row_number() over (partition by token_id order by block_time desc) as rn, *
    from contract_transfer
),

latest_transfer as (
    select * from transfer_rn
    where rn = 1 
),

min_max as (
    select (cast({{max_price}} as double) - cast({{min_price}} as double))/20.0 as bin
),

bucket_trade as (select *,
    case 
      when amount_original between {{min_price}}+0*bin and {{min_price}}+1*bin then 1*bin
      when amount_original between {{min_price}}+1*bin and {{min_price}}+2*bin then 2*bin
      when amount_original between {{min_price}}+2*bin and {{min_price}}+3*bin then 3*bin
      when amount_original between {{min_price}}+3*bin and {{min_price}}+4*bin then 4*bin
      when amount_original between {{min_price}}+4*bin and {{min_price}}+5*bin then 5*bin
      when amount_original between {{min_price}}+5*bin and {{min_price}}+6*bin then 6*bin
      when amount_original between {{min_price}}+6*bin and {{min_price}}+7*bin then 7*bin
      when amount_original between {{min_price}}+7*bin and {{min_price}}+8*bin then 8*bin
      when amount_original between {{min_price}}+8*bin and {{min_price}}+9*bin then 9*bin
      when amount_original between {{min_price}}+9*bin and {{min_price}}+10*bin then 10*bin
      when amount_original between {{min_price}}+10*bin and {{min_price}}+11*bin then 11*bin
      when amount_original between {{min_price}}+11*bin and {{min_price}}+12*bin then 12*bin
      when amount_original between {{min_price}}+12*bin and {{min_price}}+13*bin then 13*bin
      when amount_original between {{min_price}}+13*bin and {{min_price}}+14*bin then 14*bin
      when amount_original between {{min_price}}+14*bin and {{min_price}}+15*bin then 15*bin
      when amount_original between {{min_price}}+15*bin and {{min_price}}+16*bin then 16*bin
      when amount_original between {{min_price}}+16*bin and {{min_price}}+17*bin then 17*bin
      when amount_original between {{min_price}}+17*bin and {{min_price}}+18*bin then 18*bin
      when amount_original between {{min_price}}+18*bin and {{min_price}}+19*bin then 19*bin
      when amount_original between {{min_price}}+19*bin and {{min_price}}+20*bin then 20*bin
      ELSE 21*bin
    end as gap
  from latest_transfer,min_max
 )

select gap, count(*) as num
from bucket_trade
group by gap
order by gap 
```

In this example, we define two parameters `min_price` and `max_price`, divide their difference equally into 20 price bands, and then use a lengthy CASE statement to count the number of transactions in each band. Imagine if you had to break it up into 50 groups. Is there an easier way? The answer is yes. Look at the code first: 

``` sql
with contract_transfer as (
    select * 
    from nft.trades
    where nft_contract_address = 0xe361f10965542ee57D39043C9c3972B77841F581
        and tx_to != 0x0000000000000000000000000000000000000000
        and amount_original is not null
),

transfer_rn as (
    select row_number() over (partition by token_id order by block_time desc) as rn, *
    from contract_transfer
),

latest_transfer as (
    select *
    from transfer_rn
    where rn = 1 
),

min_max as (
    select (cast({{max_price}} as double) - cast({{min_price}} as double))/20.0 as bin
),

-- Generates a single column table with numbers from 1 to 20
num_series as (
    select num from unnest(sequence(1, 20)) as tbl(num)
),

-- Generates the start and end prices of the group price range
bin_gap as (
    select (num - 1) * bin as gap,
        (num - 1) * bin as price_lower,
        num * bin as price_upper
    from num_series
    join min_max on true
    
    union all
    
    -- Add an additional interval to cover other data
    select num * bin as gap,
        num * bin as price_lower,
        num * 1e4 * bin as price_upper
    from num_series
    join min_max on true
    where num = 20
),

bucket_trade as (
    select t.*,
        b.gap
      from latest_transfer t
      join bin_gap b on t.amount_original >= b.price_lower and t.amount_original < b.price_upper
 )

select gap, count(*) as num
from bucket_trade
group by gap
order by gap
```

In CTE `num_series`, we use` unnest(sequence(1, 20)) as tbl(num) `to generate a sequence of numbers from 1 to 20 points and convert it into 20 rows of one number per row. Then in `bin_gap`, we get the low and high price for each interval by joining the two CTEs. Using the `union all` set adds an additional range of high price values large enough to cover other transactions. `bucket_trade` can then be simplified to simply concatenate `bin_gap` and compare prices falling into the corresponding range. The overall logic is simplified and much clearer to understand.

Example link to the above query:
- [https://dune.com/queries/1054461](https://dune.com/queries/1054461)
- [https://dune.com/queries/1654001](https://dune.com/queries/1654001)

## Read data from Array and Struct fields

Some smart contracts emit event logs using array parameters and the data table generated by Dune after decoding is also stored in arrays. The Solana blockchain's raw transaction tables make heavy use of arrays to store data. Some data is stored in structs, or we need to borrow them when we want to extract the data (see below for an example). Let's look at how to access the data stored in array fields and struct fields.

``` sql
select tokens, deltas, evt_tx_hash
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

The first two fields returned by the preceding query are arrays (shown in  the following image):

![](img/ch11_image_10.png)

We can use `cross join unnest(tokens) as tbl1(token)` to split the `tokens` array field into multiple lines:
``` sql
select evt_tx_hash, deltas, token   -- Returns the split field
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
cross join unnest(tokens) as tbl1(token)   -- Split into multiple lines, and name the new field token
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

We can also split the `deltas` field. But because each `cross join` appends the split value to the original result set of the query, if we perform operations on both fields at the same time, we will have an incorrect result set that looks like a Cartesian product. The following screenshot shows the query code and the resulting output:

``` sql
select evt_tx_hash, token, delta
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
cross join unnest(tokens) as tbl1(token)   -- Split into multiple lines, and name the new field token
cross join unnest(deltas) as tbl2(delta)   -- Split into multiple lines, and name the new field delta
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

![](img/ch11_image_11.png)

To avoid duplication, it is advisable to split multiple fields simultaneously within the same `unnest()` function, it will return a temporary table with multiple corresponding new fields.

``` sql
select evt_tx_hash, token, delta
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
cross join unnest(tokens, deltas) as tbl(token, delta)   -- Split into multiple lines, and name the new field token snd delta
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

The result is shown in the following figure: 

![](img/ch11_image_12.png)

Example link to the above query: 
- [https://dune.com/queries/1654079](https://dune.com/queries/1654079)


## Read JSON string data

In some smart contracts, objects containing multiple values are serialized as json strings in the parse table, such as the Lens creation Profile event we saw earlier. We can use `:` to read variables directly from a json string. For example:

``` sql
select  json_value(vars, 'lax $.to') as user_address, -- Read a json string of user address
     json_value(vars, 'lax $.handle') as handle_name, -- Read a json string of user nicknames
    call_block_time,
    output_0 as profile_id,
    call_tx_hash
from lens_polygon.LensHub_call_createProfile
where call_success = true   
limit 100
```

Alternatively, use the `json_query()` or `json_extract()` function to extract the corresponding data. The `json_extract()` function supports type conversion when you need to extract array values from a JSON string. Here are some examples:
``` sql
select
json_query(vars, 'lax $.follower') AS follower, -- single value
json_query(vars, 'lax $.profileIds') AS profileIds, -- still string
from_hex(cast(json_extract(vars,'$.follower') as varchar)) as follower2, -- cast to varbinary
cast(json_extract(vars,'$.profileIds') as array(integer)) as profileIds2, -- cast to array
vars
from lens_polygon.LensHub_call_followWithSig
where cardinality(output_0) > 1
limit 10
```

Example link to the above query: 
- [https://dune.com/queries/1562662](https://dune.com/queries/1562662)
- [https://dune.com/queries/941978](https://dune.com/queries/941978)
- [https://dune.com/queries/1554454](https://dune.com/queries/1554454)

Dune SQL (Trino) For detailed help on JSON functions, check out: https://trino.io/docs/current/functions/json.html 

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch12/ch12-nft-analysis.md">
# 12 NFT Analysis

## Background Information

[ERC721](https://eips.ethereum.org/EIPS/eip-721) is one of the most used [NFT(Non-Fungable Token)](https://ethereum.org/zh/nft/) standards. compared to follow ERC20 standard in terms of fungable tokens, Traditionally, the most typical characteristics of NFT are that each token is indivisible, irreplaceable, and unique. The common uses of NFT are:


- Digital art/collections
- In-game items
- Domain names
- Tickets or coupons that allow you to attend an event
- Digital identity
- Articles

For example, in digital art, different NFTS have different styles; for instance, in the ENS domain name, each domain name is unique and cannot be repeated. As for tickets, each ticket has a fixed seat, and different seats are also different numbers.

With the development of NFT, other standard NFT have been derived:

- ERC-1155: Non-fungible tokens, each token is different, but can do quantity transfer
- SBT: Non-transferable Token
- ERC-3235: Semi-fungible token, each token is different, and supports settlement

|          | ERC20                                                | ERC721                                                                     | ERC1155                                                                                                                                    | ERC3535                                                                                                                                                                                                                                                                                                                                                               |
|----------|------------------------------------------------------|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **features** | fungible tokens(each single token is same as others) | non-fungible tokens(each single token is unique, no one is same as others) | representing fungible, semi-fungible, and non-fungible tokens.                                                                             | Semi-Fungible Token                                                                                                                                                                                                                                                                                                                                                   |
| **esamples** | address A transfer 100ETH to address B               | address A transfer an laser eye BAYC to address.(not glassed or others)    | address A transfer 5 bottles of potion in a game. Not other equipment.  each of the 5 bottles of potion is same. but we can +/- 5 bottles. | A DeFi protocol gives user A a $100 1-year bond, numbered 001. The bond can be split into 2 $50 bonds, numbered 002 and 003, which user A then transfers to holders B and C. The bond can be split into 2 $50 bonds, numbered 002 and 003. The 003 bond can in turn be split into another $20 for the 003 bond, at which point 002 is worth $30 and 003 is worth $70. |
| **scenario** | cryptocurrency                                       | Digital Collections                                                        | In-Game Assets                                                                                                                             | Financial Assets/Contracts                                                                                                                                                                                                                                                                                                                                            |

## Contract description

The contracts related to NFT are usually divided into two categories: one is the contract of the project party and the other is the contract of the third-party exchange platform used to trade NFT.

### ERC721 contract

We use ERC721 NFT as an example to show the characteristics of an NFT contract, the other can according to demand to understand, we in the market of NFT Opensea to [azuki](https://opensea.io/collection/azuki) on the NFT, for example, that contract contain what events:

``` solidity
interface ERC721 {
    /// @dev This event is fired when the ownership of any NFT changes (either way).
    ///  Both at creation time (` from `== 0) and destruction time (` to` == 0), except when the contract is created.
    event Transfer(address indexed _from, address indexed _to, uint256 indexed _tokenId);

    /// @dev Triggered when the approval address of the NFT is changed or confirmed.
    ///  A zero address indicates an address without approval
    ///  When a `Transfer` event occurs, it also means that the approved address (if any) for that NFT is reset to "none" (zero address).
    event Approval(address indexed _owner, address indexed _approved, uint256 indexed _tokenId);

    /// @dev Triggered when the owner enables or disables the operator. (Operator can manage NFTs held by owner)
    event ApprovalForAll(address indexed _owner, address indexed _operator, bool _approved);

    /// @notice Transfer ownership of NFT from one address to another
    /// @dev Throws an exception if `msg.sender` is not the current owner (or approver)
    /// Throw an exception if `_from` is not the owner, `_to` is a zero address, and `_tokenId` is not a valid id.
    ///  When the transfer completes, the function checks if `_to` is a contract, and if so, calls` onERC721Received `of` _to `and checks if the returned value is `0x150b7a02` (That is:`bytes4(keccak256("onERC721Received(address,address,uint256,bytes)"))`)  If it doesn't throw an exception.
    /// @param _from : current owner
    /// @param _to : new owner
    /// @param _tokenId : The token id to transfer.
    /// @param data : Additional parameters (no format specified) are passed to the receiver.
    function safeTransferFrom(address _from, address _to, uint256 _tokenId, bytes data) external payable;

    /// @notice Transfer ownership - The caller is responsible for confirming if `_to` is capable of receiving NFT, otherwise it may be lost permanently.
    /// @dev If `msg.sender` is not the current owner (or approver or operator) that is throwing the exception
    /// Throw an exception if `_from` is not the owner, `_to` is a zero address, and `_tokenId` is not a valid id.
    function transferFrom(address _from, address _to, uint256 _tokenId) external payable;

    /// @notice Change or confirm the approved address of the NFT
    /// @dev A zero address indicates an address without approval
    ///  If `msg.sender` is not the current owner or operator
    /// @param _approved The newly approved controller
    /// @param _tokenId : token id
    function approve(address _approved, uint256 _tokenId) external payable;

    /// @notice Enable or disable a third party (operator) to manage `msg.sender` all assets
    /// @dev To trigger the `ApprovalForAll` event, the contract must allow each owner to have multiple operators.
    /// @param _operator The address to add to the list of approved operators
    /// @param _approved `True` indicates approval and `false` indicates revocation
    function setApprovalForAll(address _operator, bool _approved) external;

    ...
}
```

For data analysis, the most important function is the Transfer event, which is triggered on every transaction and recorded on the chain. In addition to Transfer, there is also the Mint event, which is usually used to mint a new NFT at the time of sale. Dune's spells table provides `ERC721`, `ERC1155`  `Transfer` tables such as `erc721_ethereum.evt_Transfer` , `erc1155_ethereum.evt_Transfer`, etc. (different names under different blockchains), so we can query NFT transfer events for a contract or an EOA address.

In the Transfer event, there are three main parameters: the sender address `from`, the receiver address `to` and the number of the NFT `tokenId`. In the case of transaction, both from and to are a normal address. If `mint`, the from address is all 0, and if `burn`, the address of to is all 0. The `nft.mint` and `nft.burn` tables on Dune also decode this event to get the final transaction information.

![](img/ch12_nft-transfer-etherscan.png)

### marketplace contracts

Some common marketplace contracts are Opensea, X2Y2, Blur, etc. Let's take Opensea Seaport1.1 contract as an example. All functions related to a transaction will trigger the OrderFulfilled event to record the data on the chain. Dune's nft.trades parses this event to get the final trades. The seaport contract writable functions are as follows:

![](img/ch12_seaport1.1.png)

``` solidity
uint256 constant receivedItemsHash_ptr = 0x60;

/*
 *  Memory layout in _prepareBasicFulfillmentFromCalldata of
 *  data for OrderFulfilled
 *
 *   event OrderFulfilled(
 *     bytes32 orderHash,
 *     address indexed offerer,
 *     address indexed zone,
 *     address fulfiller,
 *     SpentItem[] offer,
 *       > (itemType, token, id, amount)
 *     ReceivedItem[] consideration
 *       > (itemType, token, id, amount, recipient)
 *   )
 *
```

For example, Alice  made an order for an Azuki NFT with the number [3638](https://opensea.io/assets/ethereum/0xed5af388653567af2f388e6224dc7c4b3241c544/3638)at 10ETH, then it triggers the 'fulfillBasicOrder' function, and when the transaction succeeds, it triggers the 'OrderFulfilled' event to be logged to the chain.[Etherscan link](https://etherscan.io/tx/0x9beb69ec6505e27f845f508169dae4229e851a8d7c7b580abef110bf831dc338) and[dune link](https://dune.com/queries/1660679).



## Common table Description

- Original base table: located in `Raw`-->`transactions` and `logs` tables;
- Specific project table: located in `Decoded Projects->Search`, enter the name of the specific project table and the name of the trading platform;
- Aggregate table:
  - Spells-->erc721: record all `transfers` of erc721
  - Spells-->nft: this contains information about trades, mints, transfers, fees, and burns; the most important of these is the trades table, which aggregates all of the trade data from the major exchanges.

![](img/ch12_dune-nft-related.png)

The important details of nft.trades table are as follows:

| Field                       | Description                         |
| ------------------------ | ----------------------------------- |
| blockchain               | Most of chain of data gathered in this table           |
| project                  | Trading platform name                   |
| version                  | Trading platform version                   |
| block_time               | Block time                             |
| token_id                 | NFT Token ID                        |
| collection               | NFT collection name                |
| amount_usd               | The dollar value when trading           |
| token_standard           | The standards of the Token                  |
| trade_type               | Transaction type, it is single NFT deal or multiple NFTs trade   |
| number_of_items          | Number of the NFT traded                 |
| trade_category           | Transaction type¬† (Direct buy, auction, etc...) |
| evt_type                 | Evt type (Trade, Mint, Burn)            |
| seller                   | Seller wallet address                       |
| buyer                    | Buyer wallet address                  |
| amount_original          | The original amount of transactions (under the original units of tokens token)|
| amount_raw               | The raw transaction amount without being numeric |
| currency_symbol          | The token symbol of the transaction (what token is used as the unit of payment)           |
| currency_contract        | The token contract address of the original transaction, <br>use WETH on ETH contract address       |
| nft_contract_address     | NFT contract address                     |
| project_contract_address | Trading platform contract address            |
| aggregator_name          | Aggregation platform name, if the transaction is initiated from the aggregation platform, such as gem          |
| aggregator_address       | Aggregate platform contract address          |
| tx_hash                  | Transaction hash                         |
| block_number             | Block of transaction                     |
| tx_from                  | The address from which the transaction is initiated, usually the buyer                      |
| tx_to                    | The address to which the transaction is to be received, usually the trading platform                 |
| unique_trade_id          | Transaction id                              |

## Key metrics

In general, an NFT project will focus on the following basic metrics:

**Transaction price movement**
  
It is necessary to query the transaction amount of all the trading markets and express all the transactions with a scatter plot. At the same time, different ranges can be selected through the time range, such as the last 24h, the last 7 days, the last 1 month, and so on. It should be noted that for some transactions, the transaction price is too high, you need to filter out these, otherwise you will not be able to clearly show most of the transaction price movement.

![](img/ch12_history-price.png)

Reference Links: https://dune.com/queries/1660237

**Floor price**
  
Because we can only obtain the data of completed transactions on the chain and cannot obtain the data of pending orders in the trading market, we generally use the minimum transaction amount among the last 10 transactions as the floor price, which is not much different from the pending order price, unless the project is particularly unpopular

``` sql
-- Find the 10 most recent transactions for this contract, sorted by time
with lastest_trades as (
    select * 
    from nft.trades 
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544 -- contract address of azuki NFT
    -- and block_time > now() - interval '24' hour --It can also be sorted by time
    order by block_time desc
    limit 10
)

select min(amount_original) as floor_price --Get the minimum value directly
    -- percentile_cont(.05) within GROUP (order by amount_original) as floor_price --This is done by taking the 5% quantile between the lowest and highest prices to prevent some too low price trading effects
from lastest_trades
where  currency_symbol IN ('ETH', 'WETH')
    and cast(number_of_items as integer) = 1 -- This can be filtered by different chains, different transaction tokens
```

Reference Links: https://dune.com/queries/1660139

**Transaction volume, total transaction quota, total number of transactions, etc., 24 hours /7 days /1 month transaction quota** 
  
``` sql
with total_volume as(
    SELECT
        sum(amount_original) as "Total Trade Volume(ETH)", 
        sum(amount_usd) as "Total Trade Volume(USD)",      
        count(amount_original) as "Total Trade Tx"     
    FROM nft.trades
    WHERE nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
        -- AND currency_symbol IN ('ETH', 'WETH') 
),

total_fee as (
    select 
        sum(royalty_fee_amount) as "Total Royalty Fee(ETH)",   
        sum(royalty_fee_amount_usd) as "Total Royalty Fee(USD)", 
        sum(platform_fee_amount) as "Total Platform Fee(ETH)",   
        sum(platform_fee_amount_usd) as "Total Platform Fee(USD)" 
    from nft.fees 
    WHERE nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
    -- AND royalty_fee_currency_symbol IN ('ETH', 'WETH') 
)

select * from total_volume, total_fee
```

Reference Links: https://dune.com/queries/1660292
  
**Daily/monthly/weekly volume**

``` sql
with hourly_trade_summary as (
    select date_trunc('day', block_time) as block_date, 
        sum(number_of_items) as items_traded,
        sum(amount_raw) / 1e18 as amount_raw_traded,
        sum(amount_usd) as amount_usd_traded
    from opensea.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
    -- and block_time > now() - interval '90' day
    group by 1
    order by 1
)

select block_date, 
    items_traded,
    amount_raw_traded,
    amount_usd_traded,
    sum(items_traded) over (order by block_date asc) as accumulate_items_traded,
    sum(amount_raw_traded) over (order by block_date asc) as accumulate_amount_raw_traded,
    sum(amount_usd_traded) over (order by block_date asc) as accumulate_amount_usd_traded
from hourly_trade_summary
order by block_date
```

![](img/ch12_daily-trade-volune.png)

Reference Links: https://dune.com/queries/1664420


**Current number of holders, total number of tokens, distribution of holders, etc**
``` sql
with nft_trade_details as ( --Get the buy and sell side detail table for a trade, where the sell side is negative and the buy side is positive
    select seller as trader,
        -1 * cast(number_of_items as integer) as hold_item_count
    from nft.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544

    union all
    
    select buyer as trader,
        cast(number_of_items as integer) as hold_item_count
    from nft.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
),

nft_traders as (
    select trader,
    sum(hold_item_count) as hold_item_count
    from nft_trade_details
    group by trader
    having sum(hold_item_count) > 0
    order by 2 desc
),

nft_traders_summary as (
    select (case when hold_item_count >= 100 then 'Hold >= 100 NFT'
                when hold_item_count >= 20 and hold_item_count < 100 then 'Hold 20 - 100'
                when hold_item_count >= 10 and hold_item_count < 20 then 'Hold 10 - 20'
                when hold_item_count >= 3 and hold_item_count < 10 then 'Hold 3 - 10'
                else 'Hold 1 or 2 NFT'
            end) as hold_count_type,
        count(*) as holders_count
    from nft_traders
    group by 1
    order by 2 desc
),

total_traders_count as (
    select count(*) as total_holders_count,
        max(hold_item_count) as max_hold_item_count
    from nft_traders
),

total_summary as (
    select 
        0 as total_nft_count,
        count(*) as transaction_count,
        sum(number_of_items) as number_of_items_traded,
        sum(amount_raw) / 1e18 as eth_amount_traded,
        sum(amount_usd) as usd_amount_traded
    from opensea.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
)

select *
from nft_traders_summary
join total_traders_count on true
join total_summary on true
```

Reference Links: https://dune.com/queries/1300500/2228120


## NFT Comprehensive dashboard example

We made a dashboard where you can enter the address of an NFT contract and see all kinds of information about the project. You can learn more about queries using the query on the dashboard:

[https://dune.com/sixdegree/nft-collections-metrics-custom-dashboard](https://dune.com/sixdegree/nft-collections-metrics-custom-dashboard)

![](img/ch12_nft-all-in-one.png)


## Reference

- https://mirror.xyz/0x07599B7E947A4F6240F826F41768F76149F490D5/CHcwsp_d0AINEalFq_0FcqkLeEyeeGpYDDtw82TyMes
- https://github.com/cryptochou/seaport-analysis
- https://dune.com/sixdegree/soulda-nft-soulda16club
- https://dune.com/sixdegree/digidaigaku-nft-by-limit-break

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch13/ch13-lending-analysis.md">
# 13 Lending Analysis
 
## Background Knowledge

Decentralized Finance (DeFi) is a financial innovation of blockchain. Through the composability and interoperability of various protocols, DeFi legos was born. In June 2020, the DeFi lending protocol Compound started liquidity mining, not only kicking off the DeFi Summer but also injecting new vitality, new ideas, and new users into the DeFi lending track, making lending business one of the three cores of DeFi.

### Significance of Lending Protocols

Lending protocols are the banks of DeFi. With traditional banks, users can deposit money to receive interest, or they can borrow money and return it with interest. Similarly, in DeFi's lending protocols, users can deposit or borrow money, but the difference is that there is no centralized custody institution. Instead, users interact directly with the lending protocol's smart contracts, and the operation of the code ensures everything goes smoothly. In CeFi lending, loan guarantees are divided into credit, warranty, and collateralized loans. Banks have a low risk preference, and collateralized loans are the most common among all types of loans. Thanks to the construction of big data credit systems, credit lending is becoming more common, though it requires a lot of scrutiny and certification.

![](img/ch13_bank.jpeg)

Lending in DeFi is anonymous and trustless. In terms of the model, it is basically in the form of collateralized loans, and the commonly adopted method is over-collateralization. That is to say, people can pledge $200 worth of assets and borrow less than $200 from the lending protocol. This way, there's no need to worry about defaulting on the loan and running away, so people can lend money confidently. This behavior of borrowing tokens with tokens, and even borrowing less and less, seems very foolish, but in fact, it solves real market demands:

1. Demand for trading activities: This includes arbitrage, leverage, and market-making activities. For example, market makers need to borrow funds to meet a large number of transactions; buying tokens on DEX can only go long, but you can short through borrowing; you can even continuously increase leverage by circular loans through collateralized assets (collateralize ETH to borrow USDC to buy ETH, then collateralize again to borrow and buy again).

2. Passive income: idle funds/tokens holders can earn extra income by lending assets during the process of holding tokens.

3. Token incentives: in addition to liquidity mining, leading DeFi protocols have launched staking services based on their native tokens. Token holders can stake to earn more native tokens. Token incentives face all participants of the lending protocol, and borrowers can earn token rewards through interaction, using the tokens obtained from transactions to repay part of the debt.

Compared with traditional mortgage loans such as homes and vehicles, which require human verification of asset ownership and human effort and time for asset auctions in case of default, the pawnshop model in DeFi only needs to stop collateral when the collateral rate is too low, and the liquidation of assets can end the loan contract.

### Operating Model of Lending Protocols

In the case of collateralized borrowing on the blockchain, how many tokens can be borrowed and when to liquidate are all set by a series of parameters in the smart contract.

![](img/ch13_loan.png)

Max LTV (Loan to Value): this determines the maximum ratio of debt to the value of the collateral at the time of borrowing.

Liquidation Threshold: this is a criterion for determining liquidation. Liquidation occurs when the ratio of debt to the value of the collateral rises to this level.

Liquidation Penalty: This is the penalty percentage that needs to be deducted from the collateral when liquidation occurs.

For example, in Aave V2, the Max LTV of USDC is 87%, the Liquidation Threshold is 89%, and the Liquidation Penalty is 4.5%. This means that for every 1 USDC of collateral, you can borrow up to 0.87 USD of other tokens. Liquidation occurs when the value of the borrowed tokens rises to 0.89 USD. In the case of successful liquidation, a 4.5% penalty will be deducted.

The price fluctuation of crypto assets can often be quite volatile. The over-collateralization method used by lending protocols helps to prevent situations where the debts exceed the assets. The diagram below shows different collateralization ratios corresponding to different rates and collateral requirements.

![](img/ch13_2.png)

When the collateralized assets or the borrowed assets experience significant fluctuations to a certain extent, lending protocols need to perform liquidation to avoid bad debts. 
Let's take AAVE as an example to see how the lending protocol carries out liquidation. 
First, let's introduce a concept called the Health Factor. The Health Factor is related to the account's collateral and loan amount, indicating the possibility of insolvency. So how do we calculate the Health Factor?

1. Check the liquidation line (Liquidation Threshold) of the collateral. For example, the Liquidation Threshold for USDC at this moment is 0.89.

![](img/ch13_hf1.png)

2. `Health Factor` = `Collateral Amount` * `Liquidation Threshold` / `Loaned Assets`. In this casde, `5794 * 0.89 / 4929 = 1.046`;

![](img/ch13_hf2.png)

3. If the price of the collateral drops, or the price of the borrowed assets rises, causing the Health Factor to be less than 1, then Liquidation will be performed. The specific liquidation process is as follows:

![](img/ch13_hf3.png)

So the actual inequality is: Loaned Assets Amount <= Collateral Amount * LTV < Collateral Amount * Liquidation Threshold. 
During liquidation, the portion exceeding the liquidation line will be auctioned off, and liquidators purchase the collateral. The funds obtained from the auction are used to repay the debt, and the surplus is treated as a reward for the liquidator. 
The liquidation process depends on the feed prices from the oracle, AAVE currently uses Chainlink.

Interestingly, although the idea of over-collateralization seems very reliable, and it appears that lending protocols should not have bad debt risk, is this really the case? The recent incident of Eisenberg shorting CRV through borrowing from AAVE V2 has resulted in approximately $1.7 million in bad debts. The main reason may be that this whale's position was too large, and there was not enough liquidity in the market for liquidators to buy in. From the figure below, you can see that this whale deposited 57.94 million USDC into Aave and borrowed 83.42 million CRV.

![](img/ch13_crv1.jpg)

From CoinGecko and blockchain explorers, we can see that the circulating supply of CRV tokens is only 637 million and the amount of CRV borrowed by the whale exceeds that held by all external account holders. For example, as of November 25th, there were only 42.12 million CRV in the Aave contract, and the 8th largest CRV holder, Binance 14, only held 20.21 million CRV. 

![](img/ch13_crv2.png)

In DEX, the liquidity of the ETH/CRV trading pair with the highest liquidity in Uniswap V3 was only $1.76 million, with only 1.48 million CRV. Therefore, there was not enough liquidity in the market for liquidators to buy in and complete the liquidation. After each liquidation, the remaining funds will be added to the collateral, causing the liquidation price of the remaining debt to rise. However, during the liquidation process, the price of CRV continued to rise, ultimately leading to bad debts in Aave.

To summarize, most lending protocols currently use over-collateralization, and whether to liquidate and how much to liquidate is monitored by the health factor when price fluctuates. Here we only talked about the simplest and most basic lending business. In fact, each protocol has its own features. For example, Compound uses a decentralized peer-to-peer model and the liquidity pool utilization model allows for a high utilization of funds within the pool; AAVE was the first to propose flash loans, where borrowing + operation + repayment are completed within a single block, and atomicity determines that this transaction is either completely successful or completely fails; AAVE V3 even proposes the function of cross-chain asset flow; and Euler, Kashi, and Rari and other lending platforms better meet the needs of long-tail assets through permissionless lending pools.


## Key Indicators to Focus On
After understanding the business logic of Onchain lending protocols, we can start analyzing. Next, we will list some indicators commonly used to evaluate lending protocols. It should be noted that although the flow of funds in smart contracts only goes in and out, the meanings they represent are different and need to be judged in conjunction with smart contracts and blockchain explorers.

### 1. Total Value Locked (TVL)
This indicates how much money is locked in the lending protocol's smart contract. TVL represents the liquidity of the protocol. Looking at the data from [defillama](https://defillama.com/protocols/lending), the total lending market TVL exceeds $10B, and the top five's TVL totals approximately $9.5B, with AAVE alone accounting for $3.9B. 

![](img/ch13_tvl.png)

Taking AAVE V3 on Arbitrum as an example, let's look at how to query [TVL](https://dune.com/queries/1042816/1798270).

The basic idea is: in the AAVE smart contract, the amount of money defined as `Supply` is subtracted from the `Withdraw` funds, which equates to the total value locked in the contract. If you open [Arbscan](https://arbiscan.io/address/0x794a61358d6845594f94dc1db02a252b5b4814ad) and find an [AAVE transaction](https://arbiscan.io/tx/0x6b8069b62dc762e81b41651538d211f9a1a33009bcb41798e673d715867b2f29#eventlog), you can open the log and see that `topic0 = 0x2b627736bca15cd5381dcf80b0bf11fd197d01a037c52b927a881a10fb73ba61` corresponds to the `Supply` action in the smart contract.

![](img/ch13_arbscan1.png)

![](img/ch13_tvl2.png)

Similarly, `topic0 = 0x3115d1449a7b732c986cba18244e897a450f61e1bb8d589cd2e69e6c8924f9f7` corresponds to the `Withdraw` action (note: in Dune, `topic1` refers to what is known as topic0 in etherscan). In Dune, you select transactions sent to the AAVE V3 contract from the Arbitrum log table, and define the `Deposit` and `Withdraw` actions based on the topic (action_type). Deposits are positive, withdrawals are negative, and their sum is the amount of tokens locked in the contract. Use the `bytearray_ltrim(topic1)` function to get the address of the transferred token, and use the `bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32))` function to get the quantity of the transferred token (not priced in USD).

``` sql
with aave_v3_transactions as (
    select 'Supply' as action_type,
        block_time,
        bytearray_ltrim(topic1) as token_address,
        bytearray_ltrim(topic2) as user_address,
        cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
        tx_hash
    from arbitrum.logs
    where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
        and topic0 = 0x2b627736bca15cd5381dcf80b0bf11fd197d01a037c52b927a881a10fb73ba61 -- Supply
        and block_time > date('2022-03-16') -- First transaction date
    
    union all
    
    select 'Withdraw' as action_type,
        block_time,
        bytearray_ltrim(topic1) as token_address,
        bytearray_ltrim(topic2) as user_address,
        -1 * cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
        tx_hash
    from arbitrum.logs
    where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
        and topic0 = 0x3115d1449a7b732c986cba18244e897a450f61e1bb8d589cd2e69e6c8924f9f7 -- Withdraw
        and block_time > date('2022-03-16') -- First transaction date
),

aave_v3_transactions_daily as (
    select date_trunc('day', block_time) as block_date,
        token_address,
        sum(raw_amount) as raw_amount_summary
    from aave_v3_transactions
    group by 1, 2
    order by 1, 2
)

select * from aave_v3_transactions_daily
```

At this point, we have obtained the number of tokens locked in the smart contract. To get the TVL denominated in USD, we also need to match each token with its price. Here, we have manually selected a few mainstream tokens:

``` sql
token_mapping_to_ethereum(aave_token_address, ethereum_token_address, token_symbol) as (
    values
    (0xfd086bc7cd5c481dcc9c85ebe478a1c0b69fcbb9, 0xdac17f958d2ee523a2206206994597c13d831ec7, 'USDT'),
    (0x2f2a2543b76a4166549f7aab2e75bef0aefc5b0f, 0x2260fac5e5542a773aa44fbcfedf7c193bc2c599, 'WBTC'),
    (0xd22a58f79e9481d1a88e00c343885a588b34b68b, 0xdb25f211ab05b1c97d595516f45794528a807ad8, 'EURS'),
    (0xff970a61a04b1ca14834a43f5de4533ebddb5cc8, 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48, 'USDC'),
    (0xf97f4df75117a78c1a5a0dbb814af92458539fb4, 0x514910771af9ca656af840dff83e8264ecf986ca, 'LINK'),
    (0x82af49447d8a07e3bd95bd0d56f35241523fbab1, 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2, 'WETH'),
    (0xda10009cbd5d07dd0cecc66161fc93d7c9000da1, 0x6b175474e89094c44da98b954eedeac495271d0f, 'DAI'),
    (0xba5ddd1f9d7f570dc94a51479a000e3bce967196, 0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9, 'AAVE')
),

latest_token_price as (
    select date_trunc('hour', minute) as price_date,
        contract_address,
        symbol,
        decimals,
        avg(price) as price
    from prices.usd
    where contract_address in (
        select ethereum_token_address
        from token_mapping_to_ethereum
    )
    and minute > now() - interval '1' day
    group by 1, 2, 3, 4
),

latest_token_price_row_num as (
    select  price_date,
        contract_address,
        symbol,
        decimals,
        price,
        row_number() over (partition by contract_address order by price_date desc) as row_num
    from latest_token_price
),

current_token_price as (
    select contract_address,
        symbol,
        decimals,
        price
    from latest_token_price_row_num
    where row_num = 1
),
```

Divide the raw amount by the corresponding token's decimal places (for instance, ETH has 18 decimal places, USDT has 6), to get the actual number of tokens. Then multiply this by the corresponding price to get the amount denominated in USD. Summing up these amounts will give the total TVL.

``` sql
daily_liquidity_change as (
    select d.block_date,
        p.symbol,
        d.token_address,
        d.raw_amount_summary / power(10, coalesce(p.decimals, 0)) as original_amount,
        d.raw_amount_summary / power(10, coalesce(p.decimals, 0)) * coalesce(p.price, 1) as usd_amount
    from aave_v3_transactions_daily d
    inner join token_mapping_to_ethereum m on d.token_address = m.aave_token_address
    left join current_token_price p on m.ethereum_token_address = p.contract_address
    order by 1, 2
)

select sum(usd_amount) / 1e6 as total_value_locked_usd
from daily_liquidity_change
```

Reference: https://dune.com/queries/1037796/1798021

### 2. Outstanding Loans

This refers to the amount of money that has been loaned out and has not yet been repaid. Similar to calculating TVL, refer to the data from the blockchain explorer, find the contract function corresponding to topic0(1), and subtract the repaid ('Repay') from the borrowed ('Borrow').

Reference: https://dune.com/queries/1037796/1798021

``` sql
 select 'Borrow' as action_type,
    block_time,
    bytearray_ltrim(topic1) as token_address,
    bytearray_ltrim(topic2) as user_address,
    cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
    tx_hash
from arbitrum.logs
where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
    and topic0 = 0xb3d084820fb1a9decffb176436bd02558d15fac9b0ddfed8c465bc7359d7dce0 -- Borrow
    and block_time > date('2022-03-16') -- First transaction date

union all

select 'Repay' as action_type,
    block_time,
    bytearray_ltrim(topic1) as token_address,
    bytearray_ltrim(topic2) as user_address,
    -1 * cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
    tx_hash
from arbitrum.logs
where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
    and topic0 = 0xa534c8dbe71f871f9f3530e97a74601fea17b426cae02e1c5aee42c96c784051 -- Repay
    and block_time > date('2022-03-16') -- First transaction date

limit 100
```


### 3. Capital Efficiency (Utilization Ratio)

Simply put, it refers to how much of the money deposited into the protocol has been truly utilized (borrowed). Currently, the capital efficiency of AAVE V3 on Arbitrum is around 30%, at a low leverage level. Compared to the bull market in 2021, the fund utilization rate was between 40%-80%.

![](img/ch13_ur.png)

![](img/ch13_ur.jpg)

### 4. Detailed Categories

Including the composition of assets locked in the contract and user behavior distribution. Reference: https://dune.com/queries/1026402/1771390.

![](img/ch13_4.1.png)

The top three assets in AAVE's liquidity pool on Arbitrum are WETH (37.6%), USDC (29.5%), and WBTC (22.6%). Currently, we are in a bear market where users' demand for leverage is not strong, so most are primarily depositing to earn interest.

![](img/ch13_4.2.png)

### 5. Basic Indicators

Some basic protocol analysis indicators, such as the number of users, the number of transactions, and daily change situations. Reference: https://dune.com/queries/1026141/1771147.

![](img/ch13_dunedata.png)

## Lending Dashboard

1. The comprehensive dashboard for AAVE V3 on Arbitrum. 

https://dune.com/sixdegree/aave-on-arbitrum-overview

![](img/ch13_dashboard.png)

2. And a dashboard comparing the three classic lending protocols on Ethereum: Maker, AAVE, and Compound. However, this dashboard is old, using the Dune V1 engine. Dune will soon retire V1 and will only use V2 in the future, so you can refer to its thinking when learning.

https://dune.com/datanut/Compound-Maker-and-Aave-Deposits-Loans-LTV

![](img/ch13_dashboard2.png)

## References
1. https://foresightnews.pro/article/detail/17638
2. https://learnblockchain.cn/article/5036
3. https://twitter.com/0xhiger/status/1595076528697905157
4. https://www.blocktempo.com/why-do-defi-lending-protocols-generate-bad-debts/
5. https://www.panewslab.com/zh/articledetails/k1ep9df5.html
6. https://new.qq.com/rain/a/20201121A096UF00

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch14/ch14-defi-analysis.md">
# 14 DeFi Analysis
DeFi refers to Decentralized Finance, which should be the most active field in current blockchain. When we exchange one ERC20 token for another, we can use DeFi to facilitate the exchange. DEX is Decentralized Exchange. Uniswap, PancakeSwap, CurveFi, and others are popular DEXs. In this tutorial, we will explore the analysis methods of DeFi projects using the data on the Ethereum blockchain as a case.

The dashboard for this tutorial please refer [DeFi Analysis Tutorial](https://dune.com/sixdegree/defi-analysis-tutorial)<a id="jump_8"></a>.

## DeFi Spells

Given the importance of DeFi in the Crypto area, the Dune community has established a rich Spells for it. The Spells called `dex.trades` aggregates exchange data from nearly 30 different DEXs such as Uniswap, PancakeSwap, Trader Joe, Velodrome, SushiSwap, etc. By examining the [definition](https://github.com/duneanalytics/spellbook/blob/main/models/dex/dex_trades.sql)<a id="jump_8"></a> of the `dex.trades table`, we can see that its data is sourced from other Spells, such as `uniswap.trades`, `sushiswap.trades`, `curvefi.trades`, and so on. If you analyze the data from a specific DEX, it is recommended to prioritize using the trade-specific Spells for its better query execution performance. Similarly, for DeFi projects like Uniswap, which have released multiple versions of smart contracts (including upgrading contract versions on the same blockchain or deploying contracts on different blockchains), the `uniswap.trades` table is also aggregated from other Spells. If you are only interested in analyzing data from a specific version or chain, you can use the corresponding Spells. For example, if you analyze exchange data from Uniswap V3 on Ethereum, you can directly use the `uniswap_v3_ethereum.trades` table. If you analyze exchange data from CurveFi on the Optimism chain, you can use the `curvefi.trades` Spells.

``` sql
select blockchain, 
    project, 
    project || '_' || blockchain || '.trades' as spell_table_name,
    count(*) as trade_count
from dex.trades
group by 1, 2, 3
order by 1 asc, 4 desc
```

This query lists the projects, their corresponding blockchains, and the names of the corresponding Spells in the current `dex.trades` table. Currently, the related Spells for aggregating data in `dex.trades` are shown in the following image:

![](img/ch14_image_01.png)

Query Link:

[https://dune.com/queries/17500008](https://dune.com/queries/17500008)<a id="jump_8"></a>

We can use `spell_table_name` as the table name to access the trades data Spells for the corresponding project. For example:

``` sql
select * from 
kyberswap_avalanche_c.trades
limit 1
```

## Comprehensive Analysis of the DeFi Industry
### Overview of DeFi
As mentioned above, the Spells aggregates transaction data from over a dozen mainstream DeFi projects, including Uniswap. Let's first take a look at its overview. Considering its educational purposes, we will limit our queries to recent data as an example.

``` sql 
select block_date,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from dex.trades
where block_date >= date('2022-10-01')
group by 1
order by 1
```

Using the afoementioned query, you can obtain the daily transaction count and the number of unique users. The internal logic of DeFi is complex and the `taker` stores the recipient of the transaction. Using it could reflect the true number of unique users. Additionally, the above-mentioned query is modified to calculate the cumulative transaction count per day, the count of new users per day and its cumulative value, as well as the total transaction count and the number of users. The modified SQL query is as follows:

``` sql
with trade_summary as (
    select block_date,
        count(*) as trade_count,
        count(distinct taker) as active_user_count,
        sum(amount_usd) as trade_amount
    from dex.trades
    where blockchain = 'ethereum'
        and block_date >= date('2021-01-01')
        and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
    group by 1
    order by 1
),

user_initial_trade as (
    select taker,
        min(block_date) as initial_trade_date
    from dex.trades
    where blockchain = 'ethereum'
        and block_date >= date('2021-01-01')
        and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
    group by 1
),

new_user_summary as (
    select initial_trade_date,
        count(taker) as new_user_count
    from user_initial_trade
    group by 1
    order by 1
)

select t.block_date,
    trade_count,
    active_user_count,
    trade_amount,
    new_user_count,
    active_user_count - new_user_count as existing_user_count,
    sum(trade_count) over (order by t.block_date) as accumulate_trade_count,
    sum(trade_amount) over (order by t.block_date) as accumulate_trade_amount,
    sum(new_user_count) over (order by u.initial_trade_date) as accumulate_new_user_count,
    (sum(trade_count) over ()) / 1e6 as total_trade_count,
    (sum(trade_amount) over ()) / 1e9 total_trade_amount,
    (sum(new_user_count) over ()) / 1e6 as total_new_user_count
from trade_summary t
left join new_user_summary u on t.block_date = u.initial_trade_date
order by t.block_date
```

Query interpretation:

1. Putting the original query into the `trade_summary` common table expression (CTE) for smoother utilization with window functions. In the query, we discovered anomalous data for the "POP-WETH" pool, so we directly exclude it here.
2. The CTE `user_initial_trade` calculates the initial trade date for each taker. For the sake of performance, please be aware that the trading date may not strictly represent the true initial trading date.
3. The CTE `new_user_summary` summarizes the daily count of new users based on their initial trade dates, determined by the `user_initial_trade`.
4. In the final output query code, we use the window function syntax `sum(field_name1) over (order by field_name2)` to calculate the cumulative data by date. Additionally, dividing by 1e6 or 1e9 is used to convert large numbers into their corresponding values in millions or billions, respectively.

In this query result, we add the following visualizations:

1. Add Counter-type visualizations for the output values total_trade_count, total_trade_amount, and total_new_user_count.
2. Add Bar Chart-type bar graphs for trade_count and new_user_count.
3. Add Area Chart-type area graphs for trade_amount and active_user_count.
4. Add a percentage-type Area Chart to compare the proportions of new_user_count and existing_user_count.
5. Add a Table-type visualization to display the query results.

Create a new Dashboard and include the relevant charts. As shown in the following image:

![](img/ch14_image_02.png)

Similarly, we can summarize the data on a monthly basis, calculate relevant metrics for each month, and add visualizations to the dashboard.

Query Link:
* [https://dune.com/queries/1661180](https://dune.com/queries/1661180)<a id="jump_8"></a>
* [ttps://dune.com/queries/1663358](ttps://dune.com/queries/1663358)<a id="jump_8"></a>

### Statistical analysis by project

As previously mentioned, the `dex.trades` Spells aggregates transaction data from multiple projects on different blockchains. We can use a query to compare the transaction data of each project and analyze their market share.

``` sql
select block_date,
    project,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from dex.trades
where blockchain = 'ethereum'
    and block_date >= date('2021-01-01')
    and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
group by 1, 2
order by 1, 2
```

Here, we merely compare the number of active users, transaction count, and transaction amount. Bar charts and pie charts for different fields in the result set are added in the dashboard. You may have noticed that our queries are aggregated by both day and project. When creating a Pie Chart, if we select only the `Project` as the X Column and choose `trade_count` as Y Column 1, without selecting any fields for Group By, the trade_count values for each day will automatically be accumulated together, and the total value will be displayed in the pie chart. Considering this, we don't need to write a separate query to generate the pie chart, which is considered an application technique. The dashboard shows as the following :

![](img/ch14_image_03.png)

Query link:

* [https://dune.com/queries/1669861](https://dune.com/queries/1669861)<a id="jump_8"></a>

### Grouping and summarizing by Token Pair

Almost every DeFi project supports the exchange of multiple tokens, which achieved by establishing separate liquidity pools for different token pairs. For example, Uniswap supports the exchange of various ERC20 tokens by allowing liquidity providers (LPs) to create liquidity pools for any two ERC20 tokens. Regular users can then utilize these pools to exchange tokens by paying a certain proportion of transaction fees. Taking USDC and WETH as an example, under Uniswap V3, there are four different fee tiers. LPs can create a liquidity pool for each fee tier, such as "USDC/WETH 0.3%". Considering that the popularity, circulation volume, supported platforms, and transaction fee rates differ for tokens involved in different trading pairs, it is necessary to analyze which trading pairs are more popular and have higher transaction volumes.

``` sql
with top_token_pair as (
    select token_pair,
        count(*) as transaction_count
    from dex.trades
    where blockchain = 'ethereum'
        and block_date >= date('2021-01-01')
        and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
    group by 1
    order by 2 desc
    limit 20
)

select date_trunc('month', block_date) as block_date,
    token_pair,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from dex.trades
where blockchain = 'ethereum'
    and block_date >= date('2021-01-01')
    and token_pair in (
        select token_pair from top_token_pair
    )
group by 1, 2
order by 1, 2
```

In the above query, we first define a `top_token_pair` CTE to retrieve the top 20 token pairs based on transaction count. Then, we summarize the transaction count, active user count, and transaction amount for these 20 token pairs on a monthly basis. We add the corresponding visualizations for this query and include them in the dashboard. The display is shown below.

![](img/ch14_image_04.png)

Query link:

* [https://dune.com/queries/1670196](https://dune.com/queries/1670196)<a id="jump_8"></a>

## Analysis of an individual DeFi project

For a specific individual DeFi project, we can analyze relevant data including active trading pairs, new liquidity pool count, trading volume, and active users. Taking Uniswap as an example, we can find the corresponding Spells for Uniswap on the Ethereum blockchain as the `uniswap_ethereum.trades`.

### Transaction count, active users, transaction amount

We can calculate the transaction count, active users, and transaction amount on a daily basis using the following SQL:

``` sql
select block_date,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from uniswap_ethereum.trades
where block_date >= date('2022-01-01')
group by 1
order by 1
```

Query link:

* [https://dune.com/queries/1750266](https://dune.com/queries/1750266)<a id="jump_8"></a>

### Analysis of active trading pairs
The SQL for analyzing the most active trading pairs (also known as pools or liquidity pools) in a Uniswap project is as follows:

``` sql
with top_token_pair as (
    select token_pair,
        count(*) as transaction_count
    from uniswap_ethereum.trades
    where blockchain = 'ethereum'
        and block_date >= date('2022-01-01')
    group by 1
    order by 2 desc
    limit 20
)

select date_trunc('month', block_date) as block_date,
    token_pair,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from uniswap_ethereum.trades
where blockchain = 'ethereum'
    and block_date >= date('2022-01-01')
    and token_pair in (
        select token_pair from top_token_pair
    )
group by 1, 2
order by 1, 2
```

Generate an area chart and a pie chart, and add them to the dashboard. We can observe that the "USDC-WETH" trading pair has accounted for 58% of the total transaction amount since 2022. The visualization is shown in the following:
![](img/ch14_image_05.png)

Query link:

* [https://dune.com/queries/1751001](https://dune.com/queries/1751001)<a id="jump_8"></a>

### Analysis of new liquidity pools

In our previous tutorial article, we conducted some query focusing on the liquidity pools of Uniswap V3 in "Creating Your First Dune Dashboard" section. Additionally, we have another dashboard available for monitoring newly created liquidity pools in Uniswap. Please refer to your own familiar.

Please refer to Dashboard:
* [Uniswap New Pool Filter](https://dune.com/sixdegree/uniswap-new-pool-metrics)<a id="jump_8"></a>
* [Uniswap V3 Pool Tutorial](https://dune.com/sixdegree/uniswap-v3-pool-tutorial)<a id="jump_8"></a>

### Analysis of active users
We analyze the monthly active users, new users, churned users, and retained users for Uniswap V3 on the Ethereum blockchain using the `uniswap_v3_ethereum.trades` Spells. The query code is as follows:

``` sql
with monthly_active_user as (
    select distinct taker as address,
        date_trunc('month', block_date) as active_trade_month
    from uniswap_v3_ethereum.trades
),

user_initial_trade as (
    select taker as address,
        min(date_trunc('month', block_date)) as initial_trade_month
    from uniswap_v3_ethereum.trades
    group by 1
),

user_status_detail as (
    select coalesce(c.active_trade_month, date_trunc('month', p.active_trade_month + interval '45' day)) as trade_month,
        coalesce(c.address, p.address) as address,
        (case when n.address is not null then 1 else 0 end) as is_new,
        (case when n.address is null and c.address is not null and p.address is not null then 1 else 0 end) as is_retained,
        (case when n.address is null and c.address is null and p.address is not null then 1 else 0 end) as is_churned,
        (case when n.address is null and c.address is not null and p.address is null then 1 else 0 end) as is_returned
    from monthly_active_user c
    full join monthly_active_user p on p.address = c.address and p.active_trade_month = date_trunc('month', c.active_trade_month - interval '5' day)
    left join user_initial_trade n on n.address = c.address and n.initial_trade_month = c.active_trade_month
    where coalesce(c.active_trade_month, date_trunc('month', p.active_trade_month + interval '45' day)) < current_date
),

user_status_summary as (
    select trade_month,
        address,
        (case when sum(is_new) >= 1 then 'New'
            when sum(is_retained) >= 1 then 'Retained'
            when sum(is_churned) >= 1 then 'Churned'
            when sum(is_returned) >= 1 then 'Returned'
        end) as user_status
    from user_status_detail
    group by 1, 2
),

monthly_summary as (
    select trade_month,
        user_status,
        count(address) as user_count
    from user_status_summary
    group by 1, 2
)

select trade_month,
    user_status,
    (case when user_status = 'Churned' then -1 * user_count else user_count end) as user_count
from monthly_summary
order by 1, 2
```

This query can be interpreted as follows:

1. In the CTE `monthly_active_user,` the date is transformed to the first day of each month, retrieving all user addresses that have transaction records in each month.

2. In the CTE `user_initial_trade,` the query retrieves the initial transaction date for each address and converts it to the first day of the respective month.

3. In the CTE `user_status_detail`:

- * We use Full Join to self-join the `monthly_active_user` by setting the condition to the same transaction user address and adjacent months. The alias "c" represents the current month's data, while the alias "p" represents the previous month's data. Since the date is already processed as the first day of the month, we use `date_trunc('month', c.active_trade_month - interval '5 days') `to subtract 5 days from the original date representing the first day of the month. This ensures that we obtain the "first day of the previous month." Thus, we can associate data from two consecutive months.
- * Also, since we are using a Full Join, `c.active_trade_month` may be null. We use the coalesce() function to add 45 days to the previous month's date as an alternative date to ensure that we always get the correct month.
- * We also associate `user_initial_trade` with a Left Join so that we can determine whether a user made his first trade in a certain month.
- * Multiple CASE conditions are used to determine whether a user is a new user (first trade in the current month), retained user (not a new user with trades in both the current and previous months), churned user (not a new user with no trades in the current month but trades in the previous month), or returning user (not a new user with trades in the current month but no trades in the previous month).
4. In the CTE `user_status_summary,` we count the number of users for each address and their respective status type in a given month.

5. In the CTE `monthly_summary,` we summarize the number of users based on the transaction month and user status.

6. When we finally print the result, we replace the values of "Cburned" (churned users) with a negative value so that it can be compared more easily on the chart.

Two bar charts are added, with one selecting "Enable stacking" to overlay the bars. The charts are added to the dashboard, and we can observe that the number of churned users is quite large. As shown in the picture below:

![](img/ch14_image_06.png)

Query link:

* [https://dune.com/queries/1751216](https://dune.com/queries/1751216)<a id="jump_8"></a>

This query takes inspiration from the query [Uniswap LP-MAU Breakdown](https://dune.com/queries/9796)<a id="jump_8"></a> by [@danning.sui](https://dune.com/danning.sui)<a id="jump_8"></a>. Special thanks to them!

## Analysis of a specific pair

We may also need more in-depth analysis on specific liquidity pools, including their transaction data, liquidity data, etc. Due to space limitations, we cannot provide a detailed introduction here. However, we offer some sample queries and dashboards for your reference:

Query Example:
* [uniswap-v3-poo](https://dune.com/queries/1174517)<a id="jump_8"></a>
* [XEN-Uniswap trading pool overview](https://dune.com/queries/1382063)<a id="jump_8"></a>
* [optimism uniswap lp users](https://dune.com/queries/1584678)<a id="jump_8"></a>

Dashboard Example:
* [Uniswap V3 Pool Structure And Dynamics](https://dune.com/springzhang/uniswap-v3-pool-structure-and-dynamics)<a id="jump_8"></a>
* [Uniswap V3 On Optimism Liquidity Mining Program Performance](https://dune.com/springzhang/uniswap-optimism-liquidity-mining-program-performance)<a id="jump_8"></a>

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch15/ch15-dunesql-introduction.md">
# 15 Introduction to DuneSQL

Dune has officially launched its team's self-developed query engine, Dune SQL, based on Trino ([https://trino.io/](https://trino.io/)<a id="jump_8"></a>). This article introduces some common query syntax, considerations, and details of Dune SQL.

Note: as Dune has announced that it will fully transition to the Dune SQL query engine from the second half of 2023, this tutorial upgrades all the original Query to the Dune SQL version.

## Dune SQL Syntax Overview

There are several key points to note in the syntax of Dune SQL:

* Dune SQL uses double quotation marks to quote field names or table names that contain special characters or are keywords, such as `"from"` or `"to"`.
* The string type in Dune SQL is `varchar`, and the commonly used numeric types are `double` and `decimal(38, 0)`.
* Dune SQL does not support implicit type conversions. For example, in Dune SQL, you cannot directly compare `'2022-10-01'` with block_time; you need to use functions like `date('2022-10-01')` to explicitly convert it to a date before comparison. You cannot directly concatenate numeric types and strings; you need to use `cast(number_value as varchar)` to convert them to strings before concatenation.

The Dune documentation provides a detailed syntax comparison table. You can refer to the [Syntax Comparison](https://dune.com/docs/query/syntax-differences#syntax-comparison)<a id="jump_8"></a>  for more information. The following shows a partial comparison of the differences:

![](img/ch15_image_01.png)

## Dune SQL Examples

### Dune SQL uses double quotation marks to quote special field names and table names

Dune SQL uses double quotation marks for this purpose

``` sql
select "from" as address, gas_price, gas_used
from ethereum.transactions
where success = true
limit 10
```

### Date and Time

Dune SQL does not support implicit conversion of string-formatted date values to datetime types. Explicit conversion must be used. Date and time functions or operators can be utilized for this purpose.

1. Using Date Values

Dune SQL utilizes the date() function

``` sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= date('2022-12-18')
limit 10
```
2. Using Date and Time Values

Dune SQL employs the timestamp operator

``` sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= timestamp '2022-12-18 05:00:00'
limit 10
```

3. Using Interval

Dune SQL utilizes the `interval '12' hour` syntax

``` sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= now() - interval '12' hour
limit 10
```

### Address and Transaction Hash

In Dune SQL queries, addresses and hash values can be used without enclosing them in single quotes. In this case, the case sensitivity is not enforced and there is no need to explicitly convert them to lowercase.

``` sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
    and (
        hash = 0x2a5ca5ff26e33bec43c7a0609670b7d7db6f7d74a14d163baf6de525a166ab10
        or "from" = 0x76BE685c0C8746BBafECD1a578fcaC680Db8242E
        )
```

### Dune SQL's String Type varchar and Numeric Type double

In Dune SQL, the string type is `varchar` and the commonly used numeric type is `double`. Integer values in Dune SQL are default to the `bigint` type. When performing multiplication with large numbers, it is prone to overflow errors. In such cases, you can forcefully convert them to `double` type or `decimal(38, 0)` type. Integer division in Dune SQL does not implicitly convert to a floating-point number and perform division; instead, it directly returns an integer. This aspect should also be taken into consideration.

1. Converting to String

Dune SQL

``` sql
select block_time, hash, "from" as address, "to" as contract_address,
    cast(value / 1e9 as varchar) || ' ETH' as amount_value,
    format('%,.2f', value / 1e9) || ' ETH' as amount_value_format
from ethereum.transactions
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
    and (
        hash = 0x2a5ca5ff26e33bec43c7A0609670b7d7db6f7d74a14d163baf6de525a166ab10
        or "from" = 0x76BE685c0C8746BBafECD1a578fcaC680Db8242E
        )
```

Checking the SQL output above, you can see that when casting a large or small number directly to a string using cast(), it is displayed in scientific notation, which may not be desirable. However, it is recommended to use the `format()` function, which allows for precise control over the output string format.

2. Converting to Numeric Values

Note that the type of the `value` is string in the table `erc20_ethereum.evt_Transfer`. You can use the `cast()` to convert it to the double or decimal(38, 0) numeric types.

``` sql
select evt_block_time, evt_tx_hash, "from", "to", 
    cast(value as double) as amount,
    cast(value as decimal(38, 0)) as amount2
from erc20_ethereum.evt_Transfer
where evt_block_time >= date('2022-12-18') and evt_block_time < date('2022-12-19')
    and evt_tx_hash in (
        0x2a5ca5ff26e33bec43c7a0609670b7d7db6f7d74a14d163baf6de525a166ab10,
        0xb66447ec3fe29f709c43783621cbe4d878cda4856643d1dd162ce875651430fc
    )
```

### Explicit Type Conversion

As mentioned earlier, Dune SQL does not support implicit type conversion. When we compare or perform operations on values of different types, it is necessary to ensure that they are of the same (compatible) data type. If they are not, explicit type conversion should be performed using relevant functions or operators. Otherwise, type mismatch errors may occur. Here's another simple example:

Without type conversion, the following SQL will result in an error in Dune SQL:

``` sql
select 1 as val
union all
select '2' as val
```

Explicit type conversion allows for the execution as the following in Dune SQL:

``` sql
select 1 as val
union all
select cast('2' as int) as val
```

When encountering errors like "Error: Line 47:1: column 1 in UNION query has incompatible types: integer, varchar(1) at line 47, position 1," it is necessary to address the type compatibility issues of the respective fields.

### Converting to double type to resolve numeric range overflow errors

Dune SQL supports integer types such as `int` and `bigint`. However, numeric values can often be very large due to the lack of support for decimals in blockchain systems like EVM. For example, we may encounter errors related to numeric overflow when calculating gas fees. In the following SQL, we intentionally cause an error by multiplying the calculated gas fee by 1000:

``` sql
select hash, gas_price * gas_used * 1000 as gas_fee
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
order by gas_used desc
limit 10
```

Executing the above SQL will result in an error:

``` sql
Error: Bigint multiplication overflow: 15112250000000000 * 1000.
```

To avoid type overflow errors, we can explicitly convert the first parameter to double type. The following SQL will execute correctly:

``` sql
select hash, cast(gas_price as double) * gas_used * 1000 as gas_fee
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
order by gas_used desc
limit 10
```

### Converting to double type resolves the issue of integer division not returning decimal places

Similarly, if two values are of bigint type and their division is performed, the result will be truncated to an integer and discarded the decimal portion. To obtain the decimal portion in the result, the dividend should be explicitly converted to double type.

``` sql
select hash, gas_used, gas_limit,
    gas_used / gas_limit as gas_used_percentage
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
limit 10
```

Executing the above SQL, the value of gas_used_percentage will be either 0 or 1, and the decimal part will be discarded and rounded up. Clearly, this is not the desired outcome. By explicitly converting the dividend gas_used to double type, we can obtain the correct result:

``` sql
select hash, gas_used, gas_limit,
    cast(gas_used as double) / gas_limit as gas_used_percentage
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
limit 10
```

### Converting from Hexadecimal to Decimal

Dune SQL defines a set of new functions to handle the conversion of varbinary type strings to decimal numeric values. The string must start with the prefix `0x`.

``` sql
select bytearray_to_uint256('0x00000000000000000000000000000000000000000000005b5354f3463686164c') as amount_raw
```

For detailed assistance, please refer: [Byte Array to Numeric Functions](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/varbinary/#byte-array-to-numeric-functions)<a id="jump_8"></a>.

### Generating Numeric Sequences and Date Sequences

1. Numeric Sequences

The syntax for generating numeric sequences in Dune SQL is as follows:

``` sql
select num from unnest(sequence(1, 10)) as t(num)
-- select num from unnest(sequence(1, 10, 2)) as t(num) -- step 2
```

2. Date Sequences

Dune SQL utilizes the `unnest()` in conjunction with `sequence()` to generate date sequence values and convert them into multiple rows of records.

The syntax for generating date sequences in Dune SQL is as follows:

``` sql
select block_date from unnest(sequence(date('2022-01-01'), date('2022-01-31'))) as s(block_date)
-- select block_date from unnest(sequence(date('2022-01-01'), date('2022-01-31'), interval '7' day)) as s(block_date)
```

### Array Queries

1. Dune SQL utilizes the `cardinality()` to query the size of an array.

    The syntax for array queries in Dune SQL is as follows:

    ``` sql
    select evt_block_time, evt_tx_hash, profileIds
    from lens_polygon.LensHub_evt_Followed
    where cardinality(profileIds) = 2
    limit 10
    ```

2. Dune SQL's array indexing starts counting from 1.

    Accessing Array Elements in Dune SQL:

    ``` sql
    select evt_block_time, evt_tx_hash, profileIds,
        profileIds[1] as id1, profileIds[2] as id2
    from lens_polygon.LensHub_evt_Followed
    where cardinality(profileIds) = 2
    limit 10
    ```

3. Splitting Array Elements into Multiple Rows of Records

    Splitting array elements into multiple rows of records in Dune SQL:

    ``` sql
    select evt_block_time, evt_tx_hash, profileIds,	tbl.profile_id
    from lens_polygon.LensHub_evt_Followed
    cross join unnest(profileIds) as tbl(profile_id)
    where cardinality(profileIds) = 3
    limit 20
    ```

4. Splitting Multiple Array Fields into Multiple Rows of Records
    To split multiple array fields into multiple rows (assuming they have the same length), Dune SQL can include multiple fields within the `unnest()` and output corresponding fields simultaneously.

    Splitting multiple array elements into multiple rows in Dune SQL:

    ``` sql
    SELECT evt_block_time, evt_tx_hash, ids, "values", tbl.id, tbl.val
    FROM erc1155_polygon.evt_TransferBatch
    cross join unnest(ids, "values") as tbl(id, val)
    WHERE evt_tx_hash = 0x19972e0ac41a70752643b9f4cb453e846fd5e0a4f7a3205b8ce1a35dacd3100b
    AND evt_block_time >= date('2022-12-14')
    ```

## Migrating Queries from Spark SQL to Dune SQL - Example

It is a straightforward process to migrate queries written in the existing Spark SQL engine to Dune SQL. You can directly access the Edit interface of the query and switch to "1. v2 Dune SQL" from the left dropdown menu of datasets. Then, make the necessary adjustments to the query content, as described in the previous sections of this article. Here's an example:

Spark SQL Version: [https://dune.com/queries/1773896](https://dune.com/queries/1773896)<a id="jump_8"></a>
Dune SQL Version: [https://dune.com/queries/1000162](https://dune.com/queries/1000162)<a id="jump_8"></a>

Here is a comparison of the modifications during the migration:

![](img/ch15_image_02.png)

## Other Features

Dune SQL also has a potential advanced feature that allows querying based on a saved query (Query of Query). This feature offers a lot of possibilities for simplifying query logic and optimizing cache usage. For example, you can save the base part of a complex query as a query itself and then perform further aggregation and analysis based on that query. However, this feature may still be unstable at times. Nevertheless, you can give it a try.

``` sql
-- original query: https://dune.com/queries/1752041
select * from query_1752041
where user_status = 'Retained'
```


``` sql
-- original query: https://dune.com/queries/1752041
select * from query_1752041
where user_status = 'Churned'
```

## Reference Links

1. [Syntax and operator differences](https://dune.com/docs/query/syntax-differences/#syntax-and-operator-differences)<a id="jump_8"></a>
2. [Trino Functions and Operators](https://trino.io/docs/current/functions.html)<a id="jump_8"></a>

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch16/ch16-blockchain-analysis-polygon.md">
# 16 Blockchain Analysis - Polygon

Dune platform has been developing rapidly and currently supports 10 mainstream blockchains, including Layer 1 public chains such as Ethereum, BNB, Polygon, Fantom, and Layer 2 blockchains such as Arbitrum and Optimism that are dedicated to expanding Ethereum. In this tutorial, we will explore how to start analyzing the overview of a blockchain, taking the Polygon blockchain as an example.

Polygon's motto is "Bringing Ethereum to Everyone." Polygon believes that everyone can use Web3. It is a decentralized Ethereum scaling platform that enables developers to build scalable and user-friendly DApps with low transaction fees without compromising security.

Dashboard for this tutorial: [Polygon Chain Overview](https://dune.com/sixdegree/polygOnchain-overview)<a id="jump_8"></a>

## Contents of the Blockchain Overview Analysis

Our goal is to comprehensively analyze the entire Polygon Chain to understand its current development status. The analysis includes:

* **Block Analysis**: total number of blocks, blocks mined per minute, total gas consumption, average gas consumption, daily (monthly) trend of block generation quantity, etc.
* **Transaction and User Analysis**: total transaction volume, total number of users, transaction quantity per block, comparison of successful and failed transactions, daily (monthly) trend of transaction quantity, daily (monthly) trend of active users, daily (monthly) trend of new users, comparison of new users and active users, etc.
* **Native Token MATIC Analysis**: total circulation supply, holder analysis, top holders, price trend, etc.
* **Smart Contract Analysis**: total deployed smart contracts, daily (monthly) trend of new contract deployments, comparison of transaction volume for the most popular smart contracts, and analysis of development trends.

## Block and Gas Consumption Analysis

### Total Number of Blocks and Gas Consumption

To understand the total number of blocks and gas consumption in the Polygon Chain, we can write a simple SQL to retrieve the following information: the total number of blocks, the timestamp of the genesis block, the average number of new blocks per minute, the total gas consumption, and the average gas consumption per block.

``` sql
select count(*) / 1e6 as blocks_count,
   min(time) as min_block_time,
   count(*) / ((to_unixtime(Now()) - to_unixtime(min(time))) / 60) as avg_block_per_minute,
   sum(gas_used * coalesce(base_fee_per_gas, 1)) / 1e18 as total_gas_used,
   avg(gas_used * coalesce(base_fee_per_gas, 1)) / 1e18 as average_gas_used
from polygon.blocks
```

SQL explanation:

1. By using the `to_unixtime()`, we can convert date and time to Unix Timestamp values, which allows us to calculate the number of seconds between two date and time values. We can then use this to calculate the average number of new blocks per minute. The corresponding function is `from_unixtime()`.
2. `gas_used` represents the amount of gas consumed, and `base_fee_per_gas` is the unit price per gas. Multiplying them together gives us the gas cost. The native token of Polygon, MATIC, has 18 decimal places, so dividing by 1e18 gives us the final MATIC amount.

The results of this query can be added as Counter-type visualizations and included in a dashboard. The display is as follows:

![](img/ch16_image_01.png)

Query link:[https://dune.com/queries/1835390](https://dune.com/queries/1835390)<a id="jump_8"></a>

### Daily (Monthly) New Block Generation Trend and Gas Consumption

We can aggregate by date to calculate the daily number of generated blocks and the corresponding gas consumption. To track the change, we first define a CTE to perform daily data statistics. Then, based on this CTE, we use a window function such as avg`(blocks_count) over (order by rows between 6 preceding and current row)` to calculate the 7-day moving average. The SQL is as follows:

``` sql
with block_daily as (
    select date_trunc('day', time) as block_date,
        count(*) as blocks_count,
        sum(gas_used * coalesce(base_fee_per_gas, 1)) / 1e18 as gas_used
    from polygon.blocks
    group by 1
)

select block_date,
    blocks_count,
    gas_used,
    avg(blocks_count) over (order by block_date rows between 6 preceding and current row) as ma_7_days_blocks_count,
    avg(blocks_count) over (order by block_date rows between 29 preceding and current row) as ma_30_days_blocks_count,
    avg(gas_used) over (order by block_date rows between 6 preceding and current row) as ma_7_days_gas_used
from block_daily
order by block_date
```

Add two Bar Chart for the query, displaying "Daily Block Count, 7-day Moving Average, and 30-day Moving Average Block Count" and "Daily Gas Consumption Total and 7-day Moving Average" values. Add them to the dashboard.

Make a Fork of the above query, and modify it slightly to calculate the monthly statistics. Also, change the moving average to consider a period of 12 months. This will give us the monthly new block generation trend.

The visualizations of the two SQL queries added to the dashboard will have the following display. We can observe that the number of new blocks generated remains relatively stable, but the gas fees have significantly increased since 2022, with a brief decline in between and currently approaching the previous high.

![](img/ch16_image_02.png)

Query Link:
* [https://dune.com/queries/1835421](https://dune.com/queries/1835421)<a id="jump_8"></a>
* [ttps://dune.com/queries/1835445](ttps://dune.com/queries/1835445)<a id="jump_8"></a>

## Transaction and User Analysis
### Total Transaction Volume and User Count

We want to calculate the total number of transactions and the total number of unique user addresses. A CTE can be difined to combine the sender addresses `from` and receiver addresses `to` using the UNION ALL, and then count the distinct addresses. It's important to note that we're not excluding contract addresses in this analysis. If you wish to exclude contract addresses, you can add a subquery to exclude those addresses found in the `polygon.creation_traces` table. Since the data volume is large, we'll represent the values in millions (M). Add a Counter visualization chart for each metric and include them in the dashboard.

``` sql
with transactions_detail as (
    select block_time,
        hash,
        "from" as address
    from polygon.transactions

    union all

    select block_time,
        hash,
        "to" as address
    from polygon.transactions
)

select count(distinct hash) / 1e6 as transactions_count,
    count(distinct address) / 1e6 as users_count
from transactions_detail
```

Query Link:
* [https://dune.com/queries/1836022](https://dune.com/queries/1836022)<a id="jump_8"></a>

### Daily (Monthly) Transaction and Active User Analysis

Similarly, by grouping the data by date, we can generate reports for daily transaction volume and the number of active users. By summarizing the data on a monthly basis, we can obtain monthly insights. Below is the SQL query for daily aggregation:

``` sql
with transactions_detail as (
    select block_time,
        hash,
        "from" as address
    from polygon.transactions

    union all

    select block_time,
        hash,
        "to" as address
    from polygon.transactions
)

select date_trunc('day', block_time) as block_date,
    count(distinct hash) as transactions_count,
    count(distinct address) as users_count
from transactions_detail
group by 1
order by 1
```

Add Bar Chart for both daily and monthly transaction data, displaying transaction count and active user count. You can use a secondary Y-axis for the active user count, and choose either Line or Area chart. The resulting visualization on the dashboard would be the following:

![](img/ch16_image_03.png)

Query Link:
* [https://dune.com/queries/1835817](https://dune.com/queries/1835817)<a id="jump_8"></a>
* [ttps://dune.com/queries/1836624](ttps://dune.com/queries/1836624)<a id="jump_8"></a>

### Active User and New User Statistics Analysis

For a public blockchain, the growth trend of new users is a critical analysis that reflects the popularity of the chain. We can start by identifying the first transaction date for each address (`users_initial_transaction` CTE in the query below) and then use it to calculate the number of new users per day. By associating the daily active user data with the daily new user data, we can create a comparative chart. The number of active users for a given day can be obtained by subtracting the number of new users on that day from the daily active user count. Considering the possibility of no new users on certain dates, we use a LEFT JOIN and the `coalesce()` to handle potential null values. The SQL query is as follows:

``` sql
with users_details as (
    select block_time,
        "from" as address
    from polygon.transactions
    
    union all
    
    select block_time,
        "to" as address
    from polygon.transactions
),

users_initial_transaction as (
    select address,
        min(date_trunc('day', block_time)) as min_block_date
    from users_details
    group by 1
),

new_users_daily as (
    select min_block_date as block_date,
        count(address) as new_users_count
    from users_initial_transaction
    group by 1
),

active_users_daily as (
    select date_trunc('day', block_time) as block_date,
        count(distinct address) as active_users_count
    from users_details
    group by 1
)

select u.block_date,
    active_users_count,
    coalesce(new_users_count, 0) as new_users_count,
    active_users_count - coalesce(new_users_count, 0) as existing_users_count
from active_users_daily u
left join new_users_daily n on u.block_date = n.block_date
order by u.block_date
```

FORK this daily user statistics query, adjust the date to monthly statistics using `date_trunc('month', block_time)`. This will enable us to calculate the number of active users and new users per month.

For these two queries, we can add the following visualizations:

1. Bar Chart: display the daily (or monthly) count of active users and new users. Since the proportion of new users is relatively low, set it to use the secondary Y-axis.
2. Area Chart: compare the proportion of new users and existing users.

Adding these visualizations to the dashboard will result in the following display:

![](img/ch16_image_04.png)

Query link:
* [https://dune.com/queries/1836744](https://dune.com/queries/1836744)<a id="jump_8"></a>
* [ttps://dune.com/queries/1836854](ttps://dune.com/queries/1836854)<a id="jump_8"></a>

## Native Token Analysis
### MATIC Price Trend

Dune's Spells `prices.usd` provides price of Polygon chain tokens, including the native token MATIC. Therefore, we can directly calculate the average price on a daily basis.

``` sql
select date_trunc('day', minute) as block_date,
    avg(price) as price
from prices.usd
where blockchain = 'polygon'
    and symbol = 'MATIC'
group by 1
order by 1
```

Since the query results are sorted in ascending order by date, the last record represents the average price for the most recent date, which can be considered as the "current price". We can generate a Counter chart for it, setting the "Row Number" value to "-1" to retrieve the value from the last row. Additionally, we can add a Line to display the daily average price for the MATIC token. After adding these charts to the dashboard, the display will be as shown below:

![](img/ch16_image_05.png)

Query link:
* [https://dune.com/queries/1836933](https://dune.com/queries/1836933)<a id="jump_8"></a>

### Addresses with the highest holdings of the MATIC token

Addresses with the highest holdings of the MATIC token are of interest to us, as they often have the potential to influence the token's price movements. The following query retrieves the top 1000 addresses. `MATIC` is the native token of the Polygon chain and the details of its transfers are stored in the `polygon.traces` table.  Please note that we haven't differentiated between contract and non-contract addresses in this query. Due to the low transaction gas fees on Polygon, we have omitted the calculation of gas consumption for performance reasons.

``` sql
with polygon_transfer_raw as (
    select "from" as address, (-1) * cast(value as decimal) as amount
    from polygon.traces
    where call_type = 'call'
        and success = true
        and value > uint256 '0'
    
    union all
    
    select "to" as address, cast(value as decimal) as amount
    from polygon.traces
    where call_type = 'call'
        and success = true
        and value > uint256 '0'
)

select address,
    sum(amount) / 1e18 as amount
from polygon_transfer_raw
group by 1
order by 2 desc
limit 1000
```

Considerations in the above query: the `value` in the `polygon.traces` is of type `uint256`, which is a custom type in Dune SQL. If you directly compare it with the numerical value 0, you will encounter a type mismatch error that prevents comparison. Therefore, we use syntax like `uint256 '0'` to convert the value 0 into the same type for comparison. Alternatively, you can use type conversion functions like `cast(0 as uint256)`. You can also convert the `value` to double, decimal, bigint, or other types before comparison, but in such cases, be mindful of potential data overflow issues.

We can further analyze the distribution of MATIC token holdings among the top 1000 addresses based on the above query. We can fork the previous query and make slight modifications to achieve this.

``` sql
with polygon_transfer_raw as (
    -- same as above
),

polygon_top_holders as (
    select address,
        sum(amount) / 1e18 as amount
    from polygon_transfer_raw
    group by 1
    order by 2 desc
    limit 1000
)

select (case when amount >= 10000000 then '>= 10M'
             when amount >= 1000000 then '>= 1M'
             when amount >= 500000 then '>= 500K'
             when amount >= 100000 then '>= 100K'
             else '< 100K'
        end) as amount_segment,
    count(*) as holders_count
from polygon_top_holders
group by 1
order by 2 desc
```

Generate a Bar Chart and a Pie Chart for the above two queries respectively. Add them to the dashboard, and the display is as follows:

![](img/ch16_image_06.png)

Query link:
* [https://dune.com/queries/1837749](https://dune.com/queries/1837749)<a id="jump_8"></a>
* [ttps://dune.com/queries/1837150](ttps://dune.com/queries/1837150)<a id="jump_8"></a>
* [ttps://dune.com/queries/1837781](ttps://dune.com/queries/1837781)<a id="jump_8"></a>

## Smart Contract Analysis
### Number of Created and Suicided Contracts

``` sql
select type,
    count(*) / 1e6 as transactions_count
from polygon.traces
where type in ('create', 'suicide')
    and block_time >= date('2023-01-01') -- Date conditions are added here for performance considerations
group by 1
order by 1
```

Since we have restricted the values of the `type` and specified the sorting order, we can ensure that two records are returned and their order is fixed. Therefore, we can generate Counter-type visualizations for the values in the first and second rows respectively.

Query link:
* [https://dune.com/queries/1837749](https://dune.com/queries/1837749)<a id="jump_8"></a>

### Daily (Monthly) Contract Created and Suicided Count

We can calculate the daily (monthly) count of newly created and suicided contracts by date. Considering the cumulative count is also valuable, we first use a CTE to calculate the daily count, and then use the window function `sum() over (partition by type order by block_date)` to calculate the cumulative count by date. The `partition by type` is used to specify separate aggregations based on the contract type.

``` sql
with polygon_contracts as (
    select date_trunc('day', block_time) as block_date,
        type,
        count(*) as transactions_count
    from polygon.traces
    where type in ('create', 'suicide')
    group by 1, 2
)

select block_date, 
    type,
    transactions_count,
    sum(transactions_count) over (partition by type order by block_date) as accumulate_transactions_count
from polygon_contracts
order by block_date
```

Similarly, we can adjust the date to monthly and calculate the count of newly created and suicided contracts on a monthly basis.

The above queries generate Bar Chart and Area Chart respectively. After adding them to the dashboard, the resulting display is as follows:

![](img/ch16_image_07.png)

Query link:
* [https://dune.com/queries/1837749](https://dune.com/queries/1837749)<a id="jump_8"></a>
* [ttps://dune.com/queries/1837144](ttps://dune.com/queries/1837150)<a id="jump_8"></a>
* [ttps://dune.com/queries/1837781](ttps://dune.com/queries/1837781)<a id="jump_8"></a>
### Transaction Count Statistics for Top Smart Contracts

The top smart contracts in each blockchain usually generate the majority of transaction counts. We can analyze the top 100 smart contracts with the highest transaction counts. In the output results, we have added a link field for convenience, allowing you to directly query the transaction list for each smart contract by clicking on the link.

``` sql
with contract_summary as (
    select "to" as contract_address,
        count(*) as transaction_count
    from polygon.transactions
    where success = true
    group by 1
    order by 2 desc
    limit 100
)

select contract_address,
    '<a href=https://polygonscan.com/address/' || cast(contract_address as varchar) || ' target=_blank>PolygonScan</a>' as link,
    transaction_count
from contract_summary
order by transaction_count desc
```

Generating a Bar Chart and a Table Chart for this query. Adding them to the dashboard, the display is as follows:

![](img/ch16_image_08.png)

Query link:
* [https://dune.com/queries/1838001](https://dune.com/queries/1838001)<a id="jump_8"></a>

### Analysis of Daily Transaction Volume for the Most Active Smart Contracts

We can analyze the daily transaction volume for the top smart contracts with the highest cumulative transaction count. This can provide insights into the popularity and lifespan of different smart contracts in different stages. Given the large amount of data, we will only analyze the top 20 contracts.

``` sql
with top_contracts as (
    select "to" as contract_address,
        count(*) as transaction_count
    from polygon.transactions
    where success = true
    group by 1
    order by 2 desc
    limit 20
)

select date_trunc('day', block_time) as block_date, 
    contract_address,
    count(*) as transaction_count
from polygon.transactions t
inner join top_contracts c on t."to" = c.contract_address
group by 1, 2
order by 1, 2
```

We first query the top 20 smart contracts with the highest historical transaction volume. Then, we calculate the daily transaction volume for these smart contracts. We add three different types of visualizations for the query:

1. Bar Chart: displays the daily transaction volume for different smart contracts, stacked together.
2. Area Chart: displays the daily transaction volume for different smart contracts, stacked together. We set "Normalize to percentage" to adjust the chart to display in percentages.
3. Pie Chart: compares the cumulative transaction volume percentages for these top 20 smart contracts.

After adding these charts to the dashboard, the result is shown in the following:

![](img/ch16_image_09.png)

Query link:
* [https://dune.com/queries/1838060](https://dune.com/queries/1838060)<a id="jump_8"></a>

### The most active smart contracts in the last 30 days

In addition to analyzing all historical transaction data, we can also perform a simple analysis on the most active smart contracts in recent. For example, we can analyze the top 50 smart contracts that have been the most active in the last 30 days.

``` sql
select "to" as contract_address,
    '<a href=https://polygonscan.com/address/' || cast("to" as varchar) || ' target=_blank>PolygonScan</a>' as link,
    count(*) as transaction_count
from polygon.transactions
where block_time >= now() - interval '30' day
group by 1, 2
order by 3 desc
limit 50
```

As it is a recent active projects, it may have been newly deployed and launched. Therefore, we have added hyperlinks to the query and created a Table. The display is as follows:

- Query link: [https://dune.com/queries/1838077](https://dune.com/queries/1838077)<a id="jump_8"></a>

## Summary

Above, we have conducted a preliminary analysis of the Polygon Chain from several aspects, including blocks, gas consumption, transactions, users, native tokens, and smart contracts. Through this dashboard, we can gain a general understanding of the Polygon chain. In particular, through the analysis of top smart contracts, we can identify popular projects. This allows us to choose specific projects of interest for further analysis.

So far, SixdegreeLab has completed overview analyses for multiple blockchains, which you can find here:

* [Blockchain Overview Series](https://dune.com/sixdegree/blockchain-overview-series)<a id="jump_8"></a>

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch17/ch17-mev-analysis-uniswap.md">
# 17 MEV Data Analysis - Uniswap

## What is MEV?

The concept of MEV (miner-extractable value) first appeared in the Flashboy 2.0 article in 2019, referring to the additional profit that miners can obtain by including, reordering, inserting, or ignoring transactions. With the development of blockchain and Onchain research activities in recent years, MEV has now extended to maximal extractable value.

Visually through data, as shown in the following figure, the MEV profit obtained through arbitrage reached $1.44 million in the past 30 days, during a bear market with relatively low trading volume. The previous market turmoil brought about by the FTX crash incident was just a [bull market for MEV](https://twitter.com/lviswang/status/1591664260987641856?s=20&t=YPM1Qwt_-K8IJGHxxu2gnA), where intense price fluctuations led to an explosion of arbitrage and liquidation opportunities, generating $5 million in arbitrage income in just 7 days. Therefore, MEV is always accompanying the market although ordinary users may not want to, they can't avoid being passively involved in this corner of the dark forest. At least, we should roughly understand what MEV is all about.

![](img/ch17_ep_mev_ov.jpg)

Ethereum is the most active mainnet with the richest Onchain activities. Let's discuss a few prerequisites for the birth of MEV on Ethereum:

1. The Gas mechanism of Ethereum is essentially an auction mechanism, where the highest bidder wins, and the transactions are designed to be sequential. That is, miners/validators will package the transactions with the highest gas first to maximize profits. This is one of the reasons for the high gas fees and congestion on Ethereum and it also makes MEV possible: once a profitable transaction is found, it can be executed first by bribing miners (raising gas).

2. The design of the blockchain memory pool (Mempool). All transactions sent out need to temporarily enter the memory pool, rather than being packaged directly by miners. The memory pool is filled with pending transactions and is public, which means anyone can monitor every transaction and every function call in the memory pool, providing attackers with the conditions to monitor transactions. 

![](img/ch17_mempool.jpg)

3. According to [Etherscan](https://etherscan.io/blocks) data, after the POS merge, the block production time is fixed at 12 seconds; before the POS merge, it was around 13.5 seconds. The longer block production time, which is considered for the safety of node synchronization, also provides attackers with execution time.

In summary, **MEV attackers can see all pending transactions in the public mempool and have ample time to rehearse to see if the transaction can bring profits. If they determine that it is profitable, they can raise the gas fee to achieve the effect of priority execution, thus stealing others' benefits.**

![](img/ch17_mev_process.jpg)

Here's an interesting question - shouldn't Solana, which has no mempool and fast block production speed, have no MEV? In fact, Solana also has MEV, but let's just discuss MEV on Ethereum for now.

So who are the beneficiaries of MEV?

Firstly, miners/validators win passively. The competition between buyers maximizes the income of sellers and the block space market is no exception; Secondly, the initiators of MEV attacks benefit, which is obvious. Can miners/validators get involved in MEV themselves? The answer is certainly yes. The optimal situation is that the miner/validator launches an MEV transaction exactly when they are producing a block. However, in practice, the chance of this happening is really low. The occurrence of MEV also depends somewhat on luck. A lucky validator may produce a block containing a large amount of MEV, while an unlucky one may not have any at all. According to the results of the calculation in the article [Post-Merge MEV: Modelling Validator Returns](https://pintail.xyz/posts/post-merge-mev/), some validators have hardly received any MEV in a year, while the annual return rate of some validators is far more than 100%. On average, MEV brings an additional 1.5% - 3% annual return to validators. Including block rewards, the median annual return rate for validators is roughly 6.1% to 7.6% (based on datasets from the MEV "off-peak" and "peak" periods).


## The Extraction Process of MEV
In the process of MEV extraction, scientists calculate profits and arbitrage paths, write the execution logic into contract code, and use robots to complete the call. If no one finds and executes the same arbitrage path, then only the normal GAS fee needs to be paid to the miner; if someone else finds and executes the same arbitrage path, then a higher GAS must be paid to ensure that one's transaction is completed first.

As transactions on the blockchain are public, profitable arbitrage paths can be filtered and studied, leading to intense GAS competition. And the GAS bidding on the blockchain is public, so the GAS paid to miners can often double several times within the time of a block. Ultimately, if no one drops out, all profits often need to be given to the miner until one party ends the infighting.

![](img/ch17_mev_supchain.jpg)


## Classification of MEV
MEV robots, according to their creators' intentions, perform Onchain activities, packaging transactions and delivering them to unwitting miners for block production. From a positive perspective, they are important players in ensuring market stability and DApp activity; from a negative perspective, they exploit ordinary users unequally with their inherent advantage (they can monitor the entire Mempool).

Considering that this article mainly introduces the use of Dune for MEV analysis, here is a simple classification of MEV based on Dune-related content:

### 1. Arbitrage
Arbitrage is the most common form of MEV. When the same asset has different prices on different exchanges, there is an arbitrage opportunity. Like high-frequency traders looking for arbitrage opportunities in traditional financial markets, searchers (i.e., those who mine MEV) deploy robots to discover any potential arbitrage opportunities on decentralized exchanges (DEX). AMM mechanism naturally welcomes arbitrage transactions, because the transaction price is no longer determined by the order placer, but by the transaction in the pool, so arbitrage behavior is equivalent to manually synchronizing the price of a DEX trading pair with other DEX/CEX trading pairs, ensuring market fairness and stability, and contributing to the transaction volume and activity of the protocol. So this type of MEV is considered "good" MEV. Note that only when someone discovers arbitrage and replaces the transaction by raising gas to queue jump is arbitrage considered MEV.

### 2.Liquidations
DeFi lending platforms currently adopt an over-collateralized lending model. Naturally, the price of the asset used as collateral will fluctuate over time. If the asset price falls below a certain level, the collateral will be liquidated. Typically, the collateral is sold at a discount, and the person who buys this portion of collateral is known as a liquidator. After the liquidation is completed, they will also receive a reward from the lending platform. As long as there is a liquidation opportunity, there is a chance for transaction replacement, presenting a MEV opportunity. Searchers spot liquidation transactions incoming into the transaction pool, create a transaction identical to the initial liquidation transaction, insert their own transaction, and thus the searcher becomes the liquidator and collects the reward.

This type of MEV accelerates the liquidity of DeFi, providing guarantees for the normal operation of the lending platform, and is also considered a "good" MEV.

### 3. Frontrunning, Backrunning, and Sandwich(ing)
Frontrunning is when MEV bots pay slightly higher gas fees to execute transactions ahead of a certain transaction in the Mempool, such as swapping tokens at a lower price. Backrunning is when bots try different arbitrages, liquidations, or transactions after a transaction causes a significant price displacement. 

![](img/ch17_fr.jpg)

Sandwich attacks are a combination of the previous two, sandwiching transactions on both ends. For example, MEV bots place a buy order before the transaction and a sell order after the transaction, causing the user's transaction to execute at a worse price. If the transaction slippage is set unreasonably, it is easy to suffer a sandwich attack. This kind of MEV is obviously "bad".

![](img/ch17_swa.png)

### 4. Just-in-Time liquidity Attack
JIT liquidity is a special form of liquidity provision. In DEX, liquidity providers share transaction fees. JIT refers to adding liquidity just before a large Swap to share the transaction fee of that transaction and immediately exiting liquidity after the transaction ends. This might sound strange ‚Äì doesn‚Äôt providing liquidity continuously mean continuously receiving transaction fees? Personal opinion is that being an LP brings impermanent loss, while the impermanent loss brought by instantaneous liquidity provision can almost be ignored. JIT attacks are similar to sandwich attacks because they both involve prepositions and postpositions of the victim's transaction; but in the case of JIT, the attacker adds and removes liquidity, rather than buying and selling. This type of MEV increases the liquidity of DEX without harming traders, so it is also a "good" MEV. 

![](img/ch17_JIT.png)

JIT liquidity actually occupies a very small proportion in DEX transactions. Although it sounds very powerful, according to the [Just-in-time Liquidity on the Uniswap Protocol](https://uniswap.org/blog/jit-liquidity) report, in Uniswap, JIT liquidity has always been less than 1%, so it is a kind of MEV with minor impact.

![](img/ch17_JITv.png)


## MEV Analysis with Dune

Here are two ideas for doing MEV analysis with Dune. For related queries, please refer to the [MEV Data Analytics Tutorial](https://dune.com/sixdegree/mev-data-analytics-tutorial).

### 1. Use the `Community Table` from Flashbots
 
As shown in the figure below, among the four types of tables in Dune, the Community Table is a data source provided by external organizations, including data provided by Flashbots. 

![](img/ch17_dune_com.jpg)

![](img/ch17_dune_fb.jpg)

[Flashbots](https://www.flashbots.net/) is an MEV research and development organization, established to mitigate the negative externality of MEV on the blockchain. Currently, more than 90% of Ethereum validator nodes are running Flashbots programs. For those interested in Flashbots, you can check out their [research and documentation](https://boost.flashbots.net/) on your own. All we need to know here is that they are an MEV research organization that provides MEV-related data for users to do queries and analysis on Dune.

For a long time, Flashbots' community table had been stopped at September 15, 2022. When writing this article, I checked again and found that the table started updating again from January 9, 2023, which will facilitate our MEV query. The contents of each table and the meanings of the data in each column can be found in Dune's [Flashbots documentation](https://dune.com/docs/reference/tables/community/flashbots/).

Taking the **flashbots\.mev_summary** table as an example, to query miner income:

| **Column Name**                      | **Type**  | **Description**                                        |
| ------------------------------------ | --------- | ------------------------------------------------------ |
| block\_timestamp                     | timestamp | Block timestamp                                        |
| block\_number                        | bigint    | Block number                                           |
| base\_fee\_per\_gas                  | bigint    | Unit gas fee                                       |
| coinbase\_transfer                   | bigint    | Miner's fee directly given to the miner                     |
| error                                | string    | Error                                       |
| gas\_price                           | bigint    | Gas fee                                       |
| gas\_price\_with\_coinbase\_transfer | bigint    | Total gas consumed + miner's fee directly given to the miner |
| gas\_used                            | bigint    | Gas consumed                                     |
| gross\_profit\_usd                   |  double    | Total earnings from the transaction (USD)               |
| miner\_address                       | string    | Miner's address                                   |
| miner\_payment\_usd                  |  double    | Miner's earnings (USD)                   |
| protocol                             | string    | Main interacting protocol                               |
| protocols                            | string    | Protocols involved in the transaction          |
| transaction\_hash                    | string    | Transaction hash                                |
| type                                 | string    | Type of MEV (for example, arbitrage)                       |
| timestamp                            | timestamp | Timestamp of the last file update             |


Here we take a daily basis for statistics, sum the fees paid to miners, and classify them by MEV type, i.e., daily statistics of miner fees paid to miners by each type of MEV. 

``` sql
select date_trunc('day', block_timestamp) as block_date,
    type,
    sum(miner_payment_usd) as miner_revenue_usd
from flashbots.mev_summary
where error is null
group by 1, 2
having sum(miner_payment_usd) <= 100000000 -- exclude outliers
order by 1, 2
```

Generating a Line Chart, we can see that MEV was very active in 2021, but there was a significant decrease in MEV activity in 2022 due to the market turning bearish. At the same time, opportunities for arbitrage and competition are much more intense than liquidations, so naturally, the fees paid to miners are also higher. Another detail, we find that there are a small number of obvious outliers in Flashbots' data, so we have filtered them out in the query. 

![](img/ch17_mevsumchat.png)

Query for reference: [https://dune.com/queries/1883628](https://dune.com/queries/1883628)


The next example query is to find out which project has the most profit generated by arbitrage, i.e., gross profit minus the fees paid to miners.

``` sql
select protocols,
    sum(gross_profit_usd - miner_payment_usd) as mev_pure_profit_usd
from flashbots.mev_summary
where error is null
    and type = 'arbitrage'
    and miner_payment_usd <= 1e9 -- exclude outliers
    and abs(gross_profit_usd) <= 1e9 -- exclude outliers
group by 1
order by 2 desc
```

Generate a Table type of visualization result set and a pie chart for the above query results, and we can get the following results: 

![](img/ch17_arb.png)

It can be observed that the arbitrage transactions currently recorded by Flashbots primarily involve Uniswap V2, Uniswap V3, Balancer V1, Curve, and Bancor. The majority of arbitrage profits come from the Uniswap protocol.

Query for reference: [https://dune.com/queries/1883757](https://dune.com/queries/1883757)

Considering that `protocols` is a set of multiple different protocols, we can further optimize the above query and split the data. If an arbitrage transaction involves multiple protocols, we can distribute the profits or amounts evenly. This will better show which specific protocol has generated the most arbitrage profits. Fork the above query and modify as follows: 

``` sql
with protocols_profit as (
    select protocols,
        sum(gross_profit_usd - miner_payment_usd) as mev_pure_profit_usd
    from flashbots.mev_summary
    where error is null
        and type = 'arbitrage'
        and miner_payment_usd <= 1e9 -- exclude outliers
        and abs(gross_profit_usd) <= 1e9 -- exclude outliers
    group by 1
),

protocols_profit_array as (
    select protocols,
        mev_pure_profit_usd,
        regexp_extract_all(protocols, '"([0-9a-zA-Z_]+)"', 1) as protocols_array
    from protocols_profit
),

single_protocol_profit as (
    select p.protocol,
        mev_pure_profit_usd / cardinality(protocols_array) as mev_pure_profit_usd,
        protocols_array,
        cardinality(protocols_array) as array_size,
        mev_pure_profit_usd as origin_amount
    from protocols_profit_array
    cross join unnest(protocols_array) as p(protocol)
)

select protocol,
    sum(mev_pure_profit_usd) as mev_pure_profit_usd
from single_protocol_profit
group by 1
order by 2 desc
```

In this query, since the `protocols` field is of string type, we use `regexp_extract_all()` to split it and convert it into an array, defining a CTE `protocols_profit_array` as a transition. The regular expression `"([0-9a-zA-Z_]+)"` matches any combination of alphanumeric characters or underscores enclosed in double quotes. More information can be found in [Trino Regular expression functions#](https://trino.io/docs/current/functions/regexp.html).

Then, in the `single_protocol_profit` CTE, we average the profit amounts based on the cardinality (size) of the array. Using `unnest(protocols_array) as p(protocol)` splits the array and defines it as a table alias and field alias (respectively as `p` and `protocol`). Combined with `cross join`, you can output the split `protocol` values in the SELECT clause.

Finally, we aggregate the split protocols. Adjust the visualization chart's output fields, add the data to the dashboard, and display as follows:

![](img/ch17_arb_protocol.png)

Now we can clearly see that the arbitrage income from Uniswap V2 is as high as $176M, accounting for nearly 70%.

Query for reference: [https://dune.com/queries/1883791](https://dune.com/queries/1883791)

### 2. Establish a query by joining the Labels table of Spellbook with the DeFi Spellbook table
Taking Uniswap as an example:

If we do not rely on the community tables of flashbots, especially when its maintenance may be interrupted, we can also use the `labels.arbitrage_traders` table in Spellbook. 

``` sql
select address
from labels.arbitrage_traders
where blockchain = 'ethereum'
```

We then join the uniswap_v3_ethereum.trades table with the arbitrage traders table and filter the takers (i.e., traders) which are the arbitrage trades. Next, we can count the number of transactions, the total transaction amount, the average transaction amount, count the number of independent trading robots, etc., for MEV arbitrage information. Similarly, we can also query data related to sandwich attacks. 

``` sql
with arbitrage_traders as (
    select address
    from labels.arbitrage_traders
    where blockchain = 'ethereum'
)

select block_date,
    count(*) as arbitrage_transaction_count, 
    sum(amount_usd) as arbitrage_amount,
    avg(amount_usd) as arbitrage_average_amount,
    count(distinct u.taker) as arbitrage_bots_count
from uniswap_v3_ethereum.trades u
inner join arbitrage_traders a on u.taker = a.address
where u.block_date > now() - interval '6' month
group by 1
order by 1
 ```
 
Query for reference: [https://dune.com/queries/1883865](https://dune.com/queries/1883865)

From this, we can further compare the transaction count, transaction amount of MEV robots, and regular users; the proportion of MEV transaction count and transaction volume for each trading pair in Uniswap:

To distinguish whether it is an MEV robot, we still judge by the label table; we only need to judge whether the `taker` is in `arbitrage_traders` to distinguish whether it is an arbitrage robot.

``` sql
with arbitrage_traders as (
    select address
    from labels.arbitrage_traders
    where blockchain = 'ethereum'
),

trade_details as (
    select block_date,
        taker,
        amount_usd,
        tx_hash,
        (case when a.address is null then 'MEV Bot' else 'Trader' end) as trader_type
    from uniswap_v3_ethereum.trades u
    left join arbitrage_traders a on u.taker = a.address
    where u.block_date > now() - interval '6' month
)

select block_date,
    trader_type,
    count(*) as arbitrage_transaction_count, 
    sum(amount_usd) as arbitrage_amount
from trade_details
group by 1, 2
order by 1, 2
```

Generate two Area Chart charts for the above query results, comparing the transaction count and transaction amount proportions of MEV Bots and regular Traders. We then get the following results:

![](img/ch17_uniswap_bot.png)

For specific content, you can refer to the query: [https://dune.com/queries/1883887](https://dune.com/queries/1883887)


We can also count the transaction number, transaction amount, etc., for bot and regular user trades by trading pair. We just need to categorize and count with the `token_pair` in the Spellbook, so no more examples will be given here.

## Summary

The above introduced the principle and classification of Ethereum MEV, as well as the two methods on how to use Dune to do MEV queries, using Uniswap as an example. [AndrewHong](https://twitter.com/andrewhong5297) also has a lecture on MEV in the [12-day course of Dune](https://www.youtube.com/watch?v=SMnzCw-NeFE). People who are interested can check out the explanation by the principal of Duniversity, where it is mentioned that Dune's label table is derived from Etherscan and its [coverage](https://dune.com/queries/1764004) may not necessarily be sufficient. Therefore, using the two methods introduced in this article, the final query results may slightly differ. MEV is a complex topic, so here we just aim to provoke thought, as more methods need to be explored.

## References
1. [Understanding the Full Picture of MEV](https://huobi-ventures.medium.com/understanding-the-full-picture-of-mev-4151160b7583)
2. [Foresight Ventures: Describe, Classify, Dominate MEV](https://foresightnews.pro/article/detail/10011)
3. [Flashboy 2.0](https://arxiv.org/pdf/1904.05234.pdf)
4. [Post-Merge MEV: Modelling Validator Returns](https://pintail.xyz/posts/post-merge-mev/)
5. [mev-sandwich-attacks-and-jit](https://dune.com/amdonatusprince/mev-sandwich-attacks-and-jit)
6. [uniswap-v3-mev-activity](https://dune.com/alexth/uniswap-v3-mev-activity)
7. [Just-in-time Liquidity on the Uniswap Protocol](https://uniswap.org/blog/jit-liquidity)
8. [MEV-Who are you working for](https://github.com/33357/smartcontract-apps/blob/main/Robot/MEV_Who_are_you_working_for.md)
9. [mev-data-analytics-tutorial](https://dune.com/sixdegree/mev-data-analytics-tutorial)

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch18/ch18-uniswap-multichain-analysis.md">
# 18 Uniswap Multi-Chain Analysis

Uniswap is one of the leading decentralized exchanges (DEX) in the DeFi space. The Uniswap smart contract was initially deployed on the Ethereum blockchain in 2018. It has since expanded to other chains such as Arbitrum, Optimism, Polygon, and Celo in 2021 and 2022. It continues to gain momentum with a new proposal to deploy on the Binance Smart Chain (BNB). In this article, we will explore how to analyze the performance of Uniswap across multiple chains in 2022. Please note that Celo chain is not included in this analysis as it is not currently supported by Dune.

Dashboard for this tutorial: [Uniswap V3 Performance In 2022 Multichains](https://dune.com/sixdegree/uniswap-v3-performance-in-2022-multi-chains)<a id="jump_8"></a>

All queries in this tutorial are executed using the Dune SQL.

Interestingly, during the completion of this tutorial, the Uniswap Foundation launched a new round of bounty program, focusing on analyzing Uniswap's performance across multiple chains on January 25, 2023. This tutorial hopes to provide some insights and ideas; participants can further expand on these queries to participate in the bounty program. We wish you the best of luck in earning the generous rewards. You can find more information about the Unigrants program and the [Bounty #21 - Uniswap Multichain](https://unigrants.notion.site/Bounty-21-Uniswap-Multichain-b1edc714fe1949779530e920701fd617)<a id="jump_8"></a> here.

## Key Content of Multi-Chain Data Analysis

As mentioned in the description of the "Bounty #21 - Uniswap Multichain" activity, when analyzing DeFi applications like Uniswap, the most common metrics we need to analyze include trading volume, trading value, user base, and Total Value Locked (TVL). Uniswap deploys smart contracts for numerous liquidity pools that facilitate trading pairs of different tokens. Liquidity providers (LPs) deposit funds into these pools to earn transaction fee rewards, while other users can exchange their tokens using these liquidity pools. Therefore, a more in-depth analysis can also include liquidity pool-related and LP-related metrics.

In this tutorial, we will primarily focus on the following topics:

* Overview of total trading activity (number of trades, trading volume, user count, TVL)
* Daily trading data comparison
* Daily new user comparison
* Yearly comparison of new liquidity pools created
* Daily comparison of new liquidity pools
* TVL comparison
* Daily TVL
* Liquidity pool with the highest TVL

The Dune community has created a comprehensive trade data Spells called "uniswap.trades", which aggregates transaction data from Uniswap-related smart contracts on the mentioned four blockchains. Most of our queries can directly utilize this table. However, there is currently no Spells available for liquidity pool-related data, so we will need to write queries to aggregate data from different blockchains for comparative analysis.

It is important to note that in this tutorial, we primarily focus on the data from 2022. Therefore, there are date filtering conditions in the related queries. If you want to analyze the entire historical data, simply remove these conditions.

## Summary of Overall Trading Activity

We can write a query directly against the "uniswap.trades" to summarize the total trading volume, number of trades, and count of unique user addresses.

``` sql
select blockchain,
    sum(amount_usd) as trade_amount,
    count(*) as transaction_count,
    count(distinct taker) as user_count
from uniswap.trades
where block_time >= date('2022-01-01')
    and block_time < date('2023-01-01')
group by 1
```

Considering that the result data can be quite large, we can put the above query into a CTE (Common Table Expression). When outputting from the CTE, we can convert the numbers into million or billion units and conveniently aggregate data from multiple chains together.

We will add 3 Counter charts for the total trading volume, number of trades, and user count. Additionally, we will add 3 Pie charts to display the percentage of trading volume, number of trades, and user count for each chain. Furthermore, we will include a Table chart to present detailed numbers. All these charts will be added to the dashboard, resulting in the following display:

![](img/ch18_image_01.png)

Query link:
* [https://dune.com/queries/1859214](https://dune.com/queries/1859214)<a id="jump_8"></a>

## Daily Transaction Data Comparative Analysis

Similarly, using the `uniswap.trades magical` table, we can write a SQL query to calculate the daily transaction data. The SQL query is as follows:

``` sql
with transaction_summary as (
    select date_trunc('day', block_time) as block_date,
        blockchain,
        sum(amount_usd) as trade_amount,
        count(*) as transaction_count,
        count(distinct taker) as user_count
    from uniswap.trades
    where block_time >= date('2022-01-01')
        and block_time < date('2023-01-01')
    group by 1, 2
)

select block_date,
    blockchain,
    trade_amount,
    transaction_count,
    user_count,
    sum(trade_amount) over (partition by blockchain order by block_date) as accumulate_trade_amount,
    sum(transaction_count) over (partition by blockchain order by block_date) as accumulate_transaction_count,
    sum(user_count) over (partition by blockchain order by block_date) as accumulate_user_count
from transaction_summary
order by 1, 2
```

Here, we summarize all transaction data from 2022 based on date and blockchains. We also output the cumulative data based on the date. It's important to note that the cumulative user count in this aggregation is not an accurate representation of "cumulative unique user count" since the same user can make transactions on different dates. We will explain how to calculate the unique user count separately in later queries.

Since our goal is to analyze the data performance across different chains, we can focus on the specific values as well as their proportions. Proportional analysis allows us to visually observe the trends of different chains over time. With this in mind, we generate the following charts: Line Chart for daily transaction volume, Bar Chart for daily transaction count/daily unique user count, Area Chart for cumulative transaction volume as well as transaction count/unique user count, and another Area Chart to display the percentage contribution of each daily transaction data. The resulting charts, when added to the dashboard, will appear as follows:

![](img/ch18_image_02.png)

Query link:
* [https://dune.com/queries/1928680](https://dune.com/queries/1928680)<a id="jump_8"></a>

## Daily New User Analysis

To analyze the daily new users and make comparisons, we first need to calculate the initial transaction date for each user address. Then, we can calculate the number of new users for each day based on their initial transaction dates. In the following query, we use a CTE called `user_initial_trade` to calculate the initial transaction date for each user address (`taker`) without any date filtering conditions. Then, in the CTE `new_users_summary`, we calculate the number of new users for each day in 2022. Additionally, we summarize the daily active users in the CTE `active_users_summary`. In the final output, we subtract the number of new users from the number of daily active users to obtain the number of retained users per day. This allows us to generate visualizations comparing the proportions of new users and retained users.

``` sql
with user_initial_trade as (
    select blockchain,
        taker,
        min(block_time) as block_time
    from uniswap.trades
    group by 1, 2
),

new_users_summary as (
    select date_trunc('day', block_time) as block_date,
        blockchain,
        count(*) as new_user_count
    from user_initial_trade
    where block_time >= date('2022-01-01')
        and block_time < date('2023-01-01')
    group by 1, 2
),

active_users_summary as (
    select date_trunc('day', block_time) as block_date,
        blockchain,
        count(distinct taker) as active_user_count
    from uniswap.trades
    where block_time >= date('2022-01-01')
        and block_time < date('2023-01-01')
    group by 1, 2
)

select a.block_date,
    a.blockchain,
    a.active_user_count,
    n.new_user_count,
    coalesce(a.active_user_count, 0) - coalesce(n.new_user_count, 0) as retain_user_count,
    sum(new_user_count) over (partition by n.blockchain order by n.block_date) as accumulate_new_user_count
from active_users_summary a
inner join new_users_summary n on a.block_date = n.block_date and a.blockchain = n.blockchain
order by 1, 2
```

To generate different visualizations for these queries, displaying the daily number and proportion of new users, daily number and proportion of retained users, daily cumulative number of new users, and the proportion of new users for each chain in 2022, we can create the following charts:

![](img/ch18_image_03.png)

Query link:
* [https://dune.com/queries/1928825](https://dune.com/queries/1928825)<a id="jump_8"></a>

The queries mentioned above include the comparison of daily new users and daily retained users, as well as their respective proportions. However, since the results are already grouped by blockchain, it is not possible to display both the daily number of new users and the daily number of retained users in the same chart. In this case, we can utilize the Query of Query in the Dune SQL to create a new query using the previous queries as the data source. By selecting a specific blockchain from the query results, we can display multiple metrics in a single chart, as we no longer need to group by blockchain.

``` sql
select block_date,
    active_user_count,
    new_user_count,
    retain_user_count
from query_1928825 -- This points to all returned data from query https://dune.com/queries/1928825
where blockchain = '{{blockchain}}'
order by block_date
```

Here we will define the blockchain to be filtered as a parameter of type List, which will include the names (in lowercase format) of the four supported blockchains as options. We will generate two charts for the query results, displaying the daily number of new users and their respective proportions. After adding the charts to the dashboard, the display will be as follows:

![](img/ch18_image_04.png)

Query link:
* [https://dune.com/queries/1929142](https://dune.com/queries/1929142)<a id="jump_8"></a>

## Comparative Analysis of Annual New Liquidity Pools

Dune's current Spells do not provide data on liquidity pools, so we can write our own queries to aggregate the data. We welcome everyone to submit a PR to the Spellbook repository on Dune's GitHub to generate the corresponding Spells. Using the PoolCreated event to parse the data, we will gather data from the four blockchains together. Since Uniswap V2 is only deployed on the Ethereum chain, we have not included it in the scope of our analysis.

``` sql
with pool_created_detail as (
    select 'ethereum' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_ethereum.Factory_evt_PoolCreated

    union all
    
    select 'arbitrum' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_arbitrum.UniswapV3Factory_evt_PoolCreated

    union all
    
    select 'optimism' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_optimism.Factory_evt_PoolCreated

    union all
    
    select 'polygon' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_polygon.factory_polygon_evt_PoolCreated
)

select blockchain,
    count(distinct pool) as pool_count
from pool_created_detail
where evt_block_time >= date('2022-01-01')
    and evt_block_time < date('2023-01-01')
group by 1
```

We can generate a Pie Chart to compare the number and proportion of newly created liquidity pools on each chain in 2022. Additionally, we can create a Table chart to display detailed data. After adding these charts to the dashboard, the display will look as follows:

![](img/ch18_image_05.png)

Query link:
* [https://dune.com/queries/1929177](https://dune.com/queries/1929177)<a id="jump_8"></a>

## Daily Comparison of New Liquidity Pools

Similarly, by adding a date to the grouping condition in the query, we can calculate the daily count of new liquidity pools on each chain.

``` sql
with pool_created_detail as (
    -- same as previous SQL
),

daily_pool_summary as (
    select date_trunc('day', evt_block_time) as block_date,
        blockchain,
        count(distinct pool) as pool_count
    from pool_created_detail
    group by 1, 2
)

select block_date,
    blockchain,
    pool_count,
    sum(pool_count) over (partition by blockchain order by block_date) as accumulate_pool_count
from daily_pool_summary
where block_date >= date('2022-01-01')
    and block_date < date('2023-01-01')
order by block_date
```

We can generate a Bar Chart for the daily count of new liquidity pools and an Area Chart to display the daily count percentage. Additionally, we can create an Area Chart to showcase the cumulative count of newly created liquidity pools. The visualizations can be added to the dashboard for display, as shown in the following image:

![](img/ch18_image_06.png)

Query link:
* [https://dune.com/queries/1929235](https://dune.com/queries/1929235)<a id="jump_8"></a>

## Total Value Locked (TVL) Comparison Analysis

Different tokens have different prices. When comparing TVL, we need to convert the locked amounts (quantities) of these tokens to USD values by associating them with the `prices.usd` Spells. Only then can we perform the aggregation. Each trading pair represents an independent liquidity pool with its own contract address. The TVL represents the total value, in USD, of all tokens held by these contract addresses. To calculate the current token balances in a pool, we can use the `evt_Transfer` table under the `erc20` Spells to track the inflows and outflows of each pool and derive the current balances. Each pool consists of two different tokens, so we also need to obtain the decimal places and corresponding prices of these tokens. Let's take a look at the query code:

``` sql
with pool_created_detail as (
    -- The SQL here is the same as above
),

token_transfer_detail as (
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_arbitrum.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'arbitrum'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_arbitrum.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'arbitrum'

    union all
    
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_ethereum.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'ethereum'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_ethereum.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'ethereum'

    union all
    
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_optimism.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'optimism'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_optimism.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'optimism'

    union all
    
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_polygon.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'polygon'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_polygon.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'polygon'
),

token_list as (
    select distinct contract_address
    from token_transfer_detail
),

latest_token_price as (
    select contract_address, symbol, decimals, price, minute
    from (
        select row_number() over (partition by contract_address order by minute desc) as row_num, *
        from prices.usd
        where contract_address in ( 
                select contract_address from token_list 
            )
            and minute >= now() - interval '1' day
        order by minute desc
    ) p
    where row_num = 1
),

token_transfer_detail_amount as (
    select blockchain,
        d.contract_address,
        evt_block_time,
        evt_tx_hash,
        pool,
        amount_original,
        amount_original / pow(10, decimals) * price as amount_usd
    from token_transfer_detail d
    inner join latest_token_price p on d.contract_address = p.contract_address
)

select blockchain,
    sum(amount_usd) as tvl,
    (sum(sum(amount_usd)) over ()) / 1e9 as total_tvl
from token_transfer_detail_amount
where abs(amount_usd) < 1e9 -- Exclude some outlier values from Optimism chain
group by 1
```

The explanation of the above query is as follows:

* CTE `pool_created_detail`: retrieves data for all created liquidity pools across different chains.
* CTE `token_transfer_detail`: filters out token transfer data for all Uniswap liquidity pools by joining the `evt_Transfer` table with `pool_created_detail`.
* CTE `token_list`: Filters out the list of tokens used in all trading pairs.
* CTE `latest_token_price`: calculates the current prices of these tokens. Since the price data in `prices.usd` may have a time delay, we first retrieve data from the past 1 day and then use `row_number() over (partition by contract_address order by minute desc)` to calculate the row number and return only the rows with a row number of 1, which represents the latest price records for each token.
* CTE `token_transfer_detail_amount`: joins `token_transfer_detail` with `latest_token_price` to calculate the USD value of token transfers.
* The final output query summarizes the current TVL for each blockchain and the total TVL across all chains.

Generate a Pie Chart and a Counter chart respectively. Adds them to the dashboard, resulting in the following display:

![](img/ch18_image_07.png)

Query link:
* [https://dune.com/queries/1929279](https://dune.com/queries/1929279)<a id="jump_8"></a>

### Daily TVL (Total Value Locked) Comparative Analysis

When analyzing daily TVL amounts, we need to add a date grouping dimension. However, the result obtained at this point is the daily change in TVL, not the daily balance. We also need to accumulate the balances by date to obtain the correct daily balances.


``` sql
with pool_created_detail as (
    -- The SQL here is the same as above
),

token_transfer_detail as (
    -- The SQL here is the same as above
),

token_list as (
    -- The SQL here is the same as above
),

latest_token_price as (
    -- The SQL here is the same as above
),

token_transfer_detail_amount as (
    -- The SQL here is the same as above
),

tvl_daily as (
    select date_trunc('day', evt_block_time) as block_date,
        blockchain,
        sum(amount_usd) as tvl_change
    from token_transfer_detail_amount
    where abs(amount_usd) < 1e9 -- Exclude some outlier values from Optimism chain
    group by 1, 2
)

select block_date,
    blockchain,
    tvl_change,
    sum(tvl_change) over (partition by blockchain order by block_date) as tvl
from tvl_daily
where block_date >= date('2022-01-01')
    and block_date < date('2023-01-01')
order by 1, 2
```

We discovered that there is some abnormal data on the Optimism chain, so we added the condition `abs(amount_usd) < 1e9` in the above query to exclude them. Generate an Area Chart for this query. Add it to the dashboard and the display is as follows:

![](img/ch18_image_08.png)

Query link:
* [https://dune.com/queries/1933439](https://dune.com/queries/1933439)<a id="jump_8"></a>

## Top Flow Pools by TVL

By aggregating the TVL (Total Value Locked) by the contract address of each flow pool, we can calculate the current TVL for each pool. However, if we want to compare the trade pairs more intuitively using the token symbols, we can join the tokens.erc20 Spells to generate the trade pairs. In Uniswap, the same trade pair can have multiple service fee rates (different pool addresses), so we need to aggregate them by the trade pair name. Here is the SQL to achieve this:


``` sql
with pool_created_detail as (
    -- The SQL here is the same as above
),

token_transfer_detail as (
    -- The SQL here is the same as above
),

token_list as (
    -- The SQL here is the same as above
),

latest_token_price as (
    -- The SQL here is the same as above
),

token_transfer_detail_amount as (
    -- The SQL here is the same as above
),

top_tvl_pools as (
    select pool,
        sum(amount_usd) as tvl
    from token_transfer_detail_amount
    where abs(amount_usd) < 1e9 -- Exclude some outlier values from Optimism chain
    group by 1
    order by 2 desc
    limit 200
)

select concat(tk0.symbol, '-', tk1.symbol) as pool_name,
    sum(t.tvl) as tvl
from top_tvl_pools t
inner join pool_created_detail p on t.pool = p.pool
inner join tokens.erc20 as tk0 on p.token0 = tk0.contract_address
inner join tokens.erc20 as tk1 on p.token1 = tk1.contract_address
group by 1
order by 2 desc
limit 100
```

We can generate a Bar Chart and a Table chart to display the data for the flow pools with the highest TVL (Total Value Locked).

![](img/ch18_image_09.png)

Query link:
* [https://dune.com/queries/1933442](https://dune.com/queries/1933442)<a id="jump_8"></a>

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch19/ch19-useful-metrics.md">
# 19 Useful Metrics

## Background Knowledge

In the previous tutorials, we learned a lot about data tables and SQL query statements. Accurately and effectively retrieving as well as calculating the required data is an essential skill for a qualified analyst. At the same time, understanding and interpreting these data metrics are equally crucial. Only with a deep understanding of data metrics can they provide strong support for our decision-making.

Before delving into specific metrics, let's first consider why we need data metrics. In simple terms, metrics are numerical values that reflect certain phenomena, such as the floor price of a particular NFT or the daily active trades on a DEX. Metrics directly reflect the status of the objects we are studying and provide data support for corresponding decisions. By leveraging our knowledge of data tables and SQL queries, we can build, invoke, and analyze these metrics, making our analysis efforts more efficient. Without metrics, the information we obtain would be chaotic and the insights we can gain would be limited.

In the context of blockchain, although some metrics are similar to those in financial markets, there are also unique metrics specific to the blockchain space, such as Bitcoin Dominance and All Exchanges Inflow Mean-MA7. In this tutorial, we will start by learning about several common metrics and their calculation methods:

- Total Value Locked (TVL)
- Circulating Supply
- Market Cap
- Daily/Monthly Active Users (DAU/MAU)
- Daily/Monthly New Users

## Total Value Locked (TVL)

Let's start with the first metric we are going to learn today - Total Value Locked (TVL). It describes the total value of all locked tokens in a protocol, which can be a DEX, lending platform, or even a sidechain or L2 network. TVL reflects the liquidity and popularity of the protocol and indicates user confidence.

For example, let's take a look at the TVL ranking for DEXs:

![](img/ch19_image_01.png)

And the TVL ranking for Layer 2 networks:

![](img/ch19_image_02.png)

The top-ranked protocols are the ones with higher popularity.

The calculation logic for TVL is relatively straightforward. We need to count all relevant tokens in the protocol, multiply each token's quantity by its price, and finally sum up the results. Let's use the DEX project Auragi on the Arbitrum chain as an example to explain TVL calculation. The TVL of the DEX project is reflected through the balances in its liquidity pools. To calculate the TVL for each day, we need to first calculate the balance of relevant tokens in each pair for that day and their corresponding prices in USD.

To get the token balances for each pair, we first need to organize all transaction details:

``` sql
WITH token_pairs AS (
    SELECT 
        COALESCE(k1.symbol, 'AGI') || '-' || COALESCE(k2.symbol, 'AGI') AS pair_name,
        p.pair,
        p.evt_block_time,
        p.token0,
        p.token1,
        p.stable
    FROM auragi_arbitrum.PairFactory_evt_PairCreated p
    LEFT JOIN tokens.erc20 k1 ON p.token0 = k1.contract_address AND k1.blockchain = 'arbitrum'
    LEFT JOIN tokens.erc20 k2 ON p.token1 = k1.contract_address AND k2.blockchain = 'arbitrum'
),

token_transfer_detail AS (
    SELECT DATE_TRUNC('minute', evt_block_time) AS block_date,
        evt_tx_hash AS tx_hash,
        contract_address,
        "to" AS user_address,
        CAST(value AS DECIMAL(38, 0)) AS amount_raw
    FROM erc20_arbitrum.evt_Transfer
    WHERE "to" IN (SELECT pair FROM token_pairs)
        AND evt_block_time >= DATE('2023-04-04')

    UNION ALL
    
    SELECT DATE_TRUNC('minute', evt_block_time) AS block_date,
        evt_tx_hash AS tx_hash,
        contract_address,
        "from" AS user_address,
        -1 * CAST(value AS DECIMAL(38, 0)) AS amount_raw
    FROM erc20_arbitrum.evt_Transfer
    WHERE "from" IN (SELECT pair FROM token_pairs)
        AND evt_block_time >= DATE('2023-04-04')
),

token_price AS (
    SELECT DATE_TRUNC('minute', minute) AS block_date,
        contract_address,
        decimals,
        symbol,
        AVG(price) AS price
    FROM prices.usd
    WHERE blockchain = 'arbitrum'
        AND contract_address IN (SELECT DISTINCT contract_address FROM token_transfer_detail)
        AND minute >= DATE('2023-04-04')
    GROUP BY 1, 2, 3, 4
    
    UNION ALL
    
    -- AGI price from swap trade
    SELECT DATE_TRUNC('minute', block_time) AS block_date,
        0xFF191514A9baba76BfD19e3943a4d37E8ec9a111 AS contract_address,
        18 AS decimals,
        'AGI' AS symbol,
        AVG(CASE WHEN token_in_address = 0xFF191514A9baba76BfD19e3943a4d37E8ec9a111 THEN token_in_price ELSE token_out_price END) AS price
    FROM query_2337808
    GROUP BY 1, 2, 3, 4
)

SELECT p.symbol,
    d.block_date,
    d.tx_hash,
    d.user_address,
    d.contract_address,
    d.amount_raw,
    (d.amount_raw / POWER(10, p.decimals) * p.price) AS amount_usd
FROM token_transfer_detail d
INNER JOIN token_price p ON d.contract_address = p.contract_address AND d.block_date = p.block_date
```

The above query logic is as follows:

- First, in `token_pairs`, we obtain all pairs for this project.
- With the help of the `evt_Transfer` table, we extract the transaction details of each pair.
- In `token_price`, we calculate the current price of each token. As this is a relatively new token, Dune might not have its price data. Therefore, we use trade data to calculate the price. The detailed list of trade data is obtained through another query, which we reference using a Query of Query approach.
- Finally, we join the transaction details with the price information to calculate the USD amount for each transaction.

Based on the results of the transaction details query, we can now calculate the TVL for each day.

First, we generate a date-time series in `date_series`. Considering that this is a relatively new project, we calculate the TVL on an hourly basis. If the project has been online for a sufficient period, we recommend calculating it on a daily basis.

Next, in `pool_balance_change`, we combine the transaction details above to summarize the balance changes of each token per hour.

In `pool_balance_summary`, we sort the token balances by time and sum up the cumulative balances for each token. Here, we use the `lead()` function to calculate the next date with recorded balances for each token in each time period.

Finally, we join the date series with the cumulative balances for each hour, filling in the missing transaction data for each time period. Pay attention to the join condition here: `INNER JOIN date_series d ON p.block_date <= d.block_date AND d.block_date < p.next_date`. We use two conditions here: specifying that the cumulative balance date must be less than or equal to the date-time value of the date series and the date-time value of the series must be less than the date-time value of the next recorded balance. This is a common processing technique. Not all tokens have transactions in every time period, so when encountering a time period without transactions, we need to use the balance from the previous time period to represent the balance in the current time period. This should be relatively easy to understand because there were no new changes during the "current time period," so the balance naturally remains the same as the previous time period.

The query code is as follows:

``` sql
WITH date_series AS (
    SELECT block_date
    FROM UNNEST(SEQUENCE(TIMESTAMP '2023-04-01 00:00:00', localtimestamp, INTERVAL '1' hour)) AS tbl(block_date)
),

pool_balance_change AS (
    SELECT symbol,
        DATE_TRUNC('hour', block_date) AS block_date,
        SUM(amount_usd) AS amount
    FROM query_2339248
    GROUP BY 1, 2
),

pool_balance_summary AS (
    SELECT symbol,
        block_date,
        SUM(amount) OVER (PARTITION BY symbol ORDER BY block_date) AS balance_amount,
        LEAD(block_date, 1, current_date) OVER (PARTITION BY symbol ORDER BY block_date) AS next_date
    FROM pool_balance_change
    ORDER BY 1, 2
)

SELECT d.block_date,
    p.symbol,
    p.balance_amount
FROM pool_balance_summary p
INNER JOIN date_series d ON p.block_date <= d.block_date AND d.block_date < p.next_date
ORDER BY 1, 2
```

With this query, we can visualize the TVL changes:

![](img/ch19_image_03.png)

Links to the above queries:

- https://dune.com/queries/2339317
- https://dune.com/queries/2339248
- https://dune.com/queries/2337808

Another example for calculating TVL: https://dune.com/queries/1059644/1822157

## Circulating Supply

Circulating Supply represents the current quantity of a cryptocurrency that is circulating in the market and held by holders. It differs from Total Supply, which includes all tokens issued, even those that are locked and cannot be traded. Since these locked tokens usually do not impact the price, Circulating Supply is a more commonly used metric for token quantity. The calculation method for Circulating Supply can vary depending on the cryptocurrency. For example, for tokens with linear release schedules, their supply increases over time. Tokens with deflationary burning mechanisms may require a deduction for their Circulating Supply. Let's take Bitcoin as an example and calculate its current Circulating Supply.

The Circulating Supply of Bitcoin can be calculated based on the number of blocks and the block reward schedule:

``` sql
SELECT SUM(50/POWER(2, ROUND(height/210000))) AS Supply                      
FROM bitcoin.blocks
```

## Market Cap

The third metric we'll learn today is Market Cap. You are probably familiar with this metric. In the stock market, Market Cap refers to the total value of all outstanding shares of a stock at a specific time, which is calculated by multiplying the total number of shares by the stock's price. Similarly, in the blockchain space, it is calculated by multiplying the Circulating Supply of a cryptocurrency by its current price. Therefore, the key to calculating Market Cap is to obtain the metric we just learned - Circulating Supply. Once we have the Circulating Supply, we can multiply it by the current price of the cryptocurrency to get its Market Cap.

Let's continue using Bitcoin as an example. Based on the previously calculated Circulating Supply, we can now multiply it by Bitcoin's current price to obtain its Market Cap:

``` sql
SELECT SUM(50/POWER(2, ROUND(height/210000))) AS Supply, 
       SUM(50/POWER(2, ROUND(height/210000)) * p.price) / POWER(10, 9) AS "Market Cap"
FROM bitcoin.blocks
INNER JOIN (
    SELECT price FROM prices.usd_latest
    WHERE symbol='BTC'
        AND contract_address IS NULL
) p ON TRUE
```

The Bitcoin Dominance that we mentioned earlier is calculated as the Market Cap of Bitcoin divided by the sum of the Market Caps of all cryptocurrencies.

## Daily/Monthly Active Users (DAU/MAU)

The next metric we'll learn is Daily/Monthly Active Users (DAU/MAU). Compared to absolute trading volumes, the number of active users better reflects the popularity of a protocol. Large transactions from a small number of users can inflate the trading volumes, while the count of active users provides a more objective description of the protocol's popularity. The calculation is relatively simple; we just need to count the number of wallet addresses that interacted with a specific contract and then calculate the frequency per day or per month.

Let's take the recent popular protocol Lens as an example:

``` sql
WITH daily_count AS (
    SELECT DATE_TRUNC('day', block_time) AS block_date,
        COUNT(*) AS transaction_count,
        COUNT(DISTINCT "from") AS user_count
    FROM polygon.transactions
    WHERE "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
        AND block_time >= DATE('2022-05-16')  -- contract creation date
    GROUP BY 1
    ORDER BY 1
)

SELECT block_date,
    transaction_count,
    user_count,
    SUM(transaction_count) OVER (ORDER BY block_date) AS accumulate_transaction_count,
    SUM(user_count) OVER (ORDER BY block_date) AS accumulate_user_count
FROM daily_count
ORDER BY block_date
```

We use the `DISTINCT` function to ensure that each user is counted only once per day. In addition to calculating the number of daily active users, we also use the `SUM` `OVER` function to calculate the cumulative user count. If you want to calculate the monthly active users (MAU), you can modify the query to use `DATE_TRUNC('month', block_time)` to group the counts by month.

![](img/ch19_image_04.png)



## Daily / Monthly New Users

In addition to monitoring active user data, the number of daily/monthly new users is also a very common analytical metric. Typically, to obtain accurate data on new users, we need to first calculate the date and time of the first transaction for each user address or the date and time of the first received/sent transfer record. Then, we can count the number of new users per day or per month based on this information. Here, we will use a query to calculate the number of daily new users on the Optimism chain as an example.

``` sql
with optimism_new_users as (
    SELECT "from" as address,
        min(block_time) as start_time
    FROM optimism.transactions
    GROUP BY 1
)

SELECT date_trunc('day', start_time) as block_date,
    count(n.address) as new_users_count
FROM optimism_new_users n
WHERE start_time >= date('2022-10-01')
GROUP BY 1
```

![](img/ch19_image_05.png)

Here is a practical example that combines the number of new users with specific NFT project user data statistics: [Example](https://dune.com/queries/1334302).

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch20/ch20-network-analysis.md">
# 20 Blockchain Network Analysis

## Preface

All public blockchains are essentially large networks. Analyzing Onchain data most likely involves network analysis. The existing visualizations on common data platforms like Dune currently have difficulty describing the relationships between nodes on blockchains.

Let's use the controversial FTX "hacker" address (0x59ABf3837Fa962d6853b4Cc0a19513AA031fd32b) as an example to do some network analysis (we won't debate whether it's a hacker or the Panama government). We'll look at where the ETH from this address went (we'll examine the 2-hop relationships outgoing from this address).

Tools used in the process:

- Dune: get raw data between addresses and do initial processing
- Python
  - Networkx: python package for creating, manipulating and studying complex networks. Allows storing networks in standardized and non-standardized data formats, generating various random and classic networks, analyzing network structure, building network models, designing new network algorithms, drawing networks, etc.
    - More info: [https://networkx.org/](https://networkx.org/)
  - Plotly: great package for visualizations, can generate interactive HTML files. Has a complementary frontend framework called DASH that is very user-friendly for data analysts without advanced engineering skills.
    - More info: [https://plotly.com/](https://plotly.com/)
  - Pandas: most commonly used Python package for working with data, provides many functions and methods to enable quick and convenient data manipulation.
    - More info: [https://pandas.pydata.org/](https://pandas.pydata.org/)
- Etherscan API: calculating ETH Balance on Dune is too tedious, requiring pulling all data each time. We can simply get Balance from the Etherscan API.

## Overview

The process can be broadly divided into the following steps:

- Get raw data from Dune
- Process relationships between nodes and handle various attribute data needed for drawing the network graph (pos, label, color, size etc.) using Networkx
- Visualize the network graph using Plotly

## Detailed process

#### I. Get Raw Data from Dune (SQL Part)

The SQL is quite complex so I won't go into detail, so feel free to check the URL for details if interested:

- Get data with relationships between all relevant addresses with SQL: [https://dune.com/queries/1753177](https://dune.com/queries/1753177)

  - from: sender of the transaction
  - to: receiver of the transaction
  - transfer_eth_balance: total ETH transferred between two
  - transfer_eth_count: total number of ETH transfers between two accounts

![](img/ch20_01-Graph-Raw-Relation.png)

- Get list of all addresses and associated labels via SQL: [https://dune.com/queries/2430347](https://dune.com/queries/2430347)

  - address: all addresses involved in this network analysis
  - level_type: level in the network for all addresses involved (Core, Layer One, Layer Two)
  - account_type: is a regular EOA, exchange, or smart contract
  - label: useful aggregated info for the address into a label for subsequent visualization in python

![](img/ch20_02-graph-raw-label.png)

#### II. Read local files into DataFrames using pandas and supplement with Balance column from Etherscan API

- Download Dune data locally (either via Dune API or copy-paste) and read into pandas from local files

``` python
## Change path to your own local file path
df_target_label = pd.read_csv(u'YOUR FILE PATH/graph_raw_label.csv')
df_target_relation = pd.read_csv(u'YOUR FILE PATH/graph_relation.csv')
## Get list of all addresses to query API
address_list = list(df_target_label.address.values)
balance_list = []
print(address_list)
```

- Get Balance data for all addresses via Etherscan API and write to DataFrame

``` python
while len(address_list) > 0:
    for address in address_list:

        api_key = "your_api_key"
        try:
            response = requests.get(
                "https://api.etherscan.io/api?module=account&action=balance&address=" + address + "&tag=latest&apikey=" + api_key
            )


            # Parse the JSON response
            response_json = json.loads(response.text)

            # Get balance info from response
            eth_balance = response_json["result"]
            eth_balance = int(eth_balance)/(1E18)
            balance_list.append((address,eth_balance))
            address_list.remove(address)
            time.sleep(1)
            print(eth_balance)
        except:
            print('Error')
            print('List Length:'+str(len(address_list)))


df_balance = pd.DataFrame(balance_list, columns=['address', 'Balance'])
df_target_label = df_target_label.merge(df_balance,left_on=['address'],right_on=['address'],how='left')
print('end')
```

- Add Balance to DataFrame, create Balance_level column (label based on Balance size) to control Node size in network graph later

``` python
## Define a function to return different labels based on value size, similar to CASE Statement in SQL

def get_balance_level(x):
    if x == 0:
        output = 'Small'
    elif x > 0 and x < 1000:
            output = 'Medium'
    elif x > 1000 and x < 10000:
            output = 'Large'
    else:
        output = 'Huge'
    return output


df_target_label['Balance_level'] = df_target_label['Balance'].round(2).apply(lambda x: get_balance_level(x))

df_target_label['Balance'] = df_target_label['Balance'].round(2).astype('string')
df_target_label['label'] = df_target_label['label']+' | '+ df_target_label['Balance'] +' ETH'
```

#### III. Define a function to process node relationships with NetworkX and draw with Plotly

``` python
def drew_graph(df_target_relation,df_target_label):

    def add_node_base_data(df_target_relation):
        df_target_relation = df_target_relation
        node_list = list(set(df_target_relation['from_address'].to_list()+df_target_relation['to_address'].to_list()))
        edges = list(set(df_target_relation.apply(lambda x: (x.from_address, x.to_address), axis=1).to_list()))
        G.add_nodes_from(node_list)
        G.add_edges_from(edges)
        return node_list,edges

    def add_node_attributes(df_target_label,df_key_list,df_vlaue_list,color_list):
        for node, (n,p) in zip(G.nodes(), pos.items()):
                G.nodes[node]['pos'] = p
                G.nodes[node]['color'] = '#614433'
                for id,label,layer_type,Balance_level in list(set(df_target_label.apply(lambda x: (x.address, x.label, x.level_type,x.Balance_level), axis=1).to_list())):
                        if node==id:
                            G.nodes[node]['label']=label
                            if Balance_level=='Large':
                                G.nodes[node]['size']=40
                            elif Balance_level=='Medium':
                                G.nodes[node]['size']=20
                            elif Balance_level=='Small':
                                G.nodes[node]['size']=10
                            elif Balance_level=='Huge':
                                G.nodes[node]['size']=80

                for x,y,z in zip(df_key_list,df_vlaue_list,color_list):
                    target_list = df_target_label[df_target_label[x]==y]['address'].values.tolist()
                    if len(target_list)>0:
                        for id in target_list:
                            if id==node and G.nodes[node]['color']=='#614433':
                                G.nodes[node]['color'] = z

    ############### Draw all edges
 def get_edge_trace(G):
        xtext=[]
        ytext=[]
        edge_x = []
        edge_y = []
        for edge in G.edges():
            x0, y0 = G.nodes[edge[0]]['pos']
            x1, y1 = G.nodes[edge[1]]['pos']
            xtext.append((x0+x1)/2)
            ytext.append((y0+y1)/2)

            edge_x.append(x0)
            edge_x.append(x1)
            edge_x.append(None)
            edge_y.append(y0)
            edge_y.append(y1)
            edge_y.append(None)

            xtext.append((x0+x1)/2)
            ytext.append((y0+y1)/2)


        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#333'),
            hoverinfo='none',
            mode='lines')

        eweights_trace = go.Scatter(x=xtext,y= ytext, mode='text',
                              marker_size=0.5,
                              text=[0.45, 0.7, 0.34],
                              textposition='top center',
                              hovertemplate='weight: %{text}<extra></extra>')
        return edge_trace, eweights_trace

    def get_node_trace(G):
        node_x = []
        node_y = []
        for node in G.nodes():
            x, y = G.nodes[node]['pos']
            node_x.append(x)
            node_y.append(y)

        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers',
            hoverinfo='text',
            marker=dict(
                color=[],
                colorscale = px.colors.qualitative.Plotly,
                size=10,
                line_width=0))
        return node_trace

    ###############Define Graph
    G = nx.Graph()

    ###############Add Nodes and Edges to the graph
    node_list = add_node_base_data(df_target_relation)[0]
    edges = add_node_base_data(df_target_relation)[1]
    eweights_trace = add_node_base_data(df_target_relation)[1]

    ###############choose layout and get the pos of the relevant node
    pos = nx.fruchterman_reingold_layout(G)

    df_key_list = [   'level_type'  ,'account_type' ,  'account_type' , 'account_type' ]
    df_vlaue_list = [  'Core' , 'EOA' ,           'Cex Address'   , 'Contract Address']
    color_list = [    '#109947' ,'#0031DE'      , '#F7F022'     , '#E831D6' ]

    ###############Add label, Size, color attributes to node
    add_node_attributes(df_target_label,df_key_list,df_vlaue_list,color_list)

    edge_trace, eweights_trace = get_edge_trace(G)
    node_trace = get_node_trace(G)

    ###############Write node_text, node_size, node_color into list
    node_text = []
    node_size = []
    node_color = []
    for node in G.nodes():
        x = G.nodes[node]['label']
        y = G.nodes[node]['size']
        z = G.nodes[node]['color']
        node_text.append(x)
        node_size.append(y)
        node_color.append(z)




     # Set label, size, color
    node_trace.marker.color = node_color
    node_trace.marker.size =node_size
    node_trace.text = node_text

    fig_target_id=go.Figure()
    fig_target_id.add_trace(edge_trace)
    fig_target_id.add_trace(node_trace)

    fig_target_id.update_layout(

                                    height=1000,
                                    width=1000,
                                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                    showlegend=False,
                                    hovermode='closest',
                                )

    return fig_target_id
```

#### IV. Call the drew_graph function, pass in the 2 DataFrames to draw the graph. Export as HTML file.

``` python
fig = drew_graph(df_target_relation,df_target_label)
fig.show()
fig.write_html(u'YOUR FILE PATH/FTX_Accounts_Drainer.html')
print('end')
```

#### V. Result graph

Check out the interactive version at this URL: [https://pro0xbi.github.io/FTX_Accounts_Drainer.html](https://pro0xbi.github.io/FTX_Accounts_Drainer.html)

- Node colors

  - Green is the FTX "hacker" address
  - Blue are normal EOA accounts that had large transfers (>100ETH) with it
  - Yellow are Exchange addresses (FTX)
  - Red are smart contract addresses

- Node size

  - Larger nodes indicate larger balances for that address. The largest nodes have balances >10,000 ETH

  We can see that among all addresses associated with the FTX "hacker", there are still at least 12 addresses holding >10,000 ETH, meaning at least 120,000 ETH have not been sold by the "hacker".

![](img/ch20_20-3.png)

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch21/ch21-btc-analysis.md">
# 21 Bitcoin Analysis
## Introduction to the BTC CDD

### Explanation of the Indicator

CDD stands for Coin Day Destroyed. It is an improved version of the Transaction Volume, with the improvement aimed at considering time in evaluating Onchain activities (Transfers). For tokens that have been in a HODL (Hold On for Dear Life) status for a long time (not transferred to other wallets), a larger weight is given to their movements.

Here we introduce a new concept called Coin Day. `Coin Day = Token Quantity * Number of days the Token is in HODL status`.

All BTC Onchain accumulates Coin Days every day. If a portion of BTC moves (from Wallet A to Wallet B), the accumulated Coin Days for this portion will be destroyed, which is the so-called Coin Day Destroyed.     

![](img/ch21_historical_trend.png)    


### Underlying Logic

All indicators are designed to better depict the conditions we want to reflect. In the case of this indicator, it aims to reflect the behavior of long-term holders. From this perspective, it can be considered a Smart Money type of indicator. People tend to think that long-term holders are early participants in BTC, and thus, they have a better and more experienced understanding of BTC and the market. If their tokens (long-term HODL) move, it may very well be that some changes in the market have prompted them to take action (in many cases, this means moving to an exchange or selling through OTC, but there are other scenarios as well, so it can't be generalized).

If you frequently use Glassnode, you'll find that many indicators on Glassnode are designed based on the above logic, which can be considered one of the most important underlying logics in the current BTC Onchain data analysis.

### UTXO Mechanism

Here we need to introduce a basic knowledge about BTC: the UTXO mechanism. Understanding it will help you understand how to use the several tables about BTC on Dune to complete the above calculation.

UTXO stands for Unspent Transaction Output. In the current operation mechanism of BTC, there is actually no concept of Balance. The balance of each wallet is obtained by summing the BTC amounts contained in all UTXOs owned by the wallet.

Here's a link to an article that explains it quite well: https://www.liaoxuefeng.com/wiki/1207298049439968/1207298275932480


## Related Tables in Dune

If you can roughly understand the concepts of Input, Output, and UTXO, it's easy to understand the two tables we need to use on Dune. Here's a brief explanation of the tables and fields we need to use.

### bitcoin.inputs

- Explanation: contains all data related to Input, i.e., for each address, each BTC expenditure/transfer
- Key Fields
  - `address`: wallet address
  - `block_time`: the time when this transfer Transaction occurred
  - `tx_id`: the Tx ID of this transfer Transaction
  - `value`: the BTC amount included in this transfer Transaction
  - `spent_tx_id`: the output that generated this Input (Which incoming payment was used for this expenditure)
    
![](img/ch21_input_info.png)       

### bitcoin.outputs

- Explanation: contains all data related to Output, i.e., for each address, each BTC incoming record.
- Key Fields
  - `address`: wallet address
  - `block_time`: the time when this incoming Transaction occurred
  - `tx_id`: the Tx id of this incoming Transaction
  - `value`: the BTC amount included in this incoming Transaction
  
![](img/ch21_output_info.png)    

## Dashboard Design and Implementation

### How to Design a Dashboard
#### General Approach

The design of a Dashboard depends on the final purpose of using it. The ultimate goal of a Dashboard or data is to assist in decision-making. In our view, data can aid decision-making by answering the following two questions. Only if these two questions can be effectively answered, can it be considered a qualified Dashboard.

`[a].`What is XXX? What are its characteristics?

This involves using a series of indicators to reflect the basic characteristics and current status of something (e.g., daily user volume, tx number, and new contract number for Ethereum, etc.).

`[b].`What is the cause for the change in some important indicators reflecting XXX characteristics?

When the indicators in `[a]` change, we analyze the cause of the change, or in other words, look for the reason for the data fluctuation.

#### Fluctuation Analysis

`[a]` is relatively easy to understand, so we won't go into it. The quality of indicator system design depends on your understanding of the thing itself. Each industry or each sub-field within each industry is actually different.

We can discuss the analysis of fluctuations. In my view, analyzing fluctuations is about decomposition. In general, a fluctuation in an indicator can be decomposed from two angles. Here, taking the daily burning quantity of Ethereum as an example, suppose that the destruction of Ethereum increased by 30% one day, how should we analyze it?

**1. Process of the thing's formation**

`Today's ETH burning = Total gas fee consumed today * Burn rate`

- `Total gas fee consumed today = Average gas fee consumed per tx today * Number of tx today`
  - `Number of tx today = Number of active Ethereum users today * Average number of tx issued by active Ethereum users today`
    - `Number of active Ethereum users today = Total number of Ethereum users * Active ratio today`
- `Burn rate: Depends on EIP1559 or whether there are new proposals`    

![](img/ch21_funnel_info.png)    


**2. Characteristics of the thing itself**

- Time: distinguish by hour to see which hour of the 24 hours had an increase in gas fee consumption or if it was a general increase across all hours.
- Space: if the IP of each initiating wallet could be obtained, we could see whether gas fee consumption in a certain country increased significantly (not possible in practice).
- Other characteristics: whether it was the gas fee consumption of EOA addresses or contract addresses that increased.
  - If it's an EOA address, whether it was caused by Bot or ordinary EOA addresses; if it's ordinary EOA addresses, whether it was caused by whales or ordinary wallets.
  - If it's a contract address, which type of project (Defi, Gamefi, etc.) had an increase in contract gas fee consumption; if it's a Gamefi project, which specific contract caused it.

The above are two categories of decomposition approaches. By decomposing the main indicator into sub-indicators layer by layer, we can better observe which fluctuations in the sub-indicators caused the fluctuation in the main indicator, and then infer the root cause.

### Design of the Bitcoin - Coin Day Destroyed Dashboard

Back to the main topic, we'll start designing the Bitcoin - Coin Day Destroyed Dashboard.

#### Overall Situation

First, we need a chart to reflect the overall situation. Since there's only the CDD as an indicator, which is quite simple, I've only included a historical trend chart.    

![](img/ch21_historical_trend.png)    

However, the time period of this chart is too long and it's difficult to clearly see recent changes in CDD from this chart. Therefore, I've added a trend for the recent period.

![](img/ch21_recent_trend.png)     

P.S. Here, you can still see a significant CDD abnormality before this round of downturn.

#### Fluctuation Analysis

Here, I only decomposed along three dimensions:

- Decomposition by time (hour): this way, I know roughly when the indicator abnormality occurred. [Statistics for the latest day].

![](img/ch21_hour.png)    

- Decomposition by the wallet address initiating the transaction: this way, I know what caused the indicator abnormality and whether it was caused by a single wallet or multiple wallets, as well as whether it was a small portion of old coins or a large number of new coins. [Statistics for the latest day].

![](img/ch21_wallet.png)    

- Decomposition down to the very fine granularity of the Transaction_ID: this way, I know specifically which transactions caused the abnormality and can verify this in the blockchain browser. [Statistics for the latest day].

![](img/ch21_transaction.png)    

- In addition, to facilitate analysis of fluctuations on any given day in history based on the wallet address, I added a tool module that allows you to find the distribution of CDD by wallet for any day in history by entering the date.

![](img/ch21_tool.png)    

### Completion

And just like that, a dashboard for monitoring CDD is complete. The final effect is that you can conveniently see the historical trend and recent changes of the indicator. If an abnormality occurs one day, you can quickly pinpoint the time of the abnormality and the associated wallets, as well as the specific transaction_id aids further analysis.

![](img/ch21_overview.png)    

Detailed Dashboard can be found at: https://dune.com/sixdegree/bitcoin-coin-day-destroyed-matrix


Adding some more decomposition ideas: 
- Try to decompose by the target address of the transaction, distinguishing between CDD of transactions deposited to exchanges and CDD of ordinary transactions. This way, you will know how much of the CDD is likely intended for selling.

- Try to decompose by the type of wallet. We can attempt to calculate the probability of a price drop following a large CDD abnormality for each wallet, then define some Smart Money. This way, CDD is decomposed into Smart Money CDD & Normal CDD.

If you're interested, you can fork the Dashboard and try to implement it yourself.

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch22/ch22-how-to-build-spellbook.md">
# 22 How to Build a Spellbook

Spellbook is a data transformation layer built collaboratively by the Dune community. Spells are advanced abstract views or tables built jointly by the Dune team and community users.

By building spells, all Dune community users can more easily accomplish data analysis. There are many benefits to building spells. Imagine:

- You have multiple queries that contain the same subqueries or CTEs
- Multiple queries in your reuse very long static data lists
- One of your queries has been forked or copied multiple times
- Your query contains very complex logic that can be reused elsewhere

If one of the above scenarios applies, we can turn this query into a spell by building a view. This can simplify query SQL logic, improve consistency and maintainability, as well as clarify data metrics.

The open source Spellbook project maintained by Dune can automatically build and maintain these spells. Anyone in the community can contribute spells to the Spellbook project. This tutorial attempts to write a simple spell to help everyone get started easily.

## Basic Steps to Build a Spell

In the simplest terms, a spell is essentially a SELECT query statement underneath. But the specific process of building a spell actually involves multiple aspects and multiple steps that must be followed step by step according to the documentation to complete the spell construction successfully.

The basic steps to build a spell include:

- **Determine the data object**: based on the example scenarios mentioned above, in combination with the specific problems and needs you encounter when writing queries, determine the data object to be processed to build and generate the spell, and define the mode (schema) for the output spell.
- **Configure data sources**: the data source refers to the original data tables and parsed data tables on which the spell depends. They must be defined in a YAML file. Each data source needs to be defined only once in the spell.
- **Write tests**: consider the desired query results before writing the spell and write corresponding tests based on the results. Of course, if our spell is just a view of aggregated data, the test can be added after writing the spell.
- **Write the spell**: use a `.sql` file with a certain special format (JINJA template) to build a spell for each spell to be built by writing a `SELECT` query statement. Compile and test the spell.
- **Submit a PR**: after writing the spell, compiling it locally successfully and manually testing it, create a new PR (Pull Request) on GitHub and wait for Dune's technical personnel to review and merge it. After successful merging, we can find the newly built spell in the query editor.

Dune provides more detailed instructions in their online documentation:[Spell guide](https://dune.com/docs/zh/spellbook/getting-started/)

## Preparation before Building the Magic Table

Before you start building the magic table, you need to do some essential preparation work, including familiarizing yourself with the basic usage of the dbt tool, getting acquainted with basic GitHub operations (you must have a GitHub account), and setting up your local working environment. Detailed requirements and instructions for environment setup can be found here:

[Prepare prerequisites and set up Spellbook dbt](https://dune.com/docs/spellbook/1-do-some-prerequisites%20and-set-up-Spellbook-dbt/)

For more information about DBT:

[What is dbt?](https://docs.getdbt.com/docs/introduction)

We assume that you have already configured the relevant software following the instructions in the links above and have forked the Dune Spellbook repository (https://github.com/duneanalytics/spellbook) to your own GitHub account. The following steps will be briefly explained. I am using a Mac operating system locally, so the examples provided here are for the Mac environment. If you are using a Windows environment and encounter any issues during the process, please ask in the group.

Use the `git clone` command to clone the forked repository to your local machine. Create a new working directory on your local machine. Go into that directory and use the following command to clone (copy the address from the forked repository page on GitHub, as shown in the image below):



```
git clone git@github.com:springzh/spellbook.git
```

![](img/ch22_image_00.jpg)

When you cloned the repo, you will get a new sub-directory called `spellbook`. Enter this directory:

```
cd spellbook
```

After the cloning is completed, you will see a new `spellbook` subdirectory in your working directory. Navigate to this subdirectory:

```
cd spellbook
```

If you haven't previously run `pipenv install` to create the local pipenv environment, you need to execute the installation:

```
pipenv install
```

If the above command gives an error, you can try the following:

```
sudo -H pip install -U pipenv
```

If the command returns the following error:

```
pipenv install returns warning LANG, warning Python 3.9 not found
```

You can try installing again, specifying the Python version:

```
pipenv install --python 3.9.13
```

You can use this command to confirm the Python version installed on your local machine:

```
python3 -version
```

Once the pipenv environment is installed, you can now activate it:

```
pipenv shell
```

Next, run the `dbt init` command to initialize dbt. This command will guide you through the interactive setup of dbt. Detailed instructions can be found in the link provided in the section "Prepare prerequisites and set up Spellbook dbt."

```
dbt init
```

After we finish writing the magic table or make any changes to the related files, we use `dbt compile` to compile the entire dbt project and regenerate the SQL for the magic table.

To avoid confusion, let's list the main steps again:

**First-time initialization and execution steps**:

```
# Install pipenv environment
pipenv install

# Activate pipenv environment
pipenv shell

# Initialize dbt
dbt init

# Add or modify files

# Compile dbt
dbt compile
```

**Subsequent daily execution steps after the initialization**:

```
# Activate pipenv environment
pipenv shell

# Add or modify files

# Compile dbt
dbt compile
```

While writing and debugging a new magic table, you may need to adjust and modify related files repeatedly. In this case, you can execute `dbt compile` multiple times. If there are any compilation errors, make the necessary changes based on the error messages. Once the compilation is successful, copy the generated SQL statements to Dune for actual query testing to ensure that the SQL works correctly and produces the expected results.

##  The Magic Table to Create in This Tutorial

The purpose of this tutorial is to enable everyone to quickly learn how to build a magic table using a simple example. Previously, when the Space ID on the BNB chain launched domain registration, I created a Space ID data dashboard ([SpaceID - BNB Domain](https://dune.com/sixdegree/bnb-domain-spaceid)). At that time, the Space ID only had a limited open Mint permission and users provided a lot of feedback as well as suggestions regarding the Mint rules. In response to this feedback, the SpaceID team continuously improved and upgraded its smart contracts. Within a few days, the contract for domain registration went through five major versions, from V3 to V7. This led to a problem where, to consolidate all currently registered SpaceID domain data, one had to query the data separately from the event log tables of these different contract versions and manually merge them using "Union All" operations. If you check the source code of my data dashboard queries, you'll find that most of them have a long CTE (Common Table Expression) to aggregate and merge domain registration events from different contract versions. For example: https://dune.com/queries/1239514/2124307. To keep it up to date, I had to make numerous modifications to these queries one by one, including incorporating data from new contract versions. In fact, the SpaceID project now has V8 and V9 domain registration contract versions, which are not included in my dashboard, making it outdated. If other users forked my queries and made adjustments, unfortunately, their queries would also be outdated.

![](img/ch22_image_01.jpg)

In such a case, if we build a magic table for domain registration events (actually a view), all queries can be written directly based on this magic table. When a new smart contract version is released, we only need to modify and update the definition of the magic table and submit a PR (Pull Request) for review. Once the PR is approved and merged, the data in the magic table will be automatically updated. All queries using this magic table will not require any changes. In contrast, without a magic table, my queries, as well as the queries generated by others who forked my queries, would have to be modified one by one. From here, we can see the benefits of building a magic table.

So, what we are going to do here is to build a magic table that includes all Space ID domain registration information on the `bnb` blockchain of the `spaceid` project.

## Creating Directory Structure and Files

Once we have determined what magic table we want to create, we can start working on it. When using Git, it's a good practice to always develop in a separate branch. I recommend everyone follows this approach. Let's create a new working branch called `add_bnb_spaceid` in the local cloned spellbook repository:

```
git checkout -b add_bnb_spaceid
```

Now we are automatically switched to the new git working branch `add_bnb_spaceid`. We can begin creating the directory structure and files required for the magic table.

For project-based magic tables, they are stored in the `/spellbook/models` directory using the format `[project_name]/[blockchain_name]`. All names should be in lowercase, and words should be separated by underscores. For example: `/spellbook/models/[project_name]/[blockchain_name]`. In this case, our project name is `spaceid`, and the blockchain name is `bnb`, so the complete directory structure for our magic table is: `/spellbook/models/spaceid/bnb/`.

Please navigate to the `models` directory and create a subdirectory called `spaceid` within it. Then, go inside this newly created directory and create another subdirectory called `bnb`.

The magic table files should be named as follows:

- For schema files: `[project_name]_[blockchain]_schema.yml`
- For dependency source files: `[project_name]_[blockchain]_sources.yml`
- For the SQL file of the magic table: `[project_name]_[blockchain]_[spell_name].sql`

Here, `spell_name` is the name of the magic table we want to create. We will use `registrations` as the name.

So, we need to create the following three corresponding files (keep the file content empty for now; we will explain each one later) in the `spaceid/bnb/` directory:

- spaceid_bnb_schema.yml
- spaceid_bnb_sources.yml
- spaceid_bnb_registrations.sql

The current directory and file structure should look like this:

![](img/ch22_image_02.jpg)

Reference document: [Set up your file structure for SQL, schema, and source files](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/3-set-up-your-file-structure-for-SQL-schema-and-source-files/)

## Defining the Dependency Source File

Here, we only need to use seven different versions of the `RegistrarController` contract that have been deployed by the SpaceID project so far. These tables are under the `spaceid_bnb` schema. The definition of our dependency source file `spaceid_bnb_sources.yml` is as follows:

```
version: 2

sources:
  - name: spaceid_bnb
    description: "bnb decoded tables related to SpaceId contract"
    freshness: # default freshness
      warn_after: { count: 12, period: hour }
      error_after: { count: 24, period: hour }
    tables:
      - name: BNBRegistrarControllerV3_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV4_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV5_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV6_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV7_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV8_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV9_evt_NameRegistered
        loaded_at_field: evt_block_time
```

In the defined dependency source file:

1. `version` is always set to `2`.
2. `name` specifies the schema (Schema name) of the dependency source data tables. We can create a new query on Dune, search for the relevant table, and add the table name to the query editor. The part to the left of the `.` symbol is the schema name of the table. For example, the schema name of the table `spaceid_bnb.BNBRegistrarControllerV3_evt_NameRegistered` is `spaceid_bnb`.
3. `freshness` is used to verify and ensure the automatic update of data in the magic table. If the data is not updated successfully within the specified time, a warning or error will be issued when using the magic table (I personally have not encountered such an error yet, so it may only be sent to the personnel maintaining the magic table module). Keeping the default settings is fine. This setting applies to all data source tables listed under `tables`. Of course, you can also add this setting to individual tables.
4. `tables` lists the data source tables we need to use. These tables should all belong to the schema specified above. If there are tables belonging to different schemas, we would need to add a separate definition with the same structure in the same file. You can refer to the definitions of existing magic table schema files.

- `name` sets the name of the table. Do not include the schema name here.
- `loaded_at_field` specifies the timestamp-type field used to check the loading time of the last few rows of data. This is essential for ensuring the regular update of data in the magic table, in conjunction with the `freshness` setting.

Reference documents:

- [Identify and define sources](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/4-identify-and-define-sources/)
- [Data Sources](https://dune.com/docs/zh/spellbook/data-sources/)

## Defining the Schema File

The schema file `spaceid_bnb_schema.yml` provides information such as the name, fields, and description of the magic table to be created, as well as corresponding configuration information.

```yml
version: 2

models:
  - name: spaceid_bnb_registrations
    meta:
      blockchain: bnb
      project: spaceid
      contributors: [springzh]
    config:
      tags: ['bnb','spaceid','name','registrations']
    description: >
       SpaceID V3, V4, V5, V6, V7, V8 & V9 Name Registered on BNB
    columns:
      - &version
        name: version
        description: "Contract version"
      - &block_time
        name: block_time
        description: "UTC event block time"
      - &name
        name: name
        description: "Name of the space ID"
        tests:
          - unique
      - &label
        name: label
        description: "Label of the space ID"
      - &owner
        name: owner
        description:  "Owner of the space ID"
      - &cost
        name: cost
        description:  "Cost spent to register the space id"
      - &expires
        name: expires
        description:  "Name expires date and time in Unix timestamp format"
      - &contract_address
        name: contract_address
        description:  "Contract address that called to register the space id"
      - &tx_hash
        name: tx_hash
        description:  "Transaction hash"
      - &block_number
        name: block_number
        description: "Block number in which the transaction was executed"
      - &evt_index
        name: evt_index
        description: "Event index"
```

Since the structure of the `NameRegistered` event tables for different versions of SpaceID is the same, our work is relatively simple. We can use the structure of one of the tables as a reference to define our schema file. To distinguish the source of domain registrations, we add a `version` field to store information about the smart contract version, such as 'v3', 'v4', etc.

As domain names are unique, we add a uniqueness test definition to the `name` field. During compilation, an associated test SQL will be generated to ensure that there are no duplicate values in the magic table data.

The `&field_name` syntax defines field names. The first occurrence of a field name in the file should have a "&" prefix. Later in the same file, other tables' field definitions can use `*field_name` to reference the defined field, making the code more concise.

## Writing the SQL Statement for the Magic Table View

Now we come to the most critical part of creating the magic table ‚Äì the SQL writing. Open the `spaceid_bnb_registrations.sql` file and enter the following content (with some parts omitted):

``` sql
{{
    config(
        alias='registrations'
        ,materialized = 'incremental'
        ,file_format = 'delta'
        ,incremental_strategy = 'merge'
        ,unique_key = ['name']
        ,post_hook='{{ expose_spells(\'["bnb"]\',
                                    "project",
                                    "spaceid",
                                    \'["springzh"]\') }}'
    )
}}

SELECT 'v3'                    as version,
       evt_block_time          as block_time,
       name,
       label,
       owner,
       cast(cost as double)    as cost,
       cast(expires as bigint) as expires,
       contract_address,
       evt_tx_hash             as tx_hash,
       evt_block_number        as block_number,
       evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV3_evt_NameRegistered')}}
{% if is_incremental() %}
WHERE evt_block_time >= date_trunc("day", now() - interval '1 week')
{% endif %}

UNION ALL

-- Omitted V4 - V8 parts

UNION ALL

-- There are some records in v9 table that are duplicated with those in the v5 table. So we join to exclude them
SELECT 'v9'                       as version,
       v9.evt_block_time          as block_time,
       v9.name,
       v9.label,
       v9.owner,
       cast(v9.cost as double)    as cost,
       cast(v9.expires as bigint) as expires,
       v9.contract_address,
       v9.evt_tx_hash             as tx_hash,
       v9.evt_block_number        as block_number,
       v9.evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV9_evt_NameRegistered')}} v9
LEFT JOIN {{source('spaceid_bnb', 'BNBRegistrarControllerV5_evt_NameRegistered')}} v5
    ON v9.name = v5.name
WHERE v5.name is null
```

Explanations:

- The `config` section at the beginning provides some critical configurations for the magic table. Please always maintain the same format and pay attention to escaping when using single and double quotes. The `alias` specifies the alias for the magic table, which will be the name users use to refer to the magic table in the query editor. It is recommended to use the same name as defined in the schema. The `post_hook` is a configuration for additional operations when the magic table is built and published. `expose_spells` is used to display the magic table in the query editor so that other users can find it. The parameters for this function represent, in order, the applicable blockchain (as an array), the type of magic table (project type or industry type), the name of the project or industry, and a list of contributors (as an array). For our magic table, it is the bnb blockchain, the project type, the name spaceid, and the contributor being your own GitHub account name.
- The main part is a complete SELECT query. The difference from regular queries we write is that we need to use special JINJA template syntax to reference data source tables. For example, `{{source('spaceid_bnb', 'BNBRegistrarControllerV9_evt_NameRegistered')}}` refers to the `BNBRegistrarControllerV9_evt_NameRegistered` table defined in our `spaceid_bnb_sources.yml` file.
- After receiving the review feedback, we adjusted the V9 part of the query to exclude some records that were already present in the V5 table. We did this by adding a LEFT JOIN and a WHERE clause.

Reference documents:

- [Configure Alias and Materialization Strategy](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/7-configure-alias-and-materialization-strategy/)
- [Write Your Spell as a SELECT Statement](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/6-write-your-spell-as-SELECT-statement/)

After writing the query, you can use `dbt compile` to try compiling it. If there are errors, make adjustments accordingly and recompile to ensure successful compilation.

After submitting the PR for review, you received feedback suggesting setting the view's materialization strategy to incremental. Therefore, you made adjustments to both the `config` section at the beginning and each sub-query part to accommodate incremental updates. The adjusted example is as follows:

``` sql
{{
    config(
        alias='registrations'
        ,materialized = 'incremental'
        ,file_format = 'delta'
        ,incremental_strategy = 'merge'
        ,unique_key = ['name']
        ,post_hook='{{ expose_spells(\'["bnb"]\',
                                    "project",
                                    "spaceid",
                                    \'["springzh"]\') }}'
    )
}}

SELECT 'v3'                    as version,
       evt_block_time          as block_time,
       name,
       label,
       owner,
       cast(cost as double)    as cost,
       cast(expires as bigint) as expires,
       contract_address,
       evt_tx_hash             as tx_hash,
       evt_block_number        as block_number,
       evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV3_evt_NameRegistered')}}
{% if is_incremental() %}
WHERE evt_block_time >= date_trunc("day", now() - interval '1 week')
{% endif %}

UNION ALL

-- Omitted
```

With the added incremental update configurations and conditions, when in incremental update mode (i.e., `{% if is_incremental() %}`), only data from the past week will be queried. The queried new data will be merged into the physical file that holds the view data. The `incremental_strategy = 'merge'` will ensure that existing records are ignored during this merge process.

## Adding the New Model to the dbt_project.yml File

Next, we need to modify the `dbt_project.yml` file located at the root of the `spellbook` repository to include our magic table.

```
    spaceid:
      +schema: spaceid
      bnb:
        +schema: spaceid_bnb
```

Here, we specify the project name and its schema name, as well as the blockchain name and the schema name under that blockchain. With this hierarchical structure, we can handle the magic table creation for each project deployed on different blockchains and further combine the magic tables for the same project on multiple blockchains into a project-level magic table. For specific examples, you can refer to magic tables related to projects like opensea or uniswap.

You can use `dbt compile` again to confirm that the compilation is successful.

Reference documents:

- [Configure Alias and Materialization Strategy](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/7-configure-alias-and-materialization-strategy/)
- [Defining Models in dbt](https://dune.com/docs/zh/spellbook/defining-models-in-dbt/)

## Writing Tests

To ensure that the generated magic table data is complete and accurate, we need to write appropriate tests. Create a new directory path `spaceid/bnb` under the `spellbook/test` directory and navigate into the bnb subdirectory. In this directory, create a file named `spaceid_registrations_test.sql` with the following content:

``` sql
WITH unit_tests AS (
    SELECT COUNT(*) as count_spell
    FROM {{ ref('spaceid_bnb_registrations') }} AS s
    WHERE version = 'v7'
),

spaceid_v7_registration as (
    SELECT COUNT(*) as count_event_table
    FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV7_evt_NameRegistered')}}
)
SELECT 1
FROM unit_tests
JOIN spaceid_v7_registration ON TRUE
WHERE count_spell - count_event_table <> 0
```

In this test, we use `{{ ref('spaceid_bnb_registrations') }}` to reference the generated magic table. First, we count the number of records for the V7 version from the magic table. Then, we use `{{source('spaceid_bnb', 'BNBRegistrarControllerV7_evt_NameRegistered')}}` to query the number of records from the corresponding V7 event table. Finally, we check if the counts returned by these two CTEs are the same. If they are different, the test will return a single row result. A successful test should not return any results, while returning any records indicates test failure.

Reference document: [Writing Unit Tests for Your Spell](https://dune.com/docs/zh/spellbook/getting-started/tests/)

## Compilation and Debugging

After editing and saving the test file, use `dbt compile` again to compile it. Make any necessary adjustments to fix any errors and ensure successful compilation.

At this point, an important step is to manually test the compiled query code on Dune to verify its functionality.

When the compilation is successful, a `target` subdirectory will be generated in the `spellbook` directory. Navigate to the `compiled/spellbook/models/spaceid/bnb` subdirectory, where you will find the `spaceid_bnb_registrations.sql` file. This is the SQL definition of the view behind the magic table we are building. In the same directory, there is a `spaceid_bnb_schema.yml` subdirectory, which contains automatically generated tests based on the schema definition. We can ignore this part.

For manual testing, copying and running the entire content of the query file directly is not recommended due to the large amount of data. Instead, we can copy the contents of the query file into a CTE definition and then run queries that return only a small amount of data against that CTE.

``` sql
sqlCopy code
with view_registration as (
SELECT 'v3'                    as version,
       evt_block_time          as block_time,
       name,
       label,
       owner,
       cast(cost as double)    as cost,
       cast(expires as bigint) as expires,
       contract_address,
       evt_tx_hash             as tx_hash,
       evt_block_number        as block_number,
       evt_index
FROM spaceid_bnb.BNBRegistrarControllerV3_evt_NameRegistered

-- Omitted remaining code

)

select * from view_registration
limit 1000
```

Complete manual testing query: https://dune.com/queries/2020131

The main purpose of this step is to ensure that the compiled SQL statement can run correctly on Dune. You can modify the final output query statement for more manual testing.

## Submitting the PR

Now we have processed the new magic table and completed the local testing. We are ready to add and commit the newly created and modified code files to the Github repository and submit a PR to Dune.

First, add and commit the newly created and modified code files to the local git repository. Then push the local branch to the remote Github repository:

```
# Check and confirm the newly created and modified files and directories
git status

# Add all newly created and modified files for commit
git add .

# Commit to the local git repository
git commit -m 'Add spaceid view'

# Push the local branch to the remote Github repository
git push -u origin add_bnb_spaceid
```

The `-u origin add_bnb_spaceid` part in the push command is only needed for the first push. After the first push, if you make further modifications to the related files and commit them to the local git repository, the command for pushing to Github will be:

```
git push
```

Next, open the Github website and go to the `spellbook` repository under your personal account. You will see a notification indicating that a new branch `add_bnb_spaceid` has pushed the latest changes and a Pull Request (PR) can be created for it. Click the "Create PR" button to enter the PR creation page.

In this PR page, you need to edit and confirm the following content while ensuring that you have completed the corresponding checks and tests as guided in the documentation. The content editor supports Markdown syntax, and `[ ]` will output an unchecked checkbox, while `[x]` will output a checked checkbox. Adjust these options one by one to confirm that you have completed the corresponding steps and actions.

You also need to provide a brief description of the newly added or modified Spell in the PR, making it easier for reviewers to understand the changes.

![](img/ch22_image_03.jpg)

After submitting the PR, you need to wait for the review and feedback from relevant parties. Also, pay attention to email notifications from Github. Some notifications can be ignored, such as those about `dbt slim ci (in beta) / dbt-test`. The main focus should be on feedback from the reviewers. If there are modifications to be made, proceed to modify, test, commit the changes to the local git repository, and push to Github (the modifications will automatically appear under the existing PR without creating a new one). Then, wait for another round of review.

If all modifications pass the review smoothly, your PR will be merged into the spellbook main branch and deployed to the Dune production site. After deployment, you can search for and use the magic table you built in the query editor. Congratulations!

## Additional Notes and Special Thanks

Note: as of the time of writing this document, our PR is still under review and has not been approved yet. Further modifications may be made based on feedback. The PR number for reference is 2725, and you can check the details on the PR page.

PR Github link: [add BNB spaceid view](https://github.com/duneanalytics/spellbook/pull/2725)

Special thanks to community member @hosuke (Dune: https://dune.com/hosuke) for assisting with the PR review, providing feedback and improvement suggestions, and helping to modify the materialization strategy of the magic table.

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/ch23/ch23-how-to-build-app-use-dune-api.md">
# 23 Creating an Application Using Dune API

## Project Overview

On April 25th, Dune officially opened up API access to all user levels, including free users. Now, even free users can access the Dune API. This tutorial provides a demo that demonstrates how to develop an application around the Dune API.

The demo application is deployed here: [Watcher Demo](https://dev.lentics.xyz/).

The demo application was completed in early March but due to various reasons, the tutorial has been delayed until now. We apologize for the delay. The project code was collaboratively completed by our colleagues George, Ken, and Benny. We extend our thanks to them.

Please note that the above demo application may not work continuously due to API Key limitations. We recommend forking the project and deploying it yourself using your own API Key to further explore.

The user interface of the project is shown in the following image:

![](img/ch23_watcher01.jpg)

## Introduction to Dune API Usage

Dune API is executed and results are obtained based on the Query ID. Each saved Query can automatically be converted into an API access endpoint. In the latest version of the Query Editor interface, you simply need to write the query, test its functionality, save the query, and then click the "API Endpoint" button to obtain the API endpoint URL to access the query results.

```
https://api.dune.com/api/v1/query/2408388/results?api_key=<api_key>
```

This is the simplest way to access the result set of a saved query through the API.

![](img/ch23_watcher02.jpg)

The execution result of a Query is cached by default. If you do not actively execute the Query again, the API endpoint obtained above will provide the cached result of the last execution. Typically, our applications need to actively execute queries to obtain the latest data that meets the conditions, rather than repeatedly obtaining cached result sets. This is especially true for monitoring-type applications. Therefore, we also need to access the "Execute" endpoint to execute the query and the "Status" endpoint to check the status of query execution. After receiving the information that the query has been executed, we can access the "Results" endpoint to obtain the data.

A complete API call process includes executing the query, checking the query execution status, and obtaining the query results. Detailed explanations about Dune API can be found in the API documentation: [Dune API](https://dune.com/docs/api/api-reference/#latest-results-endpoint).

## Project Requirements

In order to demonstrate the complete process of developing a project using Dune API as comprehensively as possible, the following main requirements points have been organized.

The main function of this application is to provide a pure frontend application for monitoring the creation of new liquidity pools based on the Dune API, specifically for Uniswap V3. It uses a database to save the user's choice of monitored pool addresses and implements caching to avoid making API requests for exactly the same data.

The application includes three main functionalities:

1. **New Pools**
   
    Returns a list of newly created liquidity pools that meet the selected blockchain and date range criteria. When calling the API, the user selects the blockchain name (in all lowercase) and the date parameters (YYYY-MM-DD, converted to specific dates based on user choices).

1. **Latest Swaps**

    Displays the latest 100 swap exchange records for a pool selected from the pool list in a new interface. The user enters this interface by clicking the "Latest Swap" link next to a specific pool from the previous step. When calling the API, the user provides the blockchain name, pool address, and the current hour value (YYYY-MM-DD HH:MI:SS, converted to specific date and hour values, e.g. "2023-02-27 09:00:00"). The API call returns the results, which are displayed in a list format.

3. **Large Swap Alerts**

    Allows the user to input a pool address (prompting the user to copy it from the pool list), and set a threshold for large swaps (e.g.1000USD). The application then calls the API every 5 minutes and generates an on-site alert if there are swap records that meet the specified condition. The user can set the pool address to monitor and the minimum swap amount in USD (currently providing three choices: 1000, 10000, and 100000). If the API returns data, it will be added to the on-site alert. A red badge in the navigation bar will indicate the number of unread alerts, and clicking it will display the list. After clicking on a single alert, it will be marked as read.

## Development Environment Setup

``` bash
Copy code
yarn dev
```

For other commands, refer to the `readme.md` file in the project's source code.

## Development Overview

### Project Creation

The project is based on Next.js, using tailwindcss as the CSS framework, Axios as the fetcher, dexie for front-end data operations, and prisma for back-end data operations.

```
$ yarn create next-app
$ yarn add tailwindcss autoprefixer postcss prisma -D
$ yarn add axios dexie dexie-react-hooks @prisma/client
```

### Initialize Schema

``` bash
$ yarn prisma init --datasource-provider sqlite
$ vim prisma/schema.prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "sqlite"
  url      = env("DATABASE_URL")
}

model DuneQuery {
  id           String   @unique
  execution_id String
  createdAt    DateTime @default(now())
  updatedAt    DateTime @updatedAt
}

$ yarn prisma migrate dev --name init
$ yarn prisma generate
```

### Encapsulate API Calls

Add `lib/dune.ts` to encapsulate the three steps of executing the Dune API:

``` javascript
export const executeQuery = async (id: string, parameters: any) => {
  // Generate a hash for the current execution query key, check and get the corresponding execution_id from sqlite. Remember to handle cache expiration.
  // ...
};

export const executeStatus = async (id: string) => {
  // ...
};

export const executeResults = async (id: string) => {
  // ...
};
```

### Front-end Data Display

In the `pages` directory, add a recursive function to check if `data.result` node exists to use for recursive calls. Trigger it in the `useEffect`.

### Code Deployment

The deployment process is similar to a Next.js project. The initialization of the database is already placed in `package.json`:

``` json
"scripts": {
  "dev": "prisma generate && prisma migrate dev && next dev",
  "build": "prisma generate && prisma migrate deploy && next build",
  "start": "next start"
}
```

### Writing SQL Queries for API

API calls and their corresponding query information:

- New Pools: https://dune.com/queries/2056212
- Latest Swap: https://dune.com/queries/2056310
- Alerts: https://dune.com/queries/2056547

### Important Functionality Points

1. Dune API requires executing `Execute Query ID` to obtain its `execution_id` before performing `status/results`. Handle cache expiration properly.
2. The front-end needs to make recursive calls to the system API to retrieve results.

## Dune API Documentation

- Chinese Documentation: https://dune.com/docs/zh/api/
- Latest Version: https://dune.com/docs/api/

## Project Code Repository

The source code of the project is available here: [Uniswap New Pools Watcher](https://github.com/codingtalent/watcher)

## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)
</file>

<file path="en/eisvogel.tex">
%%
% Copyright (c) 2017 - 2023, Pascal Wagler;
% Copyright (c) 2014 - 2023, John MacFarlane
%
% All rights reserved.
%
% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions
% are met:
%
% - Redistributions of source code must retain the above copyright
% notice, this list of conditions and the following disclaimer.
%
% - Redistributions in binary form must reproduce the above copyright
% notice, this list of conditions and the following disclaimer in the
% documentation and/or other materials provided with the distribution.
%
% - Neither the name of John MacFarlane nor the names of other
% contributors may be used to endorse or promote products derived
% from this software without specific prior written permission.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
% "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
% LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
% FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
% COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
% INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
% BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
% LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
% CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
% LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
% ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
% POSSIBILITY OF SUCH DAMAGE.
%%

%%
% This is the Eisvogel pandoc LaTeX template.
%
% For usage information and examples visit the official GitHub page:
% https://github.com/Wandmalfarbe/pandoc-latex-template
%%

% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode$for(hyperrefoptions)$,$hyperrefoptions$$endfor$}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names,table}{xcolor}
$if(CJKmainfont)$
\PassOptionsToPackage{space}{xeCJK}
$endif$
%
\documentclass[
$if(fontsize)$
  $fontsize$,
$endif$
$if(papersize)$
  $papersize$paper,
$else$
  paper=a4,
$endif$
$if(beamer)$
  ignorenonframetext,
$if(handout)$
  handout,
$endif$
$if(aspectratio)$
  aspectratio=$aspectratio$,
$endif$
$endif$
$for(classoption)$
  $classoption$$sep$,
$endfor$
  ,captions=tableheading
]{$if(beamer)$$documentclass$$else$$if(book)$scrbook$else$scrartcl$endif$$endif$}
$if(beamer)$
$if(background-image)$
\usebackgroundtemplate{%
  \includegraphics[width=\paperwidth]{$background-image$}%
}
% In beamer background-image does not work well when other images are used, so this is the workaround
\pgfdeclareimage[width=\paperwidth,height=\paperheight]{background}{$background-image$}
\usebackgroundtemplate{\pgfuseimage{background}}
$endif$
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbols$if(navigation)$$navigation$$else$empty$endif$
$for(beameroption)$
\setbeameroption{$beameroption$}
$endfor$
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
$if(section-titles)$
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
$endif$
$endif$
$if(beamerarticle)$
\usepackage{beamerarticle} % needs to be loaded first
$endif$
\usepackage{amsmath,amssymb}
$if(linestretch)$
\usepackage{setspace}
$else$
% Use setspace anyway because we change the default line spacing.
% The spacing is changed early to affect the titlepage and the TOC.
\usepackage{setspace}
\setstretch{1.2}
$endif$
\usepackage{iftex}
\ifPDFTeX
  \usepackage[$if(fontenc)$$fontenc$$else$T1$endif$]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
$if(mathspec)$
  \ifXeTeX
    \usepackage{mathspec} % this also loads fontspec
  \else
    \usepackage{unicode-math} % this also loads fontspec
  \fi
$else$
  \usepackage{unicode-math} % this also loads fontspec
$endif$
  \defaultfontfeatures{Scale=MatchLowercase}$-- must come before Beamer theme
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
$if(fontfamily)$
$else$
$-- Set default font before Beamer theme so the theme can override it
\usepackage{lmodern}
$endif$
$-- Set Beamer theme before user font settings so they can override theme
$if(beamer)$
$if(theme)$
\usetheme[$for(themeoptions)$$themeoptions$$sep$,$endfor$]{$theme$}
$endif$
$if(colortheme)$
\usecolortheme{$colortheme$}
$endif$
$if(fonttheme)$
\usefonttheme{$fonttheme$}
$endif$
$if(mainfont)$
\usefonttheme{serif} % use mainfont rather than sansfont for slide text
$endif$
$if(innertheme)$
\useinnertheme{$innertheme$}
$endif$
$if(outertheme)$
\useoutertheme{$outertheme$}
$endif$
$endif$
$-- User font settings (must come after default font and Beamer theme)
$if(fontfamily)$
\usepackage[$for(fontfamilyoptions)$$fontfamilyoptions$$sep$,$endfor$]{$fontfamily$}
$endif$
\ifPDFTeX\else
  % xetex/luatex font selection
$if(mainfont)$
  \setmainfont[$for(mainfontoptions)$$mainfontoptions$$sep$,$endfor$]{$mainfont$}
$endif$
$if(sansfont)$
  \setsansfont[$for(sansfontoptions)$$sansfontoptions$$sep$,$endfor$]{$sansfont$}
$endif$
$if(monofont)$
  \setmonofont[$for(monofontoptions)$$monofontoptions$$sep$,$endfor$]{$monofont$}
$endif$
$for(fontfamilies)$
  \newfontfamily{$fontfamilies.name$}[$for(fontfamilies.options)$$fontfamilies.options$$sep$,$endfor$]{$fontfamilies.font$}
$endfor$
$if(mathfont)$
$if(mathspec)$
  \ifXeTeX
    \setmathfont(Digits,Latin,Greek)[$for(mathfontoptions)$$mathfontoptions$$sep$,$endfor$]{$mathfont$}
  \else
    \setmathfont[$for(mathfontoptions)$$mathfontoptions$$sep$,$endfor$]{$mathfont$}
  \fi
$else$
  \setmathfont[$for(mathfontoptions)$$mathfontoptions$$sep$,$endfor$]{$mathfont$}
$endif$
$endif$
$if(CJKmainfont)$
  \ifXeTeX
    \usepackage{xeCJK}
    \setCJKmainfont[$for(CJKoptions)$$CJKoptions$$sep$,$endfor$]{$CJKmainfont$}
    $if(CJKsansfont)$
      \setCJKsansfont[$for(CJKoptions)$$CJKoptions$$sep$,$endfor$]{$CJKsansfont$}
    $endif$
    $if(CJKmonofont)$
      \setCJKmonofont[$for(CJKoptions)$$CJKoptions$$sep$,$endfor$]{$CJKmonofont$}
    $endif$
  \fi
$endif$
$if(luatexjapresetoptions)$
  \ifLuaTeX
    \usepackage[$for(luatexjapresetoptions)$$luatexjapresetoptions$$sep$,$endfor$]{luatexja-preset}
  \fi
$endif$
$if(CJKmainfont)$
  \ifLuaTeX
    \usepackage[$for(luatexjafontspecoptions)$$luatexjafontspecoptions$$sep$,$endfor$]{luatexja-fontspec}
    \setmainjfont[$for(CJKoptions)$$CJKoptions$$sep$,$endfor$]{$CJKmainfont$}
  \fi
$endif$
\fi
$if(zero-width-non-joiner)$
%% Support for zero-width non-joiner characters.
\makeatletter
\def\zerowidthnonjoiner{%
  % Prevent ligatures and adjust kerning, but still support hyphenating.
  \texorpdfstring{%
    \TextOrMath{\nobreak\discretionary{-}{}{\kern.03em}%
      \ifvmode\else\nobreak\hskip\z@skip\fi}{}%
  }{}%
}
\makeatother
\ifPDFTeX
  \DeclareUnicodeCharacter{200C}{\zerowidthnonjoiner}
\else
  \catcode`^^^^200c=\active
  \protected\def ^^^^200c{\zerowidthnonjoiner}
\fi
%% End of ZWNJ support
$endif$
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[$for(microtypeoptions)$$microtypeoptions$$sep$,$endfor$]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
$if(indent)$
$else$
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
$endif$
$if(verbatim-in-note)$
\usepackage{fancyvrb}
$endif$
\usepackage{xcolor}
\definecolor{default-linkcolor}{HTML}{A50000}
\definecolor{default-filecolor}{HTML}{A50000}
\definecolor{default-citecolor}{HTML}{4077C0}
\definecolor{default-urlcolor}{HTML}{4077C0}
$if(footnotes-pretty)$
% load footmisc in order to customize footnotes (footmisc has to be loaded before hyperref, cf. https://tex.stackexchange.com/a/169124/144087)
\usepackage[hang,flushmargin,bottom,multiple]{footmisc}
\setlength{\footnotemargin}{0.8em} % set space between footnote nr and text
\setlength{\footnotesep}{\baselineskip} % set space between multiple footnotes
\setlength{\skip\footins}{0.3cm} % set space between page content and footnote
\setlength{\footskip}{0.9cm} % set space between footnote and page bottom
$endif$
$if(geometry)$
$if(beamer)$
\geometry{$for(geometry)$$geometry$$sep$,$endfor$}
$else$
\usepackage[$for(geometry)$$geometry$$sep$,$endfor$]{geometry}
$endif$
$else$
$if(beamer)$
$else$
\usepackage[margin=2.5cm,includehead=true,includefoot=true,centering,$for(geometry)$$geometry$$sep$,$endfor$]{geometry}
$endif$
$endif$
$if(titlepage-logo)$
\usepackage[export]{adjustbox}
\usepackage{graphicx}
$endif$
$if(beamer)$
\newif\ifbibliography
$endif$
$if(listings)$
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstset{defaultdialect=[5.3]Lua}
\lstset{defaultdialect=[x86masm]Assembler}
$endif$
$if(listings-no-page-break)$
\usepackage{etoolbox}
\BeforeBeginEnvironment{lstlisting}{\par\noindent\begin{minipage}{\linewidth}}
\AfterEndEnvironment{lstlisting}{\end{minipage}\par\addvspace{\topskip}}
$endif$
$if(lhs)$
\lstnewenvironment{code}{\lstset{language=Haskell,basicstyle=\small\ttfamily}}{}
$endif$
$if(highlighting-macros)$
$highlighting-macros$

% Workaround/bugfix from jannick0.
% See https://github.com/jgm/pandoc/issues/4302#issuecomment-360669013)
% or https://github.com/Wandmalfarbe/pandoc-latex-template/issues/2
%
% Redefine the verbatim environment 'Highlighting' to break long lines (with
% the help of fvextra). Redefinition is necessary because it is unlikely that
% pandoc includes fvextra in the default template.
\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,fontsize=$if(code-block-font-size)$$code-block-font-size$$else$\small$endif$,commandchars=\\\{\}}

$endif$
$if(tables)$
\usepackage{longtable,booktabs,array}
$if(multirow)$
\usepackage{multirow}
$endif$
\usepackage{calc} % for calculating minipage widths
$if(beamer)$
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
$else$
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
$endif$
$endif$
% add backlinks to footnote references, cf. https://tex.stackexchange.com/questions/302266/make-footnote-clickable-both-ways
$if(footnotes-disable-backlinks)$
$else$
\usepackage{footnotebackref}
$endif$
$if(graphics)$
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
% Make use of float-package and set default placement for figures to H.
% The option H means 'PUT IT HERE' (as  opposed to the standard h option which means 'You may put it here if you like').
\usepackage{float}
\floatplacement{figure}{$if(float-placement-figure)$$float-placement-figure$$else$H$endif$}
\makeatother
$endif$
$if(svg)$
\usepackage{svg}
$endif$
$if(strikeout)$
$-- also used for underline
\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
\usepackage{soul}
\fi
$endif$
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
$if(numbersections)$
\setcounter{secnumdepth}{$if(secnumdepth)$$secnumdepth$$else$5$endif$}
$else$
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
$endif$
$if(subfigure)$
\usepackage{subcaption}
$endif$
$if(beamer)$
$else$
$if(block-headings)$
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
$endif$
$endif$
$if(pagestyle)$
\pagestyle{$pagestyle$}
$endif$
$if(csl-refs)$
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
$endif$
$if(lang)$
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
$if(babel-lang)$
\babelprovide[main,import]{$babel-lang$}
$if(mainfont)$
\ifPDFTeX
\else
\babelfont{rm}[$for(mainfontoptions)$$mainfontoptions$$sep$,$endfor$]{$mainfont$}
\fi
$endif$
$endif$
$for(babel-otherlangs)$
\babelprovide[import]{$babel-otherlangs$}
$endfor$
$for(babelfonts/pairs)$
\babelfont[$babelfonts.key$]{rm}{$babelfonts.value$}
$endfor$
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
$endif$
$for(header-includes)$
$header-includes$
$endfor$
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
$if(dir)$
\ifPDFTeX
  \TeXXeTstate=1
  \newcommand{\RL}[1]{\beginR #1\endR}
  \newcommand{\LR}[1]{\beginL #1\endL}
  \newenvironment{RTL}{\beginR}{\endR}
  \newenvironment{LTR}{\beginL}{\endL}
\fi
$endif$
$if(natbib)$
\usepackage[$natbiboptions$]{natbib}
\bibliographystyle{$if(biblio-style)$$biblio-style$$else$plainnat$endif$}
$endif$
$if(biblatex)$
\usepackage[$if(biblio-style)$style=$biblio-style$,$endif$$for(biblatexoptions)$$biblatexoptions$$sep$,$endfor$]{biblatex}
$for(bibliography)$
\addbibresource{$bibliography$}
$endfor$
$endif$
$if(nocite-ids)$
\nocite{$for(nocite-ids)$$it$$sep$, $endfor$}
$endif$
$if(csquotes)$
\usepackage{csquotes}
$endif$
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{$if(urlstyle)$$urlstyle$$else$same$endif$}
$if(links-as-notes)$
% Make links footnotes instead of hotlinks:
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
$endif$
$if(verbatim-in-note)$
\VerbatimFootnotes % allow verbatim text in footnotes
$endif$
\hypersetup{
$if(title-meta)$
  pdftitle={$title-meta$},
$endif$
$if(author-meta)$
  pdfauthor={$author-meta$},
$endif$
$if(lang)$
  pdflang={$lang$},
$endif$
$if(subject)$
  pdfsubject={$subject$},
$endif$
$if(keywords)$
  pdfkeywords={$for(keywords)$$keywords$$sep$, $endfor$},
$endif$
$if(colorlinks)$
  colorlinks=true,
  linkcolor={$if(linkcolor)$$linkcolor$$else$default-linkcolor$endif$},
  filecolor={$if(filecolor)$$filecolor$$else$default-filecolor$endif$},
  citecolor={$if(citecolor)$$citecolor$$else$default-citecolor$endif$},
  urlcolor={$if(urlcolor)$$urlcolor$$else$default-urlcolor$endif$},
$else$
  hidelinks,
$endif$
  breaklinks=true,
  pdfcreator={LaTeX via pandoc with the Eisvogel template}}
$if(title)$
\title{$title$$if(thanks)$\thanks{$thanks$}$endif$}
$endif$
$if(subtitle)$
$if(beamer)$
$else$
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
$endif$
\subtitle{$subtitle$}
$endif$
\author{$for(author)$$author$$sep$ \and $endfor$}
\date{$date$}
$if(beamer)$
$if(institute)$
\institute{$for(institute)$$institute$$sep$ \and $endfor$}
$endif$
$if(titlegraphic)$
\titlegraphic{\includegraphics{$titlegraphic$}}
$endif$
$if(logo)$
\logo{\includegraphics{$logo$}}
$endif$
$endif$



%%
%% added
%%

$if(page-background)$
\usepackage[pages=all]{background}
$endif$

%
% for the background color of the title page
%
$if(titlepage)$
\usepackage{pagecolor}
\usepackage{afterpage}
$if(titlepage-background)$
\usepackage{tikz}
$endif$
$if(geometry)$
$else$
\usepackage[margin=2.5cm,includehead=true,includefoot=true,centering]{geometry}
$endif$
$endif$

%
% break urls
%
\PassOptionsToPackage{hyphens}{url}

%
% When using babel or polyglossia with biblatex, loading csquotes is recommended
% to ensure that quoted texts are typeset according to the rules of your main language.
%
\usepackage{csquotes}

%
% captions
%
\definecolor{caption-color}{HTML}{777777}
$if(beamer)$
$else$
\usepackage[font={stretch=1.2}, textfont={color=caption-color}, position=top, skip=4mm, labelfont=bf, singlelinecheck=false, justification=$if(caption-justification)$$caption-justification$$else$raggedright$endif$]{caption}
\setcapindent{0em}
$endif$

%
% blockquote
%
\definecolor{blockquote-border}{RGB}{221,221,221}
\definecolor{blockquote-text}{RGB}{119,119,119}
\usepackage{mdframed}
\newmdenv[rightline=false,bottomline=false,topline=false,linewidth=3pt,linecolor=blockquote-border,skipabove=\parskip]{customblockquote}
\renewenvironment{quote}{\begin{customblockquote}\list{}{\rightmargin=0em\leftmargin=0em}%
\item\relax\color{blockquote-text}\ignorespaces}{\unskip\unskip\endlist\end{customblockquote}}

%
% Source Sans Pro as the default font family
% Source Code Pro for monospace text
%
% 'default' option sets the default
% font family to Source Sans Pro, not \sfdefault.
%
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  $if(fontfamily)$
  $else$
  \usepackage[default]{sourcesanspro}
  \usepackage{sourcecodepro}
  $endif$
\else % if not pdftex
  $if(mainfont)$
  $else$
  \usepackage[default]{sourcesanspro}
  \usepackage{sourcecodepro}

  % XeLaTeX specific adjustments for straight quotes: https://tex.stackexchange.com/a/354887
  % This issue is already fixed (see https://github.com/silkeh/latex-sourcecodepro/pull/5) but the
  % fix is still unreleased.
  % TODO: Remove this workaround when the new version of sourcecodepro is released on CTAN.
  \ifxetex
    \makeatletter
    \defaultfontfeatures[\ttfamily]
      { Numbers   = \sourcecodepro@figurestyle,
        Scale     = \SourceCodePro@scale,
        Extension = .otf }
    \setmonofont
      [ UprightFont    = *-\sourcecodepro@regstyle,
        ItalicFont     = *-\sourcecodepro@regstyle It,
        BoldFont       = *-\sourcecodepro@boldstyle,
        BoldItalicFont = *-\sourcecodepro@boldstyle It ]
      {SourceCodePro}
    \makeatother
  \fi
  $endif$
\fi

%
% heading color
%
\definecolor{heading-color}{RGB}{40,40,40}
$if(beamer)$
$else$
\addtokomafont{section}{\color{heading-color}}
$endif$
% When using the classes report, scrreprt, book,
% scrbook or memoir, uncomment the following line.
%\addtokomafont{chapter}{\color{heading-color}}

%
% variables for title, author and date
%
$if(beamer)$
$else$
\usepackage{titling}
\title{$title$}
\author{$for(author)$$author$$sep$, $endfor$}
\date{$date$}
$endif$

%
% tables
%
$if(tables)$

\definecolor{table-row-color}{HTML}{F5F5F5}
\definecolor{table-rule-color}{HTML}{999999}

%\arrayrulecolor{black!40}
\arrayrulecolor{table-rule-color}     % color of \toprule, \midrule, \bottomrule
\setlength\heavyrulewidth{0.3ex}      % thickness of \toprule, \bottomrule
\renewcommand{\arraystretch}{1.3}     % spacing (padding)

$if(table-use-row-colors)$
% TODO: This doesn't work anymore. I don't know why.
% Reset rownum counter so that each table
% starts with the same row colors.
% https://tex.stackexchange.com/questions/170637/restarting-rowcolors
%
% Unfortunately the colored cells extend beyond the edge of the
% table because pandoc uses @-expressions (@{}) like so:
%
% \begin{longtable}[]{@{}ll@{}}
% \end{longtable}
%
% https://en.wikibooks.org/wiki/LaTeX/Tables#.40-expressions
\let\oldlongtable\longtable
\let\endoldlongtable\endlongtable
\renewenvironment{longtable}{
\rowcolors{3}{}{table-row-color!100}  % row color
\oldlongtable} {
\endoldlongtable
\global\rownum=0\relax}
$endif$
$endif$

%
% remove paragraph indention
%
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines

%
%
% Listings
%
%

$if(listings)$

%
% general listing colors
%
\definecolor{listing-background}{HTML}{F7F7F7}
\definecolor{listing-rule}{HTML}{B3B2B3}
\definecolor{listing-numbers}{HTML}{B3B2B3}
\definecolor{listing-text-color}{HTML}{000000}
\definecolor{listing-keyword}{HTML}{435489}
\definecolor{listing-keyword-2}{HTML}{1284CA} % additional keywords
\definecolor{listing-keyword-3}{HTML}{9137CB} % additional keywords
\definecolor{listing-identifier}{HTML}{435489}
\definecolor{listing-string}{HTML}{00999A}
\definecolor{listing-comment}{HTML}{8E8E8E}

\lstdefinestyle{eisvogel_listing_style}{
  language         = java,
$if(listings-disable-line-numbers)$
  xleftmargin      = 0.6em,
  framexleftmargin = 0.4em,
$else$
  numbers          = left,
  xleftmargin      = 2.7em,
  framexleftmargin = 2.5em,
$endif$
  backgroundcolor  = \color{listing-background},
  basicstyle       = \color{listing-text-color}\linespread{1.0}%
                      \lst@ifdisplaystyle%
                      $if(code-block-font-size)$$code-block-font-size$$else$\small$endif$%
                      \fi\ttfamily{},
  breaklines       = true,
  frame            = single,
  framesep         = 0.19em,
  rulecolor        = \color{listing-rule},
  frameround       = ffff,
  tabsize          = 4,
  numberstyle      = \color{listing-numbers},
  aboveskip        = 1.0em,
  belowskip        = 0.1em,
  abovecaptionskip = 0em,
  belowcaptionskip = 1.0em,
  keywordstyle     = {\color{listing-keyword}\bfseries},
  keywordstyle     = {[2]\color{listing-keyword-2}\bfseries},
  keywordstyle     = {[3]\color{listing-keyword-3}\bfseries\itshape},
  sensitive        = true,
  identifierstyle  = \color{listing-identifier},
  commentstyle     = \color{listing-comment},
  stringstyle      = \color{listing-string},
  showstringspaces = false,
  escapeinside     = {/*@}{@*/}, % Allow LaTeX inside these special comments
  literate         =
  {√°}{{\'a}}1 {√©}{{\'e}}1 {√≠}{{\'i}}1 {√≥}{{\'o}}1 {√∫}{{\'u}}1
  {√Å}{{\'A}}1 {√â}{{\'E}}1 {√ç}{{\'I}}1 {√ì}{{\'O}}1 {√ö}{{\'U}}1
  {√†}{{\`a}}1 {√®}{{\`e}}1 {√¨}{{\`i}}1 {√≤}{{\`o}}1 {√π}{{\`u}}1
  {√Ä}{{\`A}}1 {√à}{{\`E}}1 {√å}{{\`I}}1 {√í}{{\`O}}1 {√ô}{{\`U}}1
  {√§}{{\"a}}1 {√´}{{\"e}}1 {√Ø}{{\"i}}1 {√∂}{{\"o}}1 {√º}{{\"u}}1
  {√Ñ}{{\"A}}1 {√ã}{{\"E}}1 {√è}{{\"I}}1 {√ñ}{{\"O}}1 {√ú}{{\"U}}1
  {√¢}{{\^a}}1 {√™}{{\^e}}1 {√Æ}{{\^i}}1 {√¥}{{\^o}}1 {√ª}{{\^u}}1
  {√Ç}{{\^A}}1 {√ä}{{\^E}}1 {√é}{{\^I}}1 {√î}{{\^O}}1 {√õ}{{\^U}}1
  {≈ì}{{\oe}}1 {≈í}{{\OE}}1 {√¶}{{\ae}}1 {√Ü}{{\AE}}1 {√ü}{{\ss}}1
  {√ß}{{\c c}}1 {√á}{{\c C}}1 {√∏}{{\o}}1 {√•}{{\r a}}1 {√Ö}{{\r A}}1
  {‚Ç¨}{{\EUR}}1 {¬£}{{\pounds}}1 {¬´}{{\guillemotleft}}1
  {¬ª}{{\guillemotright}}1 {√±}{{\~n}}1 {√ë}{{\~N}}1 {¬ø}{{?`}}1
  {‚Ä¶}{{\ldots}}1 {‚â•}{{>=}}1 {‚â§}{{<=}}1 {‚Äû}{{\glqq}}1 {‚Äú}{{\grqq}}1
  {‚Äù}{{''}}1
}
\lstset{style=eisvogel_listing_style}

%
% Java (Java SE 12, 2019-06-22)
%
\lstdefinelanguage{Java}{
  morekeywords={
    % normal keywords (without data types)
    abstract,assert,break,case,catch,class,continue,default,
    do,else,enum,exports,extends,final,finally,for,if,implements,
    import,instanceof,interface,module,native,new,package,private,
    protected,public,requires,return,static,strictfp,super,switch,
    synchronized,this,throw,throws,transient,try,volatile,while,
    % var is an identifier
    var
  },
  morekeywords={[2] % data types
    % primitive data types
    boolean,byte,char,double,float,int,long,short,
    % String
    String,
    % primitive wrapper types
    Boolean,Byte,Character,Double,Float,Integer,Long,Short
    % number types
    Number,AtomicInteger,AtomicLong,BigDecimal,BigInteger,DoubleAccumulator,DoubleAdder,LongAccumulator,LongAdder,Short,
    % other
    Object,Void,void
  },
  morekeywords={[3] % literals
    % reserved words for literal values
    null,true,false,
  },
  sensitive,
  morecomment  = [l]//,
  morecomment  = [s]{/*}{*/},
  morecomment  = [s]{/**}{*/},
  morestring   = [b]",
  morestring   = [b]',
}

\lstdefinelanguage{XML}{
  morestring      = [b]",
  moredelim       = [s][\bfseries\color{listing-keyword}]{<}{\ },
  moredelim       = [s][\bfseries\color{listing-keyword}]{</}{>},
  moredelim       = [l][\bfseries\color{listing-keyword}]{/>},
  moredelim       = [l][\bfseries\color{listing-keyword}]{>},
  morecomment     = [s]{<?}{?>},
  morecomment     = [s]{<!--}{-->},
  commentstyle    = \color{listing-comment},
  stringstyle     = \color{listing-string},
  identifierstyle = \color{listing-identifier}
}
$endif$

%
% header and footer
%
$if(beamer)$
$else$
$if(disable-header-and-footer)$
$else$
\usepackage[headsepline,footsepline]{scrlayer-scrpage}

\newpairofpagestyles{eisvogel-header-footer}{
  \clearpairofpagestyles
  \ihead*{$if(header-left)$$header-left$$else$$title$$endif$}
  \chead*{$if(header-center)$$header-center$$else$$endif$}
  \ohead*{$if(header-right)$$header-right$$else$$date$$endif$}
  \ifoot*{$if(footer-left)$$footer-left$$else$$for(author)$$author$$sep$, $endfor$$endif$}
  \cfoot*{$if(footer-center)$$footer-center$$else$$endif$}
  \ofoot*{$if(footer-right)$$footer-right$$else$\thepage$endif$}
  \addtokomafont{pageheadfoot}{\upshape}
}
\pagestyle{eisvogel-header-footer}

$if(book)$
\deftripstyle{ChapterStyle}{}{}{}{}{\pagemark}{}
\renewcommand*{\chapterpagestyle}{ChapterStyle}
$endif$

$if(page-background)$
\backgroundsetup{
scale=1,
color=black,
opacity=$if(page-background-opacity)$$page-background-opacity$$else$0.2$endif$,
angle=0,
contents={%
  \includegraphics[width=\paperwidth,height=\paperheight]{$page-background$}
  }%
}
$endif$
$endif$
$endif$

%%
%% end added
%%

\begin{document}

%%
%% begin titlepage
%%
$if(beamer)$
$else$
$if(titlepage)$
\begin{titlepage}
$if(titlepage-background)$
\newgeometry{top=2cm, right=4cm, bottom=3cm, left=4cm}
$else$
\newgeometry{left=6cm}
$endif$
$if(titlepage-color)$
\definecolor{titlepage-color}{HTML}{$titlepage-color$}
\newpagecolor{titlepage-color}\afterpage{\restorepagecolor}
$endif$
$if(titlepage-background)$
\tikz[remember picture,overlay] \node[inner sep=0pt] at (current page.center){\includegraphics[width=\paperwidth,height=\paperheight]{$titlepage-background$}};
$endif$
\newcommand{\colorRule}[3][black]{\textcolor[HTML]{#1}{\rule{#2}{#3}}}
\begin{flushleft}
\noindent
\\[-1em]
\color[HTML]{$if(titlepage-text-color)$$titlepage-text-color$$else$5F5F5F$endif$}
\makebox[0pt][l]{\colorRule[$if(titlepage-rule-color)$$titlepage-rule-color$$else$435488$endif$]{0\textwidth}{$if(titlepage-rule-height)$$titlepage-rule-height$$else$0$endif$pt}}
\par
\noindent

$if(titlepage-background)$
% The titlepage with a background image has other text spacing and text size
{
  \setstretch{2}
  \vfill
  \vskip -8em
  \noindent {\huge \textbf{\textsf{$title$}}}
  $if(subtitle)$
  \vskip 1em
  {\Large \textsf{$subtitle$}}
  $endif$
  \vskip 2em
  \noindent {\Large \textsf{$for(author)$$author$$sep$, $endfor$} \vskip 0.6em \textsf{$date$}}
  \vfill
}
$else$
{
  \setstretch{1.4}
  \vfill
  \noindent {\huge \textbf{\textsf{$title$}}}
  $if(subtitle)$
  \vskip 1em
  {\Large \textsf{$subtitle$}}
  $endif$
  \vskip 2em
  \noindent {\Large \textsf{$for(author)$$author$$sep$, $endfor$}}
  \vfill
}
$endif$

$if(titlepage-logo)$
\noindent
\includegraphics[width=$if(logo-width)$$logo-width$$else$35mm$endif$, left]{$titlepage-logo$}
$endif$

$if(titlepage-background)$
$else$
\textsf{$date$}
$endif$
\end{flushleft}
\end{titlepage}
\restoregeometry
\pagenumbering{arabic} 
$endif$
$endif$

%%
%% end titlepage
%%

$if(has-frontmatter)$
\frontmatter
$endif$
$if(title)$
$if(beamer)$
\frame{\titlepage}
% don't generate the default title
% $else$
% \maketitle
$endif$
$if(abstract)$
\begin{abstract}
$abstract$
\end{abstract}
$endif$
$endif$

$if(first-chapter)$
\setcounter{chapter}{$first-chapter$}
\addtocounter{chapter}{-1}
$endif$

$for(include-before)$
$include-before$

$endfor$
$if(toc)$
$if(toc-title)$
\renewcommand*\contentsname{$toc-title$}
$endif$
$if(beamer)$
\begin{frame}[allowframebreaks]
$if(toc-title)$
  \frametitle{$toc-title$}
$endif$
  \tableofcontents[hideallsubsections]
\end{frame}
$if(toc-own-page)$
\newpage
$endif$
$else$
{
$if(colorlinks)$
\hypersetup{linkcolor=$if(toccolor)$$toccolor$$else$$endif$}
$endif$
\setcounter{tocdepth}{$toc-depth$}
\tableofcontents
$if(toc-own-page)$
\newpage
$endif$
}
$endif$
$endif$
$if(lof)$
\listoffigures
$endif$
$if(lot)$
\listoftables
$endif$
$if(linestretch)$
\setstretch{$linestretch$}
$endif$
$if(has-frontmatter)$
\mainmatter
$endif$
$body$

$if(has-frontmatter)$
\backmatter
$endif$
$if(natbib)$
$if(bibliography)$
$if(biblio-title)$
$if(has-chapters)$
\renewcommand\bibname{$biblio-title$}
$else$
\renewcommand\refname{$biblio-title$}
$endif$
$endif$
$if(beamer)$
\begin{frame}[allowframebreaks]{$biblio-title$}
  \bibliographytrue
$endif$
  \bibliography{$for(bibliography)$$bibliography$$sep$,$endfor$}
$if(beamer)$
\end{frame}
$endif$

$endif$
$endif$
$if(biblatex)$
$if(beamer)$
\begin{frame}[allowframebreaks]{$biblio-title$}
  \bibliographytrue
  \printbibliography[heading=none]
\end{frame}
$else$
\printbibliography$if(biblio-title)$[title=$biblio-title$]$endif$
$endif$

$endif$
$for(include-after)$
$include-after$

$endfor$
\end{document}
</file>

<file path="en/pandock-build-pdf.sh">
# /bin/sh

# requirements: 
# 1. docker pull pandoc/extra

sudo docker run --rm \
       --volume "$(pwd):/data" \
       --user $(id -u):$(id -g) \
       pandoc/extra \
--template 'eisvogel.tex' --listings \
--table-of-contents \
--variable colorlinks:yes \
-o books/MasteringOnchainAnalytics.pdf \
    --resource-path ch00 \
    --resource-path ch01 \
    --resource-path ch02 \
    --resource-path ch03 \
    --resource-path ch04 \
    --resource-path ch05 \
    --resource-path ch06 \
    --resource-path ch07 \
    --resource-path ch08 \
    --resource-path ch09 \
    --resource-path ch10 \
    --resource-path ch11 \
    --resource-path ch12 \
    --resource-path ch13 \
    --resource-path ch14 \
    --resource-path ch15 \
    --resource-path ch16 \
    --resource-path ch17 \
    --resource-path ch18 \
    --resource-path ch19 \
    --resource-path ch20 \
    --resource-path ch21 \
    --resource-path ch22 \
    --resource-path ch23 \
ch00/ch00-become-chain-analyst.md \
ch01/ch01-dune-platform-introduction.md \
ch02/ch02-quickstart.md \
ch03/ch03-build-first-dashboard.md \
ch04/ch04-understanding-tables.md \
ch05/ch05-sql-basics-part1.md \
ch06/ch06-sql-basics-part2.md \
ch07/ch07-practice-build-lens-dashboard-part1.md \
ch08/ch08-practice-build-lens-dashboard-part2.md \
ch09/ch09-useful-queries-part1.md \
ch10/ch10-useful-queries-part2.md \
ch11/ch11-useful-queries-part3.md \
ch12/ch12-nft-analysis.md \
ch13/ch13-lending-analysis.md \
ch14/ch14-defi-analysis.md \
ch15/ch15-dunesql-introduction.md \
ch16/ch16-blockchain-analysis-polygon.md \
ch17/ch17-mev-analysis-uniswap.md \
ch18/ch18-uniswap-multichain-analysis.md \
ch19/ch19-useful-metrics.md \
ch20/ch20-network-analysis.md \
ch21/ch21-btc-analysis.md \
ch22/ch22-how-to-build-spellbook.md \
ch23/ch23-how-to-build-app-use-dune-api.md
</file>

<file path="en/readme.md">
<p align="center">
  <img src="assets/bookcover-en.png" alt="book" width="60%"/>
</p>

This is a series tutorials for blockchain analysis enthusiasts, helping new users learn blockchain data analysis from scratch and become an onchain data analyst master.

- English Version: [Mastering Onchain Analytics](https://tutorial.sixdegree.xyz)
- Chinese Version: [Á≤æÈÄöÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê](https://tutorial.sixdegree.xyz/v/zh/)


> Join & contribute: [https://github.com/SixdegreeLab/MasteringChainAnalytics](https://github.com/SixdegreeLab/MasteringChainAnalytics)


## Table of contents

- **Introduction**
  - [Introduction](readme.md)
  - [#0 become onchain analyst](ch00/ch00-become-chain-analyst.md)
- **Elementary**
  - [#1 dune platform introduction](ch01/ch01-dune-platform-introduction.md)
  - [#2 quickstart](ch02/ch02-quickstart.md)
  - [#3 build first dashboard](ch03/ch03-build-first-dashboard.md)
  - [#4 understanding tables](ch04/ch04-understanding-tables.md)
  - [#5 sql basics part1](ch05/ch05-sql-basics-part1.md)
  - [#6 sql basics part2](ch06/ch06-sql-basics-part2.md)
  - [#7 practice build lens dashboard part1](ch07/ch07-practice-build-lens-dashboard-part1.md)
  - [#8 practice build lens dashboard part2](ch08/ch08-practice-build-lens-dashboard-part2.md)
- **Intermediate**
  - [#9 useful queries part1](ch09/ch09-useful-queries-part1.md)
  - [#10 useful queries part2](ch10/ch10-useful-queries-part2.md)
  - [#11 useful queries part3](ch11/ch11-useful-queries-part3.md)
  - [#12 nft analysis](ch12/ch12-nft-analysis.md)
  - [#13 lending analysis](ch13/ch13-lending-analysis.md)
  - [#14 defi analysis](ch14/ch14-defi-analysis.md)
  - [#15 dunesql introduction](ch15/ch15-dunesql-introduction.md)
  - [#16 blockchain analysis polygon](ch16/ch16-blockchain-analysis-polygon.md)
  - [#17 mev analysis uniswap](ch17/ch17-mev-analysis-uniswap.md)
  - [#18 uniswap multichain analysis](ch18/ch18-uniswap-multichain-analysis.md)
  - [#19 useful metrics](ch19/ch19-useful-metrics.md)
- **Advanced**
  - [#20 network analysis](ch20/ch20-network-analysis.md)
  - [#21 btc analysis](ch21/ch21-btc-analysis.md)
  - [#22 how to build spellbook](ch22/ch22-how-to-build-spellbook.md)
  - [#23 how to build app use dune api](ch23/ch23-how-to-build-app-use-dune-api.md)


## About Us

`Sixdegree` is a professional onchain data analysis team Our mission is to provide users with accurate onchain data charts, analysis, and insights. We are committed to popularizing onchain data analysis. By building a community and writing tutorials, among other initiatives, we train onchain data analysts, output valuable analysis content, promote the community to build the data layer of the blockchain, and cultivate talents for the broad future of blockchain data applications. Welcome to the community exchange!

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)

## Acknowledgements

**Sponsor**

This book is sponsored by the following institutions, really appreciate their strong support when writing this book.

- [Ethereum Fundation](https://ethereum.foundation/)
- [Dune Analytics](https://dune.com/)

**Contributors**

At the same time, there are many contributors to participate in this book. Thank you very much for your hard work.

- george-taotaome, chenxsan, Brendan, ËÇñÂÆÅ, g.c., ken, shell, yueyan, wodeche,Winkey
</file>

<file path="en/SUMMARY.md">
## Introduction
- [Introduction](readme.md)
- [#0 Become onchain analyst](ch00/ch00-become-chain-analyst.md)

## Elementary

- [#1 Dune platform introduction](ch01/ch01-dune-platform-introduction.md)
- [#2 Quick start](ch02/ch02-quickstart.md)
- [#3 Build first dashboard](ch03/ch03-build-first-dashboard.md)
- [#4 Understanding tables](ch04/ch04-understanding-tables.md)
- [#5 SQL basics part1](ch05/ch05-sql-basics-part1.md)
- [#6 SQL basics part2](ch06/ch06-sql-basics-part2.md)
- [#7 Practice - build lens dashboard part1](ch07/ch07-practice-build-lens-dashboard-part1.md)
- [#8 Practice - build lens dashboard part2](ch08/ch08-practice-build-lens-dashboard-part2.md)

## Intermediate
- [#9 Useful queries part1](ch09/ch09-useful-queries-part1.md)
- [#10 Useful queries part2](ch10/ch10-useful-queries-part2.md)
- [#11 Useful queries part3](ch11/ch11-useful-queries-part3.md)
- [#12 NFT analysis](ch12/ch12-nft-analysis.md)
- [#13 Lending analysis](ch13/ch13-lending-analysis.md)
- [#14 DeFi analysis](ch14/ch14-defi-analysis.md)
- [#15 Introduction to DuneSQL ](ch15/ch15-dunesql-introduction.md)
- [#16 Blockchain analysis - polygon](ch16/ch16-blockchain-analysis-polygon.md)
- [#17 MEV analysis - uniswap](ch17/ch17-mev-analysis-uniswap.md)
- [#18 Uniswap multichain analysis](ch18/ch18-uniswap-multichain-analysis.md)
- [#19 Useful metrics](ch19/ch19-useful-metrics.md)

## Advanced
- [#20 Network analysis](ch20/ch20-network-analysis.md)
- [#21 BTC analysis](ch21/ch21-btc-analysis.md)
- [#22 How to build Spellbook](ch22/ch22-how-to-build-spellbook.md)
- [#23 How to build app use dune api](ch23/ch23-how-to-build-app-use-dune-api.md)
</file>

<file path="zh/ch01/readme.md">
---
title: 01. Êàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏à
tags:
  - sixdegreelab
  - dune
  - onchain analysis
---

# 1. Êàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏à
## TLÔºõDR
- Èìæ‰∏äÊï∞ÊçÆÁöÑ‰∏∞ÂØåÊ∫ê‰∫éÂå∫ÂùóÈìæÊäÄÊúØÁöÑÊàêÁÜüÂíåÈ°πÁõÆÁöÑÂàõÊñ∞
- ÊéåÊè°Èìæ‰∏äÊï∞ÊçÆËßÜËßíÊúâÂä©‰∫éÂáèÂ∞ë‰ø°ÊÅØÂ∑ÆÔºåÂú®ÈªëÊöóÊ£ÆÊûóÈáåÂâçË°åÂ§ö‰∏ÄÂ±Ç‰øùÊä§
- Èìæ‰∏äÊï∞ÊçÆÁúüÂÆûÂú∞ÂèçÂ∫î‰∫Ü‰ª∑ÂÄºÁöÑÊµÅÂä®ÔºåÂõ†Ê≠§ÂàÜÊûêÂêéÁöÑÊ¥ûËßÅÊõ¥Êúâ‰ª∑ÂÄº
- Êï∞ÊçÆÂàÜÊûêÊèê‰æõ‰∏Ä‰∏™ÂèØÈáèÂåñÁöÑËßÜËßíÊúÄÁªàÂéªÊîØÊíëÂÜ≥Á≠ñÔºåÂàÜÊûêÂè™ÊòØËøáÁ®ãËÄå‰∏çÊòØÁõÆÁöÑ
- Â•ΩÁöÑÊï∞ÊçÆÂàÜÊûêÊù•Ê∫ê‰∫éÊï∞ÊçÆÊÄùÁª¥ÔºåÈúÄË¶ÅÂä†Ê∑±Ë°å‰∏öÁêÜËß£ÔºåÂüπÂÖªÊäΩË±°‰∫ãÁâ©ÁöÑËÉΩÂäõ
## ‰ªÄ‰πàÊòØÈìæ‰∏äÊï∞ÊçÆ
Â§ßÈÉ®ÂàÜ‰∫∫ÂàöÊé•Ëß¶Âå∫ÂùóÈìæÊó∂ÈÉΩ‰ºöÂæóÂà∞ËøôÊ†∑ÁöÑÊ¶ÇÂøµÔºöÂå∫ÂùóÈìæÊòØ‰∏™ÂÖ¨ÂºÄÁöÑ„ÄÅ‰∏çÂèØÁØ°ÊîπÁöÑËÆ∞Ë¥¶Êú¨Ôºå‰∏ÄÂàáÁöÑËΩ¨Ë¥¶„ÄÅ‰∫§ÊòìËÆ∞ÂΩïÊòØÈÄèÊòéÂèØ‰ø°ÁöÑ„ÄÇÁÑ∂ËÄåËøô‰∏ÄÂäüËÉΩÂπ∂‰∏çÊòØÂå∫ÂùóÈìæÁöÑÂÖ®ÈÉ®ÔºåÂè™ÊòØÊúÄÂàùÊàë‰ª¨‰ªé‚ÄúÁÇπÂØπÁÇπÁöÑÁîµÂ≠êÁé∞ÈáëÁ≥ªÁªü‚ÄùÔºå‰πüÂ∞±ÊòØ‚ÄúËÆ∞Ë¥¶Êú¨‚ÄùËøô‰∏™ËßíÂ∫¶Âá∫ÂèëÁöÑ„ÄÇÈöèÁùÄÊô∫ËÉΩÂêàÁ∫¶ÁöÑÂèëÂ±ïÔºåÂå∫ÂùóÈìæÂÆûÈôÖ‰∏äÊ≠£Âú®Êàê‰∏∫‰∏Ä‰∏™Â§ßÂûãÁöÑÊï∞ÊçÆÂ∫ìÔºå‰∏ãÂõæ‰ªéÊû∂ÊûÑÂØπÊØî‰∫Ü‰º†Áªüweb2Âíåweb3Â∫îÁî®ÁöÑÂå∫Âà´ÔºöÊô∫ËÉΩÂêàÁ∫¶‰ª£Êõø‰∫ÜÂêéÁ´ØÔºåÂå∫ÂùóÈìæ‰πüÊâøÊãÖËµ∑‰∏ÄÈÉ®ÂàÜÊï∞ÊçÆÂ∫ìÁöÑÂäüËÉΩ„ÄÇË∂äÊù•Ë∂äÂ§öÁöÑÈìæ‰∏äÈ°πÁõÆÊ∂åÁé∞ÔºåÊàë‰ª¨Âú®Èìæ‰∏äÁöÑ‰∫§‰∫íË∂äÊù•Ë∂äÈ¢ëÁπÅÔºåÊØîÂ¶ÇÂú®DeFiÂçèËÆÆÈáåÊ∑ªÂä†‰∫ÜÂ§öÂ∞ëÊµÅÂä®ÊÄßÔºåmint‰∫ÜÂì™‰∫õNFTÔºåÁîöËá≥ÂÖ≥Ê≥®Âì™‰∏™Á§æ‰∫§Ë¥¶Âè∑ËÆ∞ÂΩïÈÉΩËÉΩ‰∏äÈìæÔºåÊàë‰ª¨‰∏ÄÂàá‰∏éÂå∫ÂùóÈìæÁöÑ‰∫§‰∫íÈÉΩÂ∞ÜË¢´ËÆ∞ÂΩïÂú®Ëøô‰∏™Êï∞ÊçÆÂ∫ì‰∏≠ÔºåËøô‰∫õËÆ∞ÂΩïÂ∞±Â±û‰∫éÈìæ‰∏äÊï∞ÊçÆ„ÄÇ

![](img/01.jpg)

**Èìæ‰∏äÊï∞ÊçÆÂ§ßËá¥ÂàÜ‰∏∫‰∏âÁ±ªÔºö**
1. ‰∫§ÊòìÊï∞ÊçÆ
Â¶ÇÊî∂ÂèëÂú∞ÂùÄÔºåËΩ¨Ë¥¶ÈáëÈ¢ùÔºåÂú∞ÂùÄ‰ΩôÈ¢ùÁ≠â

2. Âå∫ÂùóÊï∞ÊçÆ
‰æãÂ¶ÇÊó∂Èó¥Êà≥ÔºåÁüøÂ∑•Ë¥πÔºåÁüøÂ∑•Â•ñÂä±Á≠â

3. Êô∫ËÉΩÂêàÁ∫¶‰ª£Á†Å
Âç≥Âå∫ÂùóÈìæ‰∏äÁöÑÁºñÁ†Å‰∏öÂä°ÈÄªËæë

Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∞±ÊòØ‰ªéËøô‰∏âÁ±ªÊï∞ÊçÆ‰∏≠ÊèêÂèñÊÉ≥Ë¶ÅÁöÑ‰ø°ÊÅØËøõË°åËß£ËØª„ÄÇ ‰ªéÊï∞ÊçÆÊ†àËßíÂ∫¶Êù•ÁúãÔºåÂå∫ÂùóÈìæÊï∞ÊçÆ‰∫ßÂìÅÂèØ‰ª•ÂàÜ‰∏∫Êï∞ÊçÆÊ∫ê„ÄÅÊï∞ÊçÆÂºÄÂèëÂ∑•ÂÖ∑ÂíåÊï∞ÊçÆapp‰∏âÁ±ª„ÄÇ

![](img/02.jpg)

ÁÅµÊ¥ªËøêÁî®ÂêÑÁ±ªÊï∞ÊçÆ‰∫ßÂìÅÔºå‰ºö‰∏∫Êàë‰ª¨Âú®crypto‰∏ñÁïåÊèê‰æõÂ¥≠Êñ∞ÁöÑËßÜËßí„ÄÇ

ËôΩÁÑ∂Êàë‰ª¨‰∏ÄÁõ¥Âú®ËØ¥Èìæ‰∏äÊï∞ÊçÆÊòØÂÖ¨ÂºÄÈÄèÊòéÁöÑÔºå‰ΩÜÊòØÊàë‰ª¨ÂæàÈöæÁõ¥Êé•ËØªÂèñÈÇ£‰∫õÊï∞ÊçÆÔºåÂõ†‰∏∫‰∏ÄÁ¨îÁÆÄÂçïÁöÑswap‰∫§ÊòìÂú®Èìæ‰∏äÁúãËµ∑Êù•ÂèØËÉΩÊòØËøôÊ†∑ÁöÑÔºö

![](img/03.jpg)

Êàë‰ª¨ËÉΩÂú®Âå∫ÂùóÈìæÊµèËßàÂô®ÈáåÁúãÂà∞‰∏Ä‰∫õÂéüÂßãÈìæ‰∏äÊï∞ÊçÆÔºå‰ΩÜÊòØÊàëÁöÑÈóÆÈ¢òÊòØÊÉ≥Áü•ÈÅì‰ªäÂ§©UniswapV3Êàê‰∫§ÈáèÊòØÂ§öÂ∞ëÔºåËøô‰∏çËß£ÂÜ≥ÊàëÈóÆÈ¢òÈòøÔºÅÊàëÊÉ≥ÁúãÂà∞ÁöÑÊòØ‰∏ãÈù¢ËøôÂº†ÂõæÔºö

![](img/04.jpg)

Èìæ‰∏äÂéüÂßãÊï∞ÊçÆÂπ∂‰∏çËÉΩÁªôÊàë‰ª¨Á≠îÊ°àÔºåÊàë‰ª¨ÈúÄË¶ÅÈÄöËøáÁ¥¢Âºï (indexing)ÔºåÂ§ÑÁêÜ (processing)ÔºåÂ≠òÂÇ® (storage) Á≠âÁ≠â‰∏ÄÁ≥ªÂàóÊï∞ÊçÆÊëÑÂèñ (ingestion) ÁöÑÂ§ÑÁêÜËøáÁ®ãÔºåÂÜçÊ†πÊçÆÊâÄÊèêÈóÆÈ¢òÊù•ËÅöÂêàËøêÁÆóÂØπÂ∫îÁöÑÊï∞ÊçÆÔºåÊâçËÉΩÂæóÂà∞ÈóÆÈ¢òÁöÑÁ≠îÊ°à„ÄÇ

![](img/data-process.png)

Ë¶Å‰ªéÂ§¥ÂÅöËµ∑ÔºåÊàë‰ª¨ÂèØËÉΩÈúÄË¶ÅËá™Â∑±Êê≠ËäÇÁÇπÊù•Êé•Âå∫ÂùóÈìæÊï∞ÊçÆÔºåÂÜç‰ΩúÂ§ÑÁêÜÔºå‰ΩÜÊòØËøôÊòéÊòæÊòØÈùûÂ∏∏ËÄóÊó∂ËÄóÂäõÁöÑ„ÄÇËøòÂ•ΩÔºåÊúâËÆ∏Â§öÊï∞ÊçÆÂπ≥Âè∞ÔºåÂ¶ÇDuneÔºåFlipsideÔºåFootprintÔºå‰ªñ‰ª¨Â∞ÜÁ¥¢ÂºïÂæóÂà∞ÁöÑÂéüÂßãÈìæ‰∏äÊï∞ÊçÆÔºåÁªèËøá‰∏ÄÁ≥ªÂàóÂ§ÑÁêÜÂêéÔºåÂ≠òÂÖ•Áî±Âπ≥Âè∞Ë¥üË¥£Êõ¥Êñ∞ÂíåÁÆ°ÁêÜÁöÑÊï∞ÊçÆ‰ªìÂ∫ìÔºå‰πüÂ∞±ÊòØËØ¥Êï¥‰∏™Âå∫ÂùóÈìæÊï∞ÊçÆË¢´‰ªñ‰ª¨ÂÅöÊàê‰∫ÜÂ•ΩÂ§öÂº†ÂÖ≥Á≥ªÂûãÊï∞ÊçÆË°®Ê†ºÔºåÊàë‰ª¨Ë¶ÅÂÅöÁöÑÂ∞±ÊòØ‰ªéË°®Ê†ºÈáåÈÄâ‰∏Ä‰∫õÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÊï∞ÊçÆÊûÑÂª∫Êàë‰ª¨ÁöÑÂàÜÊûêÊï∞ÊçÆ„ÄÇÊõ¥Ëøõ‰∏ÄÊ≠•Âú∞ÔºåÊúâNansenÔºåMessariÔºåDeBankËøô‰∫õÊï∞ÊçÆÁ±ª‰∫ßÂìÅÔºå‰∏çÂÖâÊï¥ÁêÜÂ•ΩÊï∞ÊçÆÔºåËøòÊåâÁÖßÈúÄÊ±ÇÂàÜÈó®Âà´Á±ªÂú∞Â∞ÅË£ÖËµ∑Êù•ÔºåÊñπ‰æøÁî®Êà∑Áõ¥Êé•‰ΩøÁî®„ÄÇ

|ÂàÜÁ±ª | Â∫îÁî®Á§∫‰æã|
|--------|:---------------:|
|Êï∞ÊçÆÂ∫îÁî® | NansenÔºåMessariÔºåDeBank..|
|Êï∞ÊçÆÂπ≥Âè∞ |DuneÔºåFLipsideÔºåFootprint.. |
|Êï∞ÊçÆËäÇÁÇπ | InfuraÔºåQuick Node..|

## Èìæ‰∏äÊï∞ÊçÆÁöÑÈáçË¶ÅÊÄß
ÈöèÁùÄÈìæ‰∏äÁîüÊÄÅÁöÑÁπÅËç£Ôºå‰∏∞ÂØåÁöÑ‰∫§‰∫íË°å‰∏∫Â∏¶Êù•‰∫ÜÊµ∑ÈáèÊï∞ÊçÆ„ÄÇËøô‰∫õÈìæ‰∏äÊï∞ÊçÆÂØπÂ∫îÁùÄÈìæ‰∏ä‰ª∑ÂÄºÁöÑÊµÅÂä®ÔºåÂØπËøô‰∫õÊï∞ÊçÆÁöÑÂàÜÊûêÂíåÊ†πÊçÆÂàÜÊûêËÄåÂæóÂá∫ÁöÑÊ¥ûÂØüÂíåËßÅËß£ÂèòÂæóÊûÅ‰∏∫Êúâ‰ª∑ÂÄº„ÄÇÈÄöËøáÈìæ‰∏äÈÄèÊòé‰∏î‰∏ç‰ºöËØ¥Ë∞éÁöÑÊï∞ÊçÆÔºåÊàë‰ª¨ÂèØ‰ª•Êé®Êñ≠‰∫§ÊòìËÄÖÔºåÁîöËá≥Â∏ÇÂú∫Êï¥‰ΩìÁöÑÂøÉÁêÜÁä∂ÊÄÅÂíåÂøÉÁêÜÈ¢ÑÊúüÔºå‰ªéËÄåÂ∏ÆÂä©Ëá™Ë∫´ÂÅöÊõ¥ÊúâÂà©ÁöÑÂÜ≥Á≠ñÔºå‰πüÂèØ‰ª•Âú®ÈªëÊöóÊ£ÆÊûóÂâçË°å‰∏≠Êó∂‰∏∫Ëá™Â∑±ÊèêËµ∑‰∏ÄÁõèÊòéÁÅØÔºåÁÖß‰∫ÆÂâçÊñπ‰øùÊä§Ëá™Â∑±„ÄÇ

‰ª•Â§ßÂÆ∂ÁÜüÊÇâÁöÑDeFiÂçèËÆÆÊµÅÂä®ÊÄßÊåñÁüø‰∏∫‰æãÔºö‰Ω†Ê∑ªÂä†ÊµÅÂä®ÊÄßÊî∂Ëé∑‰∫ÜÂ•ñÂä±ÔºåÊ±†Â≠êÂ¢ûÂä†‰∫ÜÊ∑±Â∫¶ÔºåÁî®Êà∑‰∫´Âèó‰∫ÜÊõ¥‰ΩéÁöÑÊªëÁÇπÔºåÂ§ßÂÆ∂ÈÉΩÊúâÂÖâÊòéÁöÑÊú™Êù•Ôºå‰Ω†ÂÆâÂøÉÂú∞Â∞ÜÈí±ÈîÅÂú®ÂêàÁ∫¶Èáå„ÄÇÂèØÊòØÊüê‰∏ÄÂ§©ÔºåÈªëÂ§©ÈπÖÊÇÑÁÑ∂ËÄåËá≥ÔºåËÅ™ÊòéÈí±Ê∂àÊÅØÁÅµÈÄöÁ´ãÈ©¨Êí§ÈÄÄÔºåËÄå‰Ω†Âè™ÊòØ‰∏™ÊôÆÈÄöÊäïËµÑËÄÖÔºåÁ≠â‰Ω†ÁúãÂà∞Ë¥üÈù¢Êñ∞ÈóªÂÜçÊÉ≥Âà∞ÂéªÊèêÊ¨æÊó∂ÔºåÊâãÈáåÁöÑÂ•ñÂä±Âá†‰πéÂàÜÊñá‰∏çÂÄºÔºåÁåõÁÉàÁöÑÊó†Â∏∏ÊçüÂ§±ËÆ©‰Ω†‰øùÊú¨ÈÉΩÈöæÔºåÁõ¥ÂëºÂå∫ÂùóÈìæÈ™óÂ±Ä„ÄÇ

![image](img/scam.png)

‰ΩÜÂ¶ÇÊûú‰Ω†Êúâ‰∏™Èìæ‰∏äÊï∞ÊçÆÁöÑËßÜËßíÔºå‰Ω†ÂèØËÉΩ‰ºöÂèëÁé∞ÔºöÂçèËÆÆTVLÈô°ÁÑ∂‰∏ãÈôçÔºåÂ•ñÂä±ÁöÑ‰ª£Â∏ÅÂú®Uniswap‰∏äÊäõÈáèÊøÄÂ¢ûÔºåÊç¢Âè•ËØùËØ¥ÔºåÊúâËÅ™Êòé‰∫∫ÂæóÂà∞Ê∂àÊÅØÊàñËÄÖÂèëÁé∞‰∏çÂØπÔºåÊ±†Â≠êÈáåÁöÑÊµÅÂä®ÊÄßÂèòÂ∑ÆÈí±Âú®ÈÄÉË∑ëÔºåÂ§ßÂÆ∂ÈÉΩÁúãË∑å‰ª£Â∏ÅÁñØÁãÇÂá∫ÂîÆÔºåËØ∑ÈóÆÁé∞Âú®Â∫îËØ•Á¶ªÂú∫ÂêóÔºü

ÂΩìÁÑ∂ËøôÂè™ÊòØ‰∏™ÊäΩË±°‰∏îÁÆÄÂçïÁöÑ‰∏æ‰æãÔºå‰ΩÜÊòØÊàëÊÉ≥‰º†ÈÄíÁªôÂ§ßÂÆ∂ÁöÑÊòØÔºö**ÊôÆÈÄöÊäïËµÑËÄÖÂú®CryptoËøôÁâáÈªëÊöó‰∏õÊûó‰∏≠ÔºåÂßãÁªàÂ§Ñ‰∫é‰ø°ÊÅØ‰∏çÂØπÁß∞ÁöÑÂä£ÂäøÂú∞‰Ωç„ÄÇ** ‰ΩÜÊòØÈìæ‰∏äÊï∞ÊçÆÊòØÈÄèÊòé‰∏îÁúüÂÆûÁöÑ„ÄÇ‰∏∫‰ªÄ‰πàÂ§ßÂÆ∂ÂæàÊâßÁùÄ‰∫éËøΩË∏™NansenÁöÑSmart MoneyÔºüÂõ†‰∏∫ÊúâÂÜÖÂπïÁöÑ‰∫∫‰∏ç‰ºöÊääÊ∂àÊÅØÂëäËØâ‰Ω†Ôºå‰ΩÜÊòØ‰ø°ÊÅØ‰ºöÊò†Â∞ÑÂà∞Èìæ‰∏äË°å‰∏∫ÔºåË¢´ÁúüÂÆûÂú∞ËÆ∞ÂΩï‰∏ãÊù•ÔºåÊàë‰ª¨ÊâÄË¶ÅÂÅöÁöÑÂ∞±ÊòØÁªÜÂøÉÂú∞ËßÇÂØüËøô‰∏™Êï∞ÊçÆ‰∏ñÁïåÔºåÈÄöËøáÊçïÊçâÈìæ‰∏äÁªÜËäÇÔºåÂú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÂº•Ë°•‰ø°ÊÅØÂ∑Æ„ÄÇ

DeFi summer‰πãÂêéÔºåÊàë‰ª¨ÂºÄÂßãÂÖ≥ÂøÉÂçèËÆÆÁöÑÈîÅ‰ªìÈáèÔºõAxieÁàÜÁÅ´ÔºåÊàë‰ª¨Á†îÁ©∂Êó•Â¢ûÁî®Êà∑Êï∞ÔºõNFTÂ¥õËµ∑ÔºåÊàë‰ª¨Á†îÁ©∂mintÊï∞Ôºõ‰ª•Â§™Âùä‰∏äGasÈ£ôÂçáÔºåÊàë‰ª¨ËßÇÂØüÊòØÂì™‰∏™È°πÁõÆËøô‰πàÁÅ´ÁÉ≠„ÄÇÂèëÁé∞‰∫ÜÂêóÔºüÊàë‰ª¨ÂØπÈìæ‰∏äÊï∞ÊçÆ‰∏éÊó•‰ø±Â¢ûÁöÑ‰∫ÜËß£ÂíåÊïèÊÑüÂ∫¶ÂÆûÂàô‰∏äÊù•Ê∫ê‰∫éÈìæ‰∏äÊ¥ªÂä®ÁöÑÁπÅËç£ÂèëÂ±ïÔºåÊç¢Âè•ËØùËØ¥Ôºå**Èìæ‰∏äÊï∞ÊçÆÁöÑÈáçË¶ÅÊÄßÊù•Ê∫ê‰∫éÂå∫ÂùóÈìæÊäÄÊúØÁöÑÊàêÁÜüÂíåÂ∫îÁî®ÁöÑËì¨ÂãÉ„ÄÇ** Ë∂äÊù•Ë∂äÂ§öÁöÑÈìæ‰∏äÈ°πÁõÆÁªô‰∫ÜÊàë‰ª¨Ë∂≥Â§ü‰∏∞ÂØåÁöÑ‰∫§‰∫íÁ©∫Èó¥ÔºåÂêåÊó∂ÈöèÁùÄSBT„ÄÅOATÁöÑÊàêÁÜüÂíåÂπøÊ≥õÂ∫îÁî®Ôºå‰∏áÁâ©‰∏äÈìæÂèò‰∏∫ÂèØËÉΩÔºåËøôÊÑèÂë≥ÁùÄÊó•ÂêéÁöÑÊï∞ÊçÆÂ∞ÜÂ§öÂà∞Ë∂≥‰ª•ÊîØÊíëÊØè‰∏Ä‰∏™Áî®Êà∑‰∏∞Êª°ÁöÑÈìæ‰∏äËÇñÂÉèÔºåÂ±äÊó∂Êàë‰ª¨ËÉΩËÆ≤Âá∫ÂÖ≥‰∫éDIDÔºåSocialFiÊõ¥Â•ΩÁöÑÊïÖ‰∫ã„ÄÇ

## Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêË∞ÅÊù•ÂÅö
ÂØπ‰∫éÂ§ßÈÉ®ÂàÜÁî®Êà∑Êù•ËØ¥ÔºåÊàêÁÜüÁöÑÊï∞ÊçÆ‰∫ßÂìÅÂ∑≤ÁªèÂ§üÁî®ÔºåÁÅµÊ¥ªÁªÑÂêàÂ§ö‰∏™Êï∞ÊçÆÂ∑•ÂÖ∑Â∞±ËÉΩÂèñÂà∞‰∏çÈîôÁöÑÊïàÊûú„ÄÇÊØîÂ¶Ç‰ΩøÁî®NansenÂ∏ÆÂä©Áî®Êà∑ËøΩË∏™Â∑®È≤∏ÁöÑÂÆûÊó∂Âä®ÂêëÔºõÁî®Token TerminalÊü•ÁúãÂêÑÂçèËÆÆÁöÑÊî∂ÂÖ•ÔºõNFTÁ±ªÁöÑÊï∞ÊçÆÁõëÊéßÂπ≥Âè∞Êõ¥ÊòØ‰∫îËä±ÂÖ´Èó®„ÄÇËøô‰∫õ‚ÄúÊàêÂìÅ‚ÄùÁ±ªÊï∞ÊçÆ‰∫ßÂìÅËôΩÁÑ∂Èó®Êßõ‰ΩéÔºå‰ΩøÁî®Êñπ‰æøÔºåÂç¥‰πüÊúâÊó†Ê≥ïÊª°Ë∂≥È´òÂÆöÂà∂ÂåñË¶ÅÊ±ÇÁöÑÁì∂È¢à„ÄÇ

![image](img/07.jpg)

‰∏æ‰∏™‰æãÂ≠êÔºå ‰Ω†ÈÄöËøáhttps://ultrasound.money/ ÂèëÁé∞‰ª•Â§™Âùä‰∏äGasÊ∂àËÄóÁ™ÅÁÑ∂‰∏äÊ∂®ÔºåÊòØÁî±Ëøô‰∏™Ê≤°ÊúâÂê¨ËØ¥ËøáÁöÑXENÊé®Âä®ÁöÑÔºå‰Ω†ÊïèÈîêÂú∞ÊÑèËØÜÂà∞ÔºåËøôÂèØËÉΩÊòØ‰∏™Êó©ÊúüÊú∫‰ºöÔºÅÈÄöËøáÊé®ÁâπÊêúÁ¥¢Ôºå‰Ω†‰∫ÜËß£‰∫ÜXENÈááÁî®PoPÔºàProof of ParticipationÔºâÊåñÁüøÊú∫Âà∂ÔºåXENÊåñÁüøÂèÇ‰∏éËÄÖÊã•ÊúâÊåñÂá∫ÁöÑXEN‰ª£Â∏ÅÁöÑÊâÄÊúâÊùÉÔºåÈöèÂèÇ‰∏é‰∫∫Êï∞Â¢ûÂä†ÔºåÊåñÁüøÈöæÂ∫¶Âä†Â§ßÔºå‰æõÂ∫îÈáèÈôç‰Ωé„ÄÇ‰Ω†ÊÉ≥‰∫ÜËß£Â§ßÂÆ∂ÁöÑÂèÇ‰∏éÊÉÖÂÜµÔºåÂÖâÈù†‰∏™gasÊ∂àËÄóÂèØ‰∏çÂ§üÔºå‰Ω†ËøòÊÉ≥Áü•ÈÅìÂèÇ‰∏éÁöÑ‰∫∫Êï∞ÔºåË∂ãÂäøÔºåÂèÇ‰∏éËÄÖÈÉΩÈÄâÊã©ÈîÅ‰ªìÂ§ö‰πÖÔºüÂêåÊó∂‰Ω†ËøòÂèëÁé∞Ôºå‰ªñÂ•ΩÂÉèÊ≤°ÊúâÈò≤Â•≥Â∑´Ôºü‰ªò‰∏™gasÂ∞±ËÉΩÂèÇ‰∏éÔºåÂÜ≤ËøõÊù•ÁöÑÁßëÂ≠¶ÂÆ∂Â§öÂêóÔºüÊàëËøòÊúâÂà©Ê∂¶ÂêóÔºüÂàÜÊûêÂà∞Ëøô‰Ω†ÊÄ•ÈúÄÊï∞ÊçÆÊù•ÊîØÊíë‰Ω†‚ÄúÂÜ≤‰∏çÂÜ≤‚ÄùÁöÑÂÜ≥Á≠ñÔºåÂèØÊòØÊ≠£Âõ†‰∏∫Êó©ÊúüÔºåÊï∞ÊçÆapp‰∏≠ËøòÊ≤°ÊúâÂØπÂÆÉÁöÑÂàÜÊûêÔºåÂêåÊó∂Êï∞ÊçÆapp‰πüÂæàÂèØËÉΩ‰∏ç‰ºöÂØπÊØè‰∏Ä‰∏™ÂçèËÆÆÈÉΩËøõË°åÁõëÊéßÂàÜÊûê„ÄÇËøôÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÂ∑≤ÁªèÊúâÂæàÂ§öÊï∞ÊçÆ‰∫ßÂìÅÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨‰ªçÁÑ∂ÈúÄË¶ÅËá™Â∑±‰ºöÂÜô‰∏Ä‰∫õÊï∞ÊçÆÂàÜÊûêÔºöÁé∞ÊàêÁöÑ‰∫ßÂìÅÈöæ‰ª•Êª°Ë∂≥ÂÆöÂà∂ÂåñÁöÑÈúÄÊ±Ç„ÄÇ

![image](img/xen.png)


ÈÄöËøáËá™Â∑±ÂàÜÊûêÊï∞ÊçÆÔºöhttps://dune.com/sixdegree/xen-crypto-overviewÔºå ÊàëÂæóÁü•‰∫ÜÂ§ßÈÉ®ÂàÜ‰∫∫ÈÉΩÈÄâÊã©ÁöÑÊòØÁü≠ÊúüË¥®ÊäºÔºå‰∏îÊé•ËøëÁôæÂàÜ70ÁöÑÈÉΩÊòØÊñ∞Èí±ÂåÖÔºåËØ¥ÊòéË¢´Â§ßÂÆ∂Êí∏Âùè‰∫ÜÔºåÈÇ£ÊàëÂ∞±ÊòéÁôΩ‰∫ÜÁü≠ÊúüÊäõÂîÆÂéãÂäõ‰ºöÈùûÂ∏∏Â§ßÔºåÊâÄ‰ª•ÊàëÂ¶ÇÊûúÊÉ≥ÈÄâÊã©ÂèÇ‰∏éÔºåÂ∞±ÈÄâË¥®ÊäºÊúÄÁü≠ÁöÑÊó∂Èó¥ÔºåÂ∞ΩÂø´ÂçñÂá∫ÔºåÊØîË∞ÅË∑ëÂæóÂø´„ÄÇ
Ëá≥Ê≠§Ôºå‰Ω†Â∑≤ÁªèÂÆåÊàê‰∫ÜÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÁöÑÊï¥‰∏™ÊµÅÁ®ãÔºöÂèëÁé∞È°πÁõÆÔºåÁ†îÁ©∂È°πÁõÆÊú∫Âà∂ÔºåÊäΩË±°Âá∫ËØÑ‰º∞È°πÁõÆÁöÑÊ†áÂáÜÔºåÊúÄÂêéÊâçÊòØÂä®ÊâãÂÅöÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÂèØËßÜÂåñÔºåËæÖÂä©ÂÜ≥Á≠ñ„ÄÇ

## Â¶Ç‰ΩïÂÅöÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê
Â∞ΩÁÆ°DuneËøôÁ±ªÁöÑÊï∞ÊçÆÂàÜÊûêÂπ≥Âè∞Â∑≤Áªè‰∏∫Êàë‰ª¨ÂÅö‰∫ÜÂæàÂ§öÊï¥ÁêÜÂ∑•‰ΩúÔºåÊàë‰ª¨Âè™Ë¶ÅÁî®SQLÁ±ªÁöÑËØ≠Ê≥ï‰ªéÊï∞ÊçÆË°®‰∏≠ÊäΩÂèñÊàë‰ª¨ÈúÄË¶ÅÁöÑÈÉ®ÂàÜËøõË°åÊûÑÂª∫Â∞±ÂèØ‰ª•‰∫Ü„ÄÇÂ§ßÈÉ®ÂàÜ‰∫∫ÁöÑÂ≠¶‰π†Ë∑ØÂæÑÊàëÁõ∏‰ø°ÈÉΩÊòØÁõ¥Â•î„Ää3Êó•ÈÄüÊàêSQL„ÄãÔºåÊãø‰∏ã‰πãÂêéÂèàÂºÄÂßãËø∑Ëå´ÔºåËøòÊòØ‰∏çÁü•ÈÅìÂ¶Ç‰Ωï‰ªéÊØõÁ∫øÂõ¢‰∏≠ÊâæÂà∞Âì™Ê†πÁ∫øÂ§¥„ÄÇÊÄé‰πà‰ºöËøôÊ†∑ÔºüÂ≠¶‰π†Êï∞ÊçÆÂàÜÊûêÊúÄÈáçË¶ÅÁöÑÊòØÂüπÂÖªÊï∞ÊçÆÊÄùÁª¥ÔºåÁÜüÁªÉ‰ΩøÁî®ÁºñÁ®ãËØ≠Ë®ÄÊòØÊ¨°Ë¶ÅÁöÑ„ÄÇ

**Êï∞ÊçÆÂàÜÊûêÊèê‰æõ‰∏Ä‰∏™ÂèØÈáèÂåñÁöÑËßÜËßíÊúÄÁªàÂéªÊîØÊíëÂÜ≥Á≠ñÔºåÂàÜÊûêÂè™ÊòØËøáÁ®ãËÄå‰∏çÊòØÁõÆÁöÑ„ÄÇÁÆÄÂçïÁöÑÊ≠•È™§ÊòØÂéòÊ∏Ö‰∏â‰∏™ÈóÆÈ¢òÔºåÊûÑÂª∫Êï∞ÊçÆÊÄùÁª¥Ôºö** 

**1. ÊàëÁöÑÁõÆÁöÑÊòØ‰ªÄ‰πàÔºü**

ÊòØÂà§Êñ≠‰∏Ä‰∏™Â∏ÅÁé∞Âú®ÊòØÂê¶ÊòØ‰π∞ÂÖ•ÁöÑÂ•ΩÊó∂Êú∫ÔºüÂÜ≥ÂÆöÊòØÂê¶‰∏∫AAVEÊ∑ªÂä†ÊµÅÂä®ÊÄßËµöÂèñÊî∂ÁõäÔºüËøòÊòØÊÉ≥Áü•ÈÅìÁé∞Âú®ÂÖ•Âú∫StepnÊòØÂê¶‰∏∫Êó∂Â∑≤ÊôöÔºü

**2. ÊàëÁöÑÁ≠ñÁï•ÊòØ‰ªÄ‰πàÔºü**

‰π∞Â∏ÅÁöÑÁ≠ñÁï•Â∞±ÊòØÁ¥ßË∑üSmart moneyÔºå‰π∞Âï•Ë∑üÂï•Ôºå‰ªñËøõÊàëËøõ‰ªñÂá∫ÊàëÂá∫ÔºõËßÇÂØüÂ¶ÇÊûúÂçèËÆÆËøê‰ΩúÊÉÖÂÜµËâØÂ•ΩÔºåÂ≠òÊ¨æÂà©ÁéáÊª°ÊÑèÔºåÂ∞±ÊääÊöÇÊó∂‰∏çÂä®ÁöÑÂ∏ÅÂ≠òËøõÂéªÂêÉÂà©ÊÅØÔºõStepnÊúÄËøëÂ§ßÁÅ´ÔºåÂ¶ÇÊûúÂäøÂ§¥‰ªçÁÑ∂Âêë‰∏äÔºåÈÇ£ÊàëÂ∞±ÂèÇ‰∏éÂÖ∂‰∏≠„ÄÇ

**3. ÊàëÈúÄË¶Å‰ªÄ‰πàÊï∞ÊçÆÂ∏ÆÊàëÂÅöÂÜ≥Á≠ñÔºü**

ÈúÄË¶ÅÁõëÊéßSmart moneyÂú∞ÂùÄÁöÑÊåÅ‰ªìÂä®ÂêëÔºåÁîöËá≥ËÄÉÈáè‰ª£Â∏ÅÁöÑ‰∫§ÊòìÈáèÂíåÊåÅ‰ªìÂàÜÂ∏ÉÔºõË¶ÅÊü•‰∏Ä‰∏ãÂçèËÆÆÁöÑTVLÔºåÊú™ÂÅøÂÄ∫Âä°Êï∞È¢ùÔºåËµÑÈáëÂà©Áî®ÁéáÔºåAPRÁ≠âÔºõËÄÉËôëÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞ÔºåÂ¢ûÈïøË∂ãÂäøÔºåÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞Ôºå‰∫§ÊòìÁ¨îÊï∞ÔºåÁé©ÂÆ∂Âá∫ÂÖ•ÈáëÊÉÖÂÜµÔºåNFTÂ∏ÇÂú∫ÈáåÈÅìÂÖ∑ÁöÑÈîÄÂîÆÊÉÖÂÜµ„ÄÇ

![image](img/10.jpg)

Ëøô‰∏â‰∏™ÈóÆÈ¢òÁöÑÈöæÂ∫¶ÈÄêÊ∏êÂ¢ûÂä†Ôºå‰∏Ä‰∫åËøòÂÆπÊòìÂõûÁ≠îÔºåÊÉ≥ÊòéÁôΩÁ¨¨‰∏â‰∏™ÈóÆÈ¢òÈúÄË¶ÅÂ§ßÈáèÁöÑÂ≠¶‰π†ÂíåÁêÜËß£ÔºåËøô‰πüÊòØÂå∫ÂàÜÊï∞ÊçÆÂàÜÊûêÂ∏à‰ª¨Ê∞¥Âπ≥È´ò‰ΩéÁöÑÂ∞èÈó®Êßõ„ÄÇ‰∏ÄÂêç‰ºòÁßÄÁöÑÂàÜÊûêÂ∏àÂ∫îËØ•ÂÖ∑Â§á‰ª•‰∏ã‰∏âÁßçÁâπÁÇπÔºö

**1. ÂØπËµõÈÅìÊàñËÄÖÂçèËÆÆÊúâÁêÜËß£‰∏éËÆ§ËØÜ**

Âç≥ÂàÜÊûêÁöÑÊòØ‰ªÄ‰πàËµõÈÅìÔºüËøô‰∏™È°πÁõÆÁöÑËøêË°åÊú∫Âà∂ÊòØ‰ªÄ‰πàÔºü‰ºö‰∫ßÁîüÂì™‰∫õÊï∞ÊçÆÔºåÂàÜÂà´‰ª£Ë°®‰ªÄ‰πàÂê´‰πâÔºü

**2. ÊäΩË±°‰∫ãÁâ©ÁöÑËÉΩÂäõ**

Â∞Ü‰∏Ä‰∏™Ê®°Á≥äÁöÑÊ¶ÇÂøµÂèòÊàêÂèØÈáèÂåñÁöÑÊåáÊ†áÔºåÂç≥

>‚ÄúËøô‰∏™DEXÂçèËÆÆÂ•Ω‰∏çÂ•Ω‚Äù =>‚ÄúÊµÅÂä®ÊÄß‚Äù+‚ÄúÊàê‰∫§Èáè‚Äù+‚ÄúÊ¥ªË∑ÉÁî®Êà∑Èáè‚Äù+‚ÄúËµÑÊú¨Âà©Áî®Áéá‚Äù+‚ÄúÂçèËÆÆ‰∫ßÁîüÁöÑÊî∂Áõä‚Äù

ÂÜçÂõûÂà∞‰∏ä‰∏ÄÁÇπÔºåÈÄöËøá‰Ω†ÂØπÂçèËÆÆÁöÑ‰∫ÜËß£ÊâæÂà∞ÂØπÂ∫îÁöÑÊï∞ÊçÆ„ÄÇ

**3. Â§ÑÁêÜÊï∞ÊçÆÁöÑËÉΩÂäõ**

ËøôÈáåÂåÖÂê´ÂèñÊï∞ÊçÆÔºàÈìæ‰∏äÊï∞ÊçÆ‰ªéÂì™Êù•ÔºâÔºåÂ§ÑÁêÜÊï∞ÊçÆÔºàÊÄé‰πàÁ≠õÈÄâÊÉ≥Ë¶ÅÁöÑÊª§Èô§Êó†ÂÖ≥ÁöÑÔºâÔºå‰ª•ÂèäÊï∞ÊçÆÂèØËßÜÂåñÁöÑËÉΩÂäõ„ÄÇ

![image](img/11.jpg)

ÊÄªÁöÑÊù•ËØ¥ÔºåÊï∞ÊçÆÂàÜÊûêÂè™ÊòØÊîØÊíëÁ†îÁ©∂ÁöÑÂ∑•ÂÖ∑Ôºå‰∏çË¶Å‰∏∫‰∫ÜÂàÜÊûêËÄåÂàÜÊûê„ÄÇËøô‰∏™ËøáÁ®ãÈ¶ñÂÖàÊòØÂá∫‰∫é‰Ω†ÊÉ≥ÂØπÊüê‰∏™È°πÁõÆ„ÄÅÊ¶ÇÂøµ„ÄÅËµõÈÅìËøõË°åÁ†îÁ©∂„ÄÅÊäïËµÑÔºåÁÑ∂ÂêéÂ≠¶‰π†„ÄÅ‰∫ÜËß£È°πÁõÆÁöÑËøêË°åÊú∫Âà∂ÔºåÊäΩË±°Âá∫ÂØπÂÆöÊÄßÊ¶ÇÂøµÁöÑÂÆöÈáèÂàÜÊûêÔºåÊúÄÂêéÊâçÊòØÊâæÊï∞ÊçÆÔºåÂÅöÂèØËßÜÂåñ„ÄÇ

Êï∞ÊçÆÂàÜÊûêÊúÄÈáçË¶ÅÁöÑÂßãÁªàÊòØÊï∞ÊçÆÊÄùÁª¥ÔºåËá≥‰∫éÊúÄÂêéÂä®ÊâãÂÅöËøô‰∏ÄÊ≠•ÔºåÊó†ÈùûÊòØÁÜüÁªÉÂäüÔºåÂèØ‰ª•ÂàÜ‰∏∫‰∏§ÈÉ®ÂàÜÔºö

- ÂØπÂå∫ÂùóÈìæÊï∞ÊçÆÁªìÊûÑÁöÑ‰∫ÜËß£„ÄÇÊØîÂ¶ÇÂú®EVMÈìæ‰∏≠ÔºåÂè™ÊúâEOAË¥¶Êà∑ËÉΩÂèëËµ∑‰∫§ÊòìÔºå‰ΩÜÊòØÊô∫ËÉΩÂêàÁ∫¶Âú®Ë¢´Ë∞ÉÁî®Êó∂ÂèØ‰ª•ËΩ¨Ë¥¶ETHÔºåËøô‰∫õÂÜÖÈÉ®Ë∞ÉÁî®Â∞±ÊòØÈÄöËøátraces Ë°®Êù•ËÆ∞ÂΩïÁöÑÔºåÊâÄ‰ª•Êü•Ë°®Êó∂Êü•transactions‰ºöÈÅóÊºèÂÜÖÈÉ®Ë∞ÉÁî®ÁöÑ‰∫§Êòì„ÄÇ
- ÊéåÊè°Python„ÄÅSQLÁ≠âËØ≠Ë®Ä„ÄÇÊéåÊè°Âü∫Êú¨ÁöÑÊï∞ÊçÆÂ∫ìËØ≠Ë®ÄÔºåÊó†ËÆ∫ÊòØËá™Â∑±Êé•Êï∞ÊçÆÊàñËÄÖÁî®Êï∞ÊçÆÂπ≥Âè∞ÔºåÈÉΩÂèØ‰ª•ÊØîËæÉÂæóÂøÉÂ∫îÊâã„ÄÇ

## ÊúÄÂêé

ÁΩë‰∏äÊúâÂÖ≥Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÁöÑËµÑÊñôÊàñËÄÖÊïôÁ®ã‰∏çÂ∞ëÔºå‰ΩÜÊòØÈÉΩÊØîËæÉÈõ∂Êï£ÔºåË¥®Èáè‰πüÂèÇÂ∑Æ‰∏çÈΩê„ÄÇWeb3ÊòØ‰∏ÄÊâÄÂºÄÊîæÁöÑÂ§ßÂ≠¶Ôºå‰ΩÜÊòØÂæàÂ§öÁ≤æÂäõËä±Ë¥πÂú®ÂØªÊâæÂêàÈÄÇÁöÑÊïôÊùê‰∏äÊòØÊØîËæÉÁóõËã¶ÁöÑÔºåÂêåÊó∂Â§ßÈÉ®ÂàÜÈ´òË¥®ÈáèÁöÑÂÜÖÂÆπÈÉΩÊòØËã±Êñá‰π¶ÂÜôÔºåÂØπÂõΩÂÜÖÁöÑÁî®Êà∑ÊûÑÊàê‰∏ÄÂÆöËØ≠Ë®ÄÈöúÁ¢ç„ÄÇ

Âõ†Ê≠§ÔºåSixdegreeÂõ¢ÈòüÂ∞ÜÊé®Âá∫„ÄäÊàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏à„ÄãÁöÑÁ≥ªÂàóÊïôÁ®ãÔºå‰ª•ÂÆûÈôÖÂ∫îÁî®‰∏∫ÂØºÂêëÔºåÁªìÂêàÂå∫ÂùóÈìæÊï∞ÊçÆÁªìÊûÑÂíåSQLËØ≠Ê≥ïÔºå‰∏∫Â§ßÂÆ∂Êèê‰æõ‰∏ÄÂ•ó‰∏äÊâãÊïôÊùêÔºåÂ∏ÆÂä©Êõ¥Â§öÁöÑ‰∫∫ÊéåÊè°Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÊäÄËÉΩÔºåÊúÄÂ§ßÂåñÂà©Áî®Âå∫ÂùóÈìæÊï∞ÊçÆÁöÑÁâπÊÄßÔºå‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÊ∂àÈô§‰ø°ÊÅØÂ∑Æ„ÄÇÁÜäÂ∏ÇÂ§öBuildÔºåÊàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÂ∞±‰ªéËøôÈáåÂºÄÂßãÂêßÔºÅ

## ÂÖ≥‰∫éÊàë‰ª¨
SixdegreeLabÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫ÊâçÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•Á§æÂå∫‰∫§ÊµÅÔºÅ

## ÂèÇËÄÉËµÑÊñô
1. [The Capital Efficiency Era of DeFi](https://blog.hashflow.com/the-capital-efficiency-era-of-defi-d8b3427feae4)
2. [Using On-Chain Data for Policy Research: Part 1](https://policy.paradigm.xyz/writing/using-on-chain-data-for-policy-research-part-1)
3. [IOSGÔºöËß£ÊûêÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂπ≥Âè∞Áé∞Áä∂‰∏éÂâçÊôØ](https://foresightnews.pro/article/detail/8473)
4. [An Introduction to ¬´On-chain¬ª Analysis](https://www.blockstar.ch/post/an-introduction-to-on-chain-analysis)
5. [The Architecture of a Web 3.0 application](https://www.preethikasireddy.com/post/the-architecture-of-a-web-3-0-application)
6. [Sixdegree Dune Dashborads](https://dune.com/sixdegree)
</file>

<file path="zh/ch02/readme.md">
---
title: 02. Dune‰ªãÁªç
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - query
  - dashboard
---
# 2. DuneÂπ≥Âè∞‰ªãÁªç
ÂâçÊñáÊèêÂà∞‰ªéÊï∞ÊçÆÊ†àËßíÂ∫¶Êù•ÁúãÔºåÂå∫ÂùóÈìæÊï∞ÊçÆ‰∫ßÂìÅÂèØ‰ª•ÂàÜ‰∏∫`Êï∞ÊçÆÊ∫ê`„ÄÅ`Êï∞ÊçÆÂºÄÂèëÂ∑•ÂÖ∑`Âíå`Êï∞ÊçÆapp`‰∏âÁ±ªÔºåÁõ¥Êé•Êé•ÂÖ•Êï∞ÊçÆÊ∫êÊàêÊú¨Â§™È´òÔºåÈöæÂ∫¶‰πüÊõ¥Â§ßÔºåËÄåÊï∞ÊçÆappÂèàÊòØÂõ∫ÂÆöÂ•ΩÁöÑÔºåÊàë‰ª¨Ë¶ÅÊÉ≥ÂàÜÊûêÊï∞ÊçÆÔºå
ÈúÄË¶Å‰∏Ä‰∏™ÂºÄÂèëÂ∑•‰ΩúÈáè‰∏çÂ§ßÔºåÂèàËÉΩÊé•Ëé∑ÂèñÂêÑÁßçÊï∞ÊçÆÁöÑÂπ≥Âè∞ÔºåËøôÁ±ªÊï∞ÊçÆÂºÄÂèëÂ∑•ÂÖ∑‰∏≠ÔºåÊúÄ‰æøÊç∑ÁöÑ‰æøÊòØDuneÂπ≥Âè∞„ÄÇ

[Dune](https://dune.com/)ÊòØ‰∏Ä‰∏™Èìæ‰∏äÁöÑÊï∞ÊçÆÂàÜÊûêÂπ≥Âè∞ÔºåÁî®Êà∑ÂèØ‰ª•Âú®Âπ≥Âè∞‰∏äÈù¢‰π¶ÂÜôSQLËØ≠Âè•Ôºå‰ªéDuneËß£ÊûêÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫ì‰∏≠Á≠õÈÄâÂá∫Ëá™Â∑±ÈúÄË¶ÅÁöÑÊï∞ÊçÆÔºåÂπ∂ÁîüÊàêÂØπÂ∫îÁöÑÂõæË°®ÔºåÁªÑÊàê‰ª™Ë°®Áõò„ÄÇ

Êú¨ÊïôÁ®ãÁöÑÂÖ®ÈÉ®Êü•ËØ¢Á§∫‰æãÂíåÂºïÁî®ÁöÑÁõ∏ÂÖ≥Êü•ËØ¢ÔºàÂÆåÊï¥ÁöÑÊï∞ÊçÆÁúãÊùøÂíåÁ¨¨‰∏âÊñπË¥¶Âè∑ÁöÑÊü•ËØ¢Èô§Â§ñÔºâÂÖ®ÈÉ®‰ΩøÁî®Dune SQLÊü•ËØ¢ÂºïÊìéÊµãËØïÈÄöËøá„ÄÇDuneÂ∑≤ÁªèÂÆ£Â∏É2023Âπ¥ÂÜÖÂÖ®Èù¢ËøáÊ∏°Âà∞Dune SQLÂºïÊìéÔºåÊâÄ‰ª•Â§ßÂÆ∂Áõ¥Êé•Â≠¶‰π†Dune SQLÁöÑËØ≠Ê≥ïÂç≥ÂèØ„ÄÇ

## È°µÈù¢‰ªãÁªç

Âú®Ê≥®ÂÜåÂÆåDuneÂπ≥Âè∞ÂêéÔºåÂπ≥Âè∞ÁöÑ‰∏ªÁïåÈù¢Â¶Ç‰∏ãÔºåÂÖ∑‰ΩìÁöÑÂêÑÈ°πÂäüËÉΩÔºö

- **Discover**ÔºöÊòØÂ±ïÁ§∫Âπ≥Âè∞ÁöÑÂêÑ‰∏™ÊñπÈù¢Ë∂ãÂäø
  - **Dashboard**ÔºöÊòæÁ§∫ÂΩìÂâçÂÖ≥Ê≥®ÈáèÊúÄÂ§öÁöÑdashboardÔºåÂú®Ëøô‰∏™ÁïåÈù¢ÔºåÂèØ‰ª•Â∑¶‰∏äËßíÁöÑÊêúÁ¥¢/Âè≥‰æßÁöÑÊêúÁ¥¢Ê°ÜÊêúÁ¥¢Ëá™Â∑±ÊÑüÂÖ¥Ë∂£ÁöÑÂÖ≥ÈîÆËØçÔºåËøô‰πüÊòØÊúÄÈáçË¶ÅÁöÑ‰∏Ä‰∏™ÈÉ®ÂàÜÔºåÂèØ‰ª•ÁÇπÂáª‰∏Ä‰∏™dashboardÔºåÊü•ÁúãÂà´‰∫∫Âà∂‰ΩúÁöÑdashboard
  - QueriesÔºöÊòæÁ§∫ÁöÑÊòØÂΩìÂâçÂÖ≥Ê≥®ÈáèÊúÄÂ§öÁöÑqueryÔºåÂú®Ëøô‰∏™ÁïåÈù¢ÔºåÂèØ‰ª•Â∑¶‰∏äËßíÁöÑÊêúÁ¥¢/Âè≥‰æßÁöÑÊêúÁ¥¢Ê°ÜÊêúÁ¥¢Ëá™Â∑±ÊÑüÂÖ¥Ë∂£ÁöÑÂÖ≥ÈîÆËØçÔºõ
  - WizardsÔºöÂπ≥Âè∞‰∏≠Êî∂ËóèÈáèÊúÄÈ´òÁöÑÁî®Êà∑ÊéíÂêçÔºõ
  - TeamsÔºöÂπ≥Âè∞‰∏≠Êî∂ËóèÈáèÊúÄÈ´òÁöÑÂõ¢ÈòüÊéíÂêçÔºõ
- FavoritesÔºö
  - DashboardÔºöËá™Â∑±Êî∂ËóèÁöÑdashboardÔºåÂèØ‰ª•Âú®Âè≥‰æßÊêúÁ¥¢Ê°ÜÊêúÁ¥¢
  - QueriesÔºöËá™Â∑±Êî∂ËóèÁöÑqueryÔºåÂèØ‰ª•Âú®Âè≥‰æßÊêúÁ¥¢Ê°ÜÊêúÁ¥¢
- **My Creations**Ôºö
  - DashboardÔºöËá™Â∑±ÂàõÂª∫ÁöÑdashboardÔºåÂèØ‰ª•Âú®Âè≥‰æßÊêúÁ¥¢Ê°ÜÊêúÁ¥¢ÔºåÂ¶ÇÊûú‰Ω†ÊúâÂõ¢ÈòüÔºå‰ª™Ë°®ÁõòÂèØ‰ª•Âú®‰∏çÂêåÁöÑÂõ¢Èòü‰∏≠
  - QueriesÔºöËá™Â∑±ÂàõÂª∫ÁöÑqueryÔºåÂèØ‰ª•Âú®Âè≥‰æßÊêúÁ¥¢Ê°ÜÊêúÁ¥¢
  - ContractsÔºöËá™Â∑±Êèê‰∫§Ëß£ÊûêÁöÑÂêàÁ∫¶ÔºåÂèØ‰ª•Âú®Âè≥‰æßÊêúÁ¥¢Ê°ÜÊêúÁ¥¢
- **New Query**ÔºöÊñ∞Âª∫‰∏Ä‰∏™Êü•ËØ¢
- ÂÖ∂ÂÆÉ
  - DocsÔºöÈìæÊé•Âà∞Â∏ÆÂä©ÊñáÊ°£
  - DiscordÔºöÈìæÊé•Âà∞Á§æÂå∫ËÆ®ËÆ∫ÁªÑ

![](img/main-page.png)

## Ê†∏ÂøÉÂäüËÉΩ

### Êü•ËØ¢Query

Âú®ÁÇπÂáª`New Query` ‰πãÂêéÔºå‰ºöËøõÂÖ•‰∏Ä‰∏™Êñ∞ÁöÑÁïåÈù¢ÔºåÁïåÈù¢ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºö

- Êï∞ÊçÆË°®ÁõÆÂΩïÔºöÂú®Â∑¶‰æßÊúâ‰∏Ä‰∏™`Êï∞ÊçÆÊêúÁ¥¢Ê°Ü`Âíå`Êï∞ÊçÆÂàóË°®`ÔºåÂ±ïÂºÄÊï∞ÊçÆÂàóË°®ÂêéÂèØ‰ª•ÁúãÂà∞ÂÖ∑‰ΩìÁöÑÊØè‰∏ÄÂº†Ë°®„ÄÇÔºàÊ≥®ÔºöÂú®Á¨¨‰∏ÄÊ¨°ËøõÂÖ•ÊòæÁ§∫ÁöÑÊòØv1ÁâàÊú¨ÁöÑÔºåÂ∑≤ÂºÉÁî®ÔºåËØ∑Âú®‰∏äÈù¢ÈÄâÊã©`Dune Engine v2(SparkSQL)`Ôºâ
  - RawÔºöËÆ∞ÂΩï‰∫ÜÂêÑ‰∏™Âå∫ÂùóÈìæÁöÑÂéüÂßãÊï∞ÊçÆË°®Ôºå‰∏ªË¶Å‰∏∫Âå∫Âùó‰ø°ÊÅØblocks„ÄÅ‰∫§Êòì‰ø°ÊÅØtransactions„ÄÅ‰∫ã‰ª∂Êó•Âøó‰ø°ÊÅØlogsÂíåtracesË°®Á≠âÔºõÁõÆÂâçÊîØÊåÅÁöÑÈìæÊúâÔºöEthereum„ÄÅPolygon„ÄÅArbitrum„ÄÅSolana„ÄÅOptimism„ÄÅGnosis Chain„ÄÅAvalanche
  - Decoded projectsÔºöÂêÑ‰∏™È°πÁõÆ/ÂêàÁ∫¶ÁöÑÁõ¥Êé•Ëß£ÊûêË°®ÔºåËß£ÊûêÂá∫Êù•ÁöÑË°®‰ºöÊõ¥Âä†Ê∏ÖÊô∞ÊòìÊáÇÔºåÂ¶ÇÊûúÂàÜÊûêÂÖ∑‰ΩìÈ°πÁõÆÁî®ËøôÈáåÁöÑË°®‰ºöÊõ¥Âä†ÂêàÈÄÇ
  - SpellsÔºöÊòØ‰ªérawÂíåDecoded projects‰∏≠ÊèêÂèñÁöÑÁªºÂêàÊï∞ÊçÆË°®ÔºåÊØîÂ¶ÇDexÔºåNFTÔºåERC20Á≠âÁ≠â
  - CommunityÔºöÁ§æÂå∫Áî®Êà∑Ë¥°ÁåÆÁöÑÊï∞ÊçÆË°®

- ‰ª£Á†ÅÁºñËæëÂô®Ôºö‰Ωç‰∫éÂè≥‰∏äÊñπÁöÑÈªëËâ≤Âå∫ÂüüÔºåÁî®‰∫éÂÜôËá™Â∑±ÁöÑSQLËØ≠Âè•ÔºåÂÜôÂÆåÂèØ‰ª•ÁÇπÂáªÂè≥‰∏ãËßíÁöÑ`Run`ÊâßË°å
- ÁªìÊûú&ÂõæË°®ÂèØËßÜÂåñÔºö‰Ωç‰∫éÂè≥‰∏ãÊñπÔºåÊü•ËØ¢ÁªìÊûú‰ºöÊòæÁ§∫Âú®`Query results`ÔºåÂèØ‰ª•‰æùÊ¨°Âú®ÂêéÈù¢Êñ∞Âª∫Êñ∞ÁöÑÂ≠êÂèØËßÜÂåñÈ°µÈù¢

![query-page](img/query-page.png)

Âπ≥Âè∞ÁöÑqueryÂèØ‰ª•ÈÄöËøáÂàÜÊîØforkÁöÑÊñπÂºèÔºåÂ∞ÜÂà´‰∫∫ÁöÑqueryÂ§çÂà∂Âà∞Ëá™Â∑±ÁöÑË¥¶Êà∑‰∏ãÔºåËøõË°å‰øÆÊîπÂíåÁºñËæë„ÄÇ

**spellbook**

spellbookÊòØDuneÂπ≥Âè∞ÈùûÂ∏∏ÈáçË¶ÅÁöÑ‰∏Ä‰∏™Êï∞ÊçÆË°®ÔºåÂÆÉÊòØÁî±Á§æÂå∫Áî®Êà∑Ë¥°ÁåÆÁöÑ‰∏ÄÁ≥ªÂàóÂä†Â∑•ÂêéÁöÑÊï∞ÊçÆË°®ÔºåÂèØ‰ª•Âú®githubÈ°µÈù¢[duneanalytics/spellbook](https://github.com/duneanalytics/spellbook)Ë¥°ÁåÆËá™Â∑±ÂÆö‰πâÁöÑÊï∞ÊçÆË°®ÔºåduneÂπ≥Âè∞‰ºöÈÄöËøáËØ•ÂÆö‰πâÔºåÂú®ÂêéÂè∞ÁîüÊàêÁõ∏Â∫îÁöÑÊï∞ÊçÆÔºåÂú®‰∏äÂõæÁöÑÂâçÁ´ØÈ°µÈù¢‰∏≠ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®Ëøô‰∫õÂÆö‰πâÂ•ΩÁöÑÊï∞ÊçÆË°®ÔºåËøô‰∫õÊï∞ÊçÆË°®ÁöÑÂÆö‰πâÂíåÂ≠óÊÆµÊÑè‰πâÂèØ‰ª•Âà∞ËøôÈáåÊü•ÁúãÔºö[https://spellbook-docs.dune.com/#!/overview](https://spellbook-docs.dune.com/#!/overview)

ÁõÆÂâçspellbook‰∏≠Â∑≤ÁªèÁî±Á§æÂå∫Áî®Êà∑Ë¥°ÁåÆ‰∫ÜÂá†ÁôæÂº†ÂêÑÁßçÂêÑÊ†∑ÁöÑË°®ÔºåÊØîÂ¶Çnft.trades, dex.trades, tokens.erc20Á≠âÁ≠â

![](img/spellbook.png)

**ÂèÇÊï∞**

Âú®query‰∏≠ËøòÂèØ‰ª•ËÆæÁΩÆ‰∏Ä‰∏™ÂèØÂèòÁöÑËæìÂÖ•ÂèÇÊï∞ÔºåÊîπÂèòÊü•ËØ¢Êù°‰ª∂ÔºåÊØîÂ¶ÇÂèØ‰ª•ËÆæÁΩÆ‰∏çÂêåÁöÑÁî®Êà∑Âú∞ÂùÄÔºåÊàñËÄÖËÆæÁΩÆ‰∏çÂêåÁöÑÊó∂Èó¥ËåÉÂõ¥ÔºåÂèÇÊï∞ËÆæÁΩÆÊòØ‰ª•`'{{ÂèÇÊï∞ÂêçÁß∞}}'`ÂΩ¢ÂºèÂµåÂÖ•Âà∞Êü•ËØ¢ËØ≠Âè•‰∏≠ÁöÑ„ÄÇ

![](img/query-params.png)

### ÂõæË°®ÂèØËßÜÂåñVisualization

Âú®ÂõæË°®ÂèØËßÜÂåñ‰∏≠ÔºåDuneÂπ≥Âè∞Êèê‰æõ‰∫ÜÊï£ÁÇπÂõæ„ÄÅÊü±Áä∂Âõæ„ÄÅÊäòÁ∫øÂõæ„ÄÅÈ•ºÁä∂Âõæ„ÄÅÈù¢ÁßØÂõæÂíåËÆ°Êï∞Âô®‰ª•Âèä‰∫åÁª¥Êï∞ÊçÆË°®„ÄÇÂú®ÊâßË°åÂÆåÊü•ËØ¢ÔºåÂæóÂà∞ÁªìÊûú‰πãÂêéÔºåÂèØ‰ª•ÈÄâÊã©`New visualization` ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÂèØËßÜÂåñÂõæÔºåÂú®Âõæ‰∏≠ÂèØ‰ª•ÈÄâÊã©ÊÉ≥Ë¶ÅÊòæÁ§∫ÁöÑÊï∞ÊçÆÂ≠óÊÆµÔºåÂèØ‰ª•Á´ãÂàªÂæóÂà∞ÂØπÂ∫îÁöÑÂèØËßÜÂåñÂõæÔºåÂõæ‰∏≠ÊîØÊåÅÊòæÁ§∫Â§ö‰∏™Áª¥Â∫¶ÁöÑÊï∞ÊçÆÔºåÂú®ÂõæË°®‰∏ãÊñπÊòØËÆæÁΩÆÂõæË°®Ê†∑ÂºèÁöÑÂå∫ÂüüÔºåÂåÖÊã¨ÂêçÁß∞„ÄÅÂùêÊ†áËΩ¥Ê†ºÂºè„ÄÅÈ¢úËâ≤Á≠â‰ø°ÊÅØ„ÄÇ

![](img/visualization.png)

 ### ‰ª™Ë°®ÁõòDashboard

‰∏ä‰∏ÄÂ∞èËäÇÁöÑÂçï‰∏™ÂõæË°®ÂèØËßÜÂåñÔºåÂèØ‰ª•Âú®‰ª™Ë°®Áõò‰∏≠ÁÅµÊ¥ªÁöÑÁªÑÂêàÔºåÂΩ¢Êàê‰∏Ä‰∏™Êï∞ÊçÆÊåáÊ†áÁöÑËÅöÂêàÁúãÊùøÔºåÂπ∂ÈôÑÂ∏¶Ëß£ÈáäËØ¥ÊòéÔºåËøôÊ†∑ÂèØ‰ª•‰ªé‰∏Ä‰∏™Êõ¥Âä†ÂÖ®Èù¢ÁöÑËßíÂ∫¶ÂéªËØ¥Êòé„ÄÇÂú®`Discover`‰∏≠ÊâæÂà∞`New Dashboard`ÂèØ‰ª•Êñ∞Âª∫‰∏Ä‰∏™‰ª™Ë°®ÁõòÔºåÂú®‰ª™Ë°®Áõò‰∏≠ÂèØ‰ª•Ê∑ªÂä†ÊâÄÊúâquery‰∏≠ÁîüÊàêÁöÑÂõæË°®ÔºåÂπ∂‰∏îÂèØ‰ª•Ê∑ªÂä†markdownÊ†ºÂºèÁöÑÊñáÊú¨‰ø°ÊÅØÔºåÊØè‰∏™ÂèØËßÜÂåñÁöÑÊéß‰ª∂ÈÉΩÂèØ‰ª•ÊãñÊãΩÂπ∂Ë∞ÉÊï¥Â§ßÂ∞è„ÄÇ



![](img/dashboard.png)


### DuneÁõ∏ÂÖ≥ËµÑÊñô
- ÂÆòÊñπËµÑÊñô
  - [DuneÂÆòÊñπÊñáÊ°£ÔºàÂåÖÊã¨‰∏≠ÊñáÊñáÊ°£Ôºâ](https://dune.com/docs/)
  - [Discord](https://discord.com/invite/ErrzwBz)
  - [Youtube](https://www.youtube.com/channel/UCPrm9d2hLd_YxSExH7oRyAg)
  - [Github Spellbook](https://github.com/duneanalytics/spellbook)
- Á§æÂå∫ÊïôÁ®ã
  - [Dune Êï∞ÊçÆÁúãÊùøÈõ∂Âü∫Á°ÄÊûÅÁÆÄÂÖ•Èó®ÊåáÂçó](https://twitter.com/gm365/status/1525013340459716608)
  - [DuneÂÖ•Èó®ÊåáÂçó‚Äî‚Äî‰ª•Pooly‰∏∫‰æãÔºåÂÅö‰∏Ä‰∏™NFTÁúãÊùø](https://mirror.xyz/0xa741296A1E9DDc3D6Cf431B73C6225cFb5F6693a/iVzr5bGcGKKCzuvl902P05xo7fxc2qWfqfIHwmCXDI4)
  - [‰ªé0Âà∞1ÊûÑÂª∫‰Ω†ÁöÑDune V1 AnalyticsÁúãÊùøÔºàÂü∫Á°ÄÁØáÔºâ](https://mirror.xyz/0xbi.eth/6cbedGOx0GwZdvuxHeyTAgn333jaT34y-2qryvh8Fio)
  - [‰ªé0Âà∞1ÊûÑÂª∫‰Ω†ÁöÑDune V1 AnalyticsÁúãÊùøÔºàÂÆûÊàòÁØáÔºâ](https://mirror.xyz/0xbi.eth/603BIaKXn7s2_7A84oayY_Fn5XUPh6zDsv2OlQTdzCg)
  - [‰ªé0Âà∞1ÊûÑÂª∫‰Ω†ÁöÑDune V1 AnalyticsÁúãÊùøÔºàÂ∏∏Áî®Ë°®ÁªìÊûÑÔºâ](https://mirror.xyz/0xbi.eth/uSr336PzXtqMuE_LPBewbJ1CHN2oUs40-TDET2rnkqU)
</file>

<file path="zh/ch03/readme.md">
---
title: 03. Êñ∞Êâã‰∏äË∑Ø
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - SQL
  - erc20
---
# 3. Êï∞ÊçÆÂàÜÊûêÊñ∞Êâã‰∏äË∑Ø

## ÂÜôÂú®ÂâçÈù¢

Êàë‰ª¨ÁöÑÊïôÁ®ãÂÅèÈáçÂÆûÊàòÔºåÁªìÂêàÊó•Â∏∏Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÁöÑÂú∫ÊôØ‰∏éÈúÄÊ±ÇÊù•ÁºñÂÜô„ÄÇÊú¨ÊñáÂ∞Ü‰∏∫Â§ßÂÆ∂ËÆ≤Ëß£ÂºÄÂßãÂàõÂª∫Êï∞ÊçÆÁúãÊùø‰πãÂâçÈúÄË¶ÅÁÜüÊÇâÁöÑÁõ∏ÂÖ≥SQLÂü∫Á°ÄÁü•ËØÜ„ÄÇÊú¨ÊïôÁ®ã‰∏∫ÂÖ•Èó®Á∫ßÔºå‰∏ªË¶ÅÈù¢ÂêëÂ∏åÊúõÂ≠¶‰π†Êï∞ÊçÆÂàÜÊûêÁöÑÊñ∞ÊâãÁî®Êà∑„ÄÇÊàë‰ª¨ÂÅáÂÆöÊÇ®‰πãÂâçÂπ∂Êó†ÁºñÂÜôSQLÊü•ËØ¢ÁöÑÁªèÈ™åÔºåÊúâSQLÁªèÈ™å‰ΩÜ‰∏çÁÜüÊÇâDuneÂπ≥Âè∞ÁöÑÁî®Êà∑‰πüÂèØÂø´ÈÄüÊµèËßàÊú¨ÊïôÁ®ã„ÄÇÊú¨ÁØáÊïôÁ®ã‰∏ªË¶ÅÂåÖÊã¨DuneÂπ≥Âè∞ÁÆÄ‰ªã„ÄÅSQLÊü•ËØ¢Âø´ÈÄüÂÖ•Èó®Á≠âÂÜÖÂÆπ„ÄÇÂú®‰∏ã‰∏ÄÁØáÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰∏ÄËµ∑ÁºñÂÜôÊü•ËØ¢Âπ∂ÂàõÂª∫ÂèØËßÜÂåñÂõæË°®„ÄÅ‰ΩøÁî®Êü•ËØ¢ÂõæË°®ÂàõÂª∫Êï∞ÊçÆÁúãÊùø„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÂè™Ë¶Å‰Ω†Êúâ‰ø°ÂøÉÂπ∂Ë∑üÈöèÊàë‰ª¨ÁöÑÊïôÁ®ãÂä®ÊâãÂÆûË∑µÔºå‰Ω†‰πüÂèØ‰ª•ÂÅöÂá∫È´òË¥®ÈáèÁöÑÊï∞ÊçÆÁúãÊùøÔºåËøàÂá∫Êàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ

## Dune Âπ≥Âè∞ÁÆÄ‰ªã

[Dune](https://dune.com/)ÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂàÜÊûêÂπ≥Âè∞Ôºå‰ª•SQLÊï∞ÊçÆÂ∫ìÁöÑÊñπÂºèÊèê‰æõÂéüÂßãÂå∫ÂùóÈìæÊï∞ÊçÆÂíåÂ∑≤Ëß£ÊûêÁöÑÊï∞ÊçÆ„ÄÇÈÄöËøá‰ΩøÁî®SQLÊü•ËØ¢ÔºåÊàë‰ª¨ÂèØ‰ª•‰ªéDuneÁöÑÊï∞ÊçÆÂ∫ì‰∏≠Âø´ÈÄüÊêúÁ¥¢ÂíåÊèêÂèñÂêÑÁßçÂå∫ÂùóÈìæ‰ø°ÊÅØÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Áõ¥ËßÇÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇ‰ª•Ê≠§Êù•Ëé∑Âæó‰ø°ÊÅØÂíåËßÅËß£„ÄÇÊï∞ÊçÆÁúãÊùøÔºàDashboardÔºâÊòØDune‰∏äÂÜÖÂÆπÁöÑËΩΩ‰ΩìÔºåÁî±ÂêÑÁßçÂ∞èÈÉ®‰ª∂ÔºàWidgetÔºâÁªÑÊàê„ÄÇËøô‰∫õÂ∞èÈÉ®‰ª∂ÂèØ‰ª•ÊòØ‰ªéQueryÊü•ËØ¢ÁªìÊûúÁîüÊàêÁöÑÂèØËßÜÂåñÂõæË°®ÊàñÊñáÊú¨Ê°ÜÔºå‰Ω†ËøòÂèØ‰ª•Âú®ÊñáÊú¨Ê°Ü‰∏≠ÂµåÂÖ•ÂõæÂÉè„ÄÅÈìæÊé•Á≠â„ÄÇÊü•ËØ¢ÔºàQueryÔºâÊòØDuneÊï∞ÊçÆÈù¢ÊùøÁöÑ‰∏ªË¶ÅÊï∞ÊçÆÊù•Ê∫ê„ÄÇÊàë‰ª¨ÈÄöËøáÁºñÂÜôSQLËØ≠Âè•ÔºåÊâßË°åÊü•ËØ¢Âπ∂Âú®ÁªìÊûúÈõÜ‰∏äÁîüÊàêÂèØËßÜÂåñÂõæË°®ÔºåÂÜçÂ∞ÜÂõæË°®Ê∑ªÂä†Âà∞ÂØπÂ∫îÁöÑÊï∞ÊçÆÁúãÊùø‰∏≠„ÄÇ

‰ΩøÁî®DuneÂ§ÑÁêÜÊï∞ÊçÆÁöÑ‰∏ÄËà¨ËøáÁ®ãÂèØ‰ª•Ê¶ÇÊã¨‰∏∫ÔºöÁºñÂÜôSQLÊü•ËØ¢ÊòæÁ§∫Êï∞ÊçÆ -„ÄãÂèØËßÜÂåñÊü•ËØ¢ÁªìÊûú -„ÄãÂú®Êï∞ÊçÆÁúãÊùø‰∏≠ÁªÑË£ÖÂèØËßÜÂåñÂõæË°® -„ÄãË∞ÉÊï¥ÁæéÂåñÊï∞ÊçÆÁúãÊùø„ÄÇÂÖ≥‰∫éDuneÂπ≥Âè∞ÁöÑ‰ΩøÁî®ÔºåÂèØ‰ª•Êü•ÁúãÂÖ∂[ÂÆòÊñπÊñáÊ°£](https://dune.com/docs/)„ÄÇDuneÊúÄÊñ∞ÊñáÊ°£ÁöÑ‰∏≠ÊñáÁâàÊú¨ÁõÆÂâçÊ≠£Âú®ÁøªËØëÊï¥ÁêÜ‰∏≠Ôºå‰Ω†ÂèØ‰ª•Âú®ËøôÈáåÊâæÂà∞V1ÁâàÊú¨ÁöÑ[Dune‰∏≠ÊñáÊñáÊ°£](https://docs.dune.com/v/chinese/)„ÄÇ

## Êï∞ÊçÆÂ∫ìÂü∫Á°ÄÁü•ËØÜ

Âú®ÂºÄÂßãÁºñÂÜôÊàë‰ª¨ÁöÑÊï∞ÊçÆÁúãÊùøÊâÄÈúÄÁöÑÁ¨¨‰∏Ä‰∏™SQLÊü•ËØ¢‰πãÂâçÔºåÊàë‰ª¨ÈúÄË¶ÅÂÖà‰∫ÜËß£‰∏Ä‰∫õÂøÖÂ§áÁöÑSQLÊü•ËØ¢Âü∫Á°ÄÁü•ËØÜ„ÄÇ

### Êï∞ÊçÆÂ∫ìÁöÑÂü∫Êú¨Ê¶ÇÂøµ‰ªãÁªç

**Êï∞ÊçÆÂ∫ìÔºàDatabaseÔºâ**ÔºöÊï∞ÊçÆÂ∫ìÊòØÁªìÊûÑÂåñ‰ø°ÊÅØÊàñÊï∞ÊçÆÁöÑÊúâÂ∫èÈõÜÂêàÔºåÊòØÊåâÁÖßÊï∞ÊçÆÁªìÊûÑÊù•ÁªÑÁªá„ÄÅÂ≠òÂÇ®ÂíåÁÆ°ÁêÜÊï∞ÊçÆÁöÑ‰ªìÂ∫ì„ÄÇDuneÂπ≥Âè∞ÁõÆÂâçÊèê‰æõ‰∫ÜÂ§ö‰∏™Êï∞ÊçÆÂ∫ìÔºåÂàÜÂà´ÊîØÊåÅÊù•Ëá™‰∏çÂêåÂå∫ÂùóÈìæÁöÑÊï∞ÊçÆ„ÄÇÊú¨ÊïôÁ®ã‰ΩøÁî®DuneÂπ≥Âè∞ÁöÑ‚Äúv2 Dune SQL‚ÄùÊï∞ÊçÆÂ∫ìÊü•ËØ¢ÂºïÊìé„ÄÇÊâÄÊúâÁ§∫‰æãÊü•ËØ¢ÂíåÂºïÁî®ÁöÑ‰æãÂ≠êÈìæÊé•ÔºàÁ¨¨‰∏âÊñπÁöÑqueryÈô§Â§ñÔºâÂùá‰ª•Êõ¥Êñ∞Âà∞Dune SQL„ÄÇ

**Ê®°ÂºèÔºàSchemaÔºâ**ÔºöÂêå‰∏Ä‰∏™Êï∞ÊçÆÂ∫ì‰∏≠ÔºåÂèØ‰ª•ÂÆö‰πâÂ§ö‰∏™Ê®°Âºè„ÄÇÊàë‰ª¨ÊöÇÊó∂ÂèØ‰ª•Â∞ÜÊ®°ÂºèÁÆÄÂçïÁêÜËß£‰∏∫Êï∞ÊçÆË°®ÁöÑÊã•ÊúâËÄÖÔºàOwnerÔºâ„ÄÇ‰∏çÂêåÁöÑÊ®°Âºè‰∏ãÂèØ‰ª•Â≠òÂú®Áõ∏ÂêåÂêçÁß∞ÁöÑÊï∞ÊçÆË°®„ÄÇ

**Êï∞ÊçÆË°®ÔºàTableÔºâ**ÔºöÊï∞ÊçÆË°®ÊòØÁî±Ë°®Âêç„ÄÅË°®‰∏≠ÁöÑÂ≠óÊÆµÂíåË°®ÁöÑËÆ∞ÂΩï‰∏â‰∏™ÈÉ®ÂàÜÁªÑÊàêÁöÑ„ÄÇÊï∞ÊçÆË°®ÊòØÊàë‰ª¨ÁºñÂÜôSQLÊü•ËØ¢ËÆøÈóÆÁöÑ‰∏ªË¶ÅÂØπË±°„ÄÇDuneÂ∞ÜÊù•Ëá™‰∏çÂêåÂå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂàÜÂà´Â≠òË¥ÆÂà∞‰∏çÂêåÊ®°Âºè‰∏ãÁöÑÂ§ö‰∏™Êï∞ÊçÆË°®‰∏≠‰æõÊàë‰ª¨Êü•ËØ¢‰ΩøÁî®„ÄÇ‰ΩøÁî®Êï∞ÊçÆË°®ÁºñÂÜôÊü•ËØ¢Êó∂ÔºåÊàë‰ª¨Áî®`schema_name.table_name`ÁöÑÊ†ºÂºèÊù•ÊåáÂÆöÊü•ËØ¢Ë¶Å‰ΩøÁî®ÁöÑÊï∞ÊçÆË°®ÂêçÁß∞„ÄÇ‰æãÂ¶Ç`ethereum.transactions`Ë°®Á§∫`ethereum`Ê®°Âºè‰∏ãÁöÑ`transactions`Ë°®ÔºåÂç≥‰ª•Â§™ÂùäÁöÑ‰∫§ÊòìË°®„ÄÇÂêå‰∏Ä‰∏™Ê®°Âºè‰∏ãÁöÑÊï∞ÊçÆË°®ÂêçÁß∞ÂøÖÈ°ªÂîØ‰∏ÄÔºå‰ΩÜÊòØÁõ∏ÂêåÂêçÁß∞ÁöÑÊï∞ÊçÆË°®ÂèØ‰ª•ÂêåÊó∂Â≠òÂú®‰∫éÂ§ö‰∏™‰∏çÂêåÁöÑÊ®°Âºè‰∏ã„ÄÇ‰æãÂ¶ÇV2‰∏≠ÂêåÊó∂Â≠òÂú®`ethereum.transactions`Âíå`bnb.transactions`Ë°®„ÄÇ

**Êï∞ÊçÆÂàóÔºàColumnÔºâ**ÔºöÊï∞ÊçÆÂàó‰πüÁß∞‰∏∫Â≠óÊÆµÔºàFieldÔºâÔºåÊúâÊó∂‰πüÁÆÄÁß∞‰∏∫‚ÄúÂàó‚ÄùÔºåÊòØÊï∞ÊçÆË°®Â≠òË¥ÆÊï∞ÊçÆÁöÑÂü∫Êú¨Âçï‰Ωç„ÄÇÊØè‰∏Ä‰∏™Êï∞ÊçÆË°®ÈÉΩÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÂàóÔºåÂàÜÂà´Â≠òË¥Æ‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆ„ÄÇÁºñÂÜôÊü•ËØ¢Êó∂ÔºåÊàë‰ª¨ÂèØ‰ª•ËøîÂõûÂÖ®ÈÉ®ÂàóÊàñËÄÖÂè™ËøîÂõûÈúÄË¶ÅÁöÑÊï∞ÊçÆÂàó„ÄÇÈÄöÂ∏∏ÔºåÂè™ËøîÂõûÈúÄË¶ÅÁöÑÊúÄÂ∞ëÊï∞ÊçÆÂèØ‰ª•ÊèêÂçáÊü•ËØ¢ÁöÑÊïàÁéá„ÄÇ

**Êï∞ÊçÆË°åÔºàRowÔºâ**ÔºöÊï∞ÊçÆË°å‰πüÁß∞‰∏∫ËÆ∞ÂΩïÔºàRecordÔºâ„ÄÇÊØè‰∏Ä‰∏™ËÆ∞ÂΩïÂåÖÊã¨Êï∞ÊçÆË°®ÂÆö‰πâÁöÑÂ§ö‰∏™ÂàóÁöÑÊï∞ÊçÆ„ÄÇSQLÊü•ËØ¢ÊâßË°åÂæóÂà∞ÁöÑÁªìÊûúÂ∞±ÊòØ‰∏Ä‰∏™ÊàñÂ§ö‰∏™ËÆ∞ÂΩï„ÄÇÊü•ËØ¢ËæìÂá∫ÁöÑËÆ∞ÂΩïÈõÜÈÄöÂ∏∏‰πüË¢´Áß∞‰∏∫ÁªìÊûúÈõÜÔºàResultsÔºâ„ÄÇ

### Êú¨ÊïôÁ®ã‰ΩøÁî®ÁöÑÊï∞ÊçÆË°®

Âú®Êú¨ËäÇÁöÑSQLÊü•ËØ¢Á§∫‰æã‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®ERC20‰ª£Â∏ÅË°®`tokens.erc20`ÂÅö‰æãÂ≠ê„ÄÇERC20‰ª£Â∏ÅË°®ÊòØÁî±DuneÁ§æÂå∫Áî®Êà∑ÈÄöËøáÈ≠îÊ≥ï‰π¶ÔºàSpellbookÔºâÊñπÂºèÁîüÊàêÁöÑÊäΩË±°Êï∞ÊçÆË°®ÔºàSpellsÔºå‰πüÁß∞‰∏∫AbstractionsÔºâ„ÄÇÈô§‰∫ÜÁîüÊàêÊñπÂºè‰∏çÂêåÔºåËøôÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆË°®ÁöÑ‰ΩøÁî®ÊñπÂºèË∑üÂÖ∂‰ªñË°®ÂÆåÂÖ®‰∏ÄÊ†∑„ÄÇERC20‰ª£Â∏ÅË°®‰øùÂ≠ò‰∫ÜDuneÊîØÊåÅÊ£ÄÁ¥¢ÁöÑ‰∏çÂêåÂå∫ÂùóÈìæ‰∏äÈù¢ÁöÑÂÖºÂÆπERC20Ê†áÂáÜÁöÑ‰∏ªÊµÅ‰ª£Â∏ÅÁöÑ‰ø°ÊÅØ„ÄÇÂØπ‰∫éÊØèÁßç‰ª£Â∏ÅÔºåÂàÜÂà´ËÆ∞ÂΩï‰∫ÜÂÖ∂ÂΩíÂ±ûÁöÑÂå∫ÂùóÈìæ„ÄÅ‰ª£Â∏ÅÂêàÁ∫¶Âú∞ÂùÄ„ÄÅ‰ª£Â∏ÅÊîØÊåÅÁöÑÂ∞èÊï∞‰ΩçÊï∞Âíå‰ª£Â∏ÅÁ¨¶Âè∑‰ø°ÊÅØ„ÄÇ

ERC20‰ª£Â∏ÅË°®`tokens.erc20`ÁöÑÁªìÊûÑÂ¶Ç‰∏ãÔºö

| **ÂàóÂêç**                 | **Êï∞ÊçÆÁ±ªÂûã**   | **ËØ¥Êòé**                                    |
| ----------------------- | ------------- | ------------------------------------------ |
| blockchain              | string        | ‰ª£Â∏ÅÂΩíÂ±ûÁöÑÂå∫ÂùóÈìæÂêçÁß∞                           |
| contract\_address       | string        | ‰ª£Â∏ÅÁöÑÂêàÁ∫¶Âú∞ÂùÄ                                |
| decimals                | integer       | ‰ª£Â∏ÅÊîØÊåÅÁöÑÂ∞èÊï∞‰ΩçÊï∞                             |
| symbol                  | string        | ‰ª£Â∏ÅÁöÑÁ¨¶Âè∑                                    |

## SQLÊü•ËØ¢Âø´ÈÄüÂÖ•Èó®

Âπø‰πâÁöÑSQLÊü•ËØ¢ËØ≠Âè•Á±ªÂûãÂåÖÊã¨Êñ∞Â¢ûÔºàInsertÔºâ„ÄÅÂà†Èô§ÔºàDeleteÔºâ„ÄÅ‰øÆÊîπÔºàUpdateÔºâ„ÄÅÊü•ÊâæÔºàSelectÔºâÁ≠âÂ§ö‰∏™Á±ªÂûã„ÄÇÁã≠‰πâÁöÑSQLÊü•ËØ¢‰∏ªË¶ÅÊåá‰ΩøÁî®SelectËØ≠Âè•ËøõË°åÊï∞ÊçÆÊ£ÄÁ¥¢„ÄÇÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÁªùÂ§ßÂ§öÊï∞Êó∂ÂÄôÂè™ÈúÄ‰ΩøÁî®SelectËØ≠Âè•Â∞±ËÉΩÂÆåÊàêÂ∑•‰ΩúÔºåÊâÄ‰ª•Êàë‰ª¨ËøôÈáåÂè™‰ªãÁªçSelectÊü•ËØ¢ËØ≠Âè•„ÄÇÂêéÁª≠ÂÜÖÂÆπ‰∏≠Êàë‰ª¨‰ºö‰∫§Êõø‰ΩøÁî®Êü•ËØ¢„ÄÅQuery„ÄÅSelectÁ≠âËØçÊ±áÔºåÂ¶ÇÊó†ÁâπÂà´ËØ¥ÊòéÔºåÈÉΩÊòØÊåá‰ΩøÁî®SelectËØ≠Âè•ÁºñÂÜôQueryËøõË°åÊï∞ÊçÆÊ£ÄÁ¥¢„ÄÇ

### ÁºñÂÜôÁ¨¨‰∏Ä‰∏™Êü•ËØ¢

‰∏ãÈù¢ÁöÑSQLÂèØ‰ª•Êü•ËØ¢ÊâÄÊúâÁöÑERC20‰ª£Â∏Å‰ø°ÊÅØÔºö

```sql
select * from tokens.erc20
limit 10
```

### Select Êü•ËØ¢ËØ≠Âè•Âü∫Êú¨ËØ≠Ê≥ï‰ªãÁªç

‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑSQLÊü•ËØ¢ËØ≠Âè•ÁöÑÁªìÊûÑÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö

```sql
select Â≠óÊÆµÂàóË°®
from Êï∞ÊçÆË°®
where Á≠õÈÄâÊù°‰ª∂
order by ÊéíÂ∫èÂ≠óÊÆµ
limit ËøîÂõûËÆ∞ÂΩïÊï∞Èáè
```

**Â≠óÊÆµÂàóË°®**ÂèØ‰ª•ÈÄê‰∏™ÂàóÂá∫Êü•ËØ¢ÈúÄË¶ÅËøîÂõûÁöÑÂ≠óÊÆµÔºàÊï∞ÊçÆÂàóÔºâÔºåÂ§ö‰∏™Â≠óÊÆµ‰πãÈó¥Áî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöîÔºåÊØîÂ¶ÇÂèØ‰ª•ËøôÊ†∑ÊåáÂÆöÊü•ËØ¢ËøîÂõûÁöÑÂ≠óÊÆµÂàóË°®`contract_address, decimals, symbol`„ÄÇ‰πüÂèØ‰ª•‰ΩøÁî®ÈÄöÈÖçÁ¨¶`*`Êù•Ë°®Á§∫ËøîÂõûÊï∞ÊçÆË°®ÁöÑÂÖ®ÈÉ®Â≠óÊÆµ„ÄÇÂ¶ÇÊûúÊü•ËØ¢Áî®Âà∞‰∫ÜÂ§ö‰∏™Ë°®Âπ∂‰∏îÊüê‰∏™Â≠óÊÆµÂêåÊó∂Â≠òÂú®‰∫éËøô‰∫õË°®‰∏≠ÔºåÊàë‰ª¨Â∞±ÈúÄË¶ÅÁî®`table_name.field_name`ÁöÑÂΩ¢ÂºèÊåáÂÆöÈúÄË¶ÅËøîÂõûÁöÑÂ≠óÊÆµÂ±û‰∫éÂì™‰∏Ä‰∏™Ë°®„ÄÇ

**Êï∞ÊçÆË°®**‰ª•`schema_name.table_name`ÁöÑÊ†ºÂºèÊù•ÊåáÂÆöÔºå‰æãÂ¶Ç`tokens.erc20`„ÄÇÊàë‰ª¨ÂèØ‰ª•Áî®`as alias_name`ÁöÑËØ≠Ê≥ïÁªôË°®ÊåáÂÆö‰∏Ä‰∏™Âà´ÂêçÔºå‰æãÂ¶ÇÔºö`from tokens.erc20 as t`„ÄÇËøôÊ†∑Â∞±ÂèØ‰ª•Âêå‰∏Ä‰∏™Êü•ËØ¢‰∏≠Áî®Âà´Âêç`t`Êù•ËÆøÈóÆË°®`tokens.erc20`ÂíåÂÖ∂‰∏≠ÁöÑÂ≠óÊÆµ„ÄÇ

**Á≠õÈÄâÊù°‰ª∂**Áî®‰∫éÊåâÊåáÂÆöÁöÑÊù°‰ª∂Á≠õÈÄâËøîÂõûÁöÑÊï∞ÊçÆ„ÄÇÂØπ‰∫é‰∏çÂêåÊï∞ÊçÆÁ±ªÂûãÁöÑÂ≠óÊÆµÔºåÈÄÇÁî®ÁöÑÁ≠õÈÄâÊù°‰ª∂ËØ≠Ê≥ïÂêÑÊúâ‰∏çÂêå„ÄÇÂ≠óÁ¨¶‰∏≤Ôºà`varchar`ÔºâÁ±ªÂûãÁöÑÂ≠óÊÆµÔºåÂèØ‰ª•Áî®`=`Ôºå`like`Á≠âÊù°‰ª∂ÂÅöÁ≠õÈÄâ„ÄÇÊó•ÊúüÊó∂Èó¥Ôºà`datetime`ÔºâÁ±ªÂûãÁöÑÂ≠óÊÆµÂèØ‰ª•Áî®`>=`Ôºå`<=`Ôºå`between ... and ...`Á≠âÊù°‰ª∂ÂÅöÁ≠õÈÄâ„ÄÇ‰ΩøÁî®`like`Êù°‰ª∂Êó∂ÔºåÂèØ‰ª•Áî®ÈÄöÈÖçÁ¨¶`%`ÂåπÈÖç‰∏Ä‰∏™ÊàñÂ§ö‰∏™‰ªªÊÑèÂ≠óÁ¨¶„ÄÇÂ§ö‰∏™Á≠õÈÄâÊù°‰ª∂ÂèØ‰ª•Áî®`and`ÔºàË°®Á§∫ÂøÖÈ°ªÂêåÊó∂Êª°Ë∂≥ÔºâÊàñ`or`ÔºàË°®Á§∫Êª°Ë∂≥‰ªªÊÑè‰∏Ä‰∏™Êù°‰ª∂Âç≥ÂèØÔºâËøûÊé•Ëµ∑Êù•„ÄÇ

**ÊéíÂ∫èÂ≠óÊÆµ**Áî®‰∫éÊåáÂÆöÂØπÊü•ËØ¢ÁªìÊûúÈõÜËøõË°åÊéíÂ∫èÁöÑÂà§Êñ≠‰æùÊçÆÔºåËøôÈáåÊòØ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Â≠óÊÆµÂêçÁß∞ÔºåÂä†‰∏äÂèØÈÄâÁöÑÊéíÂ∫èÊñπÂêëÊåáÁ§∫Ôºà`asc`Ë°®Á§∫ÂçáÂ∫èÔºå`desc`Ë°®Á§∫ÈôçÂ∫èÔºâ„ÄÇÂ§ö‰∏™ÊéíÂ∫èÂ≠óÊÆµ‰πãÈó¥Áî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöî„ÄÇOrder ByÊéíÂ∫èÂ≠êÂè•ËøòÊîØÊåÅÊåâÁÖßÂ≠óÊÆµÂú®SelectÂ≠êÂè•‰∏≠Âá∫Áé∞ÁöÑ‰ΩçÁΩÆÊù•ÊåáÂÆöÊéíÂ∫èÂ≠óÊÆµÔºåÊØîÂ¶Ç`order by 1`Ë°®Á§∫ÊåâÁÖßSelectÂ≠êÂè•‰∏≠Âá∫Áé∞ÁöÑÁ¨¨‰∏Ä‰∏™Â≠óÊÆµËøõË°åÊéíÂ∫èÔºàÈªòËÆ§ÂçáÂ∫èÔºâ„ÄÇ

**ËøîÂõûËÆ∞ÂΩïÊï∞Èáè**Áî®‰∫éÊåáÂÆöÔºàÈôêÂà∂ÔºâÊü•ËØ¢ÊúÄÂ§öËøîÂõûÂ§öÂ∞ëÊù°Êª°Ë∂≥Êù°‰ª∂ÁöÑËÆ∞ÂΩï„ÄÇÂå∫ÂùóÈìæ‰øùÂ≠òÁöÑÊòØÊµ∑ÈáèÊï∞ÊçÆÔºåÈÄöÂ∏∏Êàë‰ª¨ÈúÄË¶ÅÊ∑ªÂä†ËøîÂõûËÆ∞ÂΩïÊï∞ÈáèÈôêÂà∂Êù•ÊèêÈ´òÊü•ËØ¢ÁöÑÊïàÁéá„ÄÇ

‰∏ãÈù¢Êàë‰ª¨‰∏æ‰æãËØ¥ÊòéÂ¶Ç‰Ωï‰ΩøÁî®Êü•ËØ¢ÁöÑÁõ∏ÂÖ≥ÈÉ®ÂàÜ„ÄÇÊ≥®ÊÑèÔºåÂú®SQLËØ≠Âè•‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•`--`Ê∑ªÂä†ÂçïË°åÊ≥®ÈáäËØ¥Êòé„ÄÇËøòÂèØ‰ª•‰ΩøÁî®`/*`ÂºÄÂ§¥Âíå`*/`ÁªìÂ∞æÂ∞ÜÂ§öË°åÂÜÖÂÆπÊ†áËÆ∞‰∏∫Ê≥®ÈáäËØ¥Êòé„ÄÇÊ≥®ÈáäÂÜÖÂÆπ‰∏ç‰ºöË¢´ÊâßË°å„ÄÇ

**ÊåáÂÆöËøîÂõûÁöÑÂ≠óÊÆµÂàóË°®Ôºö**

```sql
select blockchain, contract_address, decimals, symbol   -- ÈÄê‰∏™ÊåáÂÆöÈúÄË¶ÅËøîÂõûÁöÑÂàó
from tokens.erc20
limit 10
```

**Ê∑ªÂä†Á≠õÈÄâÊù°‰ª∂Ôºö**

```sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
where blockchain = 'ethereum'   -- Âè™ËøîÂõû‰ª•Â§™ÂùäÂå∫ÂùóÈìæÁöÑERC20‰ª£Â∏Å‰ø°ÊÅØ
limit 10
```

**‰ΩøÁî®Â§ö‰∏™Á≠õÈÄâÊù°‰ª∂Ôºö**

```sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
where blockchain = 'ethereum'   -- ËøîÂõû‰ª•Â§™ÂùäÂå∫ÂùóÈìæÁöÑERC20‰ª£Â∏Å‰ø°ÊÅØ
    and symbol like 'E%'    -- ‰ª£Â∏ÅÁ¨¶Âè∑‰ª•Â≠óÊØçEÂºÄÂ§¥
```

**ÊåáÂÆöÊéíÂ∫èÂ≠óÊÆµÔºö**

```sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
where blockchain = 'ethereum'   -- ËøîÂõû‰ª•Â§™ÂùäÂå∫ÂùóÈìæÁöÑERC20‰ª£Â∏Å‰ø°ÊÅØ
    and symbol like 'E%'    -- ‰ª£Â∏ÅÁ¨¶Âè∑‰ª•Â≠óÊØçEÂºÄÂ§¥
order by symbol asc -- Êåâ‰ª£Â∏ÅÁ¨¶Âè∑ÂçáÂ∫èÊéíÂàó
```

**ÊåáÂÆöÂ§ö‰∏™ÊéíÂ∫èÂ≠óÊÆµÔºö**

```sql
select blockchain, contract_address, decimals, symbol
from tokens.erc20
where blockchain = 'ethereum'   -- ËøîÂõû‰ª•Â§™ÂùäÂå∫ÂùóÈìæÁöÑERC20‰ª£Â∏Å‰ø°ÊÅØ
    and symbol like 'E%'    -- ‰ª£Â∏ÅÁ¨¶Âè∑‰ª•Â≠óÊØçEÂºÄÂ§¥
order by decimals desc, symbol asc  -- ÂÖàÊåâ‰ª£Â∏ÅÊîØÊåÅÁöÑÂ∞èÊï∞‰ΩçÊï∞ÈôçÂ∫èÊéíÂàóÔºåÂÜçÊåâ‰ª£Â∏ÅÁ¨¶Âè∑ÂçáÂ∫èÊéíÂàó
```

**‰ΩøÁî®LimitÂ≠êÂè•ÈôêÂà∂ËøîÂõûÁöÑÊúÄÂ§ßËÆ∞ÂΩïÊï∞ÈáèÔºö**

```sql
select *
from tokens.erc20
limit 10
```

### SelectÊü•ËØ¢Â∏∏Áî®ÁöÑ‰∏Ä‰∫õÂáΩÊï∞ÂíåÂÖ≥ÈîÆËØç

#### AsÂÆö‰πâÂà´Âêç

ÂèØ‰ª•ÈÄöËøá‰ΩøÁî®‚Äúas‚ÄùÂ≠êÂè•ÁªôË°®„ÄÅÂ≠óÊÆµÂÆö‰πâÂà´Âêç„ÄÇÂà´ÂêçÂØπ‰∫éË°®ÂêçÔºàÊàñÂ≠óÊÆµÂêçÔºâËæÉÈïø„ÄÅÂåÖÂê´ÁâπÊÆäÂ≠óÁ¨¶ÊàñÂÖ≥ÈîÆÂ≠óÁ≠âÊÉÖÂÜµÔºåÊàñËÄÖÈúÄË¶ÅÂØπËæìÂá∫Â≠óÊÆµÂêçÁß∞ÂÅöÊ†ºÂºèÂåñÊó∂ÔºåÈùûÂ∏∏ÂÆûÁî®„ÄÇÂà´ÂêçÁªèÂ∏∏Áî®‰∫éËÆ°ÁÆóÂ≠óÊÆµ„ÄÅÂ§öË°®ÂÖ≥ËÅî„ÄÅÂ≠êÊü•ËØ¢Á≠âÂú∫ÊôØ‰∏≠„ÄÇ

```sql
select t.contract_address as "‰ª£Â∏ÅÂêàÁ∫¶Âú∞ÂùÄ",
    t.decimals as "‰ª£Â∏ÅÂ∞èÊï∞‰ΩçÊï∞",
    t.symbol as "‰ª£Â∏ÅÁ¨¶Âè∑"
from tokens.erc20 as t
limit 10
```
ÂÆûÈôÖ‰∏ä‰∏∫‰∫Ü‰π¶ÂÜôÊõ¥Âä†ÁÆÄÊ¥ÅÔºåÂÆö‰πâÂà´ÂêçÊó∂`as`ÂÖ≥ÈîÆËØçÂèØ‰ª•ÁúÅÁï•ÔºåÂèØ‰ª•Áõ¥Êé•Â∞ÜÂà´ÂêçË∑üÂú®Ë°®ÂêçÊàñÂ≠óÊÆµÂêçÂêéÔºåÁî®‰∏Ä‰∏™Á©∫Ê†ºÂàÜÈöî„ÄÇ‰∏ãÈù¢ÁöÑÊü•ËØ¢ÔºåÂäüËÉΩÂíå‰∏ä‰∏Ä‰∏™Êü•ËØ¢ÂÆåÂÖ®Áõ∏Âêå„ÄÇ

```sql
-- ÂÆö‰πâÂà´ÂêçÊó∂Ôºåas ÂÖ≥ÈîÆËØçÂèØ‰ª•ÁúÅÁï•
select t.contract_address "‰ª£Â∏ÅÂêàÁ∫¶Âú∞ÂùÄ",
    t.decimals "‰ª£Â∏ÅÂ∞èÊï∞‰ΩçÊï∞",
    t.symbol "‰ª£Â∏ÅÁ¨¶Âè∑"
from tokens.erc20 t
limit 10
```

#### DistinctÁ≠õÈÄâÂîØ‰∏ÄÂÄº

ÈÄöËøá‰ΩøÁî®`distinct`ÂÖ≥ÈîÆËØçÔºåÊàë‰ª¨ÂèØ‰ª•Á≠õÈÄâÂá∫Âá∫Áé∞Âú®SelectÂ≠êÂè•ÂàóË°®‰∏≠ÁöÑÂ≠óÊÆµÁöÑÂîØ‰∏ÄÂÄº„ÄÇÂΩìSelectÂ≠êÂè•ÂåÖÂê´Â§ö‰∏™Â≠óÊÆµÊó∂ÔºåËøîÂõûÁöÑÊòØËøô‰∫õÂ≠óÊÆµÁöÑÂîØ‰∏ÄÂÄºÂΩìÁªÑÂêà„ÄÇ

```sql
select distinct blockchain
from tokens.erc20
```

#### Now Ëé∑ÂèñÂΩìÂâçÁ≥ªÁªüÊó•ÊúüÊó∂Èó¥

‰ΩøÁî®`now()`ÂèØ‰ª•Ëé∑ÂæóÂΩìÂâçÁ≥ªÁªüÁöÑÊó•ÊúüÊó∂Èó¥ÂÄº„ÄÇÊàë‰ª¨ËøòÂèØ‰ª•‰ΩøÁî®`current_date`Êù•ÂæóÂà∞ÂΩìÂâçÁ≥ªÁªüÊó•ÊúüÔºåÊ≥®ÊÑèËøôÈáå‰∏çÈúÄË¶ÅÂä†Êã¨Âè∑„ÄÇ

```sql
select now(), current_date
```

#### Date_Trunc Êà™ÂèñÊó•Êúü

Âå∫ÂùóÈìæ‰∏≠ÁöÑÊó•ÊúüÊó∂Èó¥Â≠óÊÆµÈÄöÂ∏∏ÊòØ‰ª•‚ÄúÂπ¥-Êúà-Êó• Êó∂:ÂàÜ:Áßí‚ÄùÁöÑÊ†ºÂºè‰øùÂ≠òÁöÑ„ÄÇÂ¶ÇÊûúË¶ÅÊåâÂ§©„ÄÅÊåâÂë®„ÄÅÊåâÊúàÁ≠âËøõË°åÊ±áÊÄªÁªüËÆ°ÔºåÂèØ‰ª•‰ΩøÁî®`date_trunc()`ÂáΩÊï∞ÂØπÊó•ÊúüÂÖàËøõË°åËΩ¨Êç¢„ÄÇ‰æãÂ¶ÇÔºö`date_trunc('day', block_time)`Â∞Üblock_timeÁöÑÂÄºËΩ¨Êç¢‰∏∫‰ª•‚ÄúÂ§©‚ÄùË°®Á§∫ÁöÑÊó•ÊúüÂÄºÔºå`date_trunc('month', block_time)`Â∞Üblock_timeÁöÑÂÄºËΩ¨Êç¢‰∏∫‰ª•‚ÄúÊúà‚ÄùË°®Á§∫ÁöÑÊó•ÊúüÂÄº„ÄÇ

```sql
select now(),
    date_trunc('day', now()) as today,
    date_trunc('month', now()) as current_month
```

#### IntervalËé∑ÂèñÊó∂Èó¥Èó¥Èöî

‰ΩøÁî®`interval '2 days'`ËøôÊ†∑ÁöÑËØ≠Ê≥ïÔºåÊàë‰ª¨ÂèØ‰ª•ÊåáÂÆö‰∏Ä‰∏™Êó∂Èó¥Èó¥Èöî„ÄÇÊîØÊåÅÂ§öÁßç‰∏çÂêåÁöÑÊó∂Èó¥Èó¥ÈöîË°®Á§∫ÊñπÂºèÔºåÊØîÂ¶ÇÔºö`'12 hours'`Ôºå`'7 days'`Ôºå`'3 months'`, `'1 year'`Á≠â„ÄÇÊó∂Èó¥Èó¥ÈöîÈÄöÂ∏∏Áî®Êù•Âú®Êüê‰∏™Êó•ÊúüÊó∂Èó¥ÂÄºÁöÑÂü∫Á°Ä‰∏äÂ¢ûÂä†ÊàñÂáèÂ∞ëÊåáÂÆöÁöÑÈó¥Èöî‰ª•ÂæóÂà∞Êüê‰∏™Êó•ÊúüÂå∫Èó¥„ÄÇ

```sql
select now() as right_now, 
    (now() - interval '2' hour) as two_hours_ago, 
    (now() - interval '2' day) as two_days_ago,
    (current_date - interval '1' year) as one_year_ago
```

#### ConcatËøûÊé•Â≠óÁ¨¶‰∏≤

Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®`concat()`ÂáΩÊï∞Â∞ÜÂ§ö‰∏™Â≠óÁ¨¶‰∏≤ËøûÊé•Âà∞‰∏ÄËµ∑ÁöÑÂà∞‰∏Ä‰∏™Êñ∞ÁöÑÂÄº„ÄÇËøòÂèØ‰ª•‰ΩøÁî®Êõ¥ÁÆÄÊ¥ÅÁöÑËøûÊé•Êìç‰ΩúÁ¨¶`||`„ÄÇ

```sql
select concat('Hello ', 'world!') as hello_world,
    'Hello' || ' ' || 'world' || '!' as hello_world_again
```

#### CastËΩ¨Êç¢Â≠óÊÆµÊï∞ÊçÆÁ±ªÂûã

SQLÊü•ËØ¢ÁßçÁöÑÊüê‰∫õÊìç‰ΩúË¶ÅÊ±ÇÁõ∏ÂÖ≥ÁöÑÂ≠óÊÆµÁöÑÊï∞ÊçÆÁ±ªÂûã‰∏ÄËá¥ÔºåÊØîÂ¶Çconcat()ÂáΩÊï∞Â∞±ÈúÄË¶ÅÂèÇÊï∞ÈÉΩÊòØÂ≠óÁ¨¶‰∏≤`varchar`Á±ªÂûã„ÄÇÂ¶ÇÊûúÈúÄË¶ÅÂ∞Ü‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆËøûÊé•Ëµ∑Êù•ÔºåÊàë‰ª¨ÂèØ‰ª•Áî®`cast()`ÂáΩÊï∞Âº∫Âà∂ËΩ¨Êç¢‰∏∫ÈúÄË¶ÅÁöÑÊï∞ÊçÆÁ±ªÂûãÔºåÊØîÂ¶ÇÔºö`cast(25 as string)`Â∞ÜÊï∞Â≠ó25ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤‚Äú25‚Äù„ÄÇËøòÂèØ‰ª•‰ΩøÁî®`data_type 'value string'`Êìç‰ΩúÁ¨¶ÊñπÂºèÂÆåÊàêÁ±ªÂûãËΩ¨Êç¢ÔºåÊØîÂ¶ÇÔºö`integer '123'`Â∞ÜÂ≠óÁ¨¶‰∏≤ËΩ¨Êç¢‰∏∫Êï∞ÂÄºÁ±ªÂûã„ÄÇ

```sql
select (cast(25 as varchar) || ' users') as user_counts,
    integer '123' as intval,
    timestamp '2023-04-28 20:00:00' as dt_time
```

#### PowerÊ±ÇÂπÇ

Âå∫ÂùóÈìæ‰∏äÁöÑERC20‰ª£Â∏ÅÈÄöÂ∏∏ÈÉΩÊîØÊåÅÂæàÂ§ö‰ΩçÁöÑÂ∞èÊï∞‰Ωç„ÄÇ‰ª•Â§™ÂùäÁöÑÂÆòÊñπ‰ª£Â∏ÅETHÊîØÊåÅ18‰ΩçÂ∞èÊï∞ÔºåÂõ†‰∏∫Áõ∏ÂÖ≥ÁºñÁ®ãËØ≠Ë®ÄÁöÑÈôêÂà∂Ôºå‰ª£Â∏ÅÈáëÈ¢ùÈÄöÂ∏∏ÊòØ‰ª•Êï¥Êï∞ÂΩ¢ÂºèÂ≠òË¥ÆÁöÑÔºå‰ΩøÁî®Êó∂ÂøÖÈ°ªÁªìÂêàÊîØÊåÅÁöÑÂ∞èÊï∞‰ΩçÊï∞ËøõË°åÊç¢ÁÆóÊâçËÉΩÂæóÂà∞Ê≠£Á°ÆÁöÑÈáëÈ¢ù„ÄÇ‰ΩøÁî®`power()`ÂáΩÊï∞ÔºåÊàñËÄÖ`pow()`ÂèØ‰ª•ËøõË°åÊ±ÇÂπÇÊìç‰ΩúÂÆûÁé∞Êç¢ÁÆó„ÄÇÂú®Dune V2‰∏≠ÔºåÂèØ‰ª•Áî®ÁÆÄÊ¥ÅÁöÑÂΩ¢ÂºèË°®Á§∫10ÁöÑNÊ¨°ÂπÇÔºå‰æãÂ¶Ç`1e18`Á≠â‰ª∑‰∫é`power(10, 18)`„ÄÇ

```sql
select 1.23 * power(10, 18) as raw_amount,
    1230000000000000000 / pow(10, 18) as original_amount,
    7890000 / 1e6 as usd_amount
```

### SelectÊü•ËØ¢ËøõÈò∂

#### Group ByÂàÜÁªÑ‰∏éÂ∏∏Áî®Ê±áÊÄªÂáΩÊï∞

SQL‰∏≠Êúâ‰∏Ä‰∫õÂ∏∏Áî®ÁöÑÊ±áÊÄªÂáΩÊï∞Ôºå`count()`ËÆ°Êï∞Ôºå`sum()`Ê±ÇÂíåÔºå`avg()`Ê±ÇÂπ≥ÂùáÂÄºÔºå`min()`Ê±ÇÊúÄÂ∞èÂÄºÔºå`max()`Ê±ÇÊúÄÂ§ßÂÄºÁ≠â„ÄÇÈô§‰∫ÜÂØπË°®‰∏≠ÊâÄÊúâÊï∞ÊçÆÊ±áÊÄªÁöÑÊÉÖÂÜµÂ§ñÔºåÊ±áÊÄªÂáΩÊï∞ÈÄöÂ∏∏ÈúÄË¶ÅÁªìÂêàÂàÜÁªÑËØ≠Âè•`group by`Êù•‰ΩøÁî®ÔºåÊåâÁÖßÊüê‰∏™Êù°‰ª∂ËøõË°åÂàÜÁªÑÊ±áÊÄªÁªüËÆ°„ÄÇGroup ByÂàÜÁªÑÂ≠êÂè•ÁöÑËØ≠Ê≥ï‰∏∫`group by field_name`ÔºåËøòÂèØ‰ª•ÊåáÂÆöÂ§ö‰∏™ÂàÜÁªÑÂ≠óÊÆµ`group by field_name1, field_name2`„ÄÇ‰∏éOrder ByÂ≠êÂè•Áõ∏‰ººÔºå‰πüÂèØ‰ª•ÊåâÂ≠óÊÆµÂú®SelectÂ≠êÂè•‰∏≠Âá∫Áé∞ÁöÑ‰ΩçÁΩÆÊù•ÊåáÂÆöÂàÜÁªÑÂ≠óÊÆµÔºåËøôÊ†∑ÂèØ‰ª•ËÆ©Êàë‰ª¨ÁöÑSQLÊõ¥Âä†ÁÆÄÊ¥Å„ÄÇ‰æãÂ¶Ç`group by 1`Ë°®Á§∫ÊåâÁ¨¨‰∏Ä‰∏™Â≠óÊÆµÂàÜÁªÑÔºå`group by 1, 2`Ë°®Á§∫ÂêåÊó∂ÊåâÁ¨¨‰∏Ä‰∏™ÂíåÁ¨¨‰∫å‰∏™Â≠óÊÆµÂàÜÁªÑ„ÄÇÊàë‰ª¨ÈÄöËøá‰∏Ä‰∫õ‰æãÂ≠êÊù•ËØ¥ÊòéÂ∏∏Áî®Ê±áÊÄªÂáΩÊï∞ÁöÑÁî®Ê≥ï„ÄÇ

**ÁªüËÆ°ÁõÆÂâçÊîØÊåÅÁöÑÂêÑ‰∏™Âå∫ÂùóÈìæÁöÑERC20‰ª£Â∏ÅÁ±ªÂûãÊï∞ÈáèÔºö**

```sql
select blockchain, count(*) as token_count
from tokens.erc20
group by blockchain
```

**ÁªüËÆ°ÊîØÊåÅÁöÑÊâÄÊúâÂå∫ÂùóÈìæÁöÑ‰ª£Â∏ÅÁ±ªÂûãÊÄªÊï∞Èáè„ÄÅÂπ≥ÂùáÂÄº„ÄÅÊúÄÂ∞èÂÄº„ÄÅÊúÄÂ§ßÂÄºÔºö**

```sql
-- ËøôÈáå‰∏∫‰∫ÜÊºîÁ§∫Áõ∏ÂÖ≥ÂáΩÊï∞Ôºå‰ΩøÁî®‰∫ÜÂ≠êÊü•ËØ¢
select count(*) as blockchain_count,
    sum(token_count) as total_token_count,
    avg(token_count) as average_token_count,
    min(token_count) as min_token_count,
    max(token_count) as max_token_count
from (
    select blockchain, count(*) as token_count
    from tokens.erc20
    group by blockchain
)
```

#### Â≠êÊü•ËØ¢ÔºàSub QueryÔºâ

Â≠êÊü•ËØ¢ÔºàSub QueryÔºâÊòØÂµåÂ•óÂú®‰∏Ä‰∏™Query‰∏≠ÁöÑQueryÔºåÂ≠êÊü•ËØ¢‰ºöËøîÂõû‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊï∞ÊçÆÈõÜ‰æõÂ§ñÂ±ÇÊü•ËØ¢Ôºà‰πüÂè´Áà∂Êü•ËØ¢„ÄÅ‰∏ªÊü•ËØ¢ÔºâËøõ‰∏ÄÊ≠•Êü•ËØ¢‰ΩøÁî®„ÄÇÂΩìÊàë‰ª¨ÈúÄË¶ÅÂøÖÈ°ª‰ªéÂéüÂßãÊï∞ÊçÆÂºÄÂßãÈÄöËøáÂ§ö‰∏™Ê≠•È™§ÁöÑÊü•ËØ¢„ÄÅÂÖ≥ËÅî„ÄÅÊ±áÊÄªÊìç‰ΩúÊâçËÉΩÂæóÂà∞ÁêÜÊÉ≥ÁöÑËæìÂá∫ÁªìÊûúÊó∂ÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•‰ΩøÁî®Â≠êÊü•ËØ¢„ÄÇÂ∞ÜÂ≠êÊü•ËØ¢ÊîæÂà∞Êã¨Âè∑‰πã‰∏≠Âπ∂‰∏∫ÂÖ∂Ëµã‰∫à‰∏Ä‰∏™Âà´ÂêçÂêéÔºåÂ∞±ÂèØ‰ª•ÂÉè‰ΩøÁî®ÂÖ∂‰ªñÊï∞ÊçÆË°®‰∏ÄÊ†∑‰ΩøÁî®Â≠êÊü•ËØ¢‰∫Ü„ÄÇ

Âú®ÂâçÈù¢ÁöÑ‰æãÂ≠ê‰∏≠Â∞±Áî®Âà∞‰∫ÜÂ≠êÊü•ËØ¢`from ( Â≠êÊü•ËØ¢ËØ≠Âè• )`ÔºåËøôÈáå‰∏çÂÜçÂçïÁã¨‰∏æ‰æã„ÄÇ

#### Â§öË°®ÂÖ≥ËÅîÔºàJoinÔºâ

ÂΩìÊàë‰ª¨ÈúÄË¶Å‰ªéÁõ∏ÂÖ≥ÁöÑÂ§ö‰∏™Ë°®ÂàÜÂà´ÂèñÊï∞ÊçÆÔºåÊàñËÄÖ‰ªéÂêå‰∏Ä‰∏™Ë°®ÂàÜÂà´Âèñ‰∏çÂêåÁöÑÊï∞ÊçÆÂπ∂ËøûÊé•Âà∞‰∏ÄËµ∑Êó∂ÔºåÂ∞±ÈúÄË¶Å‰ΩøÁî®Â§öË°®ÂÖ≥ËÅî„ÄÇÂ§öË°®ÂÖ≥ËÅîÁöÑÂü∫Êú¨ËØ≠Ê≥ï‰∏∫Ôºö`from table_a inner join table_b on table_a.field_name = table_b.field_name`„ÄÇÂÖ∂‰∏≠`table_a`Âíå`table_b`ÂèØ‰ª•ÊòØ‰∏çÂêåÁöÑË°®Ôºå‰πüÂèØ‰ª•ÊòØÂêå‰∏Ä‰∏™Ë°®ÔºåÂèØ‰ª•Êúâ‰∏çÂêåÁöÑÂà´Âêç„ÄÇ

‰∏ãÈù¢ÁöÑÊü•ËØ¢‰ΩøÁî®`tokens.erc20`‰∏éÂÖ∂Ëá™Ë∫´ÂÖ≥ËÅîÔºåÊù•Á≠õÈÄâÂá∫ÂêåÊó∂Â≠òÂú®‰∫é‰ª•Â§™ÂùäÂå∫ÂùóÈìæÂíåÂ∏ÅÂÆâÂå∫ÂùóÈìæ‰∏ä‰∏î‰ª£Â∏ÅÁ¨¶Âè∑Áõ∏ÂêåÁöÑËÆ∞ÂΩïÔºö

```sql
select a.symbol,
    a.decimals,
    a.blockchain as blockchain_a,
    a.contract_address as contract_address_a,
    b.blockchain as blockchain_b,
    b.contract_address as contract_address_b
from tokens.erc20 a
inner join tokens.erc20 b on a.symbol = b.symbol
where a.blockchain = 'ethereum'
    and b.blockchain = 'bnb'
limit 100
```

#### ÈõÜÂêàÔºàUnionÔºâ

ÂΩìÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜÊù•Ëá™‰∏çÂêåÊï∞ÊçÆË°®ÁöÑËÆ∞ÂΩïÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºåÊàñËÄÖÂ∞ÜÁî±Âêå‰∏Ä‰∏™Êï∞ÊçÆË°®ÂèñÂá∫ÁöÑÂåÖÂê´‰∏çÂêåÂ≠óÊÆµÁöÑÁªìÊûúÈõÜÂêàÂπ∂Âà∞‰∏ÄËµ∑Êó∂ÔºåÂèØ‰ª•‰ΩøÁî®`Union`ÊàñËÄÖ`Union All`ÈõÜÂêàÂ≠êÂè•Êù•ÂÆûÁé∞„ÄÇ`Union`‰ºöËá™Âä®ÂéªÈô§ÂêàÂπ∂ÂêéÁöÑÈõÜÂêàÈáåÁöÑÈáçÂ§çËÆ∞ÂΩïÔºå`Union All`Âàô‰∏ç‰ºöÂÅöÂéªÈáçÂ§ÑÁêÜ„ÄÇÂØπ‰∫éÂåÖÊã¨Êµ∑ÈáèÊï∞ÊçÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂ∫ìË°®ÔºåÂéªÈáçÂ§ÑÁêÜÊúâÂèØËÉΩÁõ∏ÂΩìËÄóÊó∂ÔºåÊâÄ‰ª•Âª∫ËÆÆÂ∞ΩÂèØËÉΩ‰ΩøÁî®`Union All`‰ª•ÊèêÂçáÊü•ËØ¢ÊïàÁéá„ÄÇ

Âõ†‰∏∫ÊöÇÊó∂Êàë‰ª¨Â∞ΩÂèØËÉΩ‰øùÊåÅÁÆÄÂçïÔºå‰∏ãÈù¢ÊºîÁ§∫ÈõÜÂêàÁöÑSQLËØ≠Âè•ÂèØËÉΩÊòæÂæóÊÑè‰πâ‰∏çÂ§ß„ÄÇ‰∏çËøáÂà´ÊãÖÂøÉÔºåËøôÈáåÂè™ÊòØ‰∏∫‰∫ÜÊòæÁ§∫ËØ≠Ê≥ï„ÄÇÂêéÁª≠Êàë‰ª¨Âú®ÂÅöÊï∞ÊçÆÁúãÊùøÁöÑÈÉ®ÂàÜÊúâÊõ¥ÂêàÈÄÇÁöÑ‰æãÂ≠êÔºö

```sql
select contract_address, symbol, decimals
from tokens.erc20
where blockchain = 'ethereum'

union all

select contract_address, symbol, decimals
from tokens.erc20
where blockchain = 'bnb'

limit 100
```

#### Case ËØ≠Âè•

‰ΩøÁî®CaseËØ≠Âè•ÔºåÊàë‰ª¨ÂèØ‰ª•Âü∫‰∫éÊüê‰∏™Â≠óÊÆµÁöÑÂÄºÊù•ÁîüÊàêÂè¶‰∏ÄÁßçÁ±ªÂûãÁöÑÂÄºÔºåÈÄöÂ∏∏ÊòØ‰∏∫‰∫ÜËÆ©ÁªìÊûúÊõ¥Áõ¥ËßÇ„ÄÇ‰∏æ‰æãÊù•ËØ¥ÔºåERC20‰ª£Â∏ÅË°®Êúâ‰∏Ä‰∏™`decimals`Â≠óÊÆµÔºå‰øùÂ≠òÂêÑÁßç‰ª£Â∏ÅÊîØÊåÅÁöÑÂ∞èÊï∞‰ΩçÊï∞„ÄÇÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥ÊåâÊîØÊåÅÁöÑÂ∞èÊï∞‰ΩçÊï∞ÊääÂêÑÁßç‰ª£Â∏ÅÂàíÂàÜ‰∏∫È´òÁ≤æÂ∫¶„ÄÅ‰∏≠Á≠âÁ≤æÂ∫¶Âíå‰ΩéÁ≤æÂ∫¶„ÄÅÊó†Á≤æÂ∫¶Á≠âÁ±ªÂûãÔºåÂàôÂèØ‰ª•‰ΩøÁî®CaseËØ≠Âè•ËøõË°åËΩ¨Êç¢„ÄÇ

```sql
select (case when decimals >= 10 then 'High precision'
            when decimals >= 5 then 'Middle precision'
            when decimals >= 1 then 'Low precision'
            else 'No precision'
        end) as precision_type,
    count(*) as token_count
from tokens.erc20
group by 1
order by 2 desc
```

#### CTEÂÖ¨ÂÖ±Ë°®Ë°®ËææÂºè
ÂÖ¨ÂÖ±Ë°®Ë°®ËææÂºèÔºåÂç≥CTEÔºàCommon Table ExpressionÔºâÔºåÊòØ‰∏ÄÁßçÂú®SQLËØ≠Âè•ÂÜÖÊâßË°åÔºà‰∏î‰ªÖÊâßË°å‰∏ÄÊ¨°ÔºâÂ≠êÊü•ËØ¢ÁöÑÂ•ΩÊñπÊ≥ï„ÄÇÊï∞ÊçÆÂ∫ìÂ∞ÜÊâßË°åÊâÄÊúâÁöÑWITHÂ≠êÂè•ÔºåÂπ∂ÂÖÅËÆ∏‰Ω†Âú®Êï¥‰∏™Êü•ËØ¢ÁöÑÂêéÁª≠‰ªªÊÑè‰ΩçÁΩÆ‰ΩøÁî®ÂÖ∂ÁªìÊûú„ÄÇ

CTEÁöÑÂÆö‰πâÊñπÂºè‰∏∫`with cte_name as ( sub_query )`ÔºåÂÖ∂‰∏≠`sub_query`Â∞±ÊòØ‰∏Ä‰∏™Â≠êÊü•ËØ¢ËØ≠Âè•„ÄÇÊàë‰ª¨‰πüÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Query‰∏≠ËøûÁª≠ÂÆö‰πâÂ§ö‰∏™CTEÔºåÂ§ö‰∏™CTE‰πãÈó¥Áî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöîÂç≥ÂèØ„ÄÇÊåâÂÆö‰πâÁöÑÂÖàÂêéÈ°∫Â∫èÔºåÂêéÈù¢ÁöÑCTEÂèØ‰ª•ËÆøÈóÆ‰ΩøÁî®ÂâçÈù¢ÁöÑCTE„ÄÇÂú®ÂêéÁª≠Êï∞ÊçÆÁúãÊùøÈÉ®ÂàÜÁöÑ‚ÄúÊü•ËØ¢6‚Äù‰∏≠Ôºå‰Ω†ÂèØ‰ª•ÁúãÂà∞ÂÆö‰πâÂ§ö‰∏™CTEÁöÑÁ§∫‰æã„ÄÇÂ∞ÜÂâçÈù¢Â≠êÊü•ËØ¢ÁöÑ‰æãÂ≠êÁî®CTEÊ†ºÂºèÊîπÂÜôÔºö

```sql
with blockchain_token_count as (
    select blockchain, count(*) as token_count
    from tokens.erc20
    group by blockchain
)

select count(*) as blockchain_count,
    sum(token_count) as total_token_count,
    avg(token_count) as average_token_count,
    min(token_count) as min_token_count,
    max(token_count) as max_token_count
from blockchain_token_count
```

## ÊÄªÁªì

ÊÅ≠ÂñúÔºÅ‰Ω†Â∑≤ÁªèÁÜüÊÇâ‰∫ÜÂàõÂª∫Á¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùøÊâÄÈúÄË¶ÅÁöÑÂÖ®ÈÉ®Áü•ËØÜÁÇπ„ÄÇÂú®‰∏ã‰∏ÄÁØáÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰∏ÄËµ∑ÂàõÂª∫‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùø„ÄÇ

‰Ω†ËøòÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÈìæÊé•Â≠¶‰π†Êõ¥Â§öÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÔºö
- [DuneÂπ≥Âè∞ÁöÑÂÆòÊñπÊñáÊ°£](https://dune.com/docs/)ÔºàDuneÔºâ
- [DuneÂÖ•Èó®ÊåáÂçó](https://mirror.xyz/0xa741296A1E9DDc3D6Cf431B73C6225cFb5F6693a/iVzr5bGcGKKCzuvl902P05xo7fxc2qWfqfIHwmCXDI4)ÔºàSixdegreeLabÊàêÂëòLouis WangÁøªËØëÔºâ
- [Dune AnalyticsÈõ∂Âü∫Á°ÄÊûÅÁÆÄÂÖ•Èó®ÊåáÂçó](https://mirror.xyz/gm365.eth/OE_CGx6BjCd-eQ441139sjsa3kTyUsmKVTclgMv09hY)ÔºàDuneÁ§æÂå∫Áî®Êà∑gm365Êí∞ÂÜôÔºâ

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Êú¨ÊñáÁî±SixdegreeLabÊàêÂëòSpring ZhangÔºà[@superamscom](https://twitter.com/superamscom)ÔºâÊí∞Á®ø„ÄÇÂõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch04/readme.md">
---
title: 04. ÂàõÂª∫DuneÊï∞ÊçÆÁúãÊùø
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - dashboard
  - uniswap
---
# 4 ÂàõÂª∫Á¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùø

Âú®‰∏ä‰∏ÄÁØá‚Äú[Êñ∞Êâã‰∏äË∑Ø](../02_get_started/readme.md)‚Äù‰∏≠ÔºåÊàë‰ª¨Â≠¶‰π†‰∫ÜÂàõÂª∫Á¨¨‰∏Ä‰∏™Êï∞ÊçÆÁúãÊùøÈúÄË¶ÅÁöÑÈ¢ÑÂ§áÁü•ËØÜÔºåÊéåÊè°‰∫ÜÂü∫Á°ÄSQLÊü•ËØ¢ÁöÑÁºñÂÜôÊäÄÂ∑ß„ÄÇÁé∞Âú®ËÆ©Êàë‰ª¨‰∏ÄËµ∑Êù•ÁºñÂÜôÊü•ËØ¢Âπ∂ÂàõÂª∫‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùø„ÄÇ‰∏∫‰∫ÜÂ∏ÆÂä©Â§ßÂÆ∂Êõ¥Âø´‰∏äÊâãÂÆûË∑µÔºåÊàë‰ª¨Ëøô‰∏™Êï∞ÊçÆÁúãÊùøÂ∞ÜÁªìÂêàÂÖ∑‰ΩìÁöÑÈ°πÁõÆÊù•Âà∂‰Ωú„ÄÇÂÆåÊàêÂêéÁöÑÊï∞ÊçÆÁúãÊùøÁöÑÁ§∫‰æãÔºö[https://dune.com/sixdegree/uniswap-v3-pool-tutorial](https://dune.com/sixdegree/uniswap-v3-pool-tutorial)„ÄÇ

Êàë‰ª¨‰∏ç‰ºöËØ¶ÁªÜÊèèËø∞ÊØè‰∏Ä‰∏™Êìç‰ΩúÊ≠•È™§„ÄÇÂÖ≥‰∫éÂ¶Ç‰Ωï‰ΩøÁî®DuneÁöÑÊü•ËØ¢ÁºñËæëÂô®ÔºàQuery EditorÔºâÂíåÊï∞ÊçÆÁúãÊùøÔºàDashboardÔºâÁöÑÂü∫Á°ÄÁü•ËØÜÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá[DuneÂπ≥Âè∞ÁöÑÂÆòÊñπÊñáÊ°£](https://dune.com/docs/)Êù•Â≠¶‰π†„ÄÇ

## ËÉåÊôØÁü•ËØÜ

ÂºÄÂßãÂàõÂª∫ÁúãÊùø‰πãÂâçÔºåÊàë‰ª¨ËøòÈúÄË¶Å‰∫ÜËß£‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑËÉåÊôØÁü•ËØÜ„ÄÇUniswapÊòØÊúÄÊµÅË°åÁöÑÂéª‰∏≠ÂøÉÂåñÈáëËûçÔºàDeFiÔºâÂçèËÆÆ‰πã‰∏ÄÔºåÊòØ‰∏ÄÂ•óÊåÅ‰πÖÁöÑ‰∏î‰∏çÂèØÂçáÁ∫ßÁöÑÊô∫ËÉΩÂêàÁ∫¶ÔºåÂÆÉ‰ª¨ÂÖ±ÂêåÂàõÂª∫‰∫Ü‰∏Ä‰∏™Ëá™Âä®ÂÅöÂ∏ÇÂïÜÔºàAMMÔºâÔºåËØ•ÂçèËÆÆ‰∏ªË¶ÅÊèê‰æõ‰ª•Â§™ÂùäÂå∫ÂùóÈìæ‰∏äÁöÑÁÇπÂØπÁÇπERC20‰ª£Â∏ÅÁöÑ‰∫§Êç¢„ÄÇUniswapÂ∑•ÂéÇÂêàÁ∫¶ÔºàFactoryÔºâÈÉ®ÁΩ≤Êñ∞ÁöÑÊô∫ËÉΩÂêàÁ∫¶Êù•ÂàõÂª∫ÊµÅÂä®ËµÑÈáëÊ±†ÔºàPoolÔºâÔºåÂ∞Ü‰∏§‰∏™ERC20‰ª£Â∏ÅËµÑ‰∫ßËøõË°åÈÖçÂØπÔºåÂêåÊó∂ËÆæÁΩÆ‰∏çÂêåÁöÑË¥πÁéáÔºàfeeÔºâ„ÄÇÊµÅÂä®ÊÄßÔºàLiquidityÔºâÊòØÊåáÂ≠òÂÇ®Âú®UniswapËµÑÈáëÊ±†ÂêàÁ∫¶‰∏≠ÁöÑÊï∞Â≠óËµÑ‰∫ßÔºåÂèØ‰æõ‰∫§ÊòìËÄÖËøõË°å‰∫§Êòì„ÄÇÊµÅÂä®ÊÄßÊèê‰æõËÄÖÔºàLiquidity ProviderÔºåÁÆÄÁß∞LPÔºâÊòØÂ∞ÜÂÖ∂Êã•ÊúâÁöÑERC20‰ª£Â∏ÅÂ≠òÂÖ•ÁªôÂÆöÁöÑÊµÅÂä®ÊÄßÊ±†ÁöÑ‰∫∫„ÄÇÊµÅÂä®ÊÄßÊèê‰æõËÄÖËé∑Âæó‰∫§ÊòìË¥πÁî®ÁöÑË°•ÂÅø‰Ωú‰∏∫Êî∂ÁõäÔºåÂêåÊó∂‰πüÊâøÊãÖ‰ª∑Ê†ºÊ≥¢Âä®Â∏¶Êù•ÁöÑÈ£éÈô©„ÄÇÊôÆÈÄöÁî®Êà∑ÔºàSwapperÔºâÈÄöËøáÂèØ‰ª•Âú®ÊµÅÂä®ËµÑÈáëÊ±†‰∏≠Â∞ÜËá™Â∑±Êã•ÊúâÁöÑ‰∏ÄÁßçERC20‰ª£Â∏ÅÂÖëÊç¢‰∏∫Âè¶‰∏ÄÁßç‰ª£Â∏ÅÔºåÂêåÊó∂ÊîØ‰ªò‰∏ÄÂÆöÁöÑÊúçÂä°Ë¥π„ÄÇÊØîÂ¶Ç‰Ω†ÂèØ‰ª•Âú®Ë¥πÁéá‰∏∫0.30%ÁöÑUSDC-WETHÊµÅÂä®ËµÑÈáëÊ±†‰∏≠ÔºåÂ∞ÜËá™Â∑±ÁöÑUSDCÂÖëÊç¢‰∏∫WETHÔºåÊàñËÄÖÂ∞ÜWETHÂÖëÊç¢‰∏∫USDCÔºå‰ªÖÈúÄÊîØ‰ªòÂ∞ëÈáèÁöÑÊúçÂä°Ë¥πÂç≥ÂèØÂÆåÊàêÂÖëÊç¢„ÄÇUniswap V3ÂçèËÆÆÁöÑÂ∑•‰ΩúÊñπÂºèÂèØ‰ª•ÁÆÄË¶ÅÊ¶ÇÊã¨‰∏∫ÔºöÂ∑•ÂéÇÂêàÁ∫¶ÂàõÂª∫ÊµÅÂä®ËµÑÈáëÊ±†ÔºàÂåÖÊã¨‰∏§ÁßçERC20‰ª£Â∏ÅÔºâ -„Äã LPÁî®Êà∑Ê∑ªÂä†ÂØπÂ∫îËµÑ‰∫ßÂà∞ÊµÅÂä®ËµÑÈáëÊ±† -„Äã ÂÖ∂‰ªñÁî®Êà∑‰ΩøÁî®ÊµÅÂä®ËµÑÈáëÊ±†ÂÖëÊç¢ÂÖ∂ÊåÅÊúâÁöÑ‰ª£Â∏ÅËµÑ‰∫ßÔºåÊîØ‰ªòÊúçÂä°Ë¥π -„Äã LPËé∑ÂæóÊúçÂä°Ë¥πÂ•ñÂä±„ÄÇ

ÂàùÂ≠¶ËÄÖÂèØËÉΩÂØπËøôÈÉ®ÂàÜÂºïÂÖ•ÁöÑ‰∏Ä‰∫õÊ¶ÇÂøµÊØîËæÉÈôåÁîüÔºå‰∏çËøáÂÆåÂÖ®‰∏çÁî®Á¥ßÂº†Ôºå‰Ω†Êó†ÈúÄ‰∫ÜËß£Êõ¥Â§öDeFiÁöÑÁü•ËØÜÂ∞±ÂèØ‰ª•È°∫Âà©ÂÆåÊàêÊú¨ÊïôÁ®ãÁöÑÂÜÖÂÆπ„ÄÇÊú¨ÁØáÊïôÁ®ã‰∏ç‰ºöÊ∑±ÂÖ•Ê∂âÂèäDeFiÂçèËÆÆÁöÑÂêÑÁßçÁªÜËäÇÔºåÊàë‰ª¨Âè™ÊòØÊÉ≥ÈÄöËøáÂÆûÈôÖÁöÑÊ°à‰æãÔºåËÆ©‰Ω†ÂØπ‚ÄúÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂà∞Â∫ïÂàÜÊûê‰ªÄ‰πà‚ÄùÊúâ‰∏Ä‰∏™Êõ¥ÊÑüÊÄßÁöÑËÆ§ËØÜ„ÄÇÂú®Êàë‰ª¨Â∞ÜË¶ÅÂàõÂª∫ÁöÑËøô‰∏™Êï∞ÊçÆÁúãÊùø‰∏≠Ôºå‰∏ªË¶Å‰ΩøÁî®Uniswap V3ÁöÑÊµÅÂä®ËµÑÈáëÊ±†‰Ωú‰∏∫Ê°à‰æã. ÂØπÂ∫îÁöÑÊï∞ÊçÆË°®‰∏∫`uniswap_v3_ethereum.Factory_evt_PoolCreated`„ÄÇÂêåÊó∂ÔºåÈÉ®ÂàÜÊü•ËØ¢‰πüÁî®Âà∞‰∫ÜÂâçÈù¢‰ªãÁªçËøáÁöÑ`tokens.erc20`Ë°®„ÄÇÂºÄÂßã‰πãÂâçÔºå‰Ω†Âè™ÈúÄË¶Å‰∫ÜËß£Ëøô‰∫õÂ∞±Ë∂≥Â§ü‰∫ÜÔºöÂèØ‰ª•ÂàõÂª∫ÂæàÂ§ö‰∏™‰∏çÂêåÁöÑÊµÅÂä®ËµÑÈáëÊ±†ÔºàPoolÔºâÔºåÊØè‰∏Ä‰∏™ÊµÅÂä®ËµÑÈáëÊ±†ÂåÖÂê´‰∏§Áßç‰∏çÂêåÁöÑERC20‰ª£Â∏ÅÔºàÁß∞‰πã‰∏∫‰ª£Â∏ÅÂØπÔºåPairÔºâÔºåÊúâ‰∏Ä‰∏™ÁªôÂÆöÁöÑË¥πÁéáÔºõÁõ∏ÂêåÁöÑ‰ª£Â∏ÅÂØπÔºàÊØîÂ¶ÇUSDC-WETHÔºâÂèØ‰ª•ÂàõÂª∫Â§ö‰∏™ÊµÅÂä®ËµÑÈáëÊ±†ÔºåÂàÜÂà´ÂØπÂ∫î‰∏çÂêåÁöÑÊî∂Ë¥πË¥πÁéá„ÄÇ

## UniswapÊµÅÂä®ËµÑÈáëÊ±†Ë°®

ÊµÅÂä®ËµÑÈáëÊ±†Ë°®`uniswap_v3_ethereum.Factory_evt_PoolCreated`ÁöÑÁªìÊûÑÂ¶Ç‰∏ãÔºö

| **ÂàóÂêç**                 | **Êï∞ÊçÆÁ±ªÂûã**   | **ËØ¥Êòé**                                    |
| ----------------------- | ------------- | ------------------------------------------ |
| contract\_address       | string        | ÂêàÁ∫¶Âú∞ÂùÄ                                    |
| evt\_block\_number      | long          | Âå∫ÂùóÁºñÂè∑                                    |
| evt\_block\_time        | timestamp     | Âå∫ÂùóË¢´ÂºÄÈááÁöÑÊó∂Èó¥                             |
| evt\_index              | integer       | ‰∫ã‰ª∂ÁöÑÁ¥¢ÂºïÁºñÂè∑                               |
| evt\_tx\_hash           | string        | ‰∫ã‰ª∂ÂΩíÂ±û‰∫§ÊòìÁöÑÂîØ‰∏ÄÂìàÂ∏åÂÄº                      |
| fee                     | integer       | ÊµÅÂä®ËµÑÈáëÊ±†ÁöÑÊî∂Ë¥πË¥πÁéáÔºà‰ª•‚ÄúÁôæ‰∏áÂàÜ‰πãN‚ÄùÁöÑÂΩ¢ÂºèË°®Á§∫Ôºâ   |
| pool                    | string        | ÊµÅÂä®ËµÑÈáëÊ±†ÁöÑÂú∞ÂùÄ                             |
| tickSpacing             | integer       | ÂàªÂ∫¶Èó¥Ë∑ù                                    |
| token0                  | string        | ËµÑÈáëÊ±†‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ERC20‰ª£Â∏ÅÂú∞ÂùÄ                  |
| token1                  | string        | ËµÑÈáëÊ±†‰∏≠ÁöÑÁ¨¨‰∫å‰∏™ERC20‰ª£Â∏ÅÂú∞ÂùÄ                  |

ÊµÅÂä®ËµÑÈáëÊ±†Ë°®ÁöÑÈÉ®ÂàÜÊï∞ÊçÆÂ¶Ç‰∏ãÂõæÊâÄÁ§∫ÔºàËøôÈáåÂè™ÊòæÁ§∫‰∫ÜÈÉ®ÂàÜÂ≠óÊÆµÔºâÔºö

![image_00.png](./img/image_00.png)

## Êï∞ÊçÆÁúãÊùøÁöÑ‰∏ªË¶ÅÂÜÖÂÆπ

Êàë‰ª¨ÁöÑÁ¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùøÂ∞ÜÂåÖÊã¨‰ª•‰∏ãÊü•ËØ¢ÂÜÖÂÆπ„ÄÇÊØè‰∏™Êü•ËØ¢‰ºöËæìÂá∫1‰∏™ÊàñÂ§ö‰∏™ÂèØËßÜÂåñÂõæË°®„ÄÇ
- Êü•ËØ¢ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞
- ‰∏çÂêåË¥πÁéáÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞Èáè
- ÊåâÂë®Ê±áÊÄªÁöÑÊñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞
- ÊúÄËøë30Â§©ÁöÑÊØèÊó•Êñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞
- ÊåâÂë®Ê±áÊÄªÁöÑÊñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞-ÊåâË¥πÁéáÂàÜÁªÑ
- ÁªüËÆ°ËµÑÈáëÊ±†Êï∞ÈáèÊúÄÂ§öÁöÑ‰ª£Â∏ÅToken
- ÊúÄÊñ∞ÁöÑ100‰∏™ÊµÅÂä®ËµÑÈáëÊ±†ËÆ∞ÂΩï

## Êü•ËØ¢1: Êü•ËØ¢ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞

ÈÄöËøá‰ΩøÁî®Ê±áÊÄªÂáΩÊï∞Count()ÔºåÊàë‰ª¨ÂèØ‰ª•ÁªüËÆ°ÂΩìÂâçÂ∑≤ÂàõÂª∫ÁöÑÂÖ®ÈÉ®ËµÑÈáëÊ±†ÁöÑÊï∞Èáè„ÄÇ

```sql
select count(*) as pool_count
from uniswap_v3_ethereum.Factory_evt_PoolCreated
```

Êàë‰ª¨Âª∫ËÆÆ‰Ω†Â§çÂà∂‰∏äÈù¢ÁöÑ‰ª£Á†ÅÔºåÂàõÂª∫Âπ∂‰øùÂ≠òÊü•ËØ¢„ÄÇ‰øùÂ≠òÊü•ËØ¢Êó∂‰∏∫ÂÖ∂Ëµ∑‰∏Ä‰∏™ÂÆπÊòìËØÜÂà´ÁöÑÂêçÁß∞ÔºåÊØîÂ¶ÇÊàë‰ΩøÁî®‚Äúuniswap-pool-count‚Äù‰Ωú‰∏∫Ëøô‰∏™Êü•ËØ¢ÁöÑÂêçÁß∞„ÄÇÂΩìÁÑ∂‰Ω†‰πüÂèØ‰ª•Áõ¥Êé•Fork‰∏ãÈù¢ÂàóÂá∫ÁöÑÂèÇËÄÉÊü•ËØ¢„ÄÇForkÊü•ËØ¢ÁöÑ‰æøÂà©‰πãÂ§ÑÊòØÂèØ‰ª•‰∫ÜËß£Êõ¥Â§öÂèØËßÜÂåñÂõæË°®ÁöÑÁªÜËäÇ„ÄÇ

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1454941](https://dune.com/queries/1454941)

## ÂàõÂª∫Êï∞ÊçÆÁúãÊùøÂπ∂Ê∑ªÂä†ÂõæË°®

### ÂàõÂª∫ÁúãÊùø

È¶ñÂÖàËØ∑ÁôªÂΩïËøõÂÖ•[DuneÁΩëÁ´ô](https://dune.com/)„ÄÇÁÑ∂ÂêéÁÇπÂáªÂ§¥ÈÉ®ÂØºËà™Ê†è‰∏≠ÁöÑ‚ÄúMy Creation‚ÄùÔºåÂÜçÁÇπÂáª‰∏ãÊñπÁöÑ‚ÄúDashboards‚ÄùÔºåËøõÂÖ•Âà∞Â∑≤ÂàõÂª∫ÁöÑÊï∞ÊçÆÁúãÊùøÈ°µÈù¢[https://dune.com/browse/dashboards/authored](https://dune.com/browse/dashboards/authored)„ÄÇË¶ÅÂàõÂª∫Êñ∞ÁöÑÊï∞ÊçÆÁúãÊùøÔºåÁÇπÂáªÂè≥‰æßËæπÊ†è‰∏≠ÁöÑ‚ÄúNew dashboard‚ÄùÊåâÈíÆÂç≥ÂèØ„ÄÇÂú®ÂºπÂá∫ÂØπËØùÊ°Ü‰∏≠ËæìÂÖ•DashboardÁöÑÂêçÁß∞ÔºåÁÑ∂ÂêéÁÇπÂáª‚ÄúSave and open‚ÄùÊåâÈíÆÂç≥ÂèØÂàõÂª∫Êñ∞Êï∞ÊçÆÁúãÊùøÂπ∂ËøõÂÖ•È¢ÑËßàÁïåÈù¢„ÄÇÊàëËøôÈáå‰ΩøÁî®‚ÄúUniswap V3 Pool Tutorial‚Äù‰Ωú‰∏∫Ëøô‰∏™Êï∞ÊçÆÁúãÊùøÁöÑÂêçÁß∞„ÄÇ

### Ê∑ªÂä†Êü•ËØ¢ÂõæË°®

Êñ∞ÂàõÂª∫ÁöÑÊï∞ÊçÆÁúãÊùøÊòØÊ≤°ÊúâÂÜÖÂÆπÁöÑÔºåÈ¢ÑËßàÈ°µÈù¢‰ºöÊòæÁ§∫‚ÄúThis dashboard is empty.‚Äù„ÄÇÊàë‰ª¨ÂèØ‰ª•Â∞Ü‰∏ä‰∏ÄÊ≠•‚ÄúÊü•ËØ¢1‚Äù‰∏≠ÂæóÂà∞ÁöÑËµÑÈáëÊ±†Êï∞ÈáèËΩ¨‰∏∫ÂèØËßÜÂåñÂõæË°®Âπ∂Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÂú®‰∏Ä‰∏™Êñ∞ÁöÑÊµèËßàÂô®Tab‰∏≠ÊâìÂºÄ‚ÄúMy Creations‚ÄùÈ°µÈù¢[https://dune.com/browse/queries/authored](https://dune.com/browse/queries/authored)ÔºåÊâæÂà∞Â∑≤‰øùÂ≠òÁöÑ‚ÄúÊü•ËØ¢1‚ÄùQueryÔºåÁÇπÂáªÂêçÁß∞ËøõÂÖ•ÁºñËæëÈ°µÈù¢„ÄÇÂõ†‰∏∫Êü•ËØ¢Â∑≤Áªè‰øùÂ≠òÂπ∂ÊâßË°åËøáÔºåÊàë‰ª¨ÂèØ‰ª•Ëá™Â∑±ÁÇπÂáª‚ÄúNew visualization‚ÄùÊåâÈíÆÊù•Êñ∞Âª∫‰∏Ä‰∏™ÂèØËßÜÂåñÂõæË°®„ÄÇÂçï‰∏™Êï∞ÂÄºÁ±ªÂûãÁöÑÁöÑÊü•ËØ¢ÁªìÊûúÔºåÈÄöÂ∏∏‰ΩøÁî®ËÆ°Êï∞Âô®ÔºàCounterÔºâÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇ‰ªé‰∏ãÊãâÂàóË°®‚ÄúSelect visualization type‚Äù‰∏≠ÈÄâÊã©‚ÄúCounter‚ÄùÔºåÂÜçÁÇπÂáª‚ÄúAdd Visualization‚ÄùÊåâÈíÆ„ÄÇÁÑ∂ÂêéÂèØ‰ª•ÁªôËøô‰∏™ÂõæË°®ÂëΩÂêçÔºåÂ∞ÜTitleÂÄº‰ªéÈªòËÆ§ÁöÑ‚ÄúCounter‚Äù‰øÆÊîπ‰∏∫‚ÄúÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞‚Äù„ÄÇÊúÄÂêéÔºåÈÄöËøáÁÇπÂáª‚ÄúAdd to dashboard‚ÄúÊåâÈíÆÔºåÂπ∂Âú®ÂºπÂá∫ÂØπËØùÊ°Ü‰∏≠ÁÇπÂáªÂØπÂ∫îÊï∞ÊçÆÁúãÊùøÂè≥ËæπÁöÑ‚ÄúAdd‚ÄùÊåâÈíÆÔºåÂ∞±ÊääËøô‰∏™ËÆ°Êï∞Âô®Á±ªÂûãÁöÑÂõæË°®Ê∑ªÂä†Âà∞‰∫ÜÊï∞ÊçÆÁúãÊùø‰∏≠„ÄÇ

Ê≠§Êó∂Êàë‰ª¨ÂèØ‰ª•ÂõûÂà∞Êï∞ÊçÆÁúãÊùøÈ°µÈù¢ÔºåÂà∑Êñ∞È°µÈù¢ÂèØ‰ª•ÁúãÂà∞Êñ∞Ê∑ªÂä†ÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇÁÇπÂáªÈ°µÈù¢Âè≥‰∏äÊñπÁöÑ‚ÄúEdit‚ÄùÊåâÈíÆÂèØ‰ª•ÂØπÊï∞ÊçÆÁúãÊùøËøõË°åÁºñËæëÔºåÂåÖÊã¨Ë∞ÉÊï¥ÂêÑ‰∏™ÂõæË°®ÁöÑÂ§ßÂ∞è„ÄÅ‰ΩçÁΩÆÔºåÊ∑ªÂä†ÊñáÊú¨ÁªÑ‰ª∂Á≠â„ÄÇ‰∏ãÈù¢ÊòØÂØπ‚ÄúÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞‚ÄùËøô‰∏™ËÆ°Êï∞Âô®ÂõæË°®Ë∞ÉÊï¥‰∫ÜÈ´òÂ∫¶‰πãÂêéÁöÑÊà™Âõæ„ÄÇ

![image_01.png](./img/image_01.png)

### Ê∑ªÂä†ÊñáÊú¨ÁªÑ‰ª∂

Âú®Êï∞ÊçÆÁúãÊùøÁöÑÁºñËæëÈ°µÈù¢ÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÁÇπÂáª‚ÄúAdd text widget‚ÄùÊåâÈíÆÔºåÊ∑ªÂä†ÊñáÊú¨ÁªÑ‰ª∂Âà∞ÁúãÊùø‰∏≠„ÄÇÊñáÊú¨ÁªÑ‰ª∂ÂèØ‰ª•Áî®Êù•‰∏∫Êï∞ÊçÆÁúãÊùøÁöÑÊ†∏ÂøÉÂÜÖÂÆπÊ∑ªÂä†ËØ¥ÊòéÔºåÊ∑ªÂä†‰ΩúËÄÖ‰ø°ÊÅØÁ≠â„ÄÇÊñáÊú¨ÁªÑ‰ª∂ÊîØÊåÅ‰ΩøÁî®MarkdownËØ≠Ê≥ïÂÆûÁé∞‰∏Ä‰∫õÊ†ºÂºèÂåñÂ§ÑÁêÜÔºåÂú®Ê∑ªÂä†ÊñáÊú¨ÁªÑ‰ª∂ÁöÑÂØπËØùÊ°Ü‰∏≠ÁÇπÂáª‚ÄúSome markdown is supported‚ÄùÂ±ïÂºÄÂèØ‰ª•ÁúãÂà∞ÊîØÊåÅÁöÑÁõ∏ÂÖ≥ËØ≠Ê≥ï„ÄÇËØ∑Ê†πÊçÆÈúÄË¶ÅËá™Ë°åÊ∑ªÂä†Áõ∏Â∫îÁöÑÊñáÊú¨ÁªÑ‰ª∂ÔºåËøôÈáåÂ∞±‰∏çËØ¶ÁªÜËØ¥Êòé‰∫Ü„ÄÇ

## Êü•ËØ¢2Ôºö‰∏çÂêåË¥πÁéáÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞Èáè

Ê†πÊçÆÊàë‰ª¨ÈúÄË¶ÅÁöÑÁªìÊûúÊï∞ÊçÆÁöÑÊ†ºÂºèÔºåÊúâ‰∏çÂêåÁöÑÊñπÂºèÊù•ÁªüËÆ°„ÄÇÂ¶ÇÊûúÊÉ≥‰ΩøÁî®ËÆ°Êï∞Âô®ÔºàCounterÔºâÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®ÔºåÂèØ‰ª•ÊääÁõ∏ÂÖ≥ÁªüËÆ°Êï∞Â≠óÂú®Âêå‰∏ÄË°å‰∏≠ËøîÂõû„ÄÇÂ¶ÇÊûúÊÉ≥Áî®‰∏Ä‰∏™ÊâáÂΩ¢ÂõæÔºàPie ChartÔºâÊù•ÊòæÁ§∫ÁªìÊûúÔºåÂàôÂèØ‰ª•ÈÄâÊã©‰ΩøÁî®Group ByÂàÜÁªÑÔºåÂ∞ÜÁªìÊûúÊï∞ÊçÆ‰ª•Â§öË°åÊñπÂºèËøîÂõû„ÄÇ

**‰ΩøÁî®FilterÂ≠êÂè•Ôºö**
```sql
select count(*) filter (where fee = 100) as pool_count_100,
    count(*) filter (where fee = 500) as pool_count_500,
    count(*) filter (where fee = 3000) as pool_count_3000,
    count(*) filter (where fee = 10000) as pool_count_10000
from uniswap_v3_ethereum.Factory_evt_PoolCreated
```

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1454947](https://dune.com/queries/1454947)

Ëøô‰∏™Êü•ËØ¢ËøîÂõû‰∫Ü4‰∏™ËæìÂá∫ÂÄºÔºåÊàë‰ª¨‰∏∫‰ªñ‰ª¨Ê∑ªÂä†Áõ∏Â∫îÁöÑËÆ°Êï∞Âô®ÁªÑ‰ª∂ÔºåÂàÜÂà´ÂëΩÂêç‰∏∫‚Äú0.01%ËµÑÈáëÊ±†Êï∞Èáè‚Äù„ÄÅ‚Äú0.05%ËµÑÈáëÊ±†Êï∞Èáè‚ÄùÁ≠â„ÄÇÁÑ∂ÂêéÊ∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠ÔºåÂú®Êï∞ÊçÆÁúãÊùøÁºñËæëÁïåÈù¢Ë∞ÉÊï¥ÂêÑÁªÑ‰ª∂ÁöÑÂ§ßÂ∞èÂíåÈ°∫Â∫è„ÄÇË∞ÉÊï¥ÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_02.png](./img/image_02.png)

**‰ΩøÁî®Group ByÂ≠êÂè•Ôºö**
```sql
select fee,
    count(*) as pool_count
from uniswap_v3_ethereum.Factory_evt_PoolCreated
group by 1
```

Ë¥πÁéá‚Äúfee‚ÄùÊòØÊï∞ÂÄºÂΩ¢ÂºèÔºå‰ª£Ë°®Áôæ‰∏áÂàÜ‰πãNÁöÑÊî∂Ë¥πË¥πÁéá„ÄÇÊØîÂ¶ÇÔºå3000Ôºå‰ª£Ë°®3000/1000000ÔºåÂç≥‚Äú0.30%‚Äù„ÄÇÁî®`fee`ÁöÑÂÄºÈô§‰ª•10000 Ôºà1e4ÔºâÂç≥ÂèØÂæóÂà∞Áî®ÁôæÂàÜÊØîË°®Á§∫ÁöÑË¥πÁéá„ÄÇ
Â∞ÜÊï∞ÂÄºËΩ¨Êç¢‰∏∫ÁôæÂàÜÊØîË°®Á§∫ÁöÑË¥πÁéáÊõ¥Âä†Áõ¥ËßÇ„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®‰øÆÊîπ‰∏äÈù¢ÁöÑÊü•ËØ¢Êù•ÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºö

```sql
select concat(format('%,.2f', fee / 1e4), '%') as fee_tier,
    count(*) as pool_count
from uniswap_v3_ethereum.Factory_evt_PoolCreated
group by 1
```
ÂÖ∂‰∏≠Ôºå`concat(format('%,.2f', fee / 1e4), '%') as fee_tier`ÈÉ®ÂàÜÁöÑ‰ΩúÁî®ÊòØÂ∞ÜË¥πÁéáËΩ¨Êç¢‰∏∫ÁôæÂàÜÊØîË°®Á§∫ÁöÑÂÄºÔºåÂÜçËøûÊé•‰∏ä‚Äú%‚ÄùÁ¨¶Âè∑Ôºå‰ΩøÁî®Âà´Âêç`fee_tier`ËæìÂá∫„ÄÇÂÖ≥‰∫éformat()ÂáΩÊï∞ÁöÑÂÖ∑‰ΩìËØ≠Ê≥ïÔºåÂèØ‰ª•Êü•ÁúãTrino ÁöÑÂ∏ÆÂä©ÔºàTrinoÊòØDune SQLÁöÑÂ∫ïÂ±ÇÂºïÊìéÔºâ„ÄÇTrinoÂ∏ÆÂä©ÈìæÊé•Ôºöhttps://trino.io/docs/current/functions.html „ÄÇ

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1455127](https://dune.com/queries/1455127)

Êàë‰ª¨‰∏∫Ëøô‰∏™Êü•ËØ¢Ê∑ªÂä†‰∏Ä‰∏™ÊâáÂΩ¢ÂõæÂõæË°®„ÄÇÁÇπÂáª‚ÄúNew visualization‚ÄùÔºå‰ªéÂõæË°®Á±ªÂûã‰∏ãÊãâÂàóË°®ÈÄâÊã©‚ÄúPie Chart‚ÄùÊâáÂΩ¢ÂõæÁ±ªÂûãÔºåÁÇπÂáª‚ÄúAdd visualization‚Äù„ÄÇÂ∞ÜÂõæË°®ÁöÑÊ†áÈ¢ò‰øÆÊîπ‰∏∫‚Äú‰∏çÂêåË¥πÁéáÁöÑËµÑÈáëÊ±†Êï∞Èáè‚Äù„ÄÇÂõæË°®ÁöÑÊ∞¥Âπ≥ÂùêÊ†áËΩ¥ÔºàX ColumnÔºâÈÄâÊã©‚Äúfee_tier‚ÄúÔºåÂûÇÁõ¥ÂùêÊ†áËΩ¥‚ÄúY Column 1‚ÄùÈÄâÊã©‚Äúpool_count‚Äù„ÄÇÂãæÈÄâÂ∑¶‰æßÁöÑ‚ÄúShow data label‚ÄùÈÄâÈ°π„ÄÇÁÑ∂ÂêéÁî®‚ÄúAdd to dashboard‚ÄùÊääËøô‰∏™ÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÂÖ∂ÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_03.png](./img/image_03.png)


## Êü•ËØ¢3ÔºöÊåâÂë®Ê±áÊÄªÁöÑÊñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞

Ë¶ÅÂÆûÁé∞Ê±áÊÄªÊØèÂë®Êñ∞Âª∫ÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞ÈáèÁöÑÁªüËÆ°ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÂú®‰∏Ä‰∏™Â≠êÊü•ËØ¢‰∏≠‰ΩøÁî®date_trunc()ÂáΩÊï∞Â∞ÜËµÑÈáëÊ±†ÁöÑÂàõÂª∫Êó•ÊúüËΩ¨Êç¢‰∏∫ÊØèÂë®ÁöÑÂºÄÂßãÊó•ÊúüÔºàÊòüÊúü‰∏ÄÔºâÔºåÁÑ∂ÂêéÂÜçÁî®Group ByËøõË°åÊ±áÊÄªÁªüËÆ°„ÄÇ

```sql
select block_date, count(pool) as pool_count
from (
    select date_trunc('week', evt_block_time) as block_date,
        evt_tx_hash,
        pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
)
group by 1
order by 1
```

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1455311](https://dune.com/queries/1455311)

ÊåâÊó∂Èó¥ÁªüËÆ°ÁöÑÊï∞ÊçÆÔºåÈÄÇÂêàÁî®Êù°ÂΩ¢Âõæ„ÄÅÈù¢ÁßØÂõæ„ÄÅÊäòÁ∫øÂõæÁ≠âÂΩ¢ÂºèÊù•ËøõË°åÂèØËßÜÂåñÔºåËøôÈáåÊàë‰ª¨Áî®Êù°ÂΩ¢Âõæ„ÄÇÁÇπÂáª‚ÄúNew visualization‚ÄùÔºå‰ªéÂõæË°®Á±ªÂûã‰∏ãÊãâÂàóË°®ÈÄâÊã©‚ÄúBar Chart‚ÄùÊù°ÂΩ¢ÂõæÁ±ªÂûãÔºåÁÇπÂáª‚ÄúAdd visualization‚Äù„ÄÇÂ∞ÜÂõæË°®ÁöÑÊ†áÈ¢ò‰øÆÊîπ‰∏∫‚ÄúÊØèÂë®Êñ∞Âª∫ËµÑÈáëÊ±†Êï∞ÈáèÁªüËÆ°‚Äù„ÄÇÂõæË°®ÁöÑÊ∞¥Âπ≥ÂùêÊ†áËΩ¥ÔºàX ColumnÔºâÈÄâÊã©‚Äúblock_date‚ÄúÔºåÂûÇÁõ¥ÂùêÊ†áËΩ¥‚ÄúY Column 1‚ÄùÈÄâÊã©‚Äúpool_count‚Äù„ÄÇÂèñÊ∂àÂãæÈÄâÂ∑¶‰æßÁöÑ‚ÄúShow chart legend‚ÄùÈÄâÈ°π„ÄÇÁÑ∂ÂêéÁî®‚ÄúAdd to dashboard‚ÄùÊääËøô‰∏™ÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÂÖ∂ÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_04.png](./img/image_04.png)


## Êü•ËØ¢4ÔºöÊúÄËøë30Â§©ÁöÑÊØèÊó•Êñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞

Á±ª‰ººÁöÑÔºåË¶ÅÂÆûÁé∞Ê±áÊÄªÊØèÂ§©Êñ∞Âª∫ÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞ÈáèÁöÑÁªüËÆ°ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÂú®‰∏Ä‰∏™Â≠êÊü•ËØ¢‰∏≠‰ΩøÁî®date_trunc()ÂáΩÊï∞Â∞ÜËµÑÈáëÊ±†ÁöÑÂàõÂª∫Êó•ÊúüËΩ¨Êç¢‰∏∫Â§©Ôºà‰∏çÂê´Êó∂ÂàÜÁßíÂÄºÔºâÔºåÁÑ∂ÂêéÂÜçÁî®Group ByËøõË°åÊ±áÊÄªÁªüËÆ°„ÄÇËøôÈáåÊàë‰ª¨‰ΩøÁî®ÂÖ¨ÂÖ±Ë°®Ë°®ËææÂºèÔºàCTEÔºâÁöÑÊñπÂºèÊù•Êü•ËØ¢„ÄÇ‰∏é‰ΩøÁî®Â≠êÊü•ËØ¢Áõ∏ÊØîÔºåCTEËÉΩËÆ©Êü•ËØ¢ÈÄªËæëÊõ¥Âä†Áõ¥ËßÇÊòìÊáÇ„ÄÅÂÆö‰πâÂêéÂèØ‰ª•Â§öÊ¨°ÈáçÁî®‰ª•ÊèêÂçáÊïàÁéá„ÄÅ‰πüÊõ¥Êñπ‰æøË∞ÉËØï„ÄÇÂêéÁª≠ÁöÑÊü•ËØ¢ÈÉΩ‰ºöÂÄæÂêë‰∫é‰ΩøÁî®CTEÊñπÂºè„ÄÇ

```sql
with pool_details as (
    select date_trunc('day', evt_block_time) as block_date, evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
    where evt_block_time >= now() - interval '29' day
)

select block_date, count(pool) as pool_count
from pool_details
group by 1
order by 1
```

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1455382](https://dune.com/queries/1455382)

Êàë‰ª¨ÂêåÊ†∑‰ΩøÁî®Êù°ÂΩ¢ÂõæÊù•ÂÅöÂèØËßÜÂåñ„ÄÇÊ∑ªÂä†‰∏Ä‰∏™Êù°ÂΩ¢ÂõæÁ±ªÂûãÁöÑÊñ∞ÂõæË°®ÔºåÂ∞ÜÊ†áÈ¢ò‰øÆÊîπ‰∏∫‚ÄúËøë30Â§©ÊØèÊó•Êñ∞Â¢ûËµÑÈáëÊ±†Êï∞Èáè‚Äù„ÄÇÂõæË°®ÁöÑÊ∞¥Âπ≥ÂùêÊ†áËΩ¥ÔºàX ColumnÔºâÈÄâÊã©‚Äúblock_date‚ÄúÔºåÂûÇÁõ¥ÂùêÊ†áËΩ¥‚ÄúY Column 1‚ÄùÈÄâÊã©‚Äúpool_count‚Äù„ÄÇÂèñÊ∂àÂãæÈÄâÂ∑¶‰æßÁöÑ‚ÄúShow chart legend‚ÄùÈÄâÈ°πÔºåÂêåÊó∂ÂãæÈÄâ‰∏ä‚ÄúShow data labels‚ÄùÈÄâÈ°π„ÄÇÁÑ∂ÂêéÊääËøô‰∏™ÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÂÖ∂ÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_05.png](./img/image_05.png)


## Êü•ËØ¢5ÔºöÊåâÂë®Ê±áÊÄªÁöÑÊñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÊÄªÊï∞-ÊåâË¥πÁéáÂàÜÁªÑ

Êàë‰ª¨ÂèØ‰ª•ÂØπÂàÜÁªÑÁªüËÆ°ÁöÑÁª¥Â∫¶ÂÅöËøõ‰∏ÄÊ≠•ÁöÑÁªÜÂàÜÔºåÊåâË¥πÁéáÊù•Ê±áÊÄªÁªüËÆ°ÊØèÂë®ÂÜÖÊñ∞Âª∫ÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞Èáè„ÄÇËøôÊ†∑Êàë‰ª¨ÂèØ‰ª•ÂØπÊØî‰∏çÂêåË¥πÁéáÂú®‰∏çÂêåÊó∂Èó¥ÊÆµÁöÑÊµÅË°åÁ®ãÂ∫¶„ÄÇËøô‰∏™‰æãÂ≠ê‰∏≠Êàë‰ª¨ÊºîÁ§∫Group byÂ§öÁ∫ßÂàÜÁªÑÔºåÂèØËßÜÂåñÂõæË°®Êï∞ÊçÆÁöÑÊù°ÂΩ¢ÂõæÁöÑÂè†Âä†Á≠âÂäüËÉΩ„ÄÇ

```sql
with pool_details as (
    select date_trunc('week', evt_block_time) as block_date, fee, evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
)

select block_date,
    concat(format('%,.2f', fee / 1e4), '%') as fee_tier,
    count(pool) as pool_count
from pool_details
group by 1, 2
order by 1, 2
```

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1455535](https://dune.com/queries/1455535)

Êàë‰ª¨ÂêåÊ†∑‰ΩøÁî®Êù°ÂΩ¢ÂõæÊù•ÂÅöÂèØËßÜÂåñ„ÄÇÊ∑ªÂä†‰∏Ä‰∏™Êù°ÂΩ¢ÂõæÁ±ªÂûãÁöÑÊñ∞ÂõæË°®ÔºåÂ∞ÜÊ†áÈ¢ò‰øÆÊîπ‰∏∫‚Äú‰∏çÂêåË¥πÁéáÊØèÂë®Êñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†Êï∞Èáè‚Äù„ÄÇÂõæË°®ÁöÑÊ∞¥Âπ≥ÂùêÊ†áËΩ¥ÔºàX ColumnÔºâÈÄâÊã©‚Äúblock_date‚ÄúÔºåÂûÇÁõ¥ÂùêÊ†áËΩ¥‚ÄúY Column 1‚ÄùÈÄâÊã©‚Äúpool_count‚Äù„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨ÈúÄË¶ÅÂú®‚ÄúGroup by‚Äù‰∏≠ÈÄâÊã©‚Äúfee_tier‚Äù‰Ωú‰∏∫ÂèØËßÜÂåñÂõæË°®ÁöÑÂàÜÁªÑÊù•ÂÆûÁé∞ÂàÜÁªÑÊòæÁ§∫ÔºåÂêåÊó∂ÂãæÈÄâÂ∑¶‰æßÁöÑ‚ÄúEnable stacking‚ÄùÈÄâÈ°πËÆ©Âêå‰∏ÄÊó•ÊúüÂêå‰∏ÄÂàÜÁªÑÁöÑÊï∞ÊçÆÂè†Âä†Âà∞‰∏ÄËµ∑ÊòæÁ§∫„ÄÇÊääËøô‰∏™ÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠ÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_06.png](./img/image_06.png)


## Êü•ËØ¢6ÔºöÁªüËÆ°ËµÑÈáëÊ±†Êï∞ÈáèÊúÄÂ§öÁöÑ‰ª£Â∏ÅToken

Â¶ÇÊûúÊÉ≥ÂàÜÊûêÂì™‰∫õERC20‰ª£Â∏ÅÂú®UniswapËµÑÈáëÊ±†‰∏≠Êõ¥ÊµÅË°åÔºàÂç≥ÂÆÉ‰ª¨ÂØπÂ∫îÁöÑËµÑÈáëÊ±†Êï∞ÈáèÊõ¥Â§öÔºâÔºåÊàë‰ª¨ÂèØ‰ª•Êåâ‰ª£Â∏ÅÁ±ªÂûãÊù•ÂÅöÂàÜÁªÑÁªüËÆ°„ÄÇ

ÊØè‰∏Ä‰∏™UniswapÊµÅÂä®ËµÑÈáëÊ±†ÈÉΩÁî±‰∏§‰∏™ERC20‰ª£Â∏ÅÁªÑÊàêÔºàtoken0Âíåtoken1ÔºâÔºåÊ†πÊçÆÂÖ∂Âú∞ÂùÄÂìàÂ∏åÂÄºÁöÑÂ≠óÊØçÈ°∫Â∫èÔºåÂêå‰∏ÄÁßçERC20‰ª£Â∏ÅÂèØËÉΩ‰øùÂ≠òÂú®token0‰∏≠Ôºå‰πüÂèØËÉΩ‰øùÂ≠òÂú®token1‰∏≠„ÄÇÊâÄ‰ª•ÔºåÂú®‰∏ãÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨ÈÄöËøá‰ΩøÁî®ÈõÜÂêàÔºàUnionÔºâÊù•ÂæóÂà∞ÂÆåÊï¥ÁöÑËµÑÈáëÊ±†ËØ¶ÁªÜ‰ø°ÊÅØÂàóË°®„ÄÇ

Âè¶Â§ñÔºåËµÑÈáëÊ±†‰∏≠‰øùÂ≠òÁöÑÊòØERC20‰ª£Â∏ÅÁöÑÂêàÁ∫¶Âú∞ÂùÄÔºåÁõ¥Êé•ÊòæÁ§∫‰∏çÂ§üÁõ¥ËßÇ„ÄÇDuneÁ§æÂå∫Áî®Êà∑Êèê‰∫§ÁöÑÈ≠îÊ≥ï‰π¶ÁîüÊàêÁöÑÊäΩË±°Êï∞ÊçÆË°®`tokens.erc20`‰øùÂ≠ò‰∫ÜERC20‰ª£Â∏ÅÁöÑÂü∫Êú¨‰ø°ÊÅØ„ÄÇÈÄöËøáÂÖ≥ËÅîËøô‰∏™Ë°®ÔºåÊàë‰ª¨ÂèØ‰ª•ÂèñÂà∞‰ª£Â∏ÅÁöÑÁ¨¶Âè∑ÔºàSymbolÔºâÔºåÂ∞èÊï∞‰ΩçÊï∞ÔºàDecimalsÔºâÁ≠â„ÄÇËøôÈáåÊàë‰ª¨Âè™ÈúÄ‰ΩøÁî®‰ª£Â∏ÅÁ¨¶Âè∑„ÄÇ

Âõ†‰∏∫Uniswap V3 ‰∏ÄÂÖ±Êúâ8000Â§ö‰∏™ËµÑÈáëÊ±†ÔºåÊ∂âÂèä6000Â§öÁßç‰∏çÂêåÁöÑERC20‰ª£Â∏ÅÔºåÊàë‰ª¨Âè™ÂÖ≥Ê≥®ËµÑÈáëÊ±†ÊúÄÂ§öÁöÑ100‰∏™‰ª£Â∏ÅÁöÑÊï∞ÊçÆ„ÄÇ‰∏ãÈù¢ÁöÑÊü•ËØ¢ÊºîÁ§∫‰ª•‰∏ãÊ¶ÇÂøµÔºöÂ§ö‰∏™CTEÔºåUnionÔºåJoinÔºåLimitÁ≠â„ÄÇ

```sql
with pool_details as (
    select token0 as token_address,
        evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated

    union all

    select token1 as token_address,
        evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
),

token_pool_summary as (
    select token_address,
        count(pool) as pool_count
    from pool_details
    group by 1
    order by 2 desc
    limit 100
)

select t.symbol, p.token_address, p.pool_count
from token_pool_summary p
inner join tokens.erc20 t on p.token_address = t.contract_address
order by 3 desc
```

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1455706](https://dune.com/queries/1455706)

Êàë‰ª¨ÂêåÊ†∑‰ΩøÁî®Êù°ÂΩ¢ÂõæÊù•ÂÅöÂèØËßÜÂåñ„ÄÇÊ∑ªÂä†‰∏Ä‰∏™Êù°ÂΩ¢ÂõæÁ±ªÂûãÁöÑÊñ∞ÂõæË°®ÔºåÂ∞ÜÊ†áÈ¢ò‰øÆÊîπ‰∏∫‚Äú‰∏çÂêåERC20‰ª£Â∏ÅÁöÑËµÑÈáëÊ±†Êï∞ÈáèÔºàTop 100Ôºâ‚Äù„ÄÇÂõæË°®ÁöÑÊ∞¥Âπ≥ÂùêÊ†áËΩ¥ÔºàX ColumnÔºâÈÄâÊã©‚Äúsymbol‚ÄúÔºåÂûÇÁõ¥ÂùêÊ†áËΩ¥‚ÄúY Column 1‚ÄùÈÄâÊã©‚Äúpool_count‚Äù„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÊéíÂ∫èÈ°∫Â∫èÔºàÊåâÊï∞Èáè‰ªéÂ§öÂà∞Â∞ëÔºâÔºåÂèñÊ∂àÂãæÈÄâÂè≥‰æßÁöÑ‚ÄúSort values‚ÄùÈÄâÈ°π„ÄÇËôΩÁÑ∂Êàë‰ª¨ÈôêÂÆö‰∫ÜÂè™ÂèñÂâçÈù¢ÁöÑ100‰∏™‰ª£Â∏ÅÁöÑÊï∞ÊçÆÔºå‰ªéÊü•ËØ¢ÁªìÊûú‰∏≠‰ªçÁÑ∂ÂèØ‰ª•ÁúãÂà∞ÔºåÂêÑÁßçTokenÁöÑËµÑÈáëÊ±†Êï∞ÈáèÂ∑ÆÂºÇÂæàÂ§ßÔºåÊúÄÂ§öÁöÑÊúâ5000Â§ö‰∏™ÔºåÂ∞ëÁöÑÂàôÂè™ÊúâÂá†‰∏™„ÄÇ‰∏∫‰∫ÜËÆ©ÂõæË°®Êõ¥Áõ¥ËßÇÔºåËØ∑ÂãæÈÄâÂè≥‰æßÁöÑ‚ÄúLogarithmic‚ÄùÈÄâÈ°πÔºåËÆ©ÂõæË°®Êï∞ÊçÆ‰ª•ÂØπÊï∞ÂåñÂêéÊòæÁ§∫„ÄÇÊääËøô‰∏™ÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠ÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_07.png](./img/image_07.png)

Áî±‰∫éÂØπÊï∞ÂåñÊòæÁ§∫Â§ÑÁêÜ‰ªéËßÜËßâ‰∏äÂº±Âåñ‰∫ÜÂ∑ÆÂºÇÂÄºÔºåÊàë‰ª¨ÂèØ‰ª•ÂêåÊó∂Ê∑ªÂä†‰∏Ä‰∏™‚ÄúTable‚ÄúÊï∞ÊçÆË°®Á±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®ÔºåÊñπ‰æøÁî®Êà∑Êü•ÁúãÂÆûÈôÖÁöÑÊï∞ÂÄº„ÄÇÁªßÁª≠‰∏∫Ëøô‰∏™Êü•ËØ¢Ê∑ªÂä†Êñ∞ÁöÑÂèØËßÜÂåñÂõæË°®ÔºåÈÄâÊã©‚ÄúTable‚ÄùÂõæË°®Á±ªÂûã„ÄÇÊ†áÈ¢òËÆæÁΩÆ‰∏∫‚ÄúÂâç100ÁßçERC20‰ª£Â∏ÅÁöÑËµÑÈáëÊ±†Êï∞ÈáèÁªüËÆ°‚Äù„ÄÇÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅÂØπËøô‰∏™ÂèØËßÜÂåñË°®Ê†ºÁöÑÁõ∏ÂÖ≥ÈÄâÈ°πÂÅöË∞ÉÊï¥ÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞Dashboard‰∏≠„ÄÇ

![image_08.png](./img/image_08.png)

‰Ω†ÂèØËÉΩÁïôÊÑèÂà∞Ë°®Ê†ºËøîÂõûÁöÑÊï∞ÊçÆÂÆûÈôÖ‰∏äÊ≤°Êúâ100Ë°åÔºåËøôÊòØÂõ†‰∏∫ÈÉ®ÂàÜÊñ∞Âá∫Áé∞ÁöÑ‰ª£Â∏ÅÂèØËÉΩËøòÊú™Ë¢´Ê∑ªÂä†Âà∞Âà∞DuneÂà∞Êï∞ÊçÆË°®‰∏≠„ÄÇ


## Êü•ËØ¢7ÔºöÊúÄÊñ∞ÁöÑ100‰∏™ÊµÅÂä®ËµÑÈáëÊ±†ËÆ∞ÂΩï

ÂΩìÊüê‰∏™È°πÁõÆÊñπÂèëË°å‰∫ÜÊñ∞ÁöÑERC20‰ª£Â∏ÅÂπ∂ÊîØÊåÅ‰∏äÂ∏ÇÊµÅÈÄöÊó∂ÔºåUniswapÁî®Êà∑ÂèØËÉΩ‰ºöÂú®Á¨¨‰∏ÄÊó∂Èó¥ÂàõÂª∫Áõ∏Â∫îÁöÑÊµÅÂä®ËµÑÈáëÊ±†Ôºå‰ª•ËÆ©ÂÖ∂‰ªñÁî®Êà∑ËøõË°åÂÖëÊç¢„ÄÇÊØîÂ¶ÇÔºåXEN‰ª£Â∏ÅÂ∞±ÊòØËøëÊúüÁöÑ‰∏Ä‰∏™ÊØîËæÉËΩ∞Âä®ÁöÑÊ°à‰æã„ÄÇ

Êàë‰ª¨ÂèØ‰ª•ÈÄöËøáÊü•ËØ¢ÊúÄÊñ∞ÂàõÂª∫ÁöÑËµÑÈáëÊ±†Êù•Ë∑üË∏™Êñ∞ÁöÑË∂ãÂäø„ÄÇ‰∏ãÈù¢ÁöÑÊü•ËØ¢ÂêåÊ†∑ÂÖ≥ËÅî`tokens.erc20`Ë°®Ëé∑ÔºåÈÄöËøá‰∏çÂêåÁöÑÂà´ÂêçÂ§öÊ¨°ÂÖ≥ËÅîÁõ∏ÂêåÁöÑË°®Êù•Ëé∑Âèñ‰∏çÂêå‰ª£Â∏ÅÁöÑÁ¨¶Âè∑„ÄÇÊú¨Êü•ËØ¢ËøòÊºîÁ§∫‰∫ÜËæìÂá∫ÂèØËßÜÂåñË°®Ê†ºÔºåËøûÊé•Â≠óÁ¨¶‰∏≤ÁîüÊàêË∂ÖÈìæÊé•Á≠âÂäüËÉΩ„ÄÇ

```sql
with last_crated_pools as (
    select p.evt_block_time,
        t0.symbol as token0_symbol,
        p.token0,
        t1.symbol as token1_symbol,
        p.token1,
        p.fee,
        p.pool,
        p.evt_tx_hash
    from uniswap_v3_ethereum.Factory_evt_PoolCreated p
    inner join tokens.erc20 t0 on p.token0 = t0.contract_address and t0.blockchain = 'ethereum'
    inner join tokens.erc20 t1 on p.token1 = t1.contract_address and t1.blockchain = 'ethereum'
    order by p.evt_block_time desc
    limit 100
)

select evt_block_time,
    token0_symbol || '-' || token1_symbol || ' ' || format('%,.2f', fee / 1e4) || '%' as pool_name,
    '<a href=https://etherscan.io/address/' || cast(pool as varchar) || ' target=_blank>' || cast(pool as varchar) || '</a>' as pool_link,
    token0,
    token1,
    fee,
    evt_tx_hash
from last_crated_pools
order by evt_block_time desc
```

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1455897](https://dune.com/queries/1455897)

Êàë‰ª¨‰∏∫Êü•ËØ¢Ê∑ªÂä†‰∏Ä‰∏™‚ÄúTable‚ÄúÊï∞ÊçÆË°®Á±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®ÔºåÂ∞ÜÊ†áÈ¢òËÆæÁΩÆ‰∏∫‚ÄúÊúÄÊñ∞ÂàõÂª∫ÁöÑËµÑÈáëÊµÅÂä®Ê±†ÂàóË°®‚Äù„ÄÇÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅÂØπËøô‰∏™ÂèØËßÜÂåñË°®Ê†ºÁöÑÁõ∏ÂÖ≥ÈÄâÈ°πÂÅöË∞ÉÊï¥ÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞Dashboard‰∏≠„ÄÇ

![image_09.png](./img/image_09.png)

# ÊÄªÁªì

Ëá≥Ê≠§ÔºåÊàë‰ª¨Â∞±ÂÆåÊàê‰∫ÜÁ¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùøÁöÑÂàõÂª∫„ÄÇËøô‰∏™Êï∞ÊçÆÁúãÊùøÁöÑÂÆåÊï¥ÁïåÈù¢ÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![dashboard.png](./img/dashboard.png)

‰∏∫‰∫ÜÈÅøÂÖçÂÜÖÂÆπÂ§™ËøáÊ∑±Â••ÈöæÊáÇÔºåÊàë‰ª¨Âè™ÊòØÂÅö‰∫Ü‰∏Ä‰∫õÂü∫Êú¨ÁöÑÊü•ËØ¢ÔºåÊï¥‰∏™Êï∞ÊçÆÁúãÊùøÁöÑÂõæË°®ÁúãËµ∑Êù•ÂèØËÉΩ‰∏ç‰∏ÄÂÆöÈÇ£‰πàÁÇ´ÈÖ∑„ÄÇ‰ΩÜÊòØËøô‰∏™Âπ∂‰∏çÈáçË¶ÅÔºåÊàë‰ª¨Êõ¥ÂÖ≥ÂøÉÁöÑÊòØ‰Ω†ËÉΩÂê¶ÈÄöËøáËøôÁØáÊïôÁ®ãÂºÄÂßãËµ∞‰∏äËá™Â∑±ÁöÑÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê‰πãË∑Ø„ÄÇ
Â∏åÊúõÂ§ßÂÆ∂Âú®ÁúãÂÆå‰πãÂêéÂä®ÊâãÂ∞ùËØï‰∏Ä‰∏ãÔºåÈÄâ‰æãUniswapÊòØ‰∏Ä‰∏™DEXÔºåÁ±ª‰ººÁöÑÊàë‰ª¨ÂèØ‰ª•ÂØπ‰ªªÊÑèÈìæ‰∏äÁöÑDEXËøõË°åÂàÜÊûê„ÄÇÁªìÂêà‰∏ä‰∏ÄËÆ≤‰∏≠ÁöÑÊäÄÂ∑ßÔºåÂ§ßÂÆ∂ÂèØ‰ª•Â∞ùËØïÂØπÂÖ∂‰ªñDEXÔºåÁîöËá≥Âêå‰∏ÄDex‰∏çÂêåÈìæ‰∏äÊï∞ÊçÆËøõË°åÂàÜÊûêÊØîËæÉÔºàÂ¶ÇUniSwapÂú®EthereumÂíåOptimism‰∏äÁöÑÊï∞ÊçÆÔºâ„ÄÇÊàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåÁúãÊùøÂ∞±ÊòØ‰Ω†ÁöÑÁÆÄÂéÜÔºåËÆ§ÁúüÂÅöËµ∑Êù•ÂêßÔºÅ

# ‰Ωú‰∏öÂÜÖÂÆπ
ËØ∑ÁªìÂêàÊïôÁ®ãÂÜÖÂÆπÔºåÂà∂‰ΩúÂØπ‰ªªÊÑèDEXËøõË°å‰∏çÂ∞ë‰∫é5‰∏™Êü•ËØ¢ÁöÑÊï∞ÊçÆÁúãÊùøÔºåÁúãÊùøÂëΩÂêçÊ†ºÂºè‰∏∫SixdegreeAssignment1-Áß∞ÂëºÔºåÂ¶ÇSixdegreeAssignment1-SpringÔºåÊñπ‰æøÂ§ßÂÆ∂‰∫íÁõ∏Â≠¶‰π†Ôºå‰πüÊñπ‰æøÊàë‰ª¨ÊääÊè°ÊïôÂ≠¶Ë¥®Èáè„ÄÇ‰∏∫‰∫ÜÈºìÂä±Â§ßÂÆ∂ÁßØÊûÅÂä®ÊâãÂà∂‰ΩúÁúãÊùøÔºåÊàë‰ª¨Â∞ÜÂØπ‰Ωú‰∏öÂÆåÊàêÊÉÖÂÜµÂíåË¥®ÈáèËøõË°åËÆ∞ÂΩïÔºå‰πãÂêéËøΩÊ∫Ø‰∏∫Â§ßÂÆ∂Êèê‰æõ‰∏ÄÂÆöÁöÑÂ•ñÂä±ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éDuneÁ§æÂå∫Ë∫´‰ªΩÔºåÂë®ËæπÂÆûÁâ©ÔºåAPIÂÖçË¥πÈ¢ùÂ∫¶ÔºåPOAPÔºåÂêÑÁ±ªÂêà‰ΩúÁöÑÊï∞ÊçÆ‰∫ßÂìÅ‰ºöÂëòÔºåÂå∫ÂùóÈìæÊï∞ÊçÆÂàÜÊûêÂ∑•‰ΩúÊú∫‰ºöÊé®ËçêÔºåÁ§æÂå∫Á∫ø‰∏ãÊ¥ªÂä®‰ºòÂÖàÊä•ÂêçËµÑÊ†º‰ª•ÂèäÂÖ∂‰ªñSixdegreeÁ§æÂå∫ÊøÄÂä±Á≠â„ÄÇ

Âä†Ê≤πÔºÅÊ¨¢ËøéÂ§ßÂÆ∂Â∞ÜËá™Â∑±ÁöÑÊï∞ÊçÆÁúãÊùøÈìæÊé•ÂàÜ‰∫´Âà∞Dune‰∫§ÊµÅÂæÆ‰ø°Áæ§„ÄÅDuneÁöÑDiscord‰∏≠ÊñáÈ¢ëÈÅì„ÄÇ

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Êú¨ÊñáÁî±SixdegreeLabÊàêÂëòSpring ZhangÔºà[@superamscom](https://twitter.com/superamscom)ÔºâÊí∞Á®ø„ÄÇÂõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch05/readme.md">
---
title: 05. ÁÜüÊÇâÊï∞ÊçÆË°®
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - erc721
---

# 5. ÁÜüÊÇâÊï∞ÊçÆË°®

‰ª•Dune‰∏∫‰ª£Ë°®ÁöÑÊï∞ÊçÆÂπ≥Âè∞Â∞ÜÂå∫ÂùóÈìæÊï∞ÊçÆËß£Êûê‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì‰∏≠„ÄÇÊï∞ÊçÆÂàÜÊûêÂ∏àÈíàÂØπÂÖ∑‰ΩìÁöÑÂàÜÊûêÈúÄÊ±ÇÔºåÁºñÂÜôSQL‰ªéÁõ∏Â∫îÁöÑÊï∞ÊçÆË°®‰∏≠Êü•ËØ¢Êï∞ÊçÆËøõË°åÂàÜÊûê„ÄÇÁõÆÂâçÂ∏ÇÈù¢‰∏äÊµÅË°åÁöÑÂå∫ÂùóÈìæË∂äÊù•Ë∂äÂ§öÔºåÊñ∞ÁöÑÂå∫ÂùóÈìæËøòÂú®‰∏çÊñ≠Âá∫Áé∞ÔºåÈÉ®ÁΩ≤Âà∞‰∏çÂêåÂå∫ÂùóÈìæ‰∏äÁöÑÂêÑÁ±ªÈ°πÁõÆ‰πüË∂äÊù•Ë∂ä‰∏∞ÂØå„ÄÇÂ¶Ç‰ΩïÂø´ÈÄüÊâæÂà∞ÂæÖÂàÜÊûêÁöÑÈ°πÁõÆÂØπÂ∫îÁöÑÊï∞ÊçÆË°®ÔºåÁêÜËß£ÊéåÊè°ÂØπÂ∫îÊï∞ÊçÆË°®ÈáåÊØè‰∏™Â≠óÊÆµÁöÑÂê´‰πâÂíåÁî®ÈÄîÔºåÊòØÊØè‰∏Ä‰∏™ÂàÜÊûêÂ∏àÂøÖÈ°ªÊéåÊè°ÁöÑÊäÄËÉΩ„ÄÇ

ÁõÆÂâçÊàë‰ª¨ÁÜüÊÇâÁöÑÂá†‰∏™Êï∞ÊçÆÂπ≥Âè∞Êèê‰æõÁöÑÂü∫Á°ÄÊï∞ÊçÆÈõÜÁöÑÊï¥‰ΩìÁªìÊûÑÊØîËæÉÁõ∏‰ººÔºåÊàë‰ª¨ËøôÈáåÂè™Âõ¥ÁªïDuneÂπ≥Âè∞Êù•ËÆ≤Ëß£„ÄÇÂ¶ÇÊûú‰Ω†ÂÅèÂ•Ω‰ΩøÁî®ÂÖ∂‰ªñÊï∞ÊçÆÂπ≥Âè∞ÔºåÂèØ‰ª•ÈÄöËøáËØ•Âπ≥Âè∞ÂØπÂ∫îÁöÑÊñáÊ°£‰∫ÜËß£ËØ¶ÊÉÖ„ÄÇÁî±‰∫éDuneÂ∑≤ÁªèÊ≠£ÂºèÂÆ£Â∏ÉÂú®2023Âπ¥ÂÜÖÂÖ®Èù¢ÂàáÊç¢Âà∞Dune SQLÊü•ËØ¢ÂºïÊìéÔºåÊàë‰ª¨Â∑≤Â∞ÜÊú¨ÊïôÁ®ã‰∏≠ÁöÑÂÖ®ÈÉ®QueryÂçáÁ∫ßÂà∞Dune SQL ÁâàÊú¨„ÄÇ

## Dune V2Êï∞ÊçÆÂºïÊìéÊï∞ÊçÆË°®‰ªãÁªç

Dune Âπ≥Âè∞ÁöÑÊï∞ÊçÆÈõÜÂàÜ‰∏∫Âá†Áßç‰∏çÂêåÁöÑÁ±ªÂûãÔºö
- **ÂéüÂßãÊï∞ÊçÆÔºàRawÔºâ**ÔºöÂ≠òÂÇ®‰∫ÜÊú™ÁªèÁºñËæëÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆ„ÄÇÂåÖÊã¨blocks„ÄÅtransactions„ÄÅtracesÁ≠âÊï∞ÊçÆË°®„ÄÇËøô‰∫õÂéüÂßãÊï∞ÊçÆË°®‰øùÂ≠ò‰∫ÜÊúÄÂéüÂßãÁöÑÈìæ‰∏äÊï∞ÊçÆÔºåÂèØÁî®‰∫éÁÅµÊ¥ªÁöÑÊï∞ÊçÆÂàÜÊûê„ÄÇ
- **Â∑≤Ëß£ÊûêÈ°πÁõÆÔºàDecoded ProjectsÔºâ**ÔºöÂ≠òÂÇ®‰∫ÜÁªèËøáËß£Á†ÅÂêéÁöÑÊô∫ËÉΩÂêàÁ∫¶‰∫ã‰ª∂Êó•ÂøóÂèäË∞ÉÁî®Êï∞ÊçÆË°®„ÄÇÊØîÂ¶ÇUniswap V3Áõ∏ÂÖ≥ÁöÑË°®ÔºåOpensea SeaportÁõ∏ÂÖ≥ÁöÑË°®Á≠â„ÄÇDune‰ΩøÁî®Êô∫ËÉΩÂêàÁ∫¶ÁöÑ ABI(Application Binary Interface) ÂíåÊ†áÂáÜÂåñ‰ª£Â∏ÅÊô∫ËÉΩÂêàÁ∫¶ÁöÑÊé•Âè£Ê†áÂáÜÔºàERC20„ÄÅERC721 Á≠âÔºâÊù•Ëß£ÊûêÊï∞ÊçÆÔºåÂπ∂Â∞ÜÊØè‰∏Ä‰∏™‰∫ã‰ª∂ÊàñËÄÖÊñπÊ≥ïË∞ÉÁî®ÁöÑÊï∞ÊçÆÂçïÁã¨‰øùÂ≠òÂà∞‰∏Ä‰∏™Êï∞ÊçÆË°®‰∏≠„ÄÇ
- **È≠îÊ≥ïË°®ÔºàSpellsÔºâ**ÔºöÈ≠îÊ≥ïË°®Âú®Dune V1‰∏≠‰πüÂè´ÊäΩË±°Ë°®ÔºàAbstractionsÔºâÔºåÊòØDuneÂíåÁ§æÂå∫Áî®Êà∑‰∏ÄËµ∑ÈÄöËøáspellbook githubÂ≠òÂÇ®Â∫ìÊù•Âª∫ËÆæÂíåÁª¥Êä§ÔºåÂπ∂ÈÄöËøádbtÁºñËØëÁîüÊàêÁöÑÊï∞ÊçÆË°®ÔºåËøô‰∫õÊï∞ÊçÆË°®ÈÄöÂ∏∏‰ΩøÁî®Ëµ∑Êù•Êõ¥‰∏∫‰æøÊç∑È´òÊïà„ÄÇ
- **Á§æÂå∫Ë¥°ÁåÆÊï∞ÊçÆÔºàCommunityÔºâ**ÔºöËøôÈÉ®ÂàÜÊòØÁî±Á¨¨‰∏âÊñπÂêà‰ΩúÁªÑÁªáÊèê‰æõÁöÑÊï∞ÊçÆÊ∫êÔºåËá™Âä®Êé•ÂÖ•Âà∞DuneÁöÑÊï∞ÊçÆÈõÜÈáå‰æõÂàÜÊûêÂ∏à‰ΩøÁî®„ÄÇÁõÆÂâçDune‰∏ä‰∏ªË¶ÅÊúâ`flashbots`Âíå`reservoir`‰∏§‰∏™Á§æÂå∫Êù•Ê∫êÊï∞ÊçÆÈõÜ„ÄÇ
- **Áî®Êà∑ÁîüÊàêÁöÑÊï∞ÊçÆË°®ÔºàUser Generated TablesÔºâ**ÔºöÁõÆÂâçDune V2ÂºïÊìéÂ∞öÊú™ÂºÄÊîæÊ≠§ÂäüËÉΩÔºåÂè™ËÉΩÈÄöËøáÈ≠îÊ≥ïË°®ÁöÑÊñπÂºèÊù•‰∏ä‰º†ÔºàÁîüÊàêÔºâËá™ÂÆö‰πâÊï∞ÊçÆË°®„ÄÇ

Âú®DuneÂπ≥Âè∞ÁöÑQueryÁºñËæëÈ°µÈù¢ÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÂ∑¶ËæπÊ†èÊù•ÈÄâÊã©ÊàñÊêúÁ¥¢ÈúÄË¶ÅÁöÑÊï∞ÊçÆË°®„ÄÇËøôÈÉ®ÂàÜÁïåÈù¢Â¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_01.png](img/image_01.png)


ÂõæÁâá‰∏≠Èó¥ÁöÑÊñáÊú¨Ê°ÜÂèØ‰ª•Áî®‰∫éÊêúÁ¥¢ÂØπÂ∫îÁöÑÊï∞ÊçÆÊ®°Âºè(Schema)ÊàñÊï∞ÊçÆË°®„ÄÇÊØîÂ¶ÇÔºåËæìÂÖ•`erc721`Â∞ÜÁ≠õÈÄâÂá∫ÂêçÁß∞ÂåÖÂê´Ëøô‰∏™Â≠óÁ¨¶‰∏≤ÁöÑÊâÄÊúâÈ≠îÊ≥ïË°®ÂíåÂ∑≤Ëß£ÊûêÈ°πÁõÆË°®„ÄÇÂõæÁâá‰∏≠‰∏äÊñπÁöÑÁ∫¢Ê°ÜÈÉ®ÂàÜÁî®‰∫éÈÄâÊã©Ë¶Å‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜÔºåÈÄî‰∏≠ÊòæÁ§∫ÁöÑ‚Äúv2 Dune SQL‚ÄùÂ∞±ÊòØÊàë‰ª¨ÈÄöÂ∏∏ËØ¥ÁöÑ‚ÄúDune SQLÂºïÊìé‚Äù„ÄÇDune Â∞Ü‰∫é2023Âπ¥‰∏ãÂçäÂπ¥ÂÖ®Èù¢ËøáÊ∏°Âà∞Dune SQLÂºïÊìéÔºåÊâÄ‰ª•Áé∞Âú®Â§ßÂÆ∂Âè™ÈúÄÁÜüÊÇâDune SQLÁöÑËØ≠Ê≥ïÂç≥ÂèØ„ÄÇ

‰∏äÂõæ‰∏≠‰∏ãÊñπÁöÑÁ∫¢Ê°ÜÂúàÂá∫ÁöÑÊòØÂâçÈù¢ÊâÄËø∞Dune V2 ÂºïÊìéÁõÆÂâçÊîØÊåÅÁöÑÂá†Â§ßÁ±ªÊï∞ÊçÆÈõÜ„ÄÇÁÇπÂáªÁ≤ó‰ΩìÂàÜÁ±ªÊ†áÁ≠æÊñáÂ≠óÂç≥ÂèØËøõÂÖ•‰∏ã‰∏ÄÁ∫ßÊµèËßàËØ•Á±ªÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÂêÑÁßçÊï∞ÊçÆÊ®°Âºè‰ª•ÂèäÂêÑÊ®°Âºè‰∏ãÁöÑÊï∞ÊçÆË°®ÂêçÁß∞„ÄÇÁÇπÂáªÂàÜÁ±ªÊ†áÁ≠æËøõÂÖ•‰∏ã‰∏ÄÁ∫ßÂêéÔºå‰Ω†ËøòÂèØ‰ª•ÁúãÂà∞‰∏Ä‰∏™ÈªòËÆ§ÈÄâÈ°π‰∏∫‚ÄúAll Chains‚ÄùÁöÑ‰∏ãÊãâÂàóË°®ÔºåÂèØ‰ª•Áî®Êù•Á≠õÈÄâ‰Ω†ÈúÄË¶ÅÁöÑÂå∫ÂùóÈìæ‰∏ãÁöÑÊï∞ÊçÆÊ®°ÂºèÂíåÊï∞ÊçÆË°®„ÄÇÂΩìËøõÂÖ•Âà∞Êï∞ÊçÆË°®Â±ÇÁ∫ßÊó∂ÔºåÁÇπÂáªË°®ÂêçÂèØ‰ª•Â±ïÂºÄÊü•ÁúãË°®‰∏≠ÁöÑÂ≠óÊÆµÂàóË°®„ÄÇÁÇπÂáªË°®ÂêçÂè≥ËæπÁöÑ‚Äú„Äã‚ÄùÂõæÊ†áÂèØ‰ª•Â∞ÜË°®ÂêçÔºàÊ†ºÂºè‰∏∫`schema_name.table_name`ÊèíÂÖ•Âà∞Êü•ËØ¢ÁºñËæëÂô®‰∏≠ÂÖâÊ†áÊâÄÂú®‰ΩçÁΩÆ„ÄÇÂàÜÁ∫ßÊµèËßàÁöÑÂêåÊó∂‰Ω†‰πüÂèØ‰ª•ËæìÂÖ•ÂÖ≥ÈîÆÂ≠óÂú®ÂΩìÂâçÊµèËßàÁöÑÂ±ÇÁ∫ßËøõ‰∏ÄÊ≠•ÊêúÁ¥¢ËøáÊª§„ÄÇ‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆË°®Êúâ‰∏çÂêåÁöÑÂ±ÇÊ¨°Ê∑±Â∫¶Ôºå‰∏ãÂõæ‰∏∫Â∑≤Ëß£ÊûêÊï∞ÊçÆË°®ÁöÑÊµèËßàÁ§∫‰æã„ÄÇ

![image_03.png](img/image_03.png)

## ÂéüÂßãÊï∞ÊçÆË°®

Âå∫ÂùóÈìæ‰∏≠ÂÖ∏ÂûãÁöÑÂéüÂßãÊï∞ÊçÆË°®ÂåÖÊã¨ÔºöÂå∫ÂùóË°®ÔºàBlocksÔºâ„ÄÅ‰∫§ÊòìË°®ÔºàTransactionsÔºâ„ÄÅÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®ÔºàTracesÔºâ„ÄÅ‰∫ã‰ª∂Êó•ÂøóË°®ÔºàLogsÔºâ‰ª•ÂèäÂêàÁ∫¶ÂàõÂª∫Ë∑üË∏™Ë°®Ôºàcreation_tracesÔºâ„ÄÇÂéüÂßãÊï∞ÊçÆË°®ÁöÑÂëΩÂêçÊ†ºÂºè‰∏∫`blockchain_name.table_name`Ôºå‰æãÂ¶Çarbitrum.logsÔºåbnb.blocksÔºåethereum.transactionsÔºåoptimism.tracesÁ≠â„ÄÇÈÉ®ÂàÜÂå∫ÂùóÈìæÊúâÊõ¥Â§öÊàñËÄÖÊõ¥Â∞ëÁöÑÂéüÂßãÊï∞ÊçÆË°®ÔºåÊàë‰ª¨‰ΩøÁî®‰ª•Â§™Âùä‰∏∫‰æãÂÅöÁÆÄÂçï‰ªãÁªç„ÄÇ

### Âå∫ÂùóË°®Ôºàethereum.blocksÔºâ
Âå∫ÂùóÔºàBlockÔºâÊòØÂå∫ÂùóÈìæÁöÑÂü∫Êú¨ÊûÑÂª∫ÁªÑ‰ª∂„ÄÇ‰∏Ä‰∏™Âå∫ÂùóÂåÖÂê´Â§ö‰∏™‰∫§ÊòìËÆ∞ÂΩï„ÄÇÂå∫ÂùóË°®ËÆ∞ÂΩï‰∫ÜÊØè‰∏Ä‰∏™Âå∫ÂùóÁîüÊàêÁöÑÊó•ÊúüÊó∂Èó¥(block time)„ÄÅÂØπÂ∫îÁöÑÂå∫ÂùóÁºñÂè∑(block number)„ÄÅÂå∫ÂùóÂìàÂ∏åÂÄº„ÄÅÈöæÂ∫¶ÂÄº„ÄÅÁáÉÊñôÊ∂àËÄóÁ≠â‰ø°ÊÅØ„ÄÇÈô§‰∫ÜÈúÄË¶ÅÂàÜÊûêÊï¥‰∏™Âå∫ÂùóÈìæÁöÑÂå∫ÂùóÁîüÊàêÁä∂ÂÜµ„ÄÅÁáÉÊñôÊ∂àËÄóÁ≠âÂú∫ÊôØÂ§ñÔºåÊàë‰ª¨‰∏ÄËà¨Âπ∂‰∏çÈúÄË¶ÅÂÖ≥Ê≥®Âíå‰ΩøÁî®Âå∫ÂùóË°®„ÄÇÂÖ∂‰∏≠ÊúÄÈáçË¶ÅÁöÑÊòØÂå∫ÂùóÁîüÊàêÊó•ÊúüÊó∂Èó¥ÂíåÂå∫ÂùóÁºñÂè∑‰ø°ÊÅØÔºåÂÆÉ‰ª¨Âá†‰πéÈÉΩÂêåÊó∂‰øùÂ≠òÂà∞‰∫ÜÂÖ∂‰ªñÊâÄÊúâÊï∞ÊçÆË°®‰∏≠ÔºåÂè™ÊòØÂØπÂ∫îÁöÑÂ≠óÊÆµÂêçÁß∞‰∏çÂêå„ÄÇ

### ‰∫§ÊòìË°®Ôºàethereum.transactionsÔºâ

‰∫§ÊòìË°®‰øùÂ≠ò‰∫ÜÂå∫ÂùóÈìæ‰∏äÂèëÁîüÁöÑÊØè‰∏Ä‰∏™‰∫§ÊòìÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºàÂêåÊó∂ÂåÖÊã¨ÊàêÂäü‰∫§ÊòìÂíåÂ§±Ë¥•‰∫§ÊòìÔºâ„ÄÇ‰ª•Â§™ÂùäÁöÑ‰∫§ÊòìË°®ÁªìÊûÑÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_02.png](img/image_02.png)

‰∫§ÊòìË°®‰∏≠ÊúÄÂ∏∏Áî®ÁöÑÂ≠óÊÆµÂåÖÊã¨block_timeÔºàÊàñblock_numberÔºâ„ÄÅfrom„ÄÅto„ÄÅvalue„ÄÅhash„ÄÅsuccessÁ≠â„ÄÇDune V2ÂºïÊìéÊòØÂü∫‰∫éÂàóÂ≠òË¥ÆÁöÑÊï∞ÊçÆÂ∫ìÔºåÊØè‰∏™Ë°®ÈáåÁöÑÊï∞ÊçÆÊòØÊåâÂàóÂ≠òË¥ÆÁöÑ„ÄÇÊåâÂàóÂ≠òË¥ÆÁöÑÊï∞ÊçÆË°®Êó†Ê≥ï‰ΩøÁî®‰º†ÁªüÊÑè‰πâ‰∏äÁöÑÁ¥¢ÂºïÔºåËÄåÊòØ‰æùËµñ‰∫é‰øùÂ≠òÊúâ‚ÄúÊúÄÂ∞èÂÄº/ÊúÄÂ§ßÂÄº‚ÄùÂ±ûÊÄßÁöÑÂÖÉÊï∞ÊçÆÊù•ÊèêÂçáÊü•ËØ¢ÊÄßËÉΩ„ÄÇÂØπ‰∫éÊï∞ÂÄºÁ±ªÂûãÊàñËÄÖÊó•ÊúüÊó∂Èó¥Á±ªÂûãÔºåÂèØ‰ª•ÂæàÂÆπÊòìËÆ°ÁÆóÂá∫‰∏ÄÁªÑÂÄº‰∏≠ÁöÑÊúÄÂ∞èÂÄº/ÊúÄÂ§ßÂÄº„ÄÇÁõ∏ÂèçÔºåÂØπ‰∫éÂ≠óÁ¨¶‰∏≤Á±ªÂûãÔºåÂõ†‰∏∫ÈïøÂ∫¶ÂèØÂèòÔºåÂæàÈöæÈ´òÊïàËÆ°ÁÆóÂá∫‰∏ÄÁªÑÂ≠óÁ¨¶‰∏≤Êï∞ÊçÆ‰∏≠ÁöÑÊúÄÂ∞èÂÄº/ÊúÄÂ§ßÂÄº„ÄÇËøôÂ∞±ÂØºËá¥V2ÂºïÊìéÂú®ÂÅöÂ≠óÁ¨¶‰∏≤Á±ªÂûãÁöÑÊü•ËØ¢Êó∂ÊØîËæÉ‰ΩéÊïàÔºåÊâÄ‰ª•Êàë‰ª¨ÈÄöÂ∏∏ÈúÄË¶ÅÂêåÊó∂ÁªìÂêà‰ΩøÁî®Êó•ÊúüÊó∂Èó¥Á±ªÂûãÊàñËÄÖÊï∞ÂÄºÁ±ªÂûãÁöÑËøáÊª§Êù°‰ª∂Êù•ÊèêÂçáÊü•ËØ¢ÊâßË°åÊÄßËÉΩ„ÄÇÂ¶ÇÂâçÊâÄËø∞Ôºåblock_time, block_numberÂ≠óÊÆµÂá†‰πéÂ≠òÂú®‰∫éÊâÄÊúâÁöÑÊï∞ÊçÆË°®‰∏≠ÔºàÂú®‰∏çÂêåÁ±ªÂûãÊï∞ÊçÆË°®‰∏≠ÂêçÁß∞‰∏çÂêåÔºâÔºåÊàë‰ª¨Â∫îÂÖÖÂàÜÂà©Áî®ÂÆÉ‰ª¨Êù•Á≠õÈÄâÊï∞ÊçÆÔºåÁ°Æ‰øùÊü•ËØ¢ÂèØ‰ª•È´òÊïàÊâßË°å„ÄÇÊõ¥Â§öÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÂèØ‰ª•Êü•Áúã[Dune V2Êü•ËØ¢ÂºïÊìéÂ∑•‰ΩúÊñπÂºè](https://docs.dune.com/dune-engine-v2-beta/query-engine#changes-in-how-the-database-works)Êù•‰∫ÜËß£„ÄÇ

### ÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®Ôºàethereum.tracesÔºâ

‰∏Ä‰∏™‰∫§ÊòìÔºàTransactionsÔºâÂèØ‰ª•Ëß¶ÂèëÊõ¥Â§öÁöÑÂÜÖÈÉ®Ë∞ÉÁî®Êìç‰ΩúÔºå‰∏Ä‰∏™ÂÜÖÈÉ®Ë∞ÉÁî®ËøòÂèØËÉΩËøõ‰∏ÄÊ≠•Ëß¶ÂèëÊõ¥Â§öÁöÑÂÜÖÈÉ®Ë∞ÉÁî®„ÄÇËøô‰∫õË∞ÉÁî®ÊâßË°åÁöÑ‰ø°ÊÅØ‰ºöË¢´ËÆ∞ÂΩïÂà∞ÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®„ÄÇÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®‰∏ªË¶ÅÂåÖÊã¨block_time„ÄÅblock_number„ÄÅtx_hash„ÄÅsuccess„ÄÅfrom„ÄÅto„ÄÅvalue„ÄÅtypeÁ≠âÂ≠óÊÆµ„ÄÇ

ÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®Êúâ‰∏§‰∏™ÊúÄÂ∏∏ËßÅÁöÑÁî®ÈÄîÔºö
1. Áî®‰∫éË∑üË∏™Âå∫ÂùóÈìæÂéüÁîü‰ª£Â∏ÅÔºàTokenÔºâÁöÑËΩ¨Ë¥¶ËØ¶ÊÉÖÊàñËÄÖÁáÉÊñôÊ∂àËÄó„ÄÇÊØîÂ¶ÇÔºåÂØπ‰∫é‰ª•Â§™ÂùäÔºåÁî®Êà∑ÂèØËÉΩÈÄöËøáÊüê‰∏™DAPPÁöÑÊô∫ËÉΩÂêàÁ∫¶Â∞ÜETHËΩ¨Ë¥¶Âà∞Âè¶‰∏Ä‰∏™ÔºàÊàñËÄÖÂ§ö‰∏™ÔºâÂú∞ÂùÄ„ÄÇËøôÁßçÊÉÖÂÜµ‰∏ãÔºå`ethereum.transactions`Ë°®ÁöÑ`value`Â≠óÊÆµÂπ∂Ê≤°Êúâ‰øùÂ≠òËΩ¨Ë¥¶ÁöÑETHÁöÑÈáëÈ¢ùÊï∞ÊçÆÔºåÂÆûÈôÖÁöÑËΩ¨Ë¥¶ÈáëÈ¢ùÂè™‰øùÂ≠òÂú®ÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®ÁöÑ`value`ÂÄº‰∏≠„ÄÇÂè¶Â§ñÔºåÁî±‰∫éÂéüÁîü‰ª£Â∏Å‰∏çÂ±û‰∫éERC20‰ª£Â∏ÅÔºåÊâÄ‰ª•‰πüÊó†Ê≥ïÈÄöËøáERC20ÂçèËÆÆÁöÑTransfer‰∫ã‰ª∂Êù•Ë∑üË∏™ËΩ¨Ë¥¶ËØ¶ÊÉÖ„ÄÇÂå∫ÂùóÈìæ‰∫§ÊòìÁöÑÁáÉÊñôË¥πÁî®‰πüÊòØÁî®ÂéüÁîü‰ª£Â∏ÅÊù•ÊîØ‰ªòÁöÑÔºåÁáÉÊñôÊ∂àËÄóÊï∞ÊçÆÂêåÊó∂‰øùÂ≠ò‰∫é‰∫§ÊòìË°®ÂíåÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®Ë°®„ÄÇ‰∏Ä‰∏™‰∫§ÊòìÂèØËÉΩÊúâÂ§ö‰∏™ÂÜÖÈÉ®ÂêàÁ∫¶Ë∞ÉÁî®ÔºåË∞ÉÁî®ÂÜÖÈÉ®ËøòÂèØ‰ª•ÂèëËµ∑Êñ∞ÁöÑË∞ÉÁî®ÔºåËøôÂ∞±ÂØºËá¥ÊØè‰∏™Ë∞ÉÁî®ÁöÑ`from`Ôºå`to`Âπ∂‰∏ç‰∏ÄËá¥Ôºå‰πüÂ∞±ÊÑèÂë≥ÁùÄÂÖ∑‰ΩìÊîØ‰ªòË∞ÉÁî®ÁáÉÊñôË¥πÁöÑË¥¶Êà∑Âú∞ÂùÄ‰∏ç‰∏ÄËá¥„ÄÇÊâÄ‰ª•ÔºåÂΩìÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÊüê‰∏™Âú∞ÂùÄÊàñËÄÖ‰∏ÄÁªÑÂú∞ÂùÄÁöÑÂéüÁîü‰ª£Â∏ÅETH‰ΩôÈ¢ùÊó∂ÔºåÂè™Êúâ‰ΩøÁî®`ethereum.traces`Ë°®ÊâçËÉΩËÆ°ÁÆóÂá∫ÂáÜÁ°ÆÁöÑ‰ΩôÈ¢ù„ÄÇ Ëøô‰∏™Êü•ËØ¢ÊúâËÆ°ÁÆóETH‰ΩôÈ¢ùÁöÑÁ§∫‰æãÔºö[ETHÈ°∂Á∫ßÊåÅÊúâËÄÖ‰ΩôÈ¢ù](https://dune.com/queries/1001498/1731554)
2. Áî®‰∫éÁ≠õÈÄâÂêàÁ∫¶Âú∞ÂùÄ„ÄÇ‰ª•Â§™Âùä‰∏äÁöÑÂú∞ÂùÄÂàÜ‰∏∫‰∏§Â§ßÁ±ªÂûãÔºåÂ§ñÈÉ®Êã•ÊúâÁöÑÂú∞ÂùÄÔºàExternal Owned Address, EOAÔºâÂíåÂêàÁ∫¶Âú∞ÂùÄÔºàContract AddressÔºâ„ÄÇEOAÂ§ñÈÉ®Êã•ÊúâÂú∞ÂùÄÊòØÊåáÁî±‰ª•Â§™ÂùäÁî®Êà∑Êã•ÊúâÁöÑÂú∞ÂùÄÔºåËÄåÂêàÁ∫¶Âú∞ÂùÄÊòØÈÄöËøáÈÉ®ÁΩ≤Êô∫ËÉΩÂêàÁ∫¶ÁöÑ‰∫§ÊòìÊù•ÂàõÂª∫ÁöÑ„ÄÇÂΩìÈÉ®ÁΩ≤Êñ∞ÁöÑÊô∫ËÉΩÂêàÁ∫¶Êó∂Ôºå`ethereum.traces`Ë°®‰∏≠ÂØπÂ∫îËÆ∞ÂΩïÁöÑ`type`Â≠óÊÆµ‰øùÂ≠òÁöÑÂÄº‰∏∫`create`„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÁâπÂæÅÁ≠õÈÄâÂá∫Êô∫ËÉΩÂêàÁ∫¶Âú∞ÂùÄ„ÄÇDune V2ÈáåÈù¢ÔºåDuneÂõ¢ÈòüÂ∑≤ÁªèÂ∞ÜÂàõÂª∫Êô∫ËÉΩÂêàÁ∫¶ÁöÑÂÜÖÈÉ®Ë∞ÉÁî®ËÆ∞ÂΩïÊï¥ÁêÜÂá∫Êù•ÔºåÂçïÁã¨ÊîæÂà∞‰∫ÜË°®`ethereum.creation_traces`‰∏≠„ÄÇÈÄöËøáÁõ¥Êé•Êü•ËØ¢Ëøô‰∏™Ë°®Â∞±ËÉΩÁ°ÆÂÆöÊüê‰∏™Âú∞ÂùÄÊòØ‰∏çÊòØÂêàÁ∫¶Âú∞ÂùÄ„ÄÇ

### ‰∫ã‰ª∂Êó•ÂøóË°®Ôºàethereum.logsÔºâ

‰∫ã‰ª∂Êó•ÂøóË°®Â≠òÂÇ®‰∫ÜÊô∫ËÉΩÂêàÁ∫¶ÁîüÊàêÁöÑÊâÄÊúâ‰∫ã‰ª∂Êó•Âøó„ÄÇÂΩìÊàë‰ª¨ÈúÄË¶ÅÊü•ËØ¢ÂàÜÊûêÈÇ£‰∫õÂ∞öÊú™Ë¢´Ëß£Á†ÅÊàñËÄÖÊó†Ê≥ïËß£Á†ÅÔºàÁî±‰∫é‰ª£Á†ÅÈùûÂºÄÊ∫êÁ≠âÂéüÂõ†ÔºâÁöÑÊô∫ËÉΩÂêàÁ∫¶Ôºå‰∫ã‰ª∂Êó•ÂøóË°®ÈùûÂ∏∏ÊúâÁî®„ÄÇÈÄöÂ∏∏ÔºåÊàë‰ª¨Âª∫ËÆÆ‰ºòÂÖà‰ΩøÁî®Â∑≤Ëß£ÊûêÁöÑÊï∞ÊçÆË°®ÔºåËøôÊ†∑ÂèØ‰ª•ÊèêÈ´òÊïàÁéáÂπ∂Èôç‰ΩéÂú®Êü•ËØ¢‰∏≠ÂºïÂÖ•ÈîôËØØÁöÑÂèØËÉΩÊÄß„ÄÇ‰ΩÜÊòØÔºåÊúâÊó∂Áî±‰∫éÊó∂ÊïàÊÄßÔºàÂêàÁ∫¶ËøòÊú™Êù•ÂæóÂèäË¢´Ëß£Á†ÅÔºâÊàñËÄÖÂêàÁ∫¶Êú¨Ë∫´‰∏çÊîØÊåÅË¢´Ëß£Á†ÅÁöÑÂéüÂõ†ÔºåÊàë‰ª¨Â∞±‰∏çÂæó‰∏çÁõ¥Êé•ËÆøÈóÆ‰∫ã‰ª∂Êó•ÂøóË°®Êù•Êü•ËØ¢Êï∞ÊçÆËøõË°åÂàÜÊûê„ÄÇ

‰∫ã‰ª∂Êó•ÂøóË°®‰∏ªË¶ÅÂåÖÊã¨block_time„ÄÅblock_number„ÄÅtx_hash„ÄÅcontract_address„ÄÅtopic1„ÄÅtopic2„ÄÅtopic3„ÄÅtopic4„ÄÅdataÁ≠âÂ≠óÊÆµ„ÄÇ‰ΩøÁî®Êó∂ÈúÄË¶ÅÊ≥®ÊÑèÁöÑË¶ÅÁÇπÂåÖÊã¨Ôºö
- `topic1` Â≠òË¥ÆÁöÑÊòØ‰∫ã‰ª∂ÂØπÂ∫îÁöÑÊñπÊ≥ïÁ≠æÂêçÁöÑÂìàÂ∏åÂÄº„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂêåÊó∂‰ΩøÁî®contract_address Âíåtopic1Á≠õÈÄâÊù°‰ª∂Êù•ÊâæÂá∫Êüê‰∏™Êô∫ËÉΩÂêàÁ∫¶ÁöÑÊüê‰∏™ÊñπÊ≥ïÁöÑÂÖ®ÈÉ®‰∫ã‰ª∂Êó•ÂøóËÆ∞ÂΩï„ÄÇ
- `topic2`„ÄÅ`topic3`„ÄÅ`topic4` Â≠òË¥ÆÁöÑÊòØ‰∫ã‰ª∂Êó•ÂøóÁöÑÂèØÁ¥¢ÂºïÂèÇÊï∞Ôºà‰∏ªÈ¢òÔºâÔºåÊØè‰∏™‰∫ã‰ª∂ÊúÄÂ§öÊîØÊåÅ3‰∏™ÂèØÁ¥¢Âºï‰∏ªÈ¢òÂèÇÊï∞„ÄÇÂΩìÁ¥¢Âºï‰∏ªÈ¢òÂèÇÊï∞‰∏çË∂≥3‰∏™Êó∂ÔºåÂâ©‰ΩôÁöÑÂ≠óÊÆµ‰∏ç‰øùÂ≠ò‰ªª‰ΩïÂÄº„ÄÇÂÖ∑‰ΩìÂà∞ÊØè‰∏Ä‰∏™‰∫ã‰ª∂ÔºåËøôÂá†‰∏™‰∏ªÈ¢òÂèÇÊï∞ÊâÄ‰øùÂ≠òÁöÑÂÄºÂêÑ‰∏çÁõ∏Âêå„ÄÇÊàë‰ª¨ÂèØ‰ª•ÁªìÂêàEtherScanËøôÊ†∑ÁöÑÂå∫ÂùóÈìæÊµèËßàÂô®‰∏äÊòæÁ§∫ÁöÑÊó•ÂøóÊù•ÂØπÁÖßÁ°ÆËÆ§ÊØè‰∏Ä‰∏™‰∏ªÈ¢òÂèÇÊï∞‰ª£Ë°®‰ªÄ‰πàÂê´‰πâ„ÄÇÊàñËÄÖ‰πüÂèØ‰ª•Êü•ÈòÖÂØπÂ∫îÊô∫ËÉΩÂêàÁ∫¶ÁöÑÊ∫ê‰ª£Á†ÅÊù•‰∫ÜËß£‰∫ã‰ª∂ÂèÇÊï∞ÁöÑËØ¶ÁªÜÂÆö‰πâ„ÄÇ
- `data`Â≠òË¥ÆÁöÑÊòØ‰∫ã‰ª∂ÂèÇÊï∞‰∏≠Ê≤°ÊúâË¢´Ê†áËÆ∞‰∏∫Á¥¢Âºï‰∏ªÈ¢òÁ±ªÂûãÁöÑÂÖ∂‰ªñÂ≠óÊÆµÁöÑ16ËøõÂà∂ÁöÑÁªÑÂêàÂÄºÔºåÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÔºå‰ª•`0x`ÂºÄÂ§¥ÔºåÊØè‰∏™ÂèÇÊï∞ÂåÖÊã¨64‰∏™Â≠óÁ¨¶ÔºåÂÆûÈôÖÂèÇÊï∞ÂÄº‰∏çË∂≥64‰ΩçÂàôÂú®Â∑¶‰æßÂ°´ÂÖÖ`0`Êù•Ë°•Ë∂≥‰ΩçÊï∞„ÄÇÂΩìÊàë‰ª¨ÈúÄË¶Å‰ªédataÈáåÈù¢Ëß£ÊûêÊï∞ÊçÆÊó∂ÔºåÂ∞±Ë¶ÅÊåâÁÖß‰∏äËø∞ÁâπÂæÅÔºå‰ªéÁ¨¨3‰∏™Â≠óÁ¨¶ÂºÄÂßãÔºå‰ª•ÊØè64‰∏™Â≠óÁ¨¶‰∏∫‰∏ÄÁªÑËøõË°åÊãÜÂàÜÔºåÁÑ∂ÂêéÂÜçÊåâÂÖ∂ÂÆûÈôÖÂ≠òË¥ÆÁöÑÊï∞ÊçÆÁ±ªÂûãËøõË°åËΩ¨Êç¢Â§ÑÁêÜÔºàËΩ¨‰∏∫Âú∞ÂùÄ„ÄÅËΩ¨‰∏∫Êï∞ÂÄºÊàñËÄÖÂ≠óÁ¨¶‰∏≤Á≠âÔºâ„ÄÇ

ËøôÈáåÊòØ‰∏Ä‰∏™Áõ¥Êé•Ëß£ÊûêlogsË°®ÁöÑÊü•ËØ¢Á§∫‰æãÔºö[https://dune.com/queries/1510688](https://dune.com/queries/1510688)„ÄÇ‰Ω†ÂèØ‰ª•Â§çÂà∂Êü•ËØ¢ÁªìÊûú‰∏≠ÁöÑtx_hashÂÄºËÆøÈóÆEtherScanÁ´ôÁÇπÔºåÂàáÊç¢Âà∞‚ÄúLogs‚ÄùÊ†áÁ≠æÈ°µËøõË°åÂØπÁÖß„ÄÇ‰∏ãÂõæÊòæÁ§∫‰∫ÜEtherScan‰∏äÁöÑ‰æãÂ≠êÔºö

![image_04.png](img/image_04.png)

## Â∑≤Ëß£ÊûêÈ°πÁõÆË°®

Â∑≤Ëß£ÊûêÈ°πÁõÆË°®ÊòØÊï∞ÈáèÊúÄÂ∫ûÂ§ßÁöÑÊï∞ÊçÆË°®Á±ªÂûã„ÄÇÂΩìÊô∫ËÉΩÂêàÁ∫¶Ë¢´Êèê‰∫§Âà∞DuneËøõË°åËß£ÊûêÊó∂ÔºåDune‰∏∫ÂÖ∂‰∏≠ÁöÑÊØè‰∏Ä‰∏™ÊñπÊ≥ïË∞ÉÁî®ÔºàCallÔºâÂíå‰∫ã‰ª∂Êó•ÂøóÔºàEventÔºâÁîüÊàê‰∏Ä‰∏™ÂØπÂ∫îÁöÑ‰∏ìÁî®Êï∞ÊçÆË°®„ÄÇÂú®DuneÁöÑÊü•ËØ¢ÁºñËæëÂô®ÁöÑÂ∑¶ËæπÊ†è‰∏≠ÔºåËøô‰∫õÂ∑≤Ëß£ÊûêÈ°πÁõÆÊï∞ÊçÆË°®ÊåâÂ¶Ç‰∏ãÂ±ÇÁ∫ßÊù•ÈÄêÁ∫ßÂ±ïÁ§∫Ôºö

```
category name -> project name (namespace) -> contract name -> function name / event name

-- Sample
Decoded projects -> uniswap_v3 -> Factory -> PoolCreated
```

Â∑≤Ëß£ÊûêÈ°πÁõÆË°®ÁöÑÂëΩÂêçËßÑÂàôÂ¶Ç‰∏ãÔºö
‰∫ã‰ª∂Êó•ÂøóÔºö`projectname_blockchain.contractName_evt_eventName`
ÂáΩÊï∞Ë∞ÉÁî®Ôºö`projectname_blockchain.contractName_call_functionName`
‰æãÂ¶ÇÔºå‰∏äÈù¢ÁöÑUniswap V3 ÁöÑ PoolCreated ‰∫ã‰ª∂ÂØπÂ∫îÁöÑË°®Âêç‰∏∫`uniswap_v3_ethereum.Factory_evt_PoolCreated`„ÄÇ

‰∏Ä‰∏™ÈùûÂ∏∏ÂÆûÁî®ÁöÑÊñπÊ≥ïÊòØÊü•ËØ¢`ethereum.contracts`È≠îÊ≥ïË°®Êù•Á°ÆËÆ§‰Ω†ÂÖ≥Ê≥®ÁöÑÊô∫ËÉΩÂêàÁ∫¶ÊòØÂê¶Â∑≤ÁªèË¢´Ëß£Êûê„ÄÇËøô‰∏™Ë°®Â≠òË¥Æ‰∫ÜÊâÄÊúâÂ∑≤Ëß£ÊûêÁöÑÊô∫ËÉΩÂêàÁ∫¶ÁöÑËÆ∞ÂΩï„ÄÇÂ¶ÇÊûúÊü•ËØ¢ÁªìÊûúÊòæÁ§∫Êô∫ËÉΩÂêàÁ∫¶Â∑≤Ë¢´Ëß£ÊûêÔºå‰Ω†Â∞±ÂèØ‰ª•Áî®‰∏äÈù¢‰ªãÁªçÁöÑÊñπÊ≥ïÂú®Êü•ËØ¢ÁºñËæëÂô®ÁïåÈù¢Âø´ÈÄüÊµèËßàÊàñÊêúÁ¥¢ÂÆö‰ΩçÂà∞ÂØπÂ∫îÁöÑÊô∫ËÉΩÂêàÁ∫¶ÁöÑÊï∞ÊçÆË°®ÂàóË°®„ÄÇÂ¶ÇÊûúÊü•ËØ¢Êó†ÁªìÊûúÔºåÂàôË°®Á§∫Êô∫ËÉΩÂêàÁ∫¶Â∞öÊú™Ë¢´Ëß£ÊûêÔºå‰Ω†ÂèØ‰ª•Â∞ÜÂÖ∂Êèê‰∫§ÁªôDuneÂõ¢ÈòüÂéªËß£ÊûêÂ§ÑÁêÜÔºö[Êèê‰∫§Ëß£ÊûêÊñ∞ÂêàÁ∫¶](https://dune.com/contracts/new)„ÄÇÂèØ‰ª•Êèê‰∫§‰ªªÊÑèÁöÑÂêàÁ∫¶Âú∞ÂùÄÔºå‰ΩÜÂøÖÈ°ªÊòØÊúâÊïàÁöÑÊô∫ËÉΩÂêàÁ∫¶Âú∞ÂùÄÂπ∂‰∏îÊòØÂèØ‰ª•Ë¢´Ëß£ÊûêÁöÑÔºàDuneËÉΩËá™Âä®ÊèêÂèñÂà∞ÂÖ∂ABI‰ª£Á†ÅÊàñËÄÖ‰Ω†ÊúâÂÆÉÁöÑABI‰ª£Á†ÅÔºâ„ÄÇ

Êàë‰ª¨Âà∂‰Ωú‰∫Ü‰∏Ä‰∏™Êï∞ÊçÆÁúãÊùøÔºå‰Ω†ÂèØ‰ª•Áõ¥Êé•Êü•ËØ¢[Ê£ÄÊü•Êô∫ËÉΩÂêàÁ∫¶ÊòØÂê¶Â∑≤Ë¢´Ëß£Á†Å](https://dune.com/sixdegree/decoded-projects-contracts-check)

## È≠îÊ≥ïË°®

È≠îÊ≥ï‰π¶ÔºàSpellbookÔºâÊòØ‰∏Ä‰∏™Áî±DuneÁ§æÂå∫ÂÖ±ÂêåÂª∫ËÆæÁöÑÊï∞ÊçÆËΩ¨Êç¢Â±ÇÈ°πÁõÆ„ÄÇÈ≠îÊ≥ïÔºàSpellÔºâÂèØ‰ª•Áî®Êù•ÊûÑÂª∫È´òÁ∫ßÊäΩË±°Ë°®Ê†ºÔºåÈ≠îÊ≥ïÂèØ‰ª•Áî®Êù•Êü•ËØ¢ËØ∏Â¶Ç NFT ‰∫§ÊòìË°®Á≠âÂ∏∏Áî®Ê¶ÇÂøµÊï∞ÊçÆ„ÄÇÈ≠îÊ≥ï‰π¶È°πÁõÆÂèØËá™Âä®ÊûÑÂª∫Âπ∂Áª¥Êä§Ëøô‰∫õË°®Ê†ºÔºå‰∏îÂØπÂÖ∂Êï∞ÊçÆË¥®ÈáèËøõË°åÊ£ÄÊµã„ÄÇ DuneÁ§æÂå∫‰∏≠ÁöÑ‰ªª‰Ωï‰∫∫ÈÉΩÂèØ‰ª•Ë¥°ÁåÆÈ≠îÊ≥ï‰π¶‰∏≠ÁöÑÈ≠îÊ≥ïÔºåÂèÇ‰∏éÊñπÂºèÊòØÊèê‰∫§github PRÔºåÈúÄË¶ÅÊéåÊè°githubÊ∫ê‰ª£Á†ÅÁÆ°ÁêÜÂ∫ìÁöÑÂü∫Êú¨‰ΩøÁî®ÊñπÊ≥ï„ÄÇÂ¶ÇÊûú‰Ω†Â∏åÊúõÂèÇ‰∏éË¥°ÁåÆÈ≠îÊ≥ïË°®ÔºåÂèØ‰ª•ËÆøÈóÆ[Dune Spellbook](https://dune.com/docs/spellbook/)ÊñáÊ°£‰∫ÜËß£ËØ¶ÊÉÖ„ÄÇ

DuneÁ§æÂå∫ÈùûÂ∏∏Ê¥ªË∑ÉÔºåÂ∑≤ÁªèÂàõÂª∫‰∫ÜÈùûÂ∏∏Â§öÁöÑÈ≠îÊ≥ïË°®„ÄÇÂÖ∂‰∏≠ÂæàÂ§öÈ≠îÊ≥ïË°®Â∑≤Ë¢´ÂπøÊ≥õ‰ΩøÁî®Âú®Êàë‰ª¨ÁöÑÊó•Â∏∏Êï∞ÊçÆÂàÜÊûê‰∏≠ÔºåÊàë‰ª¨Âú®ËøôÈáåÂØπÈáçË¶ÅÁöÑÈ≠îÊ≥ïË°®ÂÅö‰∏Ä‰∫õ‰ªãÁªç„ÄÇ

### ‰ª∑Ê†º‰ø°ÊÅØË°®Ôºàprices.usdÔºåprices.usd_latestÔºâ

‰ª∑Ê†º‰ø°ÊÅØË°®`prices.usd`ËÆ∞ÂΩï‰∫ÜÂêÑÂå∫ÂùóÈìæ‰∏ä‰∏ªÊµÅERC20‰ª£Â∏ÅÁöÑÊØèÂàÜÈíü‰ª∑Ê†º„ÄÇÂΩìÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜÂ∞ÜÂ§öÁßç‰ª£Â∏ÅËøõË°åÁªüËÆ°Ê±áÊÄªÊàñÁõ∏‰∫íÂØπÊØîÊó∂ÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂÖ≥ËÅî‰ª∑Ê†º‰ø°ÊÅØË°®Áªü‰∏ÄÊç¢ÁÆó‰∏∫ÁæéÂÖÉ‰ª∑Ê†ºÂíåÈáëÈ¢ùÂêéÂÜçËøõË°åÊ±áÊÄªÊàñÂØπÊØî„ÄÇ‰ª∑Ê†º‰ø°ÊÅØË°®ÁõÆÂâçÊèê‰æõ‰∫Ü‰ª•Â§™Âùä„ÄÅBNB„ÄÅSolanaÁ≠âÈìæÁöÑÂ∏∏ËßÅERC20‰ª£Â∏Å‰ª∑Ê†º‰ø°ÊÅØÔºåÁ≤æÁ°ÆÂà∞ÊØèÂàÜÈíü„ÄÇÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÊåâÂ§©ÊàñËÄÖÊåâÂ∞èÊó∂ÁöÑ‰ª∑Ê†ºÔºåÂèØ‰ª•ÈÄöËøáÊ±ÇÂπ≥ÂùáÂÄºÁöÑÊñπÂºèÊù•ËÆ°ÁÆóÂá∫Âπ≥Âùá‰ª∑Ê†º„ÄÇ‰∏ãÈù¢‰∏§‰∏™Á§∫‰æãÊü•ËØ¢ÊºîÁ§∫‰∫Ü‰∏§ÁßçÂêåÊó∂Ëé∑ÂèñÂ§ö‰∏™tokenÁöÑÊØèÊó•‰ª∑Ê†ºÁöÑÊñπÂºèÔºö
- [Ëé∑ÂèñÊØèÊó•Âπ≥Âùá‰ª∑Ê†º](https://dune.com/queries/1507164)
- [Ëé∑ÂèñÊØèÂ§©ÁöÑÊúÄÂêé‰∏ÄÊù°‰ª∑Ê†ºÊï∞ÊçÆ](https://dune.com/queries/1506944)

ÊúÄÊñ∞‰ª∑Ê†ºË°®Ôºàprices.usd_latestÔºâÊèê‰æõ‰∫ÜÁõ∏ÂÖ≥ERC20‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇ

### DeFi‰∫§Êòì‰ø°ÊÅØË°®(dex.tradesÔºådex_aggregator.trades)

DeFi‰∫§Êòì‰ø°ÊÅØË°®`dex.trades`Êèê‰æõ‰∫Ü‰∏ªÊµÅDEX‰∫§ÊòìÊâÄÁöÑ‰∫§ÊòìÊï∞ÊçÆÔºåÂõ†‰∏∫ÂêÑÁßçDeFiÈ°πÁõÆÊØîËæÉÂ§öÔºåDuneÁ§æÂå∫ËøòÂú®Ëøõ‰∏ÄÊ≠•ÂÆåÂñÑÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÊ∫êÔºåÁõÆÂâçÂ∑≤ÁªèÈõÜÊàêÁöÑÊúâuniswap„ÄÅsushiswap„ÄÅcurvefi„ÄÅairswap„ÄÅclipper„ÄÅshibaswap„ÄÅswapr„ÄÅdefiswap„ÄÅdfx„ÄÅpancakeswap_trades„ÄÅdodoÁ≠âDEXÊï∞ÊçÆ„ÄÇDeFi‰∫§Êòì‰ø°ÊÅØË°®ÊòØÂ∞ÜÊù•Ëá™‰∏çÂêåÈ°πÁõÆÁöÑ‰∫§Êòì‰ø°ÊÅØÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºåËøô‰∫õÈ°πÁõÆÊú¨Ë∫´‰πüÊúâÂÖ∂ÂØπÂ∫îÁöÑÈ≠îÊ≥ïË°®Ê†ºÔºåÊØîÂ¶ÇUniswap Êúâ`uniswap.trades`ÔºåCurveFiÊúâ`curvefi_ethereum.trades`Á≠â„ÄÇÂ¶ÇÊûúÊàë‰ª¨Âè™ÊÉ≥ÂàÜÊûêÂçï‰∏™DeFiÈ°πÁõÆÁöÑ‰∫§ÊòìÔºå‰ΩøÁî®Ëøô‰∫õÈ°πÁõÆÁâπÊúâÁöÑÈ≠îÊ≥ïË°®‰ºöÊõ¥Â•Ω„ÄÇ

DEXËÅöÂêàÂô®‰∫§ÊòìË°®`dex_aggregator.trades`‰øùÂ≠ò‰∫ÜÊù•Ëá™DeFiËÅöÂêàÂô®ÁöÑ‰∫§ÊòìËÆ∞ÂΩï„ÄÇËøô‰∫õËÅöÂêàÂô®ÁöÑ‰∫§ÊòìÈÄöÂ∏∏ÊúÄÁªà‰ºöÊèê‰∫§Âà∞Êüê‰∏™DEX‰∫§ÊòìÊâÄÊâßË°å„ÄÇÂçïÁã¨Êï¥ÁêÜÂà∞‰∏ÄËµ∑ÂèØ‰ª•ÈÅøÂÖç‰∏é`dex.trades`ËÆ∞ÂΩïÈáçÂ§çËÆ°ÁÆó„ÄÇÁºñÂÜôÊú¨ÊñáÊó∂ÔºåÊöÇÊó∂ËøòÂè™Êúâ`cow_protocol`ÁöÑÊï∞ÊçÆ„ÄÇ

### TokensË°®Ôºàtokens.erc20Ôºåtokens.nftÔºâ

TokensË°®ÁõÆÂâç‰∏ªË¶ÅÂåÖÊã¨ERC20‰ª£Â∏ÅË°®`tokens.erc20`ÂíåNFTË°®ÔºàERC721Ôºâ`tokens.nft`„ÄÇ`tokens.erc20`Ë°®ËÆ∞ÂΩï‰∫ÜÂêÑÂå∫ÂùóÈìæ‰∏ä‰∏ªÊµÅERC20‰ª£Â∏ÅÁöÑÂÆö‰πâ‰ø°ÊÅØÔºåÂåÖÊã¨ÂêàÁ∫¶Âú∞ÂùÄ„ÄÅ‰ª£Â∏ÅÁ¨¶Âè∑„ÄÅ‰ª£Â∏ÅÂ∞èÊï∞‰ΩçÊï∞Á≠â„ÄÇ`tokens.nft`Ë°®ËÆ∞ÂΩï‰∫ÜÂêÑNFTÈ°πÁõÆÁöÑÂü∫Êú¨‰ø°ÊÅØÔºåËøô‰∏™Ë°®ÁöÑÊï∞ÊçÆÊ∫êÁõÆÂâçËøò‰æùËµñÁ§æÂå∫Áî®Êà∑Êèê‰∫§PRÊù•ËøõË°åÊõ¥Êñ∞ÔºåÂèØËÉΩÂ≠òÂú®Êõ¥Êñ∞Âª∂Ëøü„ÄÅÊï∞ÊçÆ‰∏çÂÆåÊï¥Á≠âÈóÆÈ¢ò„ÄÇÁî±‰∫éÂå∫ÂùóÈìæ‰∏äÊï∞ÊçÆÈÉΩÊòØÂ∑≤ÂéüÂßãÊï∞ÊçÆÊ†ºÂºè‰øùÂ≠òÁöÑÔºåÈáëÈ¢ùÊï∞ÂÄº‰∏çÂåÖÊã¨Â∞èÊï∞‰ΩçÊï∞ÔºåÊàë‰ª¨ÂøÖÈ°ªÁªìÂêà`tokens.erc20`‰∏≠ÁöÑÂ∞èÊï∞‰ΩçÊï∞ÊâçËÉΩÊ≠£Á°ÆËΩ¨Êç¢Âá∫ÂÆûÈôÖÁöÑÈáëÈ¢ùÊï∞ÂÄº„ÄÇ

### ERC‰ª£Ë°®‰ø°ÊÅØË°®Ôºàerc20_ethereum.evt_TransferÔºåerc721_ethereum.evt_TransferÁ≠âÔºâ

ERC‰ª£Â∏Å‰ø°ÊÅØË°®ÂàÜÂà´ËÆ∞ÂΩï‰∫ÜERC20Ôºå ERC721ÔºàNFTÔºâÔºåERC1155Á≠âÂá†Áßç‰ª£Â∏ÅÁ±ªÂûãÁöÑÊâπÂáÜÔºàApprovalÔºâÂíåËΩ¨Ë¥¶ÔºàTransferÔºâËÆ∞ÂΩï„ÄÇÂΩìÊàë‰ª¨Ë¶ÅÁªüËÆ°Êüê‰∏™Âú∞ÂùÄÊàñËÄÖ‰∏ÄÁªÑÂú∞ÂùÄÁöÑERC‰ª£Â∏ÅËΩ¨Ë¥¶ËØ¶ÊÉÖ„ÄÅ‰ΩôÈ¢ùÁ≠â‰ø°ÊÅØÊòØÔºåÂèØ‰ª•‰ΩøÁî®Ëøô‰∏ÄÁªÑÈ≠îÊ≥ïË°®„ÄÇ

### ENSÂüüÂêç‰ø°ÊÅØË°®Ôºàens.view_registrationsÁ≠âÔºâ

ENSÂüüÂêç‰ø°ÊÅØÁõ∏ÂÖ≥ÁöÑË°®ËÆ∞ÂΩï‰∫ÜENSÂüüÂêçÊ≥®ÂÜå‰ø°ÊÅØ„ÄÅÂèçÂêëËß£ÊûêËÆ∞ÂΩï„ÄÅÂüüÂêçÊõ¥Êñ∞‰ø°ÊÅØÁ≠â„ÄÇ

### Ê†áÁ≠æ‰ø°ÊÅØË°®Ôºàlabels.allÁ≠âÔºâ

Ê†áÁ≠æ‰ø°ÊÅØË°®ÊòØ‰∏ÄÁªÑÊù•Ê∫êÂêÑ‰∏çÁõ∏ÂêåÁöÑÈ≠îÊ≥ïË°®ÔºåÂÖÅËÆ∏Êàë‰ª¨Â∞ÜÈí±ÂåÖÂú∞ÂùÄÊàñËÄÖÂêàÁ∫¶Âú∞ÂùÄÂÖ≥ËÅîÂà∞‰∏Ä‰∏™ÊàñËÄÖ‰∏ÄÁªÑÊñáÂ≠óÊ†áÁ≠æ„ÄÇÂÖ∂Êï∞ÊçÆÊù•Ê∫êÂåÖÊã¨ENSÂüüÂêç„ÄÅSafeÈí±ÂåÖ„ÄÅNFTÈ°πÁõÆ„ÄÅÂ∑≤Ëß£ÊûêÁöÑÂêàÁ∫¶Âú∞ÂùÄÁ≠âÂ§öÁßçÁ±ªÂûã„ÄÇÂΩìÊàë‰ª¨ÁöÑÊü•ËØ¢‰∏≠Â∏åÊúõÊääÂú∞ÂùÄ‰ª•Êõ¥Áõ¥ËßÇÊõ¥ÊúâÂèØËØªÊÄßÁöÑÊñπÂºèÊù•ÊòæÁ§∫ÊòØÔºåÂèØ‰ª•ÈÄöËøáDuneÂÜÖÁΩÆÁöÑ`get_labels()`ÂáΩÊï∞Êù•‰ΩøÁî®Âú∞ÂùÄÊ†áÁ≠æ„ÄÇ

### ‰ΩôÈ¢ù‰ø°ÊÅØË°®Ôºàbalances_ethereum.erc20_latestÁ≠âÔºâ

‰ΩôÈ¢ù‰ø°ÊÅØË°®‰øùÂ≠ò‰∫ÜÊØè‰∏™Âú∞ÂùÄÊØèÂ§©„ÄÅÊØèÂ∞èÊó∂„ÄÅÂíåÊúÄÊñ∞ÁöÑERC20Ôºå ERC721ÔºàNFTÔºâÔºåERC1155Âá†Áßç‰ª£Â∏ÅÁöÑ‰ΩôÈ¢ù‰ø°ÊÅØ„ÄÇÂ¶ÇÊûúÊàë‰ª¨Ë¶ÅËÆ°ÁÆóÊüêÁªÑÂú∞ÂùÄÁöÑÊúÄÊñ∞‰ΩôÈ¢ùÔºåÊàñËÄÖË∑üË∏™Ëøô‰∫õÂú∞ÂùÄÁöÑ‰ΩôÈ¢ùÈöèÊó∂Èó¥ÁöÑÂèòÂåñÊÉÖÂÜµÔºåÂèØ‰ª•‰ΩøÁî®Ëøô‰∏ÄÁªÑË°®„ÄÇ

### NFT‰∫§Êòì‰ø°ÊÅØË°®Ôºànft.tradesÁ≠âÔºâ

NFT‰∫§Êòì‰ø°ÊÅØË°®ËÆ∞ÂΩï‰∫ÜÂêÑNFT‰∫§ÊòìÂπ≥Âè∞ÁöÑNFT‰∫§ÊòìÊï∞ÊçÆ„ÄÇÁõÆÂâçÈõÜÊàê‰∫Üopensea„ÄÅmagiceden„ÄÅlooksrare„ÄÅx2y2„ÄÅsudoswap„ÄÅfoundation„ÄÅarchipelago„ÄÅcryptopunks„ÄÅelement„ÄÅsuperrare„ÄÅzora„ÄÅblurÁ≠âÁõ∏ÂÖ≥NFT‰∫§ÊòìÂπ≥Âè∞ÁöÑÊï∞ÊçÆ„ÄÇË∑üDeFi‰∫§ÊòìÊï∞ÊçÆÁ±ª‰ººÔºåËøô‰∫õÂπ≥Âè∞‰πüÂêÑËá™ÊúâÂØπÂ∫îÁöÑÈ≠îÊ≥ïË°®ÔºåÊØîÂ¶Ç`opensea.trades`„ÄÇÂΩìÂè™ÈúÄÂàÜÊûêÂçï‰∏™Âπ≥Âè∞Êó∂ÔºåÂèØ‰ª•‰ΩøÁî®ÂÆÉÁâπÊúâÁöÑÈ≠îÊ≥ïË°®„ÄÇ

### ÂÖ∂‰ªñÈ≠îÊ≥ïË°®

Èô§‰∫Ü‰∏äÈù¢ÊèêÂà∞ÁöÑÈ≠îÊ≥ïË°®‰πãÂ§ñÔºåËøòÊúâÂæàÂ§öÂÖ∂‰ªñÁöÑÈ≠îÊ≥ïË°®„ÄÇDuneÁöÑÁ§æÂå∫Áî®Êà∑ËøòÂú®‰∏çÊñ≠ÂàõÂª∫Êñ∞ÁöÑÈ≠îÊ≥ïË°®„ÄÇË¶Å‰∫ÜËß£Ëøõ‰∏ÄÊ≠•ÁöÑ‰ø°ÊÅØÔºåÂèØ‰ª•ËÆøÈóÆ[Dune È≠îÊ≥ï‰π¶](https://spellbook-docs.dune.com/#!/overview)ÊñáÊ°£ÁΩëÁ´ô„ÄÇ

## Á§æÂå∫Ë¥°ÁåÆÊï∞ÊçÆÂíåÁî®Êà∑ÁîüÊàêÊï∞ÊçÆË°®

Â¶ÇÂâçÊñáÊâÄËø∞ÔºåÁõÆÂâçDune‰∏ä‰∏ªË¶ÅÊúâ`flashbots`Âíå`reservoir`‰∏§‰∏™Á§æÂå∫Êù•Ê∫êÊï∞ÊçÆÈõÜ„ÄÇDuneÊñáÊ°£ÈáåÈù¢ÂàÜÂà´ÂØπËøô‰∏§‰∏™Êï∞ÊçÆÈõÜÂÅö‰∫ÜÁÆÄ‰ªãÔºö

[DuneÁ§æÂå∫Êù•Ê∫êÊï∞ÊçÆË°®](https://dune.com/docs/reference/tables/community/)


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch06/readme.md">
---
title: 06. SQLÂü∫Á°ÄÔºà‰∏ÄÔºâ
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - sql
  - transaction
---

# 6. SQLÂü∫Á°ÄÔºà‰∏ÄÔºâ

## Âü∫Á°ÄÊ¶ÇÂøµ
**1„ÄÅÊï∞ÊçÆ‰ªìÂ∫ìÊòØ‰ªÄ‰πàÔºü**  
ËØ¥‰∫∫ËØùÂ∞±ÊòØËØ¥Â∞±ÊòØÂá∫‰∫éÊï∞ÊçÆÁªüËÆ°ÁöÑÈúÄË¶ÅÔºåÊää‰∏Ä‰∫õÊï∞ÊçÆÂàÜÈó®Âà´Á±ªÂú∞Â≠òÂÇ®Ëµ∑Êù•,Â≠òÂÇ®ÁöÑËΩΩ‰ΩìÊòØ„ÄêÊï∞ÊçÆË°®„Äë„ÄÇÈíàÂØπÊüê‰∏Ä‰∏™ÊàñËÄÖ‰∏Ä‰∫õ‰∏ªÈ¢òÁöÑ‰∏ÄÁ≥ªÂàó„ÄêÊï∞ÊçÆË°®„ÄëÂêàÂú®‰∏ÄËµ∑Â∞±ÊòØÊï∞ÊçÆ‰ªìÂ∫ì„ÄÇ  
Ê≥®ÊÑè:
ËøôÈáåÁöÑÊï∞ÊçÆÂèØ‰ª•ÊòØÁªìÊûúÊï∞ÊçÆ(ÊØîÂ¶ÇUniswap‰∏äÁ∫ø‰ª•Êù•Êüê‰∏™‰∫§ÊòìÂØπÊØèÂ§©ÁöÑ‰∫§ÊòìÈáèÁªüËÆ°)
‰πüÂèØ‰ª•ÊòØËøáÁ®ãÊï∞ÊçÆ(Uniswap‰∏äÁ∫ø‰ª•Êù•Êüê‰∏™‰∫§ÊòìÂØπÂèëÁîüÁöÑÊØè‰∏ÄÊù°‰∫§ÊòìËÆ∞ÂΩïÊòéÁªÜÔºöË∞ÅÂèëËµ∑ÁöÑÔºåÁî®AÊç¢BÔºå‰∫§ÊòìÊó∂Èó¥Ôºåtx_hashÔºå‰∫§ÊòìÊï∞Èáè‚Ä¶.)„ÄÇ

**2„ÄÅSQLÊòØ‰ªÄ‰πàÔºü**  
ÂÅáËÆæ‰Ω†ÊÉ≥ÂêÉËÑÜÈ¶ôÁ±≥Â∑ßÂÖãÂäõÔºå‰ΩÜÊòØ‰Ω†Ëøô‰ºöÂÑøÂá∫‰∏ç‰∫ÜÈó®Ôºå‰Ω†Â∞±Âè´‰∏™Ë∑ëËÖøËØ¥ÔºöÊàëÈúÄË¶Å‰∏ÄÁõíÂ∑ßÂÖãÂäõÔºå‰ªñÁöÑÁâåÂ≠êÊòØËÑÜÈ¶ôÁ±≥„ÄÇË∑ëËÖøÂéª‰∫ÜË∂üË∂ÖÂ∏ÇÊääÂ∑ßÂÖãÂäõ‰π∞Êù•ÈÄÅÂà∞‰Ω†ÂÆ∂„ÄÇ
Á±ªÊØîËøáÊù•SQLÂ∞±ÊòØ‰Ω†ËØ¥ÁöÑÈÇ£Âè•ËØùÔºåDune AnalyticsÂ∞±ÊòØ‰∏™Ë∑ëËÖøÂÑøÔºå‰ªñÂèØ‰ª•ËÆ©‰Ω†ÂèØ‰ª•Ë∑üÊï∞ÊçÆ‰ªìÂ∫ìÂØπËØùÔºåÂπ∂‰∏îÂ∞ÜÊï∞ÊçÆ‰ªìÂ∫ìÈáåÁöÑÊï∞ÊçÆÁªô‰Ω†Êê¨Âá∫Êù•Áªô‰Ω†„ÄÇSQLÊúÄÂü∫Êú¨ÁöÑÁªìÊûÑÊàñËÄÖËØ≠Ê≥ïÂ∞±3‰∏™Ê®°ÂùóÔºåÂá†‰πéÊâÄÊúâÁöÑSQLÈÉΩ‰ºöÂåÖÂê´Ëøô3‰∏™ÈÉ®ÂàÜ:

**select**: ÂèñÂì™‰∏™Â≠óÊÆµÔºü  
**from**Ôºö‰ªéÂì™‰∏™Ë°®ÈáåÂèñÔºü  
**where**ÔºöÈôêÂà∂Êù°‰ª∂ÊòØ‰ªÄ‰πàÔºü 

**3„ÄÅÊï∞ÊçÆË°®Èïø‰ªÄ‰πàÊ†∑Ôºü**    
‰Ω†ÂèØ‰ª•ËÆ§‰∏∫Ë°®Â∞±ÊòØ‰∏Ä‰∏™‰∏Ä‰∏™ÁöÑExcel Ë°®ÔºåÊØè‰∏Ä‰∏™Excel Ë°®ÈáåÂ≠òÁöÑ‰∏çÂêåÁöÑÊï∞ÊçÆ„ÄÇ‰ª•ethereum.transactions(‰ª•Â§™Âùä‰∏äÁöÑtransactionsËÆ∞ÂΩï)‰∏∫‰æãÔºö

![query-page](img/raw_data.png)

È°∫‰æøËØ¥‰∏ãË°®ÈáåÁî®ÊØîËæÉÂ§öÁöÑÂá†‰∏™Â≠óÊÆµ
- **block_time**:‰∫§ÊòìË¢´ÊâìÂåÖÁöÑÊó∂Èó¥  
- **block_number**Ôºö‰∫§ÊòìË¢´ÊâìÂåÖÁöÑÂå∫ÂùóÈ´òÂ∫¶  
- **value**ÔºöËΩ¨Âá∫‰∫ÜÂ§öÂ∞ëETH(ÈúÄË¶ÅÈô§‰ª•power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶)  
- **from**ÔºöETH‰ªéÂì™‰∏™Èí±ÂåÖËΩ¨Âá∫ÁöÑ  
- **to**Ôºö ETHËΩ¨Âà∞‰∫ÜÂì™‰∏™Èí±ÂåÖ  
- **hash**ÔºöËøô‰∏™transactionÁöÑtx hash  
- **success**ÔºötransactionÊòØÂê¶ÊàêÂäü    

## Â∏∏ËßÅËØ≠Ê≥ï‰ª•Âèä‰ΩøÁî®Ê°à‰æã
### 1.Âü∫Á°ÄÁªìÊûÑ¬∑ËøêÁÆóÁ¨¶¬∑ÊéíÂ∫è
**Ê°à‰æã1**:ÊàëÊÉ≥ÁúãÁúãÂ≠ôÂì•Èí±ÂåÖ(0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296)Âú®2022Âπ¥1Êúà‰ªΩ‰ª•Êù•ÁöÑÊØè‰∏ÄÁ¨îETHÁöÑÂ§ßÈ¢ùËΩ¨Âá∫(>1000ETH)ÊòØÂú®‰ªÄ‰πàÊó∂ÂÄô‰ª•ÂèäÂÖ∑‰ΩìÁöÑËΩ¨Âá∫Êï∞Èáè  
#### SQL
```sql
select --SelectÂêéË∑üÁùÄÈúÄË¶ÅÊü•ËØ¢ÁöÑÂ≠óÊÆµÔºåÂ§ö‰∏™Â≠óÊÆµÁî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöî
    block_time 
    ,"from"
    ,"to"
    ,hash
    ,value /power(10,18) as value --ÈÄöËøáÂ∞ÜvalueÈô§‰ª•/power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶Ôºå18ÊòØ‰ª•Â§™ÂùäÁöÑÁ≤æÂ∫¶
from ethereum.transactions --‰ªé ethereum.transactionsË°®‰∏≠Ëé∑ÂèñÊï∞ÊçÆ
where block_time > date('2022-01-01')  --ÈôêÂà∂TransferÊó∂Èó¥ÊòØÂú®2022Âπ¥1Êúà1Êó•‰πãÂêé
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296 --ÈôêÂà∂Â≠ôÂì•ÁöÑÈí±ÂåÖ
and value /power(10,18) >1000 --ÈôêÂà∂ETH TransferÈáèÂ§ß‰∫é1000
order by block_time --Âü∫‰∫éblocktimeÂÅöÂçáÂ∫èÊéíÂàóÔºåÂ¶ÇÊûúÊÉ≥ÈôçÂ∫èÊéíÂàóÈúÄË¶ÅÂú®Êú´Â∞æÂä†desc
```

![query-page](img/base.png)

#### Dune Query URL  
[https://dune.com/queries/1523799](https://dune.com/queries/1523799 )

#### ËØ≠Ê≥ïËØ¥Êòé
- SELECT
  - SELECTÂêéËæπË∑üÁùÄÔºåÈúÄË¶ÅÊü•ËØ¢ÁöÑÂ≠óÊÆµÔºåÂ§ö‰∏™Â≠óÊÆµÁî®Ëã±ÊñáÈÄóÂè∑ÈöîÂºÄ
- FROM 
  - FROM ÂêéËæπË∑üÁùÄÊï∞ÊçÆÊù•Ê∫êÁöÑË°®
- WHERE
  - WHEREÂêéË∑üÁùÄÂØπÊï∞ÊçÆÁöÑÁ≠õÈÄâÊù°‰ª∂
- ËøêÁÆóÁ¨¶Ôºöand / or
  - Â¶ÇÊûúÁ≠õÈÄâÊù°‰ª∂Êù°‰ª∂ÊúâÂ§ö‰∏™ÔºåÂèØ‰ª•Áî®ËøêÁÆóÁ¨¶Êù•ËøûÊé•
    - and:Â§ö‰∏™Êù°‰ª∂ÂèñÂπ∂ÈõÜ
    - or:Â§ö‰∏™Êù°‰ª∂Âèñ‰∫§ÈõÜ
- ÊéíÂ∫èÔºöorder by  [Â≠óÊÆµA]  ,ÊåâÁÖßÂ≠óÊÆµAÂçáÂ∫èÊéíÂàóÔºåÂ¶ÇÊûúÈúÄË¶ÅÊåâÁÖßÈôçÂ∫èÊéíÂàóÂ∞±Âú®Êú´Â∞æÂä†‰∏ä desc
- ÂπÇ‰πòËÆ°ÁÆóÔºöÁî®‰∫éÊç¢ÁÆóValueÁöÑÁ≤æÂ∫¶ÔºåÂáΩÊï∞ÊòØPower(Number,Power)ÔºåÂÖ∂‰∏≠numberË°®Á§∫Â∫ïÊï∞ÔºõpowerË°®Á§∫ÊåáÊï∞
- Â≠óÁ¨¶‰∏≤‰∏≠Â≠óÊØçÊç¢ÁÆóÂ§ßÂ∞èÂÜô
  - lower():Â≠óÁ¨¶‰∏≤‰∏≠ÁöÑÂ≠óÊØçÁªü‰∏ÄÊç¢ÊàêÂ∞èÂÜô
  - upper():Â≠óÁ¨¶‰∏≤‰∏≠ÁöÑÂ≠óÊØçÁªü‰∏ÄÊç¢ÊàêÂ§ßÂÜô

### 2.ËÅöÂêàÂáΩÊï∞
**Ê°à‰æã2**:Ë°®ÈáåÈÉΩÊòØÊòéÁªÜÊï∞ÊçÆÔºåÊàë‰∏çÊÉ≥ÁúãÁªÜËäÇÔºåÊàëÂè™ÊÉ≥ÈÄöËøá‰∏Ä‰∫õÁªüËÆ°Êï∞ÊçÆÂéª‰∫ÜËß£Ê¶ÇÂÜµ
#### SQL
```sql
select 
    sum( value /power(10,18) ) as value --ÂØπÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊï∞ÊçÆÁöÑvalueÂ≠óÊÆµÊ±ÇÂíå
    ,max( value /power(10,18) ) as max_value --Ê±ÇÊúÄÂ§ßÂÄº
    ,min( value /power(10,18) )  as min_value--Ê±ÇÊúÄÂ∞èÂÄº
    ,count( hash ) as tx_count --ÂØπÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊï∞ÊçÆËÆ°Êï∞ÔºåÁªüËÆ°ÊúâÂ§öÂ∞ëÊù°
    ,count( distinct to ) as tx_to_address_count --ÂØπÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊï∞ÊçÆËÆ°Êï∞ÔºåÁªüËÆ°ÊúâÂ§öÂ∞ëÊù°(ÊåâÁÖßÂéªÂêëÂú∞ÂùÄtoÂéªÈáç)
from ethereum.transactions --‰ªé ethereum.transactionsË°®‰∏≠Ëé∑ÂèñÊï∞ÊçÆ
where block_time > date('2022-01-01')  --ÈôêÂà∂TransferÊó∂Èó¥ÊòØÂú®2022Âπ¥1Êúà1Êó•‰πãÂêé
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
and value /power(10,18) > 1000 --ÈôêÂà∂ETH TransferÈáèÂ§ß‰∫é1000
```

![query-page](img/agg.png)

#### Dune Query URL  
[https://dune.com/queries/1525555](https://dune.com/queries/1525555)

#### ËØ≠Ê≥ïËØ¥Êòé
- ËÅöÂêàÂáΩÊï∞
  - count()ÔºöËÆ°Êï∞ÔºåÁªüËÆ°ÊúâÂ§öÂ∞ë‰∏™ÔºõÂ¶ÇÊûúÈúÄË¶ÅÂéªÈáçËÆ°Êï∞ÔºåÊã¨Âè∑ÂÜÖÂä†distinct
  - sum()ÔºöÊ±ÇÂíå
  - min()ÔºöÊ±ÇÊúÄÂ∞èÂÄº
  - max()ÔºöÊ±ÇÊúÄÂ§ßÂÄº
  - avg()ÔºöÊ±ÇÂπ≥Âùá

### 3.Êó•ÊúüÊó∂Èó¥ÂáΩÊï∞¬∑ÂàÜÁªÑËÅöÂêà
**Ê°à‰æã3**:Êàë‰∏çÊÉ≥Âè™Áúã‰∏Ä‰∏™ÂçïÁã¨ÁöÑÊï∞Â≠óÔºåÊÉ≥ÂàÜÂ∞èÊó∂/Â§©/Âë®Êù•Áúã‰∏Ä‰∏ãË∂ãÂäø
#### 3.1 ÊääÊó∂Èó¥Êà≥ËΩ¨ÂåñÊàêÂ∞èÊó∂/Â§©/Âë®ÁöÑÊ†ºÂºèÔºåÊñπ‰æøËøõ‰∏ÄÊ≠•ÂÅöËÅöÂêàÁªüËÆ°
##### SQL
```sql
-- ÊääÁ≤íÂ∫¶Âà∞ÁßíÁöÑÊó∂Èó¥ËΩ¨Âåñ‰∏∫Â§©/Â∞èÊó∂/ÂàÜÈíü(‰∏∫‰∫ÜÊñπ‰æøÂêéÁª≠ÊåâÁÖßÂ§©ÊàñËÄÖÂ∞èÊó∂ËÅöÂêà)
select --SelectÂêéË∑üÁùÄÈúÄË¶ÅÊü•ËØ¢ÁöÑÂ≠óÊÆµÔºåÂ§ö‰∏™Â≠óÊÆµÁî®Á©∫Ê†ºÈöîÂºÄ
    block_time --transactionsÂèëÁîüÁöÑÊó∂Èó¥
    ,date_trunc('hour',block_time) as stat_hour --ËΩ¨ÂåñÊàêÂ∞èÊó∂ÁöÑÁ≤íÂ∫¶
    ,date_trunc('day',block_time) as stat_date --ËΩ¨ÂåñÊàêÂ§©ÁöÑÁ≤íÂ∫¶
    ,date_trunc('week',block_time) as stat_week--ËΩ¨ÂåñÊàêweekÁöÑÁ≤íÂ∫¶
    ,"from"
    ,"to"
    ,hash
    ,value /power(10,18) as value --ÈÄöËøáÂ∞ÜvalueÈô§‰ª•/power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶Ôºå18ÊòØ‰ª•Â§™ÂùäÁöÑÁ≤æÂ∫¶
from ethereum.transactions --‰ªé ethereum.transactionsË°®‰∏≠Ëé∑ÂèñÊï∞ÊçÆ
where block_time > date('2021-01-01')  --ÈôêÂà∂TransferÊó∂Èó¥ÊòØÂú®2022Âπ¥1Êúà1Êó•‰πãÂêé
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
and value /power(10,18) >1000 --ÈôêÂà∂ETH TransferÈáèÂ§ß‰∫é1000
order by block_time --Âü∫‰∫éblocktimeÂÅöÂçáÂ∫èÊéíÂàóÔºåÂ¶ÇÊûúÊÉ≥ÈôçÂ∫èÊéíÂàóÈúÄË¶ÅÂú®Êú´Â∞æÂä†desc
```

![query-page](img/Date_Function_Format.png)

##### Dune Query URL  
[https://dune.com/queries/1527740](https://dune.com/queries/1527740)

##### ËØ≠Ê≥ïËØ¥Êòé
  - DATE_TRUNC('datepart', timestamp)
      - Êó∂Èó¥Êà≥ÁöÑÊà™Êñ≠ÂáΩÊï∞
      - Ê†πÊçÆdatepartÂèÇÊï∞ÁöÑ‰∏çÂêå‰ºöÂæóÂà∞‰∏çÂêåÁöÑÊïàÊûú
        - minute:Â∞ÜËæìÂÖ•Êó∂Èó¥Êà≥Êà™Êñ≠Ëá≥ÂàÜÈíü
        - hour:Â∞ÜËæìÂÖ•Êó∂Èó¥Êà≥Êà™Êñ≠Ëá≥Â∞èÊó∂
        - day:Â∞ÜËæìÂÖ•Êó∂Èó¥Êà≥Êà™Êñ≠Ëá≥Â§©
        - week:Â∞ÜËæìÂÖ•Êó∂Èó¥Êà≥Êà™Êñ≠Ëá≥ÊüêÂë®ÁöÑÊòüÊúü‰∏Ä
        - year:Â∞ÜËæìÂÖ•Êó∂Èó¥Êà≥Êà™Êñ≠Ëá≥‰∏ÄÂπ¥ÁöÑÁ¨¨‰∏ÄÂ§©

#### 3.2 Âü∫‰∫é‰πãÂâçÂæóÂà∞ÁöÑÂ§ÑÁêÜÂêéÁöÑÊó∂Èó¥Â≠óÊÆµÔºå‰ΩøÁî®group by + sum ÂÆåÊàêÂàÜÁªÑËÅöÂêà
##### SQL
```sql
select 
    date_trunc('day',block_time) as stat_date
    ,sum( value /power(10,18) ) as value --ÂØπÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊï∞ÊçÆÁöÑvalueÂ≠óÊÆµÊ±ÇÂíå
from ethereum.transactions --‰ªé ethereum.transactionsË°®‰∏≠Ëé∑ÂèñÊï∞ÊçÆ
where block_time > date('2022-01-01')  --ÈôêÂà∂TransferÊó∂Èó¥ÊòØÂú®2022Âπ¥1Êúà1Êó•‰πãÂêé
and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
and value /power(10,18) > 1000 --ÈôêÂà∂ETH TransferÈáèÂ§ß‰∫é1000
group by  1
order by 1
```

![query-page](img/group_by.png)

##### Dune Query URL  
[https://dune.com/queries/1525668](https://dune.com/queries/1525668)

##### ËØ≠Ê≥ïËØ¥Êòé
- ÂàÜÁªÑËÅöÂêà(group by)  
ÂàÜÁªÑËÅöÂêàÁöÑËØ≠Ê≥ïÊòØgroup by„ÄÇÂàÜÁªÑËÅöÂêàÈ°æÂêçÊÄù‰πâÂ∞±ÊòØÂÖàÂàÜÁªÑÂêéËÅöÂêàÔºåÈúÄË¶ÅÈÖçÂêàËÅöÂêàÂáΩÊï∞‰∏ÄËµ∑‰ΩøÁî®„ÄÇ

![query-page](img/group_by_case.png)

ÂÅáËÆæ‰∏äËæπË°®Ê†ºÊòØ‰∏Ä‰∏™ÂÆ∂Â∫≠(3‰∏™‰∫∫)2020Âπ¥Ââç2‰∏™ÊúàÁöÑÁîüÊ¥ªÂºÄÈîÄÊòéÁªÜÔºåÂ¶ÇÊûú‰Ω†Âè™Áî®ÁÆÄÂçïÁöÑsumÔºåÈÇ£‰Ω†Âè™ËÉΩÂæóÂà∞ÊÄªËÆ°ÁöÑ12900ÔºõÂ¶ÇÊûú‰Ω†ÊÉ≥ÁöÑÂà∞Âè≥Ëæπ2ÁßçÁªüËÆ°Êï∞ÊçÆÔºåÈÇ£Â∞±ÈúÄË¶ÅÁî®Âà∞ÂàÜÁªÑËÅöÂêàgroup byÔºàÊåâÁÖß„Äê‰∫∫Âëò„ÄëÂàÜÁªÑËÅöÂêàÊàñËÄÖÊåâÁÖß„ÄêÊúà‰ªΩ„ÄëÂàÜÁªÑËÅöÂêàÔºâ

### 4.ËÅîË°®Êü•ËØ¢¬∑Â≠êÊü•ËØ¢
**Ê°à‰æã4**:ÊàëÊÉ≥‰ªéËΩ¨Âá∫ETHÁöÑUSDÈáëÈ¢ùÁöÑËßíÂ∫¶ÂéªÁúãÂ≠ôÂì•ÁöÑËΩ¨Âá∫Ë°å‰∏∫
#### 4.1 ËΩ¨Âá∫Êï∞ÊçÆÁúãÂà∞ÁöÑÈÉΩÊòØETHÁöÑÈáèÔºåÊàëÊÉ≥Áúã‰∏ãÊØèÊ¨°ËΩ¨Âá∫‰ª∑ÂÄºÂ§öÂ∞ëUSD
##### SQL
```sql
select
     block_time
     ,transactions_info.stat_minute  as stat_minute
    ,"from"
    ,"to"
    ,hash
    ,eth_amount --ÈÄöËøáÂ∞ÜvalueÈô§‰ª•/power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶Ôºå18ÊòØ‰ª•Â§™ÂùäÁöÑÁ≤æÂ∫¶
    ,price
    ,eth_amount * price as usd_value
from 
(
    select --SelectÂêéË∑üÁùÄÈúÄË¶ÅÊü•ËØ¢ÁöÑÂ≠óÊÆµÔºåÂ§ö‰∏™Â≠óÊÆµÁî®Á©∫Ê†ºÈöîÂºÄ
        block_time
        ,date_trunc('minute',block_time) as stat_minute --Êääblock_timeÁî®date_truncÂ§ÑÁêÜÊàêÂàÜÈíüÔºåÊñπ‰æø‰Ωú‰∏∫‰∏ªÈîÆÂéªÂÖ≥ËÅî
        ,"from"
        ,"to"
        ,hash
        ,value /power(10,18) as eth_amount --ÈÄöËøáÂ∞ÜvalueÈô§‰ª•/power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶Ôºå18ÊòØ‰ª•Â§™ÂùäÁöÑÁ≤æÂ∫¶
    from ethereum.transactions --‰ªé ethereum.transactionsË°®‰∏≠Ëé∑ÂèñÊï∞ÊçÆ
    where block_time > date('2022-01-01')  --ÈôêÂà∂TransferÊó∂Èó¥ÊòØÂú®2022Âπ¥1Êúà1Êó•‰πãÂêé
    and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
    and value /power(10,18) >1000 --ÈôêÂà∂ETH TransferÈáèÂ§ß‰∫é1000
    order by block_time --Âü∫‰∫éblocktimeÂÅöÂçáÂ∫èÊéíÂàóÔºåÂ¶ÇÊûúÊÉ≥ÈôçÂ∫èÊéíÂàóÈúÄË¶ÅÂú®Êú´Â∞æÂä†desc
) transactions_info
left join --ËÆ≤transactions_info‰∏éprice_infoÁöÑÊï∞ÊçÆÂÖ≥ËÅîÔºåÂÖ≥ËÅîÊñπÂºè‰∏∫ left join
(
    --prices.usdË°®ÈáåÂ≠òÁöÑÊòØÂàÜÈíüÁ∫ßÂà´ÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ
    select
        date_trunc('minute',minute) as stat_minute --ÊääminuteÁî®date_truncÂ§ÑÁêÜÊàêÂàÜÈíüÔºåÊñπ‰æø‰Ωú‰∏∫‰∏ªÈîÆÂéªÂÖ≥ËÅî
        ,price
    from prices.usd
    where blockchain = 'ethereum' --Âèñ‰ª•Â§™Âùä‰∏äÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ
    and symbol = 'WETH' --ÂèñWETHÁöÑÊï∞ÊçÆ
) price_info on  transactions_info.stat_minute = price_info.stat_minute --left joinÂÖ≥ËÅîÁöÑ‰∏ªÈîÆ‰∏∫stat_minute
```

![query-page](img/left_join.png)

##### Dune Query URL  
[https://dune.com/queries/1528027](https://dune.com/queries/1528027)

##### ËØ≠Ê≥ïËØ¥Êòé
  - ËÅîË°®Êü•ËØ¢
    - Â§ßÈÉ®ÂàÜÊÉÖÂÜµ‰∏ãÊàë‰ª¨ÈúÄË¶ÅÁöÑÊï∞ÊçÆ‰∏çÊòØÂú®Âêå‰∏ÄÂº†Ë°®ÈáåÔºåÊØîÂ¶ÇtransactionË°®Â≠òÂÇ®ÁöÑÂ∞±ÊòØÂè™ÊúâtransactionÊï∞ÊçÆÔºåÊ≤°Êúâ‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇÂ¶ÇÊûúÊàë‰ª¨Â∏åÊúõËÉΩÂ§üËÆ°ÁÆóÂá∫transactionÂØπÂ∫îUSD ‰ª∑ÂÄºÔºåÈÇ£Â∞±ÈúÄË¶ÅÁî®ËÅîË°®Êü•ËØ¢Êää‰ª∑Ê†ºÊï∞ÊçÆÁªôÂÖ≥ËÅîËøõÊù•
    - ËÅîË°®Êü•ËØ¢ÂèØ‰ª•ÁêÜËß£‰∏∫Êää‰∏§‰∏™Ë°®ÈÄöËøá‰∏ÄÂÆöÁöÑÊù°‰ª∂ÂÖ≥ËÅîËµ∑Êù•ÂΩ¢Êàê‰∏ÄÂº†ËôöÊãüÁöÑË°®Ôºå‰Ω†ÂèØ‰ª•Êñπ‰æøÂú∞ÂØπËøôËôöÊãüË°®ÂÅöÊõ¥Â§öÂ§ÑÁêÜ„ÄÇ
  - ËÅîË°®Êü•ËØ¢Êúâ2‰∏™ÈÉ®ÂàÜÊûÑÊàê
    - ËÅîË°®ÊñπÂºè(join,left join ,right join ,cross join,full join)
    - ÂÖ≥ËÅîÊù°‰ª∂(on)
  - Áî®ÂæóÊúÄÂ§öÁöÑËÅîË°®ÊñπÂºèÊòØjoin Ë∑üleft joinÔºå‰ª•Ëøô2‰∏™‰∏∫‰æãÂ≠êÂéªËß£Èáä‰∏ãÂÖ∑‰ΩìÁöÑÁî®Ê≥ï

 ![query-page](img/left_join_case.png)  

      - join:Êää‰∏§‰∏™Ë°®ÊåâÁÖßÂÖ≥ËÅîÊù°‰ª∂(on)ÂÖ≥ËÅîÂú®‰∏ÄËµ∑ÔºåÂèñ‰∫§ÈõÜ   
        - Table A Ë∑ü Table BÈÄöËøáÂßìÂêçÂÖ≥ËÅîÔºåÂÖ∂‰∏≠‰∫§ÈõÜÊòØÂ∞èÁ∫¢ÂíåÂ∞èÊòéÔºåÂõ†‰∏∫joinÊòØÂèñ‰∫§ÈõÜÔºåÂõ†Ê≠§ÊúÄÁªàÁªìÊûúÈáåÂßìÂêçÂ∞±Âè™ÊúâÂ∞èÊòéÂíåÂ∞èÁ∫¢  
        - ‰∏§Ë°®‰∏≠ÊâÄÊúâÁ¨¶ÂêàË¶ÅÊ±ÇÁöÑÊï∞ÊçÆÈÉΩÈúÄË¶ÅÂÖ≥ËÅîÔºåÂõ†‰∏∫Table B‰∏≠Â∞èÊòéÊúâ2Êù°ËÆ∞ÂΩïÔºåÊâÄ‰ª•ÂÖ≥ËÅîÁöÑÁªìÊûú‰∏≠Â∞èÊòé‰πüÊúâ‰∏§Êù°Êï∞ÊçÆ  
      - left joinÔºö‰ª•Â∑¶Ë°®‰∏∫‰∏ªÔºåÊääÂè≥Ë°®ÊåâÁÖßÂÖ≥ËÅîÊù°‰ª∂(on)ÂæÄÂ∑¶Ë°®ÂéªÂÖ≥ËÅîÔºåÂ¶ÇÊûúÂÖ≥ËÅî‰∏çÂà∞Â∞±Áî®nullÂ°´ÂÖÖ  
        - Table A Ë∑ü Table BÈÄöËøáÂßìÂêçÂÖ≥ËÅîÔºåÂõ†‰∏∫ÊòØ‰ª•Â∑¶Ë°®‰∏∫‰∏ªÔºåÊâÄ‰ª•Â∞ΩÁÆ°Â∑¶Ë°®‰∏≠Â∞èÂÖ∞ÂíåÂ∞èÁªøÂú®Âè≥Ë°®‰∏≠Ê≤°ÊúâÁ¨¶ÂêàÂÖ≥ËÅîÊù°‰ª∂ÁöÑÊï∞ÊçÆÔºå‰ΩÜÊòØÂ∞èÂÖ∞ÂíåÂ∞èÁªø‰πü‰ºöÂá∫Áé∞Âú®ÁªìÊûú‰∏≠ÔºåÂè≥Ë°®ÈÇ£ÈÉ®ÂàÜÂõ†‰∏∫ÂÖ≥ËÅî‰∏çÂà∞Êï∞ÊçÆÔºåÂõ†Ê≠§ÈÉΩÁî®nullÂ°´ÂÖÖ
      
#### 4.2 ÊàëÊÉ≥Êää4.1ÁöÑÊòéÁªÜÊï∞ÊçÆÊåâÁÖßÂ§©ÂéªÂàÜÁªÑËÅöÂêàÔºå‰ΩÜÊòØ‰∏çÊÉ≥ÂÜôÂµåÂ•óÂ§™Â§öÂ±ÇÁöÑsql
##### SQL
```sql
with  transactions_info as --ÈÄöËøáwith as Âª∫Á´ãÂ≠êÊü•ËØ¢ÂëΩÂêç‰∏∫transactions_info
(
    select
         block_time
         ,transactions_info.stat_minute  as stat_minute
        ,"from"
        ,"to"
        ,hash
        ,eth_amount --ÈÄöËøáÂ∞ÜvalueÈô§‰ª•/power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶Ôºå18ÊòØ‰ª•Â§™ÂùäÁöÑÁ≤æÂ∫¶
        ,price
        ,eth_amount* price as usd_value
    from 
    (
        select --SelectÂêéË∑üÁùÄÈúÄË¶ÅÊü•ËØ¢ÁöÑÂ≠óÊÆµÔºåÂ§ö‰∏™Â≠óÊÆµÁî®Á©∫Ê†ºÈöîÂºÄ
            block_time
            ,date_trunc('minute',block_time) as stat_minute --Êääblock_timeÁî®date_truncÂ§ÑÁêÜÊàêÂàÜÈíüÔºåÊñπ‰æø‰Ωú‰∏∫‰∏ªÈîÆÂéªÂÖ≥ËÅî
            ,"from"
            ,"to"
            ,hash
            ,value /power(10,18) as eth_amount --ÈÄöËøáÂ∞ÜvalueÈô§‰ª•/power(10,18)Êù•Êç¢ÁÆóÁ≤æÂ∫¶Ôºå18ÊòØ‰ª•Â§™ÂùäÁöÑÁ≤æÂ∫¶
        from ethereum.transactions --‰ªé ethereum.transactionsË°®‰∏≠Ëé∑ÂèñÊï∞ÊçÆ
        where block_time > date('2022-01-01')  --ÈôêÂà∂TransferÊó∂Èó¥ÊòØÂú®2022Âπ¥1Êúà1Êó•‰πãÂêé
            and "from" = 0x3DdfA8eC3052539b6C9549F12cEA2C295cfF5296
            and value /power(10,18) >1000 --ÈôêÂà∂ETH TransferÈáèÂ§ß‰∫é1000
        order by block_time --Âü∫‰∫éblocktimeÂÅöÂçáÂ∫èÊéíÂàóÔºåÂ¶ÇÊûúÊÉ≥ÈôçÂ∫èÊéíÂàóÈúÄË¶ÅÂú®Êú´Â∞æÂä†desc
    ) transactions_info
    left join --ËÆ≤transactions_info‰∏éprice_infoÁöÑÊï∞ÊçÆÂÖ≥ËÅîÔºåÂÖ≥ËÅîÊñπÂºè‰∏∫ left join
    (
        --prices.usdË°®ÈáåÂ≠òÁöÑÊòØÂàÜÈíüÁ∫ßÂà´ÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ
        select
            date_trunc('minute',minute) as stat_minute --ÊääminuteÁî®date_truncÂ§ÑÁêÜÊàêÂàÜÈíüÔºåÊñπ‰æø‰Ωú‰∏∫‰∏ªÈîÆÂéªÂÖ≥ËÅî
            ,price
        from prices.usd
        where blockchain = 'ethereum' --Âèñ‰ª•Â§™Âùä‰∏äÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ
            and symbol = 'WETH' --ÂèñWETHÁöÑÊï∞ÊçÆ
    ) price_info on  transactions_info.stat_minute = price_info.stat_minute --left joinÂÖ≥ËÅîÁöÑ‰∏ªÈîÆ‰∏∫stat_minute
)

select date_trunc('day',block_time) as stat_date
    ,sum(eth_amount) as eth_amount
    ,sum(usd_value) as usd_value
from transactions_info --‰ªéÂ≠êÊü•ËØ¢ÂΩ¢ÊàêÁöÑ‚ÄòËôöÊãüË°®‚Äôtransactions_info‰∏≠ÂèñÈúÄË¶ÅÁöÑÊï∞ÊçÆ
group by 1
order by 1
```

![query-page](img/with_as.png)

##### Dune Query URL  
[https://dune.com/queries/1528564](https://dune.com/queries/1528564)

##### ËØ≠Ê≥ïËØ¥Êòé
   - Â≠êÊü•ËØ¢(with as )  
    - ÈÄöËøáwith as ÂèØ‰ª•ÊûÑÂª∫‰∏Ä‰∏™Â≠êÊü•ËØ¢ÔºåÊää‰∏ÄÊÆµSQLÁöÑÁªìÊûúÂèòÊàê‰∏Ä‰∏™'ËôöÊãüË°®'ÔºàÂèØÁ±ªÊØî‰∏∫‰∏Ä‰∏™ËßÜÂõæÊàñËÄÖÂ≠êÊü•ËØ¢ÔºâÔºåÊé•‰∏ãÊù•ÁöÑSQL‰∏≠ÂèØ‰ª•Áõ¥Êé•‰ªéËøô‰∏™'ËôöÊãüË°®'‰∏≠ÂèñÊï∞ÊçÆ  
    - ÈÄöËøáwith as ÂèØ‰ª•ÊØîËæÉÂ•ΩÂú∞ÊèêÈ´òSQLÁöÑÈÄªËæëÁöÑÂèØËØªÊÄßÔºå‰πüÂèØ‰ª•ÈÅøÂÖçÂ§öÈáçÂµåÂ•ó
</file>

<file path="zh/ch07/readme.md">
---
title: 07. SQLÂü∫Á°ÄÔºà‰∫åÔºâ
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - sql
  - transaction
---

# 7. SQLÂü∫Á°ÄÔºà‰∫åÔºâ

Âú®‚ÄúSQLÂü∫Á°ÄÔºà‰∏ÄÔºâ‚ÄùÈÉ®ÂàÜÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏Ä‰∫õSQLÁöÑÂü∫Á°ÄÁü•ËØÜÔºåÂåÖÊã¨SQLÊü•ËØ¢ËØ≠Âè•ÁöÑÂü∫Á°ÄÁªìÊûÑËØ≠Ê≥ïËØ¥Êòé„ÄÅÊó•ÊúüÊó∂Èó¥„ÄÅÂàÜÁªÑËÅöÂêà„ÄÅÂ≠êÊü•ËØ¢ÂíåÂÖ≥ËÅîÊü•ËØ¢Á≠âÂÜÖÂÆπ„ÄÇÊé•‰∏ãÊù•Êàë‰ª¨ÁªßÁª≠‰ªãÁªç‰∏Ä‰∫õÂ∏∏Áî®ÁöÑSQLÂü∫Á°ÄÁü•ËØÜÁÇπ„ÄÇ

## Â∏∏Áî®Êó•ÊúüÂáΩÊï∞ÂíåÊó•ÊúüÊó∂Èó¥Èó¥Èöî‰ΩøÁî®

Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÈÉΩÊåâ‰∫§ÊòìÂèëÁîüÁöÑÊó∂Èó¥ÂÖàÂêéÈ°∫Â∫èË¢´ËÆ∞ÂΩï‰øùÂ≠òÔºåÊó•Â∏∏Êï∞ÊçÆÂàÜÊûê‰∏≠ÁªèÂ∏∏ÈúÄË¶ÅÂØπ‰∏ÄÊÆµÊó∂Èó¥ËåÉÂõ¥ÂÜÖÂØπÊï∞ÊçÆËøõË°åÁªüËÆ°„ÄÇ‰∏ä‰∏ÄÈÉ®ÂàÜ‰ªãÁªçËøáÁöÑ`date_trunc()`ÂáΩÊï∞Áî®‰∫éÊåâÊåáÂÆöÁöÑÈó¥ÈöîÔºàÂ§©„ÄÅÂë®„ÄÅÂ∞èÊó∂Á≠âÔºâÊà™Êñ≠Êó•ÊúüÂÄº„ÄÇÈô§Ê≠§‰πãÂ§ñËøòÊúâ‰∏Ä‰∫õÂ∏∏Áî®ÁöÑÂáΩÊï∞ÂíåÂ∏∏ËßÅÁî®Ê≥ï„ÄÇ

### 1. Now()ÂíåCurrent_Date()ÂáΩÊï∞
ÂáΩÊï∞`now()`Áî®‰∫éËé∑ÂèñÂΩìÂâçÁ≥ªÁªüÁöÑÊó•ÊúüÂíåÊó∂Èó¥ÂÄº„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÔºåÂÖ∂ÂÜÖÈÉ®‰øùÂ≠òÁöÑÊòØÂåÖÊã¨‰∫ÜÊó∂ÂàÜÁßíÂÄºÁöÑÔºå‰ΩÜÊòØDuneÁöÑÊü•ËØ¢ÁºñËæëÂô®ÈªòËÆ§Âè™ÊòæÁ§∫Âà∞‚ÄúÊó∂:ÂàÜ‚Äú„ÄÇÂΩìÊàë‰ª¨Ë¶ÅÂ∞ÜÊó•ÊúüÂ≠óÊÆµË∑ü‰ª∑Ê†ºË°®`prices.usd`‰∏≠ÁöÑ`minute`Â≠óÊÆµËøõË°åÂÖ≥ËÅîÊó∂ÔºåÂøÖÈ°ªÂÖàÊåâÂàÜÈíüËøõË°åÊà™Âèñ„ÄÇÂê¶ÂàôÂèØËÉΩÂÖ≥ËÅî‰∏çÂà∞Ê≠£Á°ÆÁöÑ‰ª∑Ê†ºËÆ∞ÂΩï„ÄÇ

ÂáΩÊï∞`current_date()`Áî®‰∫éËé∑ÂèñÂΩìÂâçÊó•ÊúüÔºà‰∏çÂê´Êó∂ÂàÜÁßíÈÉ®ÂàÜÔºâ„ÄÇÂΩìÊàë‰ª¨ÈúÄË¶ÅÊåâÊó•Êúü„ÄÅÊó∂Èó¥Á≠õÈÄâÊï∞ÊçÆÊó∂ÔºåÂ∏∏Â∏∏ÈúÄË¶ÅÁªìÂêà‰ΩøÁî®ÂÆÉ‰ª¨ÂÖ∂‰∏≠‰πã‰∏ÄÔºåÂÜçÁªìÂêàÁõ∏ÂÖ≥Êó•ÊúüÊó∂Èó¥ÂáΩÊï∞Êù•Êç¢ÁÆóÂá∫ÈúÄË¶ÅÁöÑÂáÜÁ°ÆÊó•ÊúüÊàñËÄÖÊó∂Èó¥„ÄÇÂáΩÊï∞`current_date()`Áõ∏ÂΩì‰∫é`date_trunc('day', now())`ÔºåÂç≥ÂØπ`now()`ÂáΩÊï∞ÁöÑÂÄºÊåâ‚ÄúÂ§©‚ÄùËøõË°åÊà™Âèñ„ÄÇËøòÂèØ‰ª•ÁúÅÁï•`current_date()`ÁöÑÊã¨Âè∑ÔºåÁõ¥Êé•ÂÜôÊàê`current_date`ÂΩ¢Âºè„ÄÇ

```sql
select now() -- ÂΩìÂâçÁ≥ªÁªüÊó•ÊúüÂíåÊó∂Èó¥
    ,current_date() -- ÂΩìÂâçÁ≥ªÁªüÊó•Êúü
    ,current_date   -- ÂèØ‰ª•ÁúÅÁï•Êã¨Âè∑
    ,date_trunc('day', now()) -- ‰∏écurrent_dateÁõ∏Âêå
```

### 2. DateAdd()„ÄÅDate_Add()„ÄÅDate_Sub()ÂíåDateDiff()ÂáΩÊï∞

ÂáΩÊï∞`dateadd(unit, value, expr)`Âú®‰∏Ä‰∏™Êó•ÊúüË°®ËææÂºè‰∏äÊ∑ªÂä†‰∏Ä‰∏™ÁöÑÊó•ÊúüÊó∂Èó¥Âçï‰Ωç„ÄÇËøôÈáåÁöÑ‚ÄúÊó•ÊúüÊó∂Èó¥Âçï‰Ωç‚Äù‰ΩøÁî®Â∏∏ÈáèË°®Á§∫ÔºåÂ∏∏Áî®ÁöÑÊúâHOUR„ÄÅDAY„ÄÅWEEK„ÄÅMONTHÁ≠â„ÄÇÂÖ∂‰∏≠ÁöÑvalueÂÄºÂèØ‰ª•‰∏∫Ë¥üÊï∞ÔºåË°®Á§∫‰ªéÂêéÈù¢ÁöÑË°®ËææÂºèÂáèÂéªÂØπÂ∫îÁöÑÊó•ÊúüÊó∂Èó¥Âçï‰Ωç„ÄÇ‰πüÊ≠£ÊòØÂõ†‰∏∫ÂèØ‰ª•Áî®Ë¥üÊï∞Ë°®Á§∫ÂáèÂéª‰∏Ä‰∏™Êó•ÊúüÊó∂Èó¥Èó¥ÈöîÔºåÊâÄ‰ª•‰∏çÈúÄË¶Å‰πüÁ°ÆÂÆûÊ≤°Êúâ`datesub()`ÂáΩÊï∞„ÄÇ

ÂáΩÊï∞`date_add(startDate, numDays)`Âú®‰∏Ä‰∏™Êó•ÊúüË°®ËææÂºè‰∏äÂä†‰∏äÊàñËÄÖÂáèÂéªÊåáÂÆöÁöÑÂ§©Êï∞ÔºåËøîÂõûÂè¶Â§ñ‰∏Ä‰∏™Êó•Êúü„ÄÇÂèÇÊï∞`numDays`‰∏∫Ê≠£Êï∞Ë°®Á§∫ËøîÂõû`startDate`‰πãÂêéÊåáÂÆöÂ§©Êï∞ÁöÑÊó•ÊúüÔºå‰∏∫Ë¥üË°®Á§∫ËøîÂõû‰πãÂâçÊåáÂÆöÂ§©Êï∞ÁöÑÊó•Êúü„ÄÇÂáΩÊï∞`date_sub(startDate, numDays)`‰ΩúÁî®Á±ª‰ººÔºå‰ΩÜË°®Á§∫ÁöÑÊÑèÊÄùÊ≠£Â•ΩÁõ∏ÂèçÔºåÂç≥Ë¥üÊï∞Ë°®Á§∫ËøîÂõû‰πãÂêéÁöÑÊó•ÊúüÔºåÊ≠£Êï∞Ë°®Á§∫‰πãÂâçÁöÑÊó•Êúü„ÄÇ

ÂáΩÊï∞`datediff(endDate, startDate)`ËøîÂõû‰∏§‰∏™Êó•ÊúüË°®ËææÂºè‰πãÈó¥Èó¥ÈöîÁöÑÂ§©Êï∞„ÄÇÂ¶ÇÊûú`endDate`Âú®`startDate`‰πãÂêéÔºåËøîÂõûÊ≠£ÂÄºÔºåÂú®‰πãÂâçÂàôËøîÂõûË¥üÂÄº„ÄÇ

SQLÁ§∫‰æãÂ¶Ç‰∏ãÔºö

```sql
select date_add('MONTH', 2, current_date) -- ÂΩìÂâçÊó•ÊúüÂä†2‰∏™ÊúàÂêéÁöÑÊó•Êúü
    ,date_add('HOUR', 12, now()) -- ÂΩìÂâçÊó•ÊúüÊó∂Èó¥Âä†12Â∞èÊó∂
    ,date_add('DAY', -2, current_date) -- ÂΩìÂâçÊó•ÊúüÂáèÂéª2Â§©
    ,date_add('DAY', 2, current_date) -- ÂΩìÂâçÊó•ÊúüÂä†‰∏ä2Â§©
    ,date_add('DAY', -5, current_date) -- ÂΩìÂâçÊó•ÊúüÂä†‰∏ä-5Â§©ÔºåÁõ∏ÂΩì‰∫éÂáèÂéª5Â§©
    ,date_diff('DAY', date('2022-11-22'), date('2022-11-25')) -- ÁªìÊùüÊó•ÊúüÊó©‰∫éÂºÄÂßãÊó•ÊúüÔºåËøîÂõûË¥üÂÄº
    ,date_diff('DAY', date('2022-11-25'), date('2022-11-22')) -- ÁªìÊùüÊó•ÊúüÊôö‰∫éÂºÄÂßãÊó•ÊúüÔºåËøîÂõûÊ≠£ÂÄº
```

### 3. INTERVAL Á±ªÂûã

IntervalÊòØ‰∏ÄÁßçÊï∞ÊçÆÁ±ªÂûãÔºå‰ª•ÊåáÂÆöÁöÑÊó•ÊúüÊó∂Èó¥Âçï‰ΩçË°®Á§∫Êüê‰∏™Êó∂Èó¥Èó¥Èöî„ÄÇ‰ª•Interval Ë°®Á§∫ÁöÑÊó∂Èó¥Èó¥Èöî‰ΩøÁî®Ëµ∑Êù•ÈùûÂ∏∏‰æøÂà©ÔºåÈÅøÂÖçË¢´ÂâçÈù¢ÁöÑÂá†‰∏™ÂêçÁß∞Áõ∏‰ºº„ÄÅ‰ΩúÁî®‰πüÁ±ª‰ººÁöÑÊó•ÊúüÂáΩÊï∞Âõ∞Êâ∞„ÄÇ

```sql
select now() - interval '2' hour -- 2‰∏™Â∞èÊó∂‰πãÂâç
    ,current_date - interval '7' day -- 7Â§©‰πãÂâç
    ,now() + interval '1' month -- ‰∏Ä‰∏™Êúà‰πãÂêéÁöÑÂΩìÂâçÊó∂Âàª
```

Êõ¥Â§öÊó•ÊúüÊó∂Èó¥Áõ∏ÂÖ≥ÂáΩÊï∞ÁöÑËØ¥ÊòéÔºåËØ∑ÂèÇËÄÉ[Êó•Êúü„ÄÅÊó∂Èó¥ÂáΩÊï∞ÂíåËøêÁÆóÁ¨¶](https://trino.io/docs/current/functions/datetime.html)

## Êù°‰ª∂Ë°®ËææÂºèCase„ÄÅIf

ÂΩìÊàë‰ª¨ÈúÄË¶ÅÂ∫îÁî®Êù°‰ª∂ÈÄªËæëÁöÑÊó∂ÂÄôÔºåÂèØ‰ª•Â∫îÁî®`case`ËØ≠Âè•„ÄÇCASEËØ≠Âè•ÁöÑÂ∏∏Áî®ËØ≠Ê≥ïÊ†ºÂºè‰∏∫`CASE {WHEN cond1 THEN res1} [...] [ELSE def] END`ÔºåÂÆÉÂèØ‰ª•Áî®Â§ö‰∏™‰∏çÂêåÁöÑÊù°‰ª∂ËØÑ‰º∞‰∏Ä‰∏™Ë°®ËææÂºèÔºåÂπ∂ËøîÂõûÁ¨¨‰∏Ä‰∏™ËØÑ‰º∞ÁªìÊûú‰∏∫ÁúüÂÄºÔºàTrueÔºâÁöÑÊù°‰ª∂ÂêéÈù¢ÁöÑÂÄºÔºåÂ¶ÇÊûúÂÖ®ÈÉ®Êù°‰ª∂ÈÉΩ‰∏çÊª°Ë∂≥ÔºåÂàôËøîÂõû`else`ÂêéÈù¢ÁöÑÂÄº„ÄÇÂÖ∂‰∏≠ÁöÑ`else`ÈÉ®ÂàÜËøòÂèØ‰ª•ÁúÅÁï•ÔºåÊ≠§Êó∂ËøîÂõûNULL„ÄÇ

Êàë‰ª¨Âú®‚ÄúLensÂÆûË∑µÊ°à‰æãÔºöÂàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôÂüüÂêçÂàÜÊûê‚ÄùÈÉ®ÂàÜÂ∞±Â§öÊ¨°Áî®Âà∞‰∫ÜCASEËØ≠Âè•„ÄÇÂÖ∂‰∏≠ÈÉ®ÂàÜ‰ª£Á†ÅÊëòÂΩïÂ¶Ç‰∏ãÔºö

```sql
-- ...ÁúÅÁï•ÈÉ®ÂàÜ‰ª£Á†Å...

profiles_summary as (
    select (
            case
                when length(short_name) >= 20 then 20 -- ÂüüÂêçÈïøÂ∫¶Â§ß‰∫é20Êó∂ÔºåËßÜ‰∏∫20ÂØπÂæÖ
                else length(short_name) -- ÂüüÂêçÈïøÂ∫¶Â∞è‰∫é20ÔºåÁõ¥Êé•‰ΩøÁî®ÂÖ∂ÈïøÂ∫¶ÂÄº
            end) as name_length, -- Â∞ÜcaseËØ≠Âè•ËØÑ‰º∞ËøîÂõûÁöÑÁªìÊûúÂëΩÂêç‰∏∫‰∏Ä‰∏™Êñ∞ÁöÑÂ≠óÊÆµ
        handle_type,
        count(*) as name_count
    from profile_created
    group by 1, 2
),

profiles_total as (
    select count(*) as total_profile_count,
        sum(case
                when handle_type = 'Pure Digits' then 1 -- Á±ªÂûãÂÄºÁ≠â‰∫éÁªôÂÆöÂÄºÔºåËøîÂõû1
                else 0  -- Á±ªÂûãÂÄº‰∏çÁ≠â‰∫éÁªôÂÆöÂÄºÔºåËøîÂõû 0
            end
        ) as pure_digit_profile_count,
        sum(case 
                when handle_type = 'Pure Letters' then 1  -- Á±ªÂûãÂÄºÁ≠â‰∫éÁªôÂÆöÂÄºÔºåËøîÂõû1
                else 0  -- Á±ªÂûãÂÄº‰∏çÁ≠â‰∫éÁªôÂÆöÂÄºÔºåËøîÂõû 0
            end
        ) as pure_letter_profile_count
    from profile_created
)

-- ...ÁúÅÁï•ÈÉ®ÂàÜ‰ª£Á†Å...
```

ÂèØ‰ª•ÁúãÂà∞ÔºåÈÄöËøáCASEËØ≠Âè•ÔºåÊàë‰ª¨ÂèØ‰ª•Ê†πÊçÆÂÆûÈôÖÁöÑÈúÄË¶ÅÂØπÊï∞ÊçÆËøõË°åÁÅµÊ¥ªÁöÑËΩ¨Êç¢ÔºåÊñπ‰æøÂêéÁª≠ÁöÑÁªüËÆ°Ê±áÊÄª„ÄÇ

‰∏äËø∞Á§∫‰æãÊü•ËØ¢ÁöÑÁõ∏ÂÖ≥ÈìæÊé•Ôºö
- Êü•ËØ¢Ôºö[https://dune.com/queries/1535541](https://dune.com/queries/1535541)
- ËØ¥ÊòéÔºö[LensÂàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôÂüüÂêçÂàÜÊûê](https://sixdegreelab.gitbook.io/mastering-chain-analytics/ru-men-jiao-cheng/06_pratical_case_lens_protocol)

ÂáΩÊï∞`if(cond, expr1, expr2)` ÁöÑ‰ΩúÁî®Êó∂Ê†πÊçÆÊù°‰ª∂ÂÄºËØÑ‰º∞ÁöÑÁúüÂÅáÔºåËøîÂõû‰∏§‰∏™Ë°®ËææÂºè‰∏≠ÁöÑÂÖ∂‰∏≠‰∏Ä‰∏™ÂÄº„ÄÇÂ¶ÇÊûúÊù°‰ª∂ËØÑ‰º∞ÁªìÊûú‰∏∫ÁúüÂÄºÔºåÂàôËøîÂõûÁ¨¨‰∏Ä‰∏™Ë°®ËææÂºèÔºåÂ¶ÇÊûúËØÑ‰º∞‰∏∫ÂÅáÂÄºÔºåÂàôËøîÂõûÁ¨¨‰∫å‰∏™Ë°®ËææÂºè„ÄÇ

```sql
select if(1 < 2, 'a', 'b') -- Êù°‰ª∂ËØÑ‰º∞ÁªìÊûú‰∏∫ÁúüÔºåËøîÂõûÁ¨¨‰∏Ä‰∏™Ë°®ËææÂºè
    ,if('a' = 'A', 'case-insensitive', 'case-sensitive') -- Â≠óÁ¨¶‰∏≤ÂÄºÂå∫ÂàÜÂ§ßÂ∞èÂÜô
 ```

## Â≠óÁ¨¶‰∏≤Â§ÑÁêÜÁöÑÂ∏∏Áî®ÂáΩÊï∞

1. Substring() ÂáΩÊï∞

ÂΩìÊúâÊó∂Êàë‰ª¨Âõ†‰∏∫Êüê‰∫õÁâπÊÆäÁöÑÂéüÂõ†‰∏çÂæó‰∏ç‰ΩøÁî®ÂéüÂßãÊï∞ÊçÆË°®`transactions`Êàñ`logs`Âπ∂Ëß£ÊûêÂÖ∂‰∏≠ÁöÑ`data`Êï∞ÊçÆÊó∂ÔºåÈúÄË¶ÅÂÖà‰ªéÂÖ∂‰∏≠ÊèêÂèñÈÉ®ÂàÜÂ≠óÁ¨¶‰∏≤ÔºåÁÑ∂ÂêéËøõË°åÈíàÂØπÊÄßÁöÑËΩ¨Êç¢Â§ÑÁêÜÔºåÊ≠§Êó∂Â∞±ÈúÄË¶Å‰ΩøÁî®SubstringÂáΩÊï∞„ÄÇSubstringÂáΩÊï∞ÁöÑËØ≠Ê≥ïÊ†ºÂºè‰∏∫`substring(expr, pos [, len])`ÊàñËÄÖ`substring(expr FROM pos [FOR len] ] )`ÔºåË°®Á§∫Âú®Ë°®ËææÂºè`expr`‰∏≠Ôºå‰ªé‰ΩçÁΩÆ`pos`ÂºÄÂßãÔºåÊà™Âèñ`len`‰∏™Â≠óÁ¨¶Âπ∂ËøîÂõû„ÄÇÂ¶ÇÊûúÁúÅÁï•ÂèÇÊï∞`len`ÔºåÂàô‰∏ÄÁõ¥Êà™ÂèñÂà∞Â≠óÁ¨¶‰∏≤Êú´Â∞æ„ÄÇ

2. Concat() ÂáΩÊï∞Âíå || Êìç‰ΩúÁ¨¶

ÂáΩÊï∞`concat(expr1, expr2 [, ...] )`Â∞ÜÂ§ö‰∏™Ë°®ËææÂºè‰∏≤Êé•Âà∞‰∏ÄËµ∑ÔºåÂ∏∏Áî®Êù•ÈìæÊé•Â≠óÁ¨¶‰∏≤„ÄÇÊìç‰ΩúÁ¨¶`||`ÁöÑÂäüËÉΩÂíåConcatÂáΩÊï∞Áõ∏Âêå„ÄÇ

```sql
select concat('a', ' ', 'b', ' c') -- ËøûÊé•Â§ö‰∏™Â≠óÁ¨¶‰∏≤
    , 'a' || ' ' || 'b' || ' c' -- ‰∏éconcat()ÂäüËÉΩÁõ∏Âêå
```

3. Right() ÂáΩÊï∞
ÂáΩÊï∞`right(str, len)`‰ªéÂ≠óÁ¨¶‰∏≤`str`‰∏≠ËøîÂõûÂè≥ËæπÂºÄÂßãËÆ°Êï∞ÁöÑ`len`‰∏™Â≠óÁ¨¶„ÄÇÂ¶ÇÂâçÊâÄËø∞ÔºåÂú®`logs`ËøôÊ†∑ÁöÑÂéüÂßãÊï∞ÊçÆË°®ÈáåÊï∞ÊçÆÊòØÊåâ64‰∏™Â≠óÁ¨¶‰∏ÄÁªÑËøûÊé•Âà∞‰∏ÄËµ∑ÂêéÊîæÂÖ•`data`ÈáåÈù¢ÁöÑÔºåÂØπ‰∫éÂêàÁ∫¶Âú∞ÂùÄÊàñÁî®Êà∑Âú∞ÂùÄÔºåÂÖ∂ÈïøÂ∫¶ÊòØ40‰∏™Â≠óÁ¨¶ÔºåÂú®‰øùÂ≠òÊó∂Â∞±‰ºöÂú®Â∑¶ËæπÂ°´ÂÖÖ`0`Êù•Ë°•Ë∂≥64‰ΩçÈïøÂ∫¶„ÄÇËß£ÊûêÊèêÂèñÂú∞ÂùÄÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Â∞±ÈúÄË¶ÅÊèêÂèñÂè≥ËæπÁöÑ40‰∏™Â≠óÁ¨¶ÔºåÂÜçÂä†‰∏ä`0x`ÂâçÁºÄÂ∞ÜÂÖ∂ËøòÂéü‰∏∫Ê≠£Á°ÆÁöÑÂú∞ÂùÄÊ†ºÂºè„ÄÇ

Ê≥®ÊÑèÔºåÂú®Dune SQL‰∏≠ÔºåÁõ¥Êé•‰ΩøÁî®`right()`ÂáΩÊï∞ÂèØËÉΩËøîÂõûËØ≠Ê≥ïÈîôËØØÔºåÂèØ‰ª•Â∞ÜÂáΩÊï∞ÂêçÊîæÂà∞ÂèåÂºïÂè∑‰∏≠Êù•Ëß£ÂÜ≥ÔºåÂç≥‰ΩøÁî®`"right"()`„ÄÇÁî±‰∫éËøôÁßçÊñπÂºèÊòæÂæóÊØîËæÉÁπÅÁêêÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®substringÂáΩÊï∞ÁöÑË¥üÊï∞ÂºÄÂßã‰ΩçÁΩÆÂèÇÊï∞Êù•Ë°®Á§∫‰ªéÂ≠óÁ¨¶‰∏≤Âè≥ËæπÂºÄÂßãËÆ°Êï∞Á°ÆÂÆöÊà™ÂèñÁöÑÂºÄÂßã‰ΩçÁΩÆ„ÄÇ

‰∏ãÈù¢ÊòØ‰∏Ä‰∏™‰ΩøÁî®‰∏äËø∞ÂáΩÊï∞ÁöÑ‰∏Ä‰∏™ÁªºÂêà‰æãÂ≠êÔºåËøô‰∏™‰æãÂ≠ê‰ªé`logs`Ë°®Ëß£ÊûêË∑®ÈìæÂà∞ArbitrumÁöÑËÆ∞ÂΩïÔºåÁªºÂêà‰ΩøÁî®‰∫ÜÂá†‰∏™ÊñπÂºèÔºö

```sql
select date_trunc('day', block_time) as block_date, --Êà™ÂèñÊó•Êúü
    concat('0x', "right"(substring(cast(data as varchar), 3 + 64 * 2, 64), 40)) as address, -- ÊèêÂèñdata‰∏≠ÁöÑÁ¨¨3ÈÉ®ÂàÜËΩ¨Êç¢‰∏∫Áî®Êà∑Âú∞ÂùÄÔºå‰ªéÁ¨¨3‰∏™Â≠óÁ¨¶ÂºÄÂßãÔºåÊØè64‰Ωç‰∏∫‰∏ÄÁªÑ
    concat('0x', "right"(substring(cast(data as varchar), 3 + 64 * 3, 64), 40)) as token, -- ÊèêÂèñdata‰∏≠ÁöÑÁ¨¨4ÈÉ®ÂàÜËΩ¨Êç¢‰∏∫Áî®Êà∑Âú∞ÂùÄ
    concat('0x', substring(substring(cast(data as varchar), 3 + 64 * 3, 64), -40, 40)) as same_token, -- ÊèêÂèñdata‰∏≠ÁöÑÁ¨¨4ÈÉ®ÂàÜËΩ¨Êç¢‰∏∫Áî®Êà∑Âú∞ÂùÄ
    substring(cast(data as varchar), 3 + 64 * 4, 64) as hex_amount, -- ÊèêÂèñdata‰∏≠ÁöÑÁ¨¨5ÈÉ®ÂàÜ
    bytearray_to_uint256(bytearray_substring(data, 1 + 32 * 4, 32)) as amount, -- ÊèêÂèñdata‰∏≠ÁöÑÁ¨¨5ÈÉ®ÂàÜÔºåËΩ¨Êç¢‰∏∫10ËøõÂà∂Êï∞ÂÄº
    tx_hash
from ethereum.logs
where contract_address = 0x5427fefa711eff984124bfbb1ab6fbf5e3da1820   -- Celer Network: cBridge V2 
    and topic0 = 0x89d8051e597ab4178a863a5190407b98abfeff406aa8db90c59af76612e58f01  -- Send
    and substring(cast(data as varchar), 3 + 64 * 5, 64) = '000000000000000000000000000000000000000000000000000000000000a4b1'   -- 42161ÔºåÁõ¥Êé•Âà§Êñ≠16ËøõÂà∂ÂÄº
    and substring(cast(data as varchar), 3 + 64 * 3, 64) = '000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc2' -- WETHÔºåÁõ¥Êé•Âà§Êñ≠16ËøõÂà∂ÂÄº
    and block_time >= now() - interval '30' day
limit 10
```

‰∏äËø∞Á§∫‰æãÊü•ËØ¢ÁöÑÁõ∏ÂÖ≥ÈìæÊé•Ôºö
- [https://dune.com/queries/1647016](https://dune.com/queries/1647016)
- [Â≠óÁ¨¶‰∏≤ÂáΩÊï∞ÂíåËøêÁÆóÁ¨¶](https://trino.io/docs/current/functions/string.html)

## Á™óÂè£ÂáΩÊï∞

Â§öË°åÊï∞ÊçÆÁöÑÁªÑÂêàÊàê‰∏∫Á™óÂè£ÔºàWindowÔºâ„ÄÇÂØπÁ™óÂè£‰∏≠ÁöÑ‰∏ÄÁªÑË°åËøõË°åÊìç‰ΩúÂπ∂Ê†πÊçÆËØ•ÁªÑË°åËÆ°ÁÆóÊØè‰∏ÄË°åÁöÑËøîÂõûÂÄºÁöÑÂáΩÊï∞Âè´Á™óÂè£ÂáΩÊï∞„ÄÇÁ™óÂè£ÂáΩÊï∞ÂØπ‰∫éÂ§ÑÁêÜ‰ªªÂä°ÂæàÊúâÁî®Ôºå‰æãÂ¶ÇËÆ°ÁÆóÁßªÂä®Âπ≥ÂùáÂÄº„ÄÅËÆ°ÁÆóÁ¥ØÁßØÁªüËÆ°ÈáèÊàñÂú®ÁªôÂÆöÂΩìÂâçË°åÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÁöÑÊÉÖÂÜµ‰∏ãËÆøÈóÆË°åÁöÑÂÄº„ÄÇÁ™óÂè£ÂáΩÊï∞ÁöÑÂ∏∏Áî®ËØ≠Ê≥ïÊ†ºÂºèÔºö

```sql
function OVER window_spec
```

ÂÖ∂‰∏≠Ôºå`function`ÂèØ‰ª•ÊòØÊéíÂêçÁ™óÂè£ÂáΩÊï∞„ÄÅÂàÜÊûêÁ™óÂè£ÂáΩÊï∞ÊàñËÄÖËÅöÂêàÂáΩÊï∞„ÄÇ`over`ÊòØÂõ∫ÂÆöÂøÖÈ°ª‰ΩøÁî®ÁöÑÂÖ≥ÈîÆÂ≠ó„ÄÇ`window_spec`ÈÉ®ÂàÜÂèàÊúâ‰∏§ÁßçÂèØËÉΩÁöÑÂèòÂåñÔºö`partition by partition_feild order by order_field`ÊàñËÄÖ`order by order_field`ÔºåÂàÜÂà´Ë°®Á§∫ÂÖàÂàÜÂå∫ÂÜçÊéíÂ∫èÂíå‰∏çÂàÜÂå∫Áõ¥Êé•ÊéíÂ∫è„ÄÇÈô§‰∫ÜÊääÊâÄÊúâË°åÂΩì‰ΩúÂêå‰∏Ä‰∏™ÂàÜÁªÑÁöÑÊÉÖÂÜµÂ§ñÔºåÂàÜÁªÑÂáΩÊï∞ÂøÖÈ°ªÈÖçÂêà `order by`Êù•‰ΩøÁî®„ÄÇ

1. LEAD()„ÄÅ LAG() ÂáΩÊï∞

Lead()ÂáΩÊï∞‰ªéÂàÜÂå∫ÂÜÖÁöÑÂêéÁª≠Ë°åËøîÂõûÊåáÂÆöË°®ËææÂºèÁöÑÂÄº„ÄÇÂÖ∂ËØ≠Ê≥ï‰∏∫`lead(expr [, offset [, default] ] )`„ÄÇLag()ÂáΩÊï∞‰ªé‰ªéÂàÜÂå∫‰∏≠ÁöÑÂâçÂ∫èË°åËøîÂõûÊåáÂÆöË°®ËææÂºèÁöÑÂÄº„ÄÇÂΩìÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜÁªìÊûúÈõÜ‰∏≠Êüê‰∏ÄÂàóÁöÑÂÄºÔºåË∑ü‰∏ä‰∏ÄË°åÊàñËÄÖ‰∏ã‰∏ÄË°åÁöÑÁõ∏ÂêåÂàóÁöÑÂÄºËøõË°åÊØîËæÉÔºàÂΩìÁÑ∂‰πüÂèØ‰ª•Èó¥ÈöîÂ§öË°åÂèñÂÄºÔºâÊó∂ÔºåËøô‰∏§‰∏™ÂáΩÊï∞Â∞±ÈùûÂ∏∏ÊúâÁî®„ÄÇ

Êàë‰ª¨‰πãÂâçÁöÑÊïôÁ®ã‰∏≠‰ªãÁªçËøá‰∏Ä‰∏™Êü•ËØ¢ÔºåÁî®‰∫éÁªüËÆ°Uniswap V3 Ëøë30Â§©ÊØèÊó•Êñ∞Â¢ûËµÑÈáëÊ±†Êï∞Èáè„ÄÇÂÖ∂SQL‰∏∫Ôºö

```sql
with pool_details as (
    select date_trunc('day', evt_block_time) as block_date, evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
    where evt_block_time >= now() - interval '29' day
)

select block_date, count(pool) as pool_count
from pool_details
group by 1
order by 1
```

Â¶ÇÊûúÊàë‰ª¨Âú®ÁõÆÂâçÁöÑÊù°ÂΩ¢ÂõæÂü∫Á°Ä‰∏äËøòÂ∏åÊúõÊ∑ªÂä†‰∏ÄÊù°Êõ≤Á∫øÊù•ÊòæÁ§∫ÊØèÂ§©Êñ∞Âª∫ËµÑÈáëÊ±†Êï∞ÈáèÁöÑÂèòÂåñÊÉÖÂÜµÔºåÂ∞±ÂèØ‰ª•‰ΩøÁî®Lag()ÂáΩÊï∞Êù•ËÆ°ÁÆóÂá∫ÊØèÂ§©Áõ∏ËæÉ‰∫éÂâç‰∏ÄÂ§©ÁöÑÂèòÂåñÂÄºÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ÂèØËßÜÂåñ„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÈÄªËæëÊ∏ÖÊô∞ÔºåÊàë‰ª¨Â¢ûÂä†‰∫Ü‰∏Ä‰∏™CTEÔºå‰øÆÊîπÂêéÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with pool_details as (
    select date_trunc('day', evt_block_time) as block_date, evt_tx_hash, pool
    from uniswap_v3_ethereum.Factory_evt_PoolCreated
    where evt_block_time >= now() - interval '29' day
),

pool_summary as (
    select block_date,
        count(pool) as pool_count
    from pool_details
    group by 1
    order by 1
)

select block_date,
    pool_count,
    lag(pool_count, 1) over (order by block_date) as pool_count_previous, -- ‰ΩøÁî®Lag()ÂáΩÊï∞Ëé∑ÂèñÂâç‰∏ÄÂ§©ÁöÑÂÄº
    pool_count - (lag(pool_count, 1) over (order by block_date)) as pool_count_diff -- Áõ∏ÂáèÂæóÂà∞ÂèòÂåñÂÄº
from pool_summary
order by block_date
```

Â∞Ü`pool_count_diff`Ê∑ªÂä†Âà∞ÂèØËßÜÂåñÂõæË°®Ôºà‰ΩøÁî®Âè≥‰æßÂùêÊ†áËΩ¥ÔºåÂõæÂΩ¢Á±ªÂûãÈÄâÊã©LineÔºâÔºåÊïàÊûúÂ¶Ç‰∏ãÂõæÔºö

![part_2_01.png](img/part_2_01.png)

ÂΩìÊàë‰ª¨ÈúÄË¶ÅÂêë‚ÄúÂâç‚ÄùÂØπÊØî‰∏çÂêåË°åÁöÑÊï∞ÊçÆÊó∂ÔºåÂ∞±ÂèØ‰ª•‰ΩøÁî®Lead()ÂáΩÊï∞„ÄÇÊØîÂ¶ÇÔºåÊàë‰ª¨‰πãÂâçÂú®LensÂÆû‰æã‰∏≠‰ªãÁªçËøáÂèëÂ∏ÉÂ∏ñÂ≠êÊúÄÂ§öÁöÑÂàõ‰ΩúËÄÖË¥¶Âè∑Êü•ËØ¢ÔºåÊàë‰ª¨Â∞ÜÂÖ∂ÂÅö‰∏Ä‰∫õË∞ÉÊï¥ÔºåËøîÂõûÂèëÂ∏ñÊúÄÂ§öÁöÑ50‰∏™Ë¥¶Âè∑ÔºåÂêåÊó∂ÂØπÊØîËøô‰∫õË¥¶Âè∑ÂèëÂ∏ñÊï∞ÈáèÁöÑÂ∑ÆÂºÇÔºàÁ¨¨‰∏ÄÂêçÂíåÁ¨¨‰∫åÂêç‰πãÂ∑Æ„ÄÅÁ¨¨‰∫åÂêçÂíåÁ¨¨‰∏âÂêç‰πãÂ∑ÆÔºåÁ≠âÁ≠âÔºâ„ÄÇÂÖ≥ÈîÆÈÉ®ÂàÜÊü•ËØ¢‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
with post_data as (
    -- Ëé∑ÂèñÂéüÂßãÂèëÂ∏ñËØ¶ÁªÜÊï∞ÊçÆÔºåËØ∑ÂèÇËÄÉÂÆåÊï¥SQLÈìæÊé•
),

top_post_profiles as (
    select profile_id,
        count(*) as post_count
    from post_data
    group by 1
    order by 2 desc
    limit 50
)

select row_number() over (order by post_count desc) as rank_id, -- ÁîüÊàêËøûÁª≠Ë°åÂè∑ÔºåÁî®Êù•Ë°®Á§∫ÊéíÂêç
    profile_id,
    post_count,
    lead(post_count, 1) over (order by post_count desc) as post_count_next, -- Ëé∑Âèñ‰∏ã‰∏ÄË°åÁöÑÂèëÂ∏ñÊï∞ÊçÆ
    post_count - (lead(post_count, 1) over (order by post_count desc)) as post_count_diff -- ËÆ°ÁÆóÂΩìÂâçË°åÂíå‰∏ã‰∏ÄË°åÁöÑÂèëÂ∏ñÊï∞ÈáèÂ∑Æ
from top_post_profiles
order by post_count desc
```

Êü•ËØ¢ÁªìÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫ÔºåÂÖ∂‰∏≠ÂèØ‰ª•ÁúãÂà∞Êúâ‰∫õË¥¶Âè∑‰πãÈó¥ÁöÑÂèëÂ∏ñÊï∞ÈáèÂ∑ÆÂºÇÂæàÂ∞èÔºö

![part_2_02.png](img/part_2_02.png)

ÂÆåÊï¥ÁöÑSQLÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1647422](https://dune.com/queries/1647422)

2. Row_Number() ÂáΩÊï∞

Row_Number() ÊòØ‰∏Ä‰∏™ÊéíÂêçÁ±ªÂûãÁöÑÁ™óÂè£ÂáΩÊï∞ÔºåÁî®‰∫éÊåâÁÖßÊåáÂÆöÁöÑÊéíÂ∫èÊñπÂºèÁîüÊàê‰∏çÂêåÁöÑË°åÂè∑Ôºå‰ªé1ÂºÄÂßãËøûÁª≠ÁºñÂè∑„ÄÇÂú®‰∏ä‰∏Ä‰∏™‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨Â∑≤Áªè‰ΩøÁî®‰∫Ü`row_number() over (order by post_count desc) as rank_id`Êù•ÁîüÊàêË°åÂè∑Áî®Êù•Ë°®Á§∫ÊéíÂêçÔºåËøôÈáå‰∏çÂÜç‰∏æ‰æã„ÄÇÂ¶ÇÊûúÁªìÂêà`partition by`ÂàÜÂå∫Â≠óÂè•ÔºåRow_Number()Â∞ÜÂú®ÊØè‰∏Ä‰∏™ÂàÜÂå∫ÂÜÖÈÉ®‰ªé1ÂºÄÂßãÁºñÂè∑„ÄÇÂà©Áî®Ëøô‰∏™ÁâπÊÄßÔºåÊàë‰ª¨ÂèØ‰ª•Áî®Êù•ÂÆûÁé∞‰∏Ä‰∫õÈ´òÁ∫ßÁ≠õÈÄâ„ÄÇ‰æãÂ¶ÇÔºåÊàë‰ª¨Êúâ‰∏ÄÁªÑTokenÂú∞ÂùÄÔºåÈúÄË¶ÅËÆ°ÁÆóÂπ∂ËøîÂõû‰ªñ‰ª¨ÊúÄËøë1Â∞èÊó∂ÂÜÖÁöÑÂπ≥Âùá‰ª∑Ê†º„ÄÇËÄÉËôëÂà∞DuneÁöÑÊï∞ÊçÆ‰ºöÂ≠òÂú®‰∏ÄÂà∞Âá†ÂàÜÈíüÁöÑÂª∂ËøüÔºåÂ¶ÇÊûúÊåâÂΩìÂâçÁ≥ªÁªüÊó•ÊúüÁöÑ‚ÄúÂ∞èÊó∂‚ÄùÊï∞ÂÄºÁ≠õÈÄâÔºåÂπ∂‰∏ç‰∏ÄÂÆöÊÄªÊòØËÉΩËøîÂõûÈúÄË¶ÅÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇÁõ∏ÂØπÊõ¥ÂÆâÂÖ®ÁöÑÊñπÊ≥ïÊòØÊâ©Â§ßÂèñÂÄºÁöÑÊó∂Èó¥ËåÉÂõ¥ÔºåÁÑ∂Âêé‰ªé‰∏≠Á≠õÈÄâÂá∫ÊØè‰∏™TokenÊúÄËøëÁöÑÈÇ£Êù°ËÆ∞ÂΩï„ÄÇËøôÊ†∑Âç≥‰ΩøÂá∫Áé∞Êï∞ÊçÆÊúâÂá†‰∏™Â∞èÊó∂ÁöÑÂª∂ËøüÁöÑÁâπÊÆäÊÉÖÂÜµÔºåÊàë‰ª¨ÁöÑÊü•ËØ¢‰ªçÁÑ∂ÂèØ‰ª•Â∑•‰ΩúËâØÂ•Ω„ÄÇÊ≠§Êó∂Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Row_Number()ÂáΩÊï∞ÁªìÂêà`partition by`Êù•ÊåâÂàÜÂå∫ÁîüÊàêË°åÂè∑ÂÜçÊ†πÊçÆË°åÂè∑Á≠õÈÄâÂá∫ÈúÄË¶ÅÁöÑÊï∞ÊçÆ„ÄÇ

```sql
with latest_token_price as (
    select date_trunc('hour', minute) as price_date, -- ÊåâÂ∞èÊó∂ÂàÜÁªÑËÆ°ÁÆó
        contract_address,
        symbol,
        decimals,
        avg(price) as price -- ËÆ°ÁÆóÂπ≥Âùá‰ª∑Ê†º
    from prices.usd
    where contract_address in (
        0xdac17f958d2ee523a2206206994597c13d831ec7,
        0x2260fac5e5542a773aa44fbcfedf7c193bc2c599,
        0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,
        0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48,
        0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9
    )
    and minute > now() - interval '1' day -- ÂèñÊúÄÂêé‰∏ÄÂ§©ÂÜÖÁöÑÊï∞ÊçÆÔºåÁ°Æ‰øùÂç≥‰ΩøÊï∞ÊçÆÊúâÂª∂Ëøü‰πüÂ∑•‰ΩúËâØÂ•Ω
    group by 1, 2, 3, 4
),

latest_token_price_row_num as (
    select  price_date,
        contract_address,
        symbol,
        decimals,
        price,
        row_number() over (partition by contract_address order by price_date desc) as row_num -- ÊåâÂàÜÂå∫ÂçïÁã¨ÁîüÊàêË°åÂè∑
    from latest_token_price
)

select contract_address,
    symbol,
    decimals,
    price
from latest_token_price_row_num
where row_num = 1 -- ÊåâË°åÂè∑Á≠õÈÄâÂá∫ÊØè‰∏™tokenÊúÄÊñ∞ÁöÑÂπ≥Âùá‰ª∑Ê†º
```

‰ª•‰∏äÊü•ËØ¢ÁªìÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![part_2_03.png](img/part_2_03.png)

ÂÆåÊï¥ÁöÑSQLÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1647482](https://dune.com/queries/1647482)


Á™óÂè£ÂáΩÊï∞ÁöÑÊõ¥Â§öÂÆåÊï¥ËµÑÊñôÔºö
- [ÂàÜÊûêÁ™óÂáΩÊï∞](https://trino.io/docs/current/functions/window.html)


## array_agg()ÂáΩÊï∞

Â¶ÇÊûú‰Ω†ÊÉ≥Â∞ÜÊü•ËØ¢ÁªìÊûúÈõÜ‰∏≠ÊØè‰∏ÄË°åÊï∞ÊçÆÁöÑÊüê‰∏ÄÂàóÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºåÂèØ‰ª•‰ΩøÁî® array_agg()ÂáΩÊï∞„ÄÇÂ¶ÇÊûúÂ∏åÊúõÂ∞ÜÂ§öÂàóÊï∞ÊçÆÈÉΩÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºàÊÉ≥Ë±°Â∞ÜÊü•ËØ¢ÁªìÊûúÂØºÂá∫‰∏∫CSVÁöÑÊÉÖÂΩ¢ÔºâÔºå‰Ω†ÂèØ‰ª•ËÄÉËôëÁî®ÂâçÈù¢‰ªãÁªçÁöÑÂ≠óÁ¨¶‰∏≤ËøûÊé•ÁöÑÊñπÂºèÂ∞ÜÂ§öÂàóÊï∞ÊçÆÂêàÂπ∂‰∏∫‰∏ÄÂàóÔºåÁÑ∂ÂêéÂÜçÂ∫îÁî® array_agg()ÂáΩÊï∞„ÄÇËøôÈáå‰∏æ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºö

```sql
select array_agg(contract_address) from
(
    select contract_address 
    from ethereum.logs
    where block_time >= current_date
    limit 10
) t
```

## ÊÄªÁªì

ÊØè‰∏ÄÁßçÊï∞ÊçÆÂ∫ìÈÉΩÊúâÂá†ÂçÅ‰∏™ÁîöËá≥‰∏äÁôæ‰∏™ÂÜÖÁΩÆÁöÑÂáΩÊï∞ÔºåËÄåÊàë‰ª¨ËøôÈáå‰ªãÁªçÁöÑÂè™ÊòØÂÖ∂‰∏≠‰∏ÄÂ∞èÈÉ®ÂàÜÂ∏∏Áî®ÁöÑÂáΩÊï∞„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥Ë¶ÅÊàê‰∏∫ÁÜüÁªÉÁöÑÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåÊàë‰ª¨Âº∫ÁÉàÂª∫ËÆÆÈòÖËØªÂπ∂‰∫ÜËß£ËøôÈáåÁöÑÊØè‰∏Ä‰∏™ÂÜÖÁΩÆÂáΩÊï∞ÁöÑÁî®Ê≥ïÔºö
[Trino ÂáΩÊï∞](https://trino.io/docs/current/functions.html)„ÄÇ

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch08/readme.md">
---
title: 08. Lens ProtocolÊï∞ÊçÆÁúãÊùøÔºà‰∏ÄÔºâ
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - lens
---

# 8. ÂÆûË∑µÊ°à‰æãÔºöÂà∂‰ΩúLens ProtocolÁöÑÊï∞ÊçÆÁúãÊùøÔºà‰∏ÄÔºâ

‰∏∫‰∫ÜËÆ©Â§ßÂÆ∂Â∞ΩÂø´‰∏äÊâãÂºÄÂßãÊï∞ÊçÆÂàÜÊûêÔºåÊàë‰ª¨‰ºöÂ∞Ü‰∏Ä‰∫õÂÅèÁêÜËÆ∫ÁöÑÂÜÖÂÆπÊîæÂà∞ÊïôÁ®ãÁöÑÂêéÁª≠ÈÉ®ÂàÜÔºåÂâçÂçäÈÉ®ÂàÜÂàôÊõ¥Â§öËÆ≤Ëß£‰∏Ä‰∫õÂèØ‰ª•ÁªìÂêàËµ∑Êù•ÂÆûË∑µÁöÑÂÜÖÂÆπ„ÄÇÊú¨ÁØáÊïôÁ®ãÊàë‰ª¨‰∏ÄËµ∑Êù•‰∏∫Lens ProtocolÈ°πÁõÆÂà∂‰Ωú‰∏Ä‰∏™Êï∞ÊçÆÁúãÊùø„ÄÇ

## LensÂçèËÆÆÊòØ‰ªÄ‰πàÔºü

Êù•Ëá™[LensÂÆòÁΩë](https://docs.lens.xyz/docs/what-is-lens)ÁöÑ‰ªãÁªçÊï¥ÁêÜÂ¶Ç‰∏ãÔºö
LensÂçèËÆÆÔºàLens ProtocolÔºåÁÆÄÁß∞ LensÔºâÊòØPolygonÂå∫ÂùóÈìæ‰∏äÁöÑ Web3 Á§æ‰∫§ÂõæË∞±ÁîüÊÄÅÁ≥ªÁªü„ÄÇÂÆÉÊó®Âú®ËÆ©Âàõ‰ΩúËÄÖÊã•ÊúâËá™Â∑±‰∏éÁ§æÂå∫‰πãÈó¥ÁöÑËÅîÁ≥ªÔºåÂΩ¢Êàê‰∏Ä‰∏™ÂÆåÂÖ®ÂèØÁªÑÂêàÁöÑ„ÄÅÁî®Êà∑Êã•ÊúâÁöÑÁ§æ‰∫§ÂõæË∞±„ÄÇËØ•ÂçèËÆÆ‰ªé‰∏ÄÂºÄÂßãÂ∞±ËÄÉËôëÂà∞‰∫ÜÊ®°ÂùóÂåñÔºåÂÖÅËÆ∏Ê∑ªÂä†Êñ∞ÂäüËÉΩÂíå‰øÆÂ§çÈóÆÈ¢òÔºåÂêåÊó∂Á°Æ‰øùÁî®Êà∑Êã•ÊúâÁöÑÂÜÖÂÆπÂíåÁ§æ‰∫§ÂÖ≥Á≥ª‰∏çÂèØÂèò„ÄÇLensÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÁ§æ‰∫§Â™í‰ΩìÁΩëÁªú‰∏≠ÁöÑ‰∏Ä‰∫õ‰∏ªË¶ÅÈóÆÈ¢ò„ÄÇWeb2 ÁΩëÁªúÈÉΩ‰ªéÂÖ∂‰∏ìÊúâÁöÑÈõÜ‰∏≠ÂºèÊï∞ÊçÆÂ∫ì‰∏≠ËØªÂèñÊï∞ÊçÆ„ÄÇÁî®Êà∑ÁöÑ‰∏™‰∫∫ËµÑÊñô„ÄÅÊúãÂèãÂÖ≥Á≥ªÂíåÂÜÖÂÆπË¢´ÈîÅÂÆöÂú®ÁâπÂÆöÁΩëÁªú‰∏≠ÔºåÂÖ∂ÊâÄÊúâÊùÉÂΩíÁΩëÁªúËøêËê•ÂïÜÊã•Êúâ„ÄÇÂêÑÁΩëÁªú‰πãÈó¥‰∫íÁõ∏Á´û‰∫âÔºå‰∫âÂ§∫Áî®Êà∑Ê≥®ÊÑèÂäõÔºåÂèòÊàê‰∏ÄÁßçÈõ∂ÂíåÊ∏∏Êàè„ÄÇLensÈÄöËøáÊàê‰∏∫Áî®Êà∑Êã•ÊúâÁöÑ„ÄÅ‰ªª‰ΩïÂ∫îÁî®Á®ãÂ∫èÈÉΩÂèØ‰ª•Êé•ÂÖ•ÁöÑÂºÄÊîæÁ§æ‰∫§ÂõæË∞±Êù•Á∫†Ê≠£Ëøô‰∏ÄÁÇπ„ÄÇÁî±‰∫éÁî®Êà∑Êã•ÊúâËá™Â∑±ÁöÑÊï∞ÊçÆÔºå‰ªñ‰ª¨ÂèØ‰ª•Â∞ÜÂÖ∂Â∏¶Âà∞‰ªª‰ΩïÂü∫‰∫éLensÂçèËÆÆÊûÑÂª∫ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏≠„ÄÇ‰Ωú‰∏∫ÂÖ∂ÂÜÖÂÆπÁöÑÁúüÊ≠£ÊâÄÊúâËÄÖÔºåÂàõ‰ΩúËÄÖ‰∏çÂÜçÈúÄË¶ÅÊãÖÂøÉÂü∫‰∫éÂçï‰∏™Âπ≥Âè∞ÁöÑÁÆóÊ≥ïÂíåÊîøÁ≠ñÁöÑÁ™ÅÁÑ∂ÂèòÂåñËÄåÂ§±Âéª‰ªñ‰ª¨ÁöÑÂÜÖÂÆπ„ÄÅËßÇ‰ºóÂíåÊî∂ÂÖ•Êù•Ê∫ê„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®LensÂçèËÆÆÁöÑÊØè‰∏™Â∫îÁî®Á®ãÂ∫èÈÉΩÊúâÁõä‰∫éÊï¥‰∏™ÁîüÊÄÅÁ≥ªÁªüÔºå‰ªéËÄåÂ∞ÜÈõ∂ÂíåÊ∏∏ÊàèÂèòÊàê‰∫ÜÂçè‰ΩúÊ∏∏Êàè„ÄÇ

LensÂçèËÆÆÈáåÈù¢‰∏ªË¶ÅÊ∂âÂèä‰ª•‰∏ãËßíËâ≤ÔºàÂÆû‰ΩìÔºâÔºö‰∏™‰∫∫ËµÑÊñôÔºàProfileÔºâ„ÄÅÂá∫ÁâàÁâ©ÔºàPublicationÔºâ„ÄÅËØÑËÆ∫ÔºàCommentÔºâ„ÄÅÈïúÂÉèÔºàMirrorÔºâ„ÄÅÊî∂ËóèÔºàCollect)Ôºâ„ÄÅÂÖ≥Ê≥®ÔºàFollowÔºâ„ÄÇÂêåÊó∂ÔºåÂçèËÆÆÈáåÈù¢Â≠òÂú®3ÁßçÁ±ªÂûãÁöÑNFTÔºåÂç≥Ôºö‰∏™‰∫∫ËµÑÊñôNFTÔºàProfile NFTÔºâ„ÄÅÂÖ≥Ê≥®NFTÔºàFollow NFTÔºâ„ÄÅÊî∂ËóèNFTÔºàCollect NFTÔºâ„ÄÇ

Lens‰∏äÁöÑÂÖ∏Âûã‰ΩøÁî®Âú∫ÊôØÂåÖÊã¨Ôºö

- Âàõ‰ΩúËÄÖÊ≥®ÂÜåÂàõÂª∫‰ªñ‰ª¨ÁöÑProfileÔºåÈì∏ÈÄ†ÂÖ∂‰∏ìÂ±ûÁöÑProfileNFT„ÄÇÂèØ‰ª•ËÆæÁΩÆ‰∏™ÊÄßÂåñÂêçÁß∞ÔºàProfile Handle NameÔºåÂèØÁÆÄÂçïÁ±ªÊØî‰∏∫ÂüüÂêçÔºåÂç≥‚ÄúLensÂüüÂêç‚ÄùÔºâ„ÄÇÂêåÊó∂ÔºåÂèØ‰ª•ËÆæÁΩÆË¥¶Âè∑Â§¥ÂÉèÂõæÁâáURL„ÄÅË¢´ÂÖ≥Ê≥®Êó∂ÁöÑËßÑÂàôÔºàÈÄöËøáËÆæÁΩÆÁâπÊÆäÁöÑËßÑÂàôÔºåÂèØ‰ª•‰∫ßÁîüÊî∂ÁõäÔºåÊØîÂ¶ÇÂèØ‰ª•ËÆæÁΩÆÁî®Êà∑ÈúÄË¶ÅÊîØ‰ªò‰∏ÄÂÆöÁöÑË¥πÁî®ÊâçËÉΩÂÖ≥Ê≥®ProfileÔºâ„ÄÇÁõÆÂâç‰ªÖËÆ∏ÂèØÂêçÂçïÂÜÖÁöÑÂú∞ÂùÄÂèØ‰ª•ÂàõÂª∫‰∏™‰∫∫ËµÑÊñôË¥¶Âè∑„ÄÇ
- Âàõ‰ΩúËÄÖÂèëÂ∏ÉÂÜÖÂÆπÂá∫ÁâàÁâ©ÔºàPublicationÔºâÔºåÂåÖÊã¨ÊñáÁ´†ÔºàÂ∏ñÂ≠êÔºåPostÔºâ„ÄÅÈïúÂÉèÔºàMirrorÔºâ„ÄÅËØÑËÆ∫ÔºàCommentÔºâÁ≠â„ÄÇ
- ÊôÆÈÄöÁî®Êà∑ÂèØ‰ª•ÂÖ≥Ê≥®Âàõ‰ΩúËÄÖÔºåÊî∂ËóèÊÑüÂÖ¥Ë∂£ÁöÑÂá∫ÁâàÁâ©„ÄÇ
- Âú®Áõ∏ÂÖ≥Êìç‰ΩúÊ≠•È™§‰∏≠Ôºå3Áßç‰∏çÂêåÁ±ªÂûãNFTË¢´ÂàÜÂà´Èì∏ÈÄ†Âπ∂‰º†ËæìÁªô‰∏çÂêåÁöÑÁî®Êà∑Âú∞ÂùÄ„ÄÇ

## Lens ÂçèËÆÆ‰∏ªË¶ÅÂàÜÊûêÂÜÖÂÆπ

ÈíàÂØπLensËøôÊ†∑ÁöÑÈ°πÁõÆÔºåÊàë‰ª¨ÂèØ‰ª•‰ªéÊï¥‰Ωì‰∏äÂàÜÊûêÂÖ∂Ê¶ÇÂÜµÔºå‰πüÂèØ‰ª•‰ªé‰∏çÂêåËßíÂ∫¶„ÄÅÈíàÂØπÂÖ∂‰∏≠ÁöÑ‰∏çÂêåËßíËâ≤Á±ªÂûãËøõË°åÊï∞ÊçÆÂàÜÊûê„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂèØ‰ª•ÂàÜÊûêÁöÑÂÜÖÂÆπÁöÑÊ¶ÇÂÜµÔºö
- ÊÄªÁî®Êà∑Êï∞Èáè„ÄÅÊÄªÁöÑÂàõ‰ΩúËÄÖÊï∞Èáè„ÄÅÂàõ‰ΩúËÄÖÂç†ÊØîÁ≠â
- ÊÄªÂá∫ÁâàÁâ©Êï∞Èáè„ÄÅÊÄªËØÑËÆ∫Êï∞Èáè„ÄÅÊÄªÈïúÂÉèÊï∞Èáè„ÄÅÊÄªÂÖ≥Ê≥®Êï∞Èáè„ÄÅÊÄªÊî∂ËóèÊï∞ÈáèÁ≠â
- Áî®Êà∑Áõ∏ÂÖ≥ÁöÑÂàÜÊûêÔºöÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞Èáè„ÄÅÊØèÊó•Êñ∞Â¢ûÂàõ‰ΩúËÄÖÊï∞Èáè„ÄÅÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞Èáè„ÄÅÊ¥ªË∑ÉÂàõ‰ΩúËÄÖÊï∞Èáè„ÄÅÁî®Êà∑Êï¥‰ΩìÊ¥ªË∑ÉÂ∫¶ÁöÑÂèòÂåñË∂ãÂäøÁ≠â
- LensË¥¶Âè∑‰∏™ÊÄßÂåñÂüüÂêçÁöÑÁõ∏ÂÖ≥ÂàÜÊûêÔºöÂüüÂêçÊ≥®ÂÜåÊï∞Èáè„ÄÅ‰∏çÂêåÁ±ªÂûãÂüüÂêçÁöÑÊ≥®ÂÜåÊÉÖÂÜµÔºàÁ∫ØÊï∞Â≠ó„ÄÅÁ∫ØÂ≠óÊØç„ÄÅ‰∏çÂêåÈïøÂ∫¶ÔºâÁ≠â
- Âàõ‰ΩúËÄÖÁöÑÊ¥ªË∑ÉÂ∫¶ÂàÜÊûêÔºöÂèëÂ∏ÉÂá∫ÁâàÁâ©ÁöÑÊï∞Èáè„ÄÅË¢´ÂÖ≥Ê≥®ÁöÑÊ¨°Êï∞„ÄÅË¢´ÈïúÂÉèÁöÑÊ¨°Êï∞„ÄÅÊúÄÁÉ≠Èó®Âàõ‰ΩúËÄÖÁ≠â
- Âá∫ÁâàÁâ©ÁöÑÁõ∏ÂÖ≥ÂàÜÊûêÔºöÂÜÖÂÆπÂèëÂ∏ÉÊï∞Èáè„ÄÅÂ¢ûÈïøË∂ãÂäø„ÄÅË¢´ÂÖ≥Ê≥®Ê¨°Êï∞„ÄÅË¢´Êî∂ËóèÊ¨°Êï∞„ÄÅÊúÄÁÉ≠Èó®Âá∫ÁâàÁâ©Á≠â
- ÂÖ≥Ê≥®ÁöÑÁõ∏ÂÖ≥ÂàÜÊûêÔºöÂÖ≥Ê≥®ÁöÑÊï∞ÈáèÂèäÂÖ∂ÂèòÂåñË∂ãÂäø„ÄÅÂÖ≥Ê≥®ËÄÖÁöÑÊàêÊú¨ÂàÜÊûê„ÄÅÂÖ≥Ê≥®Âàõ‰ΩúËÄÖÊúÄÂ§öÁöÑÁî®Êà∑Á≠â
- Êî∂ËóèÁöÑÁõ∏ÂÖ≥ÂàÜÊûêÔºöÊØèÊó•Êî∂ËóèÊï∞Èáè„ÄÅÁÉ≠Èó®Êî∂ËóèÁ≠â
- Âàõ‰ΩúËÄÖÁöÑÊî∂ÁõäÂàÜÊûêÔºöÈÄöËøáÂÖ≥Ê≥®‰∫ßÁîüÁöÑÊî∂Áõä„ÄÅÂÖ∂‰ªñÊî∂ÁõäÁ≠â
- ‰ªéNFTÁöÑËßíÂ∫¶ËøõË°åÁõ∏ÂÖ≥ÂàÜÊûêÔºöÊØèÊó•Èì∏ÈÄ†Êï∞Èáè„ÄÅÊ∂âÂèäÁöÑÊàêÊú¨ÔºàÂÖ≥Ê≥®Ë¥πÁî®ÔºâÁ≠â

ÂèØ‰ª•ÂàÜÊûêÁöÑÂÜÖÂÆπÈùûÂ∏∏‰∏∞ÂØå„ÄÇÂú®Ëøô‰∏™ÁúãÊùø‰∏≠ÔºåÊàë‰ª¨‰ªÖ‰ΩøÁî®ÈÉ®ÂàÜÂÜÖÂÆπÂÅöÊ°à‰æã„ÄÇÂÖ∂‰ªñÂÜÖÂÆπËØ∑Â§ßÂÆ∂ÂàÜÂà´ÂéªÂ∞ùËØïÂàÜÊûê„ÄÇ

## Êï∞ÊçÆË°®‰ªãÁªç

Âú®LensÁöÑÂÆòÊñπÊñáÊ°£[Â∑≤ÈÉ®ÁΩ≤ÁöÑÊô∫ËÉΩÂêàÁ∫¶](https://docs.lens.xyz/docs/deployed-contract-addresses)È°µÈù¢ÔºåÊèêÁ§∫‰ΩøÁî®LensHub‰ª£ÁêÜÔºàLensHub ProxyÔºâËøô‰∏™Êô∫ËÉΩÂêàÁ∫¶‰Ωú‰∏∫‰∫§‰∫íÁöÑ‰∏ªË¶ÅÂêàÁ∫¶„ÄÇÈô§‰∫ÜÂ∞ëÈÉ®ÂàÜÂíåNFTÁõ∏ÂÖ≥ÁöÑÊü•ËØ¢ÈúÄË¶ÅÁî®Âà∞Êô∫ËÉΩÂêàÁ∫¶FollowNFT‰∏ãÁöÑÊï∞ÊçÆË°®Â§ñÔºåÊàë‰ª¨Âü∫Êú¨‰∏ä‰∏ªË¶ÅÂÖ≥Ê≥®LensHubËøô‰∏™Êô∫ËÉΩÂêàÁ∫¶‰∏ãÈù¢ÁöÑÂ∑≤Ëß£ÊûêË°®Â∞±ÂèØ‰ª•‰∫Ü„ÄÇ‰∏ãÂõæÂàóÂá∫‰∫ÜËøô‰∏™Êô∫ËÉΩÂêàÁ∫¶‰∏ãÈÉ®ÂàÜÊï∞ÊçÆË°®„ÄÇ

![image_01.png](img/image_01.png)

‰πãÂâçÁöÑÊïôÁ®ãÊèêËøáÔºåÂ∑≤Ëß£ÊûêÁöÑÊô∫ËÉΩÂêàÁ∫¶Êï∞ÊçÆË°®Êúâ‰∏§Â§ßÁ±ªÂûãÔºö‰∫ã‰ª∂Êó•ÂøóË°®(Event Log)ÂíåÂáΩÊï∞Ë∞ÉÁî®Ë°®ÔºàFunction CallÔºâ„ÄÇ‰∏§ÁßçÁ±ªÂûãÁöÑË°®ÂàÜÂà´‰ª•Ôºö`projectname_blockchain.contractName_evt_eventName`ÂíåÔºö`projectname_blockchain.contractName_call_functionName`Ê†ºÂºèÂëΩÂêç„ÄÇÊµèËßàLensHubÂêàÁ∫¶‰∏ãÁöÑË°®Ê†ºÂàóË°®ÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞‰∏ãÈù¢Ëøô‰∫õ‰∏ªË¶ÅÁöÑÊï∞ÊçÆË°®Ôºö
- Êî∂ËóèË°®Ôºàcollect/collectWithSigÔºâ
- ËØÑËÆ∫Ë°®Ôºàcomment/commentWithSigÔºâ
- ‰∏™‰∫∫ËµÑÊñôË°®ÔºàcreateProfileÔºâ
- ÂÖ≥Ê≥®Ë°®Ôºàfollow/followWithSigÔºâ
- ÈïúÂÉèË°®Ôºàmirror/mirrorWithSigÔºâ
- Â∏ñÂ≠êË°®Ôºàpost/postWithSigÔºâ
- Token‰º†ËæìË°®ÔºàTransferÔºâ

Èô§‰∫ÜToken‰º†ËæìË°®ÊòØ‰∫ã‰ª∂Ë°®‰πãÂ§ñÔºå‰∏äËø∞ÂÖ∂‰ªñË°®Ê†ºÈÉΩÊòØÂáΩÊï∞Ë∞ÉÁî®Ë°®„ÄÇÂÖ∂‰∏≠ÂêéÁºÄÂ∏¶Êúâ`WithSig`ÁöÑÊï∞ÊçÆË°®ÔºåË°®Á§∫ÈÄöËøáÁ≠æÂêçÔºàSignatureÔºâÊéàÊùÉÊù•ÊâßË°åÁöÑÊìç‰Ωú„ÄÇÈÄöËøáÁ≠æÂêçÊéàÊùÉÔºåÂèØ‰ª•Êñπ‰æøÂú∞ÈÄöËøáAPIÊàñËÄÖÂÖÅËÆ∏ÂÖ∂‰ªñÊéàÊùÉÊñπ‰ª£Ë°®Êüê‰∏™Áî®Êà∑ÊâßË°åÊüêÈ°πÊìç‰Ωú„ÄÇÂΩìÊàë‰ª¨ÂàÜÊûêÂ∏ñÂ≠êË°®Á≠âÁ±ªÂûãÊó∂ÔºåÈúÄË¶ÅÂ∞ÜÁõ∏ÂÖ≥Ë°®ÈáåÁöÑÊï∞ÊçÆÈõÜÂêàÂà∞‰∏ÄËµ∑ËøõË°åÂàÜÊûê„ÄÇ

Â§ßÂÆ∂ÂèØ‰ª•Âú®ÂàóË°®‰∏≠ÁúãÂà∞ËøòÊúâÂÖ∂‰ªñÂæàÂ§ö‰∏çÂêåÊñπÊ≥ïÁöÑÊï∞ÊçÆË°®ÔºåÁî±‰∫éËøô‰∫õË°®ÂÖ®ÈÉ®ÈÉΩÊòØÂú®LensHubÊô∫ËÉΩÂêàÁ∫¶‰∏ãÁîüÊàêÁöÑÔºåÊâÄ‰ª•‰ªñ‰ª¨‰∫§‰∫íÁöÑcontract_addressÂÖ®ÈÉ®ÈÉΩÊòØLensHubËøô‰∏™Âú∞ÂùÄÔºåÂç≥`0xdb46d1dc155634fbc732f92e853b10b288ad5a1d`„ÄÇÂΩìÊàë‰ª¨Ë¶ÅÂàÜÊûêLensÁöÑÊÄª‰ΩìÁî®Êà∑Êï∞ÊçÆÊó∂ÔºåÂ∫îËØ•‰ΩøÁî®polygon.transactions ÂéüÂßãË°®ÔºåÊü•ËØ¢ÂÖ∂‰∏≠‰∏éËøô‰∏™ÂêàÁ∫¶Âú∞ÂùÄ‰∫§‰∫íÁöÑÊï∞ÊçÆÔºåËøôÊ†∑ÊâçËÉΩÂæóÂà∞ÂÆåÊï¥ÁöÑÊï∞ÊçÆ„ÄÇ

## LensÂçèËÆÆÊ¶ÇËßàÂàÜÊûê

ÈÄöËøáÊü•Áúã[LensHubÊô∫ËÉΩÂêàÁ∫¶ÂàõÂª∫‰∫§ÊòìËØ¶ÊÉÖ](https://polygonscan.com/tx/0xca69b18b7e2daf4695c6d614e263d6aa9bdee44bee91bee7e0e6e5e5e4262fca)ÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ËØ•Êô∫ËÉΩÂêàÁ∫¶ÈÉ®ÁΩ≤‰∏é2022Âπ¥5Êúà16Êó•„ÄÇÂΩìÊàë‰ª¨Êü•ËØ¢`polygon.transactions`ÂéüÂßãË°®ËøôÊ†∑ÁöÑÂéüÂßãÊï∞ÊçÆË°®Êó∂ÔºåÈÄöËøáËÆæÁΩÆÊó•ÊúüÊó∂Èó¥ËøáÊª§Êù°‰ª∂ÔºåÂèØ‰ª•ÊûÅÂ§ßÂú∞ÊèêÈ´òÊü•ËØ¢ÊâßË°åÊÄßËÉΩ„ÄÇ

### ÊÄª‰∫§ÊòìÊï∞ÈáèÂíåÊÄªÁî®Êà∑Êï∞Èáè
Â¶ÇÂâçÊâÄËø∞ÔºåÊúÄÂáÜÁ°ÆÁöÑÊü•ËØ¢Áî®Êà∑Êï∞ÈáèÁöÑÊï∞ÊçÆÊ∫êÊòØ`polygon.transactions`ÂéüÂßãË°®ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Â¶Ç‰∏ãÁöÑqueryÊù•Êü•ËØ¢LensÂΩìÂâçÁöÑ‰∫§ÊòìÊï∞ÈáèÂíåÊÄªÁî®Êà∑Êï∞Èáè„ÄÇÊàë‰ª¨Áõ¥Êé•Êü•ËØ¢ÂèëÈÄÅÁªôLensHubÊô∫ËÉΩÂêàÁ∫¶ÁöÑÂÖ®ÈÉ®‰∫§ÊòìËÆ∞ÂΩïÔºåÈÄöËøá`distinct`ÂÖ≥ÈîÆÂ≠óÊù•ÁªüËÆ°Áã¨Á´ãÁî®Êà∑Âú∞ÂùÄÊï∞Èáè„ÄÇÁî±‰∫éÊàë‰ª¨Â∑≤Áü•ËØ•Êô∫ËÉΩÂêàÁ∫¶ÁöÑÂàõÂª∫Êó•ÊúüÔºåÊâÄ‰ª•Áî®Ëøô‰∏™Êó•Êúü‰Ωú‰∏∫ËøáÊª§Êù°‰ª∂Êù•‰ºòÂåñÊü•ËØ¢ÊÄßËÉΩ„ÄÇ

```sql
select count(*) as transaction_count,
    count(distinct "from") as user_count    -- count unique users
from polygon.transactions
where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
    and block_time >= date('2022-05-16')  -- contract creation date
```

ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÊü•ËØ¢Ôºå‰ΩøÁî®‰∏äÈù¢ÁöÑSQL‰ª£Á†ÅÔºåËøêË°åÊü•ËØ¢ÂæóÂà∞ÁªìÊûúÂêéÔºå‰øùÂ≠òQuery„ÄÇÁÑ∂Âêé‰∏∫ÂÖ∂Ê∑ªÂä†‰∏§‰∏™`Counter`Á±ªÂûãÂà∞ÂèØËßÜÂåñÂõæË°®ÔºåÊ†áÈ¢òÂàÜÂà´ËÆæÁΩÆ‰∏∫‚ÄúLens Total Transactions‚ÄùÂíå‚ÄúLens Total Users‚Äù„ÄÇ

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö[https://dune.com/queries/1533678](https://dune.com/queries/1533678)

Áé∞Âú®Êàë‰ª¨ÂèØ‰ª•Â∞ÜÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø„ÄÇÁî±‰∫éËøôÊòØÊàë‰ª¨ÁöÑÁ¨¨‰∏Ä‰∏™Êü•ËØ¢ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®Ê∑ªÂä†ÂèØËßÜÂåñÂõæË°®Âà∞Êï∞ÊçÆÁúãÊùøÁöÑÂºπÂá∫ÂØπËØùÊ°Ü‰∏≠ÂàõÂª∫Êñ∞ÁöÑÊï∞ÊçÆÁúãÊùø„ÄÇÂàáÊç¢Âà∞Á¨¨‰∏Ä‰∏™CounterÔºåÁÇπÂáª‚ÄúAdd to dashboard‚ÄùÊåâÈíÆÔºåÂú®ÂØπËØùÊ°Ü‰∏≠ÔºåÁÇπÂáªÂ∫ïÈÉ®ÁöÑ‚ÄúNew dashboard‚ÄùÊåâÈíÆÔºåËæìÂÖ•Êï∞ÊçÆÁúãÊùøÁöÑÂêçÁß∞ÂêéÔºåÁÇπÂáª‚ÄúSave dashboard‚ÄùÊåâÈíÆÂàõÂª∫Á©∫ÁôΩÁöÑÊï∞ÊçÆÁúãÊùø„ÄÇÊàëËøôÈáå‰ΩøÁî®‚ÄúLens Protocol Ecosystem Analysis‚Äù‰Ωú‰∏∫ÁúãÊùøÁöÑÂêçÁß∞„ÄÇ‰øùÂ≠ò‰πãÂêéÊàë‰ª¨Â∞±ÂèØ‰ª•Âú®ÂàóË°®‰∏≠ÁúãÂà∞ÂàöÂàõÂª∫ÁöÑÊï∞ÊçÆÁúãÊùøÔºåÁÇπÂáªÂÖ∂Âè≥ËæπÁöÑ‚ÄúAdd‚ÄùÊåâÈíÆÔºåÂ∞±ÂèØ‰ª•Â∞ÜÂΩìÂâçCounterÊ∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÂÖ≥Èó≠ÂØπËØùÊ°ÜÂêéÂàáÊç¢Âà∞Âè¶‰∏Ä‰∏™CounterÔºå‰πüÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞Êñ∞ÂàõÂª∫ÁöÑÊï∞ÊçÆÁúãÊùø„ÄÇ

Ê≠§Êó∂ÔºåÊàë‰ª¨ÂèØ‰ª•ÁÇπÂáªDuneÁΩëÁ´ôÂ§¥ÈÉ®ÁöÑ‚ÄúMy Creations‚ÄùÈìæÊé•ÔºåÂÜçÈÄâÊã©‚ÄúDashboards‚Äù TabÊù•ÂàáÊç¢Âà∞Êï∞ÊçÆÁúãÊùøÂàóË°®„ÄÇÁÇπÂáªÊàë‰ª¨Êñ∞ÂàõÂª∫ÁöÑÁúãÊùøÂêçÁß∞ÔºåËøõÂÖ•ÁúãÊùøÁöÑÈ¢ÑËßàÁïåÈù¢„ÄÇÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÂàöÊâçÊ∑ªÂä†ÁöÑ‰∏§‰∏™CounterÁ±ªÂûãÂèØËßÜÂåñÂõæË°®„ÄÇÂú®ËøôÈáåÔºåÈÄöËøáÁÇπÂáª‚ÄúEdit‚ÄùÊåâÈíÆËøõÂÖ•ÁºñËæëÊ®°ÂºèÔºå‰Ω†ÂèØ‰ª•ÂØπÂõæË°®ÁöÑÂ§ßÂ∞è„ÄÅ‰ΩçÁΩÆÂÅöÁõ∏Â∫îÁöÑË∞ÉÊï¥ÔºåÂèØ‰ª•ÈÄöËøáÁÇπÂáª‚Äú‚ÄùÊåâÈíÆÊù•Ê∑ªÂä†ÊñáÊú¨ÁªÑ‰ª∂ÔºåÂØπÊï∞ÊçÆÁúãÊùøÂÅö‰∏Ä‰∫õËØ¥ÊòéÊàñËÄÖÁæéÂåñ„ÄÇ‰∏ãÂõæÊòØË∞ÉÊï¥ÂêéÁöÑÊï∞ÊçÆÁúãÊùøÁöÑÁïåÈù¢Á§∫‰æã„ÄÇ

![image_02.png](img/image_02.png)

Êàë‰ª¨Êñ∞ÂàõÂª∫ÁöÑÊï∞ÊçÆÁúãÊùøÁöÑÈìæÊé•ÊòØÔºö[Lens Protocol Ecosystem Analysis](https://dune.com/sixdegree/lens-protocol-ecosystem-analysis)

### ÊåâÂ§©ÁªüËÆ°ÁöÑ‰∫§ÊòìÊï∞ÈáèÂíåÁã¨Á´ãÁî®Êà∑Êï∞Èáè

Ë¶ÅÊÉ≥ÂàÜÊûêLensÂçèËÆÆÂú®Ê¥ªË∑ÉÂ∫¶ÊñπÈù¢ÁöÑÂ¢ûÈïøÂèòÂåñË∂ãÂäøÔºåÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™Êü•ËØ¢ÔºåÊåâÊó•ÊúüÊù•ÁªüËÆ°ÊØèÂ§©ÁöÑ‰∫§ÊòìÊï∞ÈáèÂíåÊ¥ªË∑ÉÁî®Êà∑Âú∞ÂùÄÊï∞Èáè„ÄÇÈÄöËøáÂú®Êü•ËØ¢‰∏≠Ê∑ªÂä†`block_time`Â≠óÊÆµÂπ∂‰ΩøÁî®`date_trunc()`ÂáΩÊï∞Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Êó•ÊúüÔºà‰∏çÂê´Êó∂ÂàÜÁßíÊï∞ÂÄºÈÉ®ÂàÜÔºâÔºåÁªìÂêà`group by`Êü•ËØ¢Â≠êÂè•ÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÁªüËÆ°Âá∫ÊØèÂ§©ÁöÑÊï∞ÊçÆ„ÄÇÊü•ËØ¢‰ª£Á†ÅÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö

```sql
select date_trunc('day', block_time) as block_date,
    count(*) as transaction_count,
    count(distinct "from") as user_count
from polygon.transactions
where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
    and block_time >= date('2022-05-16')  -- contract creation date
group by 1
order by 1
```

‰øùÂ≠òÊü•ËØ¢Âπ∂‰∏∫ÂÖ∂Ê∑ªÂä†‰∏§‰∏™`Bar Chart`Á±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®Ôºå`Y column 1`ÂØπÂ∫îÁöÑÂ≠óÊÆµÂàÜÂà´ÈÄâÊã©`transaction_count`Âíå`user_count`ÔºåÂèØËßÜÂåñÂõæË°®ÁöÑÊ†áÈ¢òÂàÜÂà´ËÆæÁΩÆ‰∏∫‚ÄúLens Daily Transactions‚ÄùÂíå‚ÄúLens Daily Users‚Äù„ÄÇÂ∞ÜÂÆÉ‰ª¨ÂàÜÂà´Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_03.png](img/image_03.png)

ÈÄöÂ∏∏Âú®ÊåâÊó•ÊúüÁªüËÆ°Êü•ËØ¢Âà∞Êó∂ÂÄôÔºåÊàë‰ª¨ÂèØ‰ª•ÊåâÊó•ÊúüÂ∞ÜÁõ∏ÂÖ≥Êï∞ÊçÆÊ±áÊÄªÂà∞‰∏ÄËµ∑ÔºåËÆ°ÁÆóÂÖ∂Á¥ØËÆ°ÂÄºÂπ∂Â∞ÜÂÖ∂‰∏éÊØèÊó•Êï∞ÊçÆÊ∑ªÂä†Âà∞Âêå‰∏ÄÂº†ÂèØËßÜÂåñÂõæË°®‰∏≠Ôºå‰ª•‰æøÂØπÊï¥‰ΩìÁöÑÊï∞ÊçÆÂ¢ûÈïøË∂ãÂäøÊúâÊõ¥Áõ¥ËßÇÁöÑËÆ§ËØÜ„ÄÇÈÄöËøá‰ΩøÁî®`sum() over ()`Á™óÂè£ÂáΩÊï∞ÔºåÂèØ‰ª•ÂæàÊñπ‰æøÂú∞ÂÆûÁé∞Ëøô‰∏™ÈúÄÊ±Ç„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÈÄªËæëÁÆÄÂçïÊòìÊáÇÔºåÊàë‰ª¨ÊÄªÊòØÂÄæÂêë‰∫é‰ΩøÁî®CTEÊù•Â∞ÜÂ§çÊùÇÁöÑÊü•ËØ¢ÈÄªËæëÂàÜËß£‰∏∫Â§öÊ≠•„ÄÇÂ∞Ü‰∏äÈù¢ÁöÑÊü•ËØ¢‰øÆÊîπ‰∏∫Ôºö

```sql
with daily_count as (
    select date_trunc('day', block_time) as block_date,
        count(*) as transaction_count,
        count(distinct "from") as user_count
    from polygon.transactions
    where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
        and block_time >= date('2022-05-16')  -- contract creation date
    group by 1
    order by 1
)

select block_date,
    transaction_count,
    user_count,
    sum(transaction_count) over (order by block_date) as accumulate_transaction_count,
    sum(user_count) over (order by block_date) as accumulate_user_count
from daily_count
order by block_date
```

Êü•ËØ¢ÊâßË°åÂÆåÊØïÂêéÔºåÊàë‰ª¨ÂèØ‰ª•Ë∞ÉÊï¥‰πãÂâçÊ∑ªÂä†ÁöÑ‰∏§‰∏™ÂèØËßÜÂåñÂõæË°®„ÄÇÂàÜÂà´Âú®`Y column 2`‰∏ãÈÄâÊã©`accumulate_transaction_count`Âíå`accumulate_user_count`Â∞ÜÂÆÉ‰ª¨‰Ωú‰∏∫Á¨¨‰∫å‰∏™ÊåáÊ†áÂÄºÊ∑ªÂä†Âà∞ÂõæË°®‰∏≠„ÄÇÁî±‰∫éÁ¥ØËÆ°ÂÄºË∑üÊØèÂ§©ÁöÑÊï∞ÂÄºÂæÄÂæÄ‰∏çÂú®Âêå‰∏Ä‰∏™Êï∞ÈáèÁ∫ßÔºåÈªòËÆ§ÁöÑÂõæË°®ÊòæÁ§∫ÊïàÊûúÂπ∂‰∏çÁêÜÊÉ≥„ÄÇÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÈÄâÊã©‚ÄúEnable right y-axis‚ÄùÈÄâÈ°πÔºåÁÑ∂ÂêéÊääÊñ∞Ê∑ªÂä†ÁöÑÁ¨¨‰∫åÂàóËÆæÁΩÆ‰∏∫‰ΩøÁî®Âè≥ÂùêÊ†áËΩ¥ÔºåÂêåÊó∂‰øÆÊîπÂÖ∂‚ÄúChart Type‚Äù‰∏∫‚ÄúArea‚ÄùÔºàÊàñËÄÖ‚ÄúLine‚ÄùÔºå‚ÄúScatter‚ÄùÔºâÔºåËøôÊ†∑Ë∞ÉÊï¥ÂêéÔºåÂõæË°®ÁöÑÊòæÁ§∫ÊïàÊûúÂ∞±ÊØîËæÉÁêÜÊÉ≥‰∫Ü„ÄÇ

‰∏∫‰∫ÜÂ∞ÜÊØèÊó•‰∫§ÊòìÊï∞Èáè‰∏éÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞ÈáèÂÅöÂØπÊØîÔºåÊàë‰ª¨ÂèØ‰ª•ÂÜçÊ∑ªÂä†‰∏Ä‰∏™ÂèØËßÜÂåñÂõæË°®ÔºåÊ†áÈ¢òËÆæÁΩÆ‰∏∫‚ÄúLens Daily Transactions VS Users‚ÄùÔºåÂú®YËΩ¥ÊñπÂêëÂàÜÂà´ÈÄâÊã©transaction_countÂíåuser_countÂàó„ÄÇÂêåÊ†∑ÔºåÂõ†‰∏∫‰∏§È°πÊï∞ÂÄº‰∏çÂú®Âêå‰∏Ä‰∏™Êï∞ÈáèÁ∫ßÔºåÊàë‰ª¨ÂêØÁî®Âè≥‰æßÂùêÊ†áËΩ¥ÔºåÂ∞Üuser_countËÆæÁΩÆ‰∏∫‰ΩøÁî®Âè≥ÂùêÊ†áËΩ¥ÔºåÂõæË°®Á±ªÂûãÈÄâÊã©‚ÄúLine‚Äù„ÄÇ‰πüÂ∞ÜËøô‰∏™ÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø„ÄÇÈÄöËøáÊü•ÁúãËøô‰∏™ÂõæË°®ÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÔºåÂú®2022Âπ¥11ÊúàÂàùÁöÑÂá†Â§©ÈáåÔºåLensÁöÑÊØèÊó•‰∫§ÊòìÈáèÂá∫Áé∞‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÈ´òÂ≥∞Ôºå‰ΩÜÊòØÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞ÈáèÁöÑÂ¢ûÈïøÂàôÊ≤°ÊúâÈÇ£‰πàÊòéÊòæ„ÄÇ

ËøôÈáåÈúÄË¶ÅÈ¢ùÂ§ñËØ¥ÊòéÁöÑÊòØÔºåÂõ†‰∏∫Âêå‰∏Ä‰∏™Áî®Êà∑ÂèØËÉΩ‰∏≠‰∏çÂêåÁöÑÊó•ÊúüÈÉΩÊúâ‰ΩøÁî®LensÔºåÂΩìÊàë‰ª¨Ê±áÊÄªÂ§öÂ§©ÁöÑÊï∞ÊçÆÂà∞‰∏ÄËµ∑Êó∂ÔºåÁ¥ØËÆ°ÂæóÂà∞ÁöÑÁî®Êà∑Êï∞ÈáèÂπ∂‰∏ç‰ª£Ë°®ÂÆûÈôÖÁöÑÁã¨Á´ãÁî®Êà∑ÊÄªÊï∞ÔºåËÄåÊòØ‰ºöÂ§ß‰∫éÂÆûÈôÖÁî®Êà∑ÊÄªÊï∞„ÄÇÂ¶ÇÊûúÈúÄË¶ÅÁªüËÆ°ÊØèÊó•Êñ∞Â¢ûÁöÑÁã¨Á´ãÁî®Êà∑Êï∞ÈáèÂèäÂÖ∂ÊÄªÊï∞ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÂèñÂæóÊØè‰∏™Áî®Êà∑ÊúÄÊó©ÁöÑ‰∫§ÊòìËÆ∞ÂΩïÔºåÁÑ∂ÂêéÂÜçÁî®Áõ∏ÂêåÁöÑÊñπÊ≥ïÊåâÂ§©Ê±áÊÄªÁªüËÆ°„ÄÇÂÖ∑‰ΩìËøôÈáå‰∏çÂÜçÂ±ïÂºÄËØ¥ÊòéÔºåËØ∑Â§ßÂÆ∂Ëá™Ë°åÂ∞ùËØï„ÄÇÂè¶Â§ñÂ¶ÇÊûú‰Ω†ÊÉ≥ÊåâÂë®„ÄÅÊåâÊúàÊù•ÁªüËÆ°ÔºåÂè™ÈúÄForkËøô‰∏™Êü•ËØ¢Ôºå‰øÆÊîπ`date_trunc()`ÂáΩÊï∞ÁöÑÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞‰∏∫‚Äúweek‚ÄùÊàñËÄÖ‚Äúmonth‚ÄùÂç≥ÂèØÂÆûÁé∞„ÄÇ‰Ωú‰∏∫ÂØπÊØîÔºåÊàë‰ª¨ForkÂπ∂‰øÆÊîπ‰∫Ü‰∏Ä‰∏™ÊåâÊúàÁªüËÆ°ÁöÑÊü•ËØ¢ÔºåÂè™Â∞ÜÂÖ∂‰∏≠ÁöÑ‚Äú‚ÄùÂä†Âà∞‰∫ÜÊï∞ÊçÆÁúãÊùø‰∏≠„ÄÇ

Ë∞ÉÊï¥ÂÆåÊàêÂêéÔºåÊï∞ÊçÆÁúãÊùø‰∏≠ÁöÑÂõæË°®‰ºöËá™Âä®Êõ¥Êñ∞‰∏∫ÊúÄÊñ∞ÁöÑÊòæÁ§∫ÁªìÊûúÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ

![image_04.png](img/image_04.png)

‰ª•‰∏ä‰∏§‰∏™Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1534604](https://dune.com/queries/1534604)
- [https://dune.com/queries/1534774](https://dune.com/queries/1534774)

## Âàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôÔºàProfileÔºâÊï∞ÊçÆÂàÜÊûê

LensÁöÑÂàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôË¥¶Âè∑ÁõÆÂâç‰ªÖÈôê‰∫éËÆ∏ÂèØÁôΩÂêçÂçïÂÜÖÁöÑÁî®Êà∑Êù•ÂàõÂª∫ÔºåÂàõÂª∫‰∏™‰∫∫ËµÑÊñôÁöÑÊï∞ÊçÆ‰øùÂ≠òÂú®`createProfile`Ë°®‰∏≠„ÄÇÁî®‰∏ãÈù¢ÁöÑÊü•ËØ¢ÔºåÊàë‰ª¨ÂèØ‰ª•ËÆ°ÁÆóÂá∫ÂΩìÂâçÂ∑≤ÁªèÂàõÂª∫ÁöÑ‰∏™‰∫∫ËµÑÊñôÁöÑÊï∞Èáè„ÄÇ

```sql
select count(*) as profile_count
from lens_polygon.LensHub_call_createProfile
where call_success = true   -- Only count success calls
```

ÂàõÂª∫‰∏Ä‰∏™CounterÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®ÔºåTitleËÆæÁΩÆ‰∏∫‚ÄúTotal Profiles‚ÄùÔºåÂ∞ÜÂÖ∂Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇ

Êàë‰ª¨ÂêåÊ†∑ÂÖ≥ÂøÉÂàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôÈöèÊó•ÊúüÁöÑÂèòÂåñÂíåÂ¢ûÈïøÊÉÖÂÜµ„ÄÇÁî®‰∏ãÈù¢ÁöÑÊü•ËØ¢ÂèØ‰ª•ÁªüËÆ°Âá∫ÊØèÊó•„ÄÅÊØèÊúàÁöÑ‰∏™‰∫∫ËµÑÊñôÂàõÂª∫ÊÉÖÂÜµ„ÄÇ

```sql
with daily_profile_count as (
    select date_trunc('day', call_block_time) as block_date,
        count(*) as profile_count
    from lens_polygon.LensHub_call_createProfile
    where call_success = true
    group by 1
    order by 1
)

select block_date,
    profile_count,
    sum(profile_count) over (order by block_date) as accumulate_profile_count
from daily_profile_count
order by block_date
```

Áî®Á±ª‰ººÁöÑÊñπÊ≥ïÂàõÂª∫Âπ∂Ê∑ªÂä†ÂèØËßÜÂåñÂõæË°®Âà∞Êï∞ÊçÆÁúãÊùø„ÄÇÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_05.png](img/image_05.png)

‰ª•‰∏ä‰∏§‰∏™Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1534486](https://dune.com/queries/1534486)
- [https://dune.com/queries/1534927](https://dune.com/queries/1534927)
- [https://dune.com/queries/1534950](https://dune.com/queries/1534950)

## Âàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôÂüüÂêçÂàÜÊûê

LensËá¥Âäõ‰∫éÊâìÈÄ†‰∏Ä‰∏™Á§æ‰∫§ÂõæË∞±ÁîüÊÄÅÁ≥ªÁªüÔºåÊØè‰∏™Âàõ‰ΩúËÄÖÂèØ‰ª•ÁªôËá™Â∑±ÁöÑË¥¶Âè∑ËÆæÁΩÆ‰∏Ä‰∏™‰∏™ÊÄßÂåñÁöÑÂêçÁß∞ÔºàProfile Handle NameÔºâÔºåËøô‰πüÊòØÈÄöÂ∏∏Â§ßÂÆ∂ËØ¥ÁöÑLensÂüüÂêç„ÄÇ‰∏éENSÁ≠âÂÖ∂‰ªñÂüüÂêçÁ≥ªÁªüÁ±ª‰ººÔºåÊàë‰ª¨‰ºöÂÖ≥Ê≥®‰∏Ä‰∫õÁü≠ÂüüÂêç„ÄÅÁ∫ØÊï∞Â≠óÂüüÂêçÁ≠âÁöÑÊ≥®ÂÜåÊÉÖÂÜµ„ÄÅ‰∏çÂêåÂ≠óÁ¨¶ÈïøÂ∫¶ÁöÑÂüüÂêçÂ∑≤Ê≥®ÂÜåÊï∞ÈáèÁ≠â‰ø°ÊÅØ„ÄÇÂú®`createProfile`Ë°®‰∏≠ÔºåÂ≠óÊÆµ`vars`‰ª•Â≠óÁ¨¶‰∏≤Ê†ºÂºè‰øùÂ≠ò‰∫Ü‰∏Ä‰∏™jsonÂØπË±°ÔºåÈáåÈù¢Â∞±ÂåÖÊã¨‰∫ÜÁî®Êà∑ÁöÑ‰∏™ÊÄßÂåñÂüüÂêç„ÄÇÂú®Dune V2‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®`:`Á¨¶Âè∑Êù•ËÆøÈóÆjsonÂ≠óÁ¨¶‰∏≤‰∏≠ÁöÑÂÖÉÁ¥†ÁöÑÂÄºÔºå‰æãÂ¶ÇÁî®`vars:handle`Ëé∑ÂèñÂüüÂêç‰ø°ÊÅØ„ÄÇ

‰ΩøÁî®‰∏ãÈù¢ÁöÑSQLÔºåÊàë‰ª¨ÂèØ‰ª•Ëé∑ÂèñÂ∑≤Ê≥®ÂÜåLensÂüüÂêçÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºö
```sql
select json_value(vars, 'lax $.to') as user_address,
    json_value(vars, 'lax $.handle')  as handle_name,
    replace(json_value(vars, 'lax $.handle') , '.lens', '') as short_handle_name,
    call_block_time,
    output_0 as profile_id,
    call_tx_hash
from lens_polygon.LensHub_call_createProfile
where call_success = true
```

‰∏∫‰∫ÜÁªüËÆ°‰∏çÂêåÈïøÂ∫¶„ÄÅ‰∏çÂêåÁ±ªÂûãÔºàÁ∫ØÊï∞Â≠ó„ÄÅÁ∫ØÂ≠óÊØç„ÄÅÊ∑∑ÂêàÔºâLensÂüüÂêçÁöÑÊï∞Èáè‰ª•ÂèäÂêÑÁ±ªÂûã‰∏ãÂ∑≤Ê≥®ÂÜåÂüüÂêçÁöÑÊÄªÊï∞ÈáèÔºåÊàë‰ª¨ÂèØ‰ª•Â∞Ü‰∏äÈù¢ÁöÑÊü•ËØ¢ÊîæÂà∞‰∏Ä‰∏™CTE‰∏≠„ÄÇ‰ΩøÁî®CTEÁöÑÂ•ΩÂ§ÑÊòØÂèØ‰ª•ÁÆÄÂåñÈÄªËæëÔºà‰Ω†ÂèØ‰ª•ÊåâÈ°∫Â∫èÂàÜÂà´Ë∞ÉËØï„ÄÅÊµãËØïÊØè‰∏Ä‰∏™CTEÔºâ„ÄÇÂêåÊó∂ÔºåCTE‰∏ÄÁªèÂÆö‰πâÔºåÂ∞±ÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Êü•ËØ¢ÁöÑÂêéÁª≠SQLËÑöÊú¨‰∏≠Â§öÊ¨°‰ΩøÁî®ÔºåÈùûÂ∏∏‰æøÊç∑„ÄÇÈâ¥‰∫éÊü•ËØ¢ÂêÑÁ±ªÂüüÂêçÁöÑÂ∑≤Ê≥®ÂÜåÊÄªÊï∞ÈáèÂíåÂØπÂ∫î‰∏çÂêåÂ≠óÁ¨¶ÈïøÂ∫¶ÁöÑÂ∑≤Ê≥®ÂÜåÊï∞ÈáèÈÉΩÂü∫‰∫é‰∏äÈù¢ÁöÑÊü•ËØ¢ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Êü•ËØ¢‰∏≠Â∞ÜÂÆÉ‰ª¨ÊîæÂà∞‰∏ÄËµ∑„ÄÇÂõ†‰∏∫ÂâçËø∞ÁªüËÆ°ÈÉΩÈúÄË¶ÅÂå∫ÂàÜÂüüÂêçÁ±ªÂûãÔºåÊàë‰ª¨Âú®Ëøô‰∏™Êü•ËØ¢‰∏≠Â¢ûÂä†‰∫Ü‰∏Ä‰∏™Â≠óÊÆµ`handle_type`Êù•‰ª£Ë°®ÂüüÂêçÁöÑÁ±ªÂûã„ÄÇ‰øÆÊîπÂêéÁöÑÊü•ËØ¢‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        (case when regexp_like(replace(json_value(vars, 'lax $.handle'), '.lens', ''), '^[0-9]+$') then 'Pure Digits'
            when regexp_like(replace(json_value(vars, 'lax $.handle'), '.lens', ''), '^[a-z]+$') then 'Pure Letters'
            else 'Mixed'
        end) as handle_type,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
),

profiles_summary as (
    select (case when length(short_name) >= 20 then 20 else length(short_name) end) as name_length,
        handle_type,
        count(*) as name_count
    from profile_created
    group by 1, 2
),

profiles_total as (
    select count(*) as total_profile_count,
        sum(case when handle_type = 'Pure Digits' then 1 else 0 end) as pure_digit_profile_count,
        sum(case when handle_type = 'Pure Letters' then 1 else 0 end) as pure_letter_profile_count
    from profile_created
)

select cast(name_length as varchar) || ' Chars' as name_length_type,
    handle_type,
    name_count,
    total_profile_count,
    pure_digit_profile_count,
    pure_letter_profile_count
from profiles_summary
join profiles_total on true
order by handle_type, name_length
```

‰øÆÊîπÂêéÁöÑÊü•ËØ¢‰ª£Á†ÅÁõ∏ÂØπÊØîËæÉÂ§çÊùÇÔºåËß£ËØªÂ¶Ç‰∏ãÔºö
1. CTE `profile_created`ÈÄöËøá‰ΩøÁî®‚Äú:‚ÄúÁ¨¶Âè∑Êù•‰ªé‰øùÂ≠ò‰∫é`vars`Â≠óÊÆµ‰∏≠ÁöÑjsonÂ≠óÁ¨¶‰∏≤ÈáåÈù¢ÊèêÂèñÂá∫ProfileÁöÑÂüüÂêç‰ø°ÊÅØÂíåÂüüÂêçÂΩíÂ±ûÁöÑÁî®Êà∑Âú∞ÂùÄ„ÄÇÁî±‰∫é‰øùÂ≠òÁöÑÂüüÂêçÂåÖÊã¨‰∫Ü`.lens`ÁöÑÂêéÁºÄÔºåÊàë‰ª¨ÈÄöËøá`replace()`ÊñπÊ≥ïÂ∞ÜÂêéÁºÄÈÉ®ÂàÜÊ∏ÖÈô§Âπ∂ÂëΩÂêçÊñ∞ÁöÑÂ≠óÊÆµ‰∏∫`short_name`ÔºåÊñπ‰æøÂêéÈù¢ËÆ°ÁÆóÂüüÂêçÁöÑÂ≠óÁ¨¶ÈïøÂ∫¶„ÄÇËøõ‰∏ÄÊ≠•ÔºåÊàë‰ª¨ÈÄöËøá‰∏Ä‰∏™CASEËØ≠Âè•ÔºåÁªìÂêàÊ≠£ÂàôË°®ËææÂºèÂåπÈÖçÊìç‰ΩúÁ¨¶`rlike`Êù•Âà§Êñ≠ÂüüÂêçÊòØÂê¶Áî±Á∫ØÊï∞Â≠óÊàñËÄÖÁ∫ØÂ≠óÊØçÁªÑÊàêÔºåÂπ∂Ëµã‰∫à‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤ÂêçÁß∞ÂÄºÔºåÂëΩÂêçÊ≠§Â≠óÊÆµ‰∏∫`handle_type`„ÄÇÂèØÂèÇËÄÉ[rlike operator](https://docs.databricks.com/sql/language-manual/functions/rlike.html)‰∫ÜËß£Ê≠£ÂàôË°®ËææÂºèÂåπÈÖçÁöÑÊõ¥Â§ö‰ø°ÊÅØ„ÄÇ
2. CTE `profiles_summary`Âü∫‰∫é`profile_created`ÊâßË°åÊ±áÊÄªÊü•ËØ¢„ÄÇÊàë‰ª¨È¶ñÂÖà‰ΩøÁî®`length()`ÂáΩÊï∞ËÆ°ÁÆóÂá∫ÊØè‰∏Ä‰∏™ÂüüÂêçÁöÑÂ≠óÁ¨¶ÈïøÂ∫¶„ÄÇÂõ†‰∏∫Â≠òÂú®Â∞ëÈáèÁâπÂà´ÈïøÁöÑÂüüÂêçÔºåÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™CASEËØ≠Âè•ÔºåÂ∞ÜÈïøÂ∫¶Â§ß‰∫é20‰∏™Â≠óÁ¨¶ÁöÑÂüüÂêçÁªü‰∏ÄÊåâ20Êù•ÂØπÂæÖ„ÄÇÁÑ∂ÂêéÊàë‰ª¨Âü∫‰∫éÂüüÂêçÈïøÂ∫¶`name_length`Âíå`handle_type`ÊâßË°å`group by`Ê±áÊÄªÁªüËÆ°ÔºåËÆ°ÁÆóÂêÑÁßçÂüüÂêçÁöÑÊï∞Èáè„ÄÇ
3. CTE `profiles_total`‰∏≠ÔºåÊàë‰ª¨ÁªüËÆ°ÂüüÂêçÊÄªÊï∞Èáè„ÄÅÁ∫ØÊï∞Â≠óÂüüÂêçÁöÑÊï∞ÈáèÂíåÁ∫ØÂ≠óÊØçÂüüÂêçÁöÑÊï∞Èáè„ÄÇ
4. ÊúÄÂêéÔºåÊàë‰ª¨Â∞Ü`profiles_summary`Âíå`profiles_total`Ëøô‰∏§‰∏™CTEÂÖ≥ËÅîÂà∞‰∏ÄËµ∑ËæìÂá∫ÊúÄÁªàÊü•ËØ¢ÁªìÊûú„ÄÇÁî±‰∫é`profiles_total`Âè™Êúâ‰∏ÄË°åÊï∞ÊçÆÔºåÊàë‰ª¨Áõ¥Êé•‰ΩøÁî®`true`‰Ωú‰∏∫JOINÁöÑÊù°‰ª∂Âç≥ÂèØ„ÄÇÂè¶Â§ñÔºåÂõ†‰∏∫`name_length`ÊòØÊï∞ÂÄºÁ±ªÂûãÔºåÊàë‰ª¨Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºåÂπ∂ËøûÊé•Âà∞Âè¶‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Êù•ÂæóÂà∞ÂèØËØªÊÄßÊõ¥Âº∫ÁöÑÂüüÂêçÈïøÂ∫¶Á±ªÂûãÂêçÁß∞„ÄÇÊàë‰ª¨Â∞ÜËæìÂá∫ÁªìÊûúÊåâÂüüÂêçÁ±ªÂûãÂíåÈïøÂ∫¶ËøõË°åÊéíÂ∫è„ÄÇ

ÊâßË°åÊü•ËØ¢Âπ∂‰øùÂ≠ò‰πãÂêéÔºåÊàë‰ª¨‰∏∫ÂÖ∂Ê∑ªÂä†‰∏ãÂàóÂèØËßÜÂåñÂõæË°®Âπ∂ÂàÜÂà´Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠Ôºö
1. Ê∑ªÂä†‰∏§‰∏™CounterÔºåÂàÜÂà´ËæìÂá∫Á∫ØÊï∞Â≠óÂüüÂêçÁöÑÊï∞ÈáèÂíåÁ∫ØÂ≠óÊØçÂüüÂêçÁöÑÊï∞Èáè„ÄÇÂõ†‰∏∫‰πãÂâçÂ∑≤ÁªèÊúâ‰∏Ä‰∏™ÂüüÂêçÊ≥®ÂÜåÊÄªÊï∞ÈáèÁöÑCounterÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜËøô‰∏§‰∏™Êñ∞ÁöÑCounterÂõæË°®Ë∑üÂÆÉÊîæÁΩÆÂà∞Âêå‰∏ÄË°å„ÄÇ
2. Ê∑ªÂä†‰∏Ä‰∏™ÂüüÂêçÁ±ªÂûãÂàÜÂ∏ÉÁöÑÊâáÂΩ¢ÂõæÔºàPie ChartÔºâÔºåTitleËÆæÁΩÆ‰∏∫‚ÄúProfiles Handle Name Type Distribution‚ÄùÔºå‚ÄúX Column‚ÄúÈÄâÊã©`handle_type`Â≠óÊÆµÔºå‚ÄúY Column 1‚ÄùÈÄâÊã©`name_count`Â≠óÊÆµ„ÄÇ
3. Ê∑ªÂä†‰∏Ä‰∏™ÂüüÂêçÈïøÂ∫¶ÂàÜÂ∏ÉÁöÑÊâáÂΩ¢ÂõæÔºàPie ChartÔºâÔºåTitleËÆæÁΩÆ‰∏∫‚ÄúProfiles Handle Name Length Distribution‚ÄùÔºå‚ÄúX Column‚ÄúÈÄâÊã©`name_length_type`Â≠óÊÆµÔºå‚ÄúY Column 1‚ÄùÈÄâÊã©`name_count`Â≠óÊÆµ„ÄÇ
4. Ê∑ªÂä†‰∏Ä‰∏™ÂüüÂêçÈïøÂ∫¶ÂàÜÂ∏ÉÁöÑÊü±Áä∂ÂõæÔºàBar ChartÔºâÔºåTitleËÆæÁΩÆ‰∏∫‚ÄúProfiles Handle Name Count By Length‚ÄùÔºå‚ÄúX Column‚ÄúÈÄâÊã©`name_length_type`Â≠óÊÆµÔºå‚ÄúY Column 1‚ÄùÈÄâÊã©`name_count`Â≠óÊÆµÔºå‚ÄúGroup by‚ÄùÈÄâÊã©`handle_type`Â≠óÊÆµ„ÄÇÂêåÊó∂ÂèñÊ∂àÂãæÈÄâ‚ÄúSort values‚ÄùÈÄâÈ°πÔºåÂÜçÂãæÈÄâ‚ÄúEnable stacking‚ÄùÈÄâÈ°π„ÄÇ
5. Ê∑ªÂä†‰∏Ä‰∏™ÂüüÂêçÈïøÂ∫¶ÂàÜÂ∏ÉÁöÑÈù¢ÁßØÂõæÔºàArea ChartÔºâÔºåTitleËÆæÁΩÆ‰∏∫‚ÄúProfile Handle Name Count Percentage By Type‚ÄùÔºå‚ÄúX Column‚ÄúÈÄâÊã©`name_length_type`Â≠óÊÆµÔºå‚ÄúY Column 1‚ÄùÈÄâÊã©`name_count`Â≠óÊÆµÔºå‚ÄúGroup by‚ÄùÈÄâÊã©`handle_type`Â≠óÊÆµ„ÄÇÂèñÊ∂àÂãæÈÄâ‚ÄúSort values‚ÄùÈÄâÈ°πÔºåÂÜçÂãæÈÄâ‚ÄúEnable stacking‚ÄùÈÄâÈ°πÔºåÂè¶Â§ñÂÜçÂãæÈÄâ‚ÄúNormalize to percentage‚ÄùÈÄâÈ°π„ÄÇ

Â∞Ü‰∏äËø∞ÂèØËßÜÂåñÂõæË°®ÂÖ®ÈÉ®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠ÔºåË∞ÉÊï¥ÊòæÁ§∫È°∫Â∫èÂêéÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_06.png](img/image_06.png)

Êú¨Êü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1535541](https://dune.com/queries/1535541)

## Â∑≤Ê≥®ÂÜåÂüüÂêçÊêúÁ¥¢

Èô§‰∫ÜÂØπÂ∑≤Ê≥®ÂÜåLensÂüüÂêçÁöÑÂàÜÂ∏ÉÊÉÖÂÜµÁöÑË∑üË∏™ÔºåÁî®Êà∑‰πüÂÖ≥Ê≥®Â∑≤Ê≥®ÂÜåÂüüÂêçÁöÑËØ¶ÁªÜÊÉÖÂÜµ„ÄÇ‰∏∫Ê≠§ÔºåÂèØ‰ª•Êèê‰æõ‰∏Ä‰∏™ÊêúÁ¥¢ÂäüËÉΩÔºåÂÖÅËÆ∏Áî®Êà∑ÊêúÁ¥¢Â∑≤Ê≥®ÂÜåÂüüÂêçÁöÑËØ¶ÁªÜÂàóË°®„ÄÇÂõ†‰∏∫ÁõÆÂâçÂ∑≤ÁªèÊ≥®ÂÜå‰∫ÜÁ∫¶10‰∏á‰∏™LensË¥¶Âè∑ÔºåÊàë‰ª¨Âú®‰∏ãÈù¢ÁöÑÊü•ËØ¢‰∏≠ÈôêÂà∂ÊúÄÂ§öËøîÂõû10000Êù°ÊêúÁ¥¢ÁªìÊûú„ÄÇ

È¶ñÂÖàÔºåÊàë‰ª¨ÂèØ‰ª•Âú®Êü•ËØ¢‰∏≠ÂÆö‰πâ‰∏Ä‰∏™ÂèÇÊï∞`{{name_contains}}`ÔºàDune ‰ΩøÁî®‰∏§‰∏™Ëä±Êã¨Âè∑ÂåÖÂõ¥‰ΩèÂèÇÊï∞ÂêçÁß∞ÔºåÈªòËÆ§ÂèÇÊï∞Á±ªÂûã‰∏∫Â≠óÁ¨¶‰∏≤`Text`Á±ªÂûãÔºâ„ÄÇÁÑ∂Âêé‰ΩøÁî®`like`ÂÖ≥ÈîÆËØç‰ª•Âèä`%`ÈÄöÈÖçÁ¨¶Êù•ÊêúÁ¥¢ÂêçÁß∞‰∏≠ÂåÖÂê´ÁâπÂÆöÂ≠óÁ¨¶ÁöÑÂüüÂêçÔºö

```sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
)

select call_block_time,
    profile_id,
    handle_name,
    short_name,
    call_tx_hash
from profile_created
where short_name like '%{{name_contains}}%' -- Êü•ËØ¢ÂêçÁß∞ÂåÖÂê´ËæìÂÖ•ÁöÑÂ≠óÁ¨¶‰∏≤ÁöÑÂüüÂêç
order by call_block_time desc
limit 1000
```

Âú®Êü•ËØ¢ÊâßË°å‰πãÂâçÔºåDune ÂºïÊìé‰ºöÁî®ËæìÂÖ•ÁöÑÂèÇÊï∞ÂÄºÊõøÊç¢SQLËØ≠Âè•‰∏≠ÁöÑÂèÇÊï∞ÂêçÁß∞„ÄÇÂΩìÊàë‰ª¨ËæìÂÖ•‚Äújohn‚ÄùÊó∂Ôºå`where short_name like '%{{name_contains}}%'`Â≠êÂè•‰ºöË¢´ÊõøÊç¢‰∏∫`where short_name like '%john%'`ÔºåÂÖ∂Âê´‰πâÂ∞±ÊòØÊêúÁ¥¢`short_name`ÂåÖÂê´Â≠óÁ¨¶‰∏≤`john`ÁöÑÊâÄÊúâÂüüÂêç„ÄÇÊ≥®ÊÑèËôΩÁÑ∂ÂèÇÊï∞Á±ªÂûãÊòØÂ≠óÁ¨¶‰∏≤Á±ªÂûãÔºå‰ΩÜÊòØÂèÇÊï∞ÊõøÊç¢Êó∂‰∏ç‰ºöÂ≠óÊÆµÁªôÊàë‰ª¨Ê∑ªÂä†ÂâçÂêéÁöÑÂçïÂºïÂè∑„ÄÇÂçïÂºïÂè∑ÈúÄË¶ÅÊàë‰ª¨Áõ¥Êé•ËæìÂÖ•Âà∞Êü•ËØ¢‰∏≠ÔºåÂ¶ÇÊûúÂøòËÆ∞ËæìÂÖ•‰∫ÜÂàô‰ºöÂºïËµ∑ËØ≠Ê≥ïÈîôËØØ„ÄÇ

Â¶ÇÂâçÊâÄËø∞ÔºåÂüüÂêçÁöÑÈïøÂ∫¶‰πüÂæàÂÖ≥ÈîÆÔºåË∂äÁü≠ÁöÑÂüüÂêçË∂äÁ®ÄÁº∫„ÄÇÈô§‰∫ÜÊêúÁ¥¢ÂüüÂêçÂåÖÂê´ÁöÑÂ≠óÁ¨¶ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÜçÊ∑ªÂä†‰∏Ä‰∏™ÂüüÂêçÈïøÂ∫¶ËøáÊª§ÁöÑÂèÇÊï∞`{{name_length}}`ÔºåÂ∞ÜÂÖ∂ÂèÇÊï∞Á±ªÂûã‰øÆÊîπ‰∏∫‰∏ãÊãâÂàóË°®Á±ªÂûãÔºåÂêåÊó∂Â°´ÂÖ•Êï∞Â≠ó5-20ÁöÑÂ∫èÂàó‰Ωú‰∏∫ÂèÇÊï∞ÂÄºÂàóË°®ÔºåÊØèË°å‰∏Ä‰∏™ÂÄº„ÄÇÂõ†‰∏∫LensÂüüÂêçÁõÆÂâçÊúÄÂ∞ë5‰∏™Â≠óÁ¨¶ÔºåËÄå‰∏îË∂ÖËøá20‰∏™Â≠óÁ¨¶ÁöÑÂüüÂêçÂæàÂ∞ëÔºåÊâÄ‰ª•Êàë‰ª¨ÈÄâÊã©5Âà∞20‰Ωú‰∏∫Âå∫Èó¥„ÄÇÂèÇÊï∞ËÆæÁΩÆÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ

![image_08.png](img/image_08.png)

Ê∑ªÂä†‰∫ÜÊñ∞ÁöÑÂèÇÊï∞ÂêéÔºåÊàë‰ª¨Ë∞ÉÊï¥SQLËØ≠Âè•ÁöÑWHEREÂ≠êÂè•‰∏∫Â¶Ç‰∏ãÊâÄÁ§∫„ÄÇÂÖ∂Âê´‰πâ‰∏∫Êü•ËØ¢ÂêçÁß∞ÂåÖÂê´ËæìÂÖ•ÁöÑÂÖ≥ÈîÆÂ≠óÔºåÂêåÊó∂ÂüüÂêçÂ≠óÁ¨¶ÈïøÂ∫¶Á≠â‰∫éÈÄâÊã©ÁöÑÈïøÂ∫¶ÂÄºÁöÑÂüüÂêçÂàóË°®„ÄÇÊ≥®ÊÑèÔºåËôΩÁÑ∂Êàë‰ª¨ÁöÑ`name_length`ÂèÇÊï∞ÁöÑÂÄºÂÖ®ÈÉ®ÊòØÊï∞Â≠óÔºå‰ΩÜListÁ±ªÂûãÂèÇÊï∞ÁöÑÈªòËÆ§Á±ªÂûãÊòØÂ≠óÁ¨¶‰∏≤ÔºåÊâÄ‰ª•Êàë‰ª¨‰ΩøÁî®`cast()`ÂáΩÊï∞ËΩ¨Êç¢ÂÖ∂Á±ªÂûã‰∏∫Êï¥Êï∞Á±ªÂûãÂêéÂÜçËøõË°åÊØîËæÉ„ÄÇ

```sql
where short_name like '%{{name_contains}}%' -- ÂêçÁß∞ÂåÖÂê´ËæìÂÖ•ÁöÑÂ≠óÁ¨¶‰∏≤ÁöÑÂüüÂêç
    and length(short_name) = cast('{{name_length}}' as integer) -- ÂüüÂêçÈïøÂ∫¶Á≠â‰∫éÈÄâÊã©ÁöÑÈïøÂ∫¶ÂÄº
```

ÂêåÊ†∑ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÜçÊ∑ªÂä†‰∏Ä‰∏™ÂüüÂêçÂ≠óÁ¨¶‰∏≤Ê®°ÂºèÁ±ªÂûãÁöÑÂèÇÊï∞`{{name_pattern}}`ÔºåÁî®Êù•ËøáÊª§Á∫ØÊï∞Â≠óÂüüÂêçÊàñÁ∫ØÂ≠óÊØçÂüüÂêç„ÄÇËøôÈáåÂêåÊ†∑ËÆæÁΩÆÂèÇÊï∞‰∏∫ListÁ±ªÂûãÔºåÂàóË°®ÂåÖÊã¨‰∏â‰∏™ÈÄâÈ°πÔºöAny„ÄÅPure Digits„ÄÅPure Letters„ÄÇSQLËØ≠Âè•ÁöÑWHEREÂ≠êÂè•Áõ∏Â∫î‰øÆÊîπ‰∏∫Â¶Ç‰∏ãÊâÄÁ§∫„ÄÇË∑ü‰πãÂâçÁöÑÊü•ËØ¢Á±ª‰ººÔºåÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™CASEËØ≠Âè•Êù•Âà§Êñ≠ÂΩìÂâçÊü•ËØ¢ÂüüÂêçÁöÑÁ±ªÂûãÔºåÂ¶ÇÊûúÊü•ËØ¢Á∫ØÊï∞Â≠óÊàñËÄÖÁ∫ØÂ≠óÊØçÂüüÂêçÔºåÂàô‰ΩøÁî®Áõ∏Â∫îÁöÑË°®ËææÂºèÔºåÂ¶ÇÊûúÊü•ËØ¢‰ªªÊÑèÊ®°ÂºèÂàô‰ΩøÁî®` 1 = 1 `ËøôÊ†∑ÁöÑÊÄªÊòØËøîÂõûÁúüÂÄºÁöÑÁõ∏Á≠âÂà§Êñ≠ÔºåÁõ∏ÂΩì‰∫éÂøΩÁï•Ëøô‰∏™ËøáÊª§Êù°‰ª∂„ÄÇ

```sql
where short_name like '%{{name_contains}}%' -- ÂêçÁß∞ÂåÖÂê´ËæìÂÖ•ÁöÑÂ≠óÁ¨¶‰∏≤ÁöÑÂüüÂêç
    and length(short_name) = cast('{{name_length}}' as integer) -- ÂüüÂêçÈïøÂ∫¶Á≠â‰∫éÈÄâÊã©ÁöÑÈïøÂ∫¶ÂÄº
    and (case when '{{name_pattern}}' = 'Pure Digits' then regexp_like(short_name, '^[0-9]+$')
            when '{{name_pattern}}' = 'Pure Letters' then regexp_like(short_name, '^[a-z]+$')
            else 1 = 1
        end)
```

Âõ†‰∏∫Êàë‰ª¨Âú®ËøôÂá†‰∏™ÊêúÁ¥¢Êù°‰ª∂‰πãÈó¥‰ΩøÁî®‰∫Ü`and`ËøûÊé•Êù°‰ª∂ÔºåÁõ∏ÂΩì‰∫éÂøÖÈ°ªÂêåÊó∂Êª°Ë∂≥ÊâÄÊúâÊù°‰ª∂ÔºåËøôÊ†∑ÁöÑÊêúÁ¥¢Êúâ‰∏ÄÂÆöÁöÑÂ±ÄÈôêÊÄß„ÄÇÊàë‰ª¨ÂØπÂÖ∂ÂÅöÈÄÇÂΩìË∞ÉÊï¥Ôºåname_lengthÂèÇÊï∞‰πüÂÜçÂ¢ûÂä†‰∏Ä‰∏™ÈªòËÆ§ÈÄâÈ°π‚Äú0‚Äù„ÄÇÂΩìÁî®Êà∑Êú™ËæìÂÖ•ÊàñËÄÖÊú™ÈÄâÊã©Êüê‰∏™ËøáÊª§Êù°‰ª∂Êó∂ÔºåÊàë‰ª¨ÂøΩÁï•ÂÆÉ„ÄÇËøôÊ†∑ÊêúÁ¥¢Êü•ËØ¢Â∞±ÂèòÂæóÈùûÂ∏∏ÁÅµÊ¥ª‰∫Ü„ÄÇÂÆåÊï¥ÁöÑSQLËØ≠Âè•Â¶Ç‰∏ãÔºö

```sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
)

select call_block_time,
    profile_id,
    handle_name,
    short_name,
    '<a href=https://polygonscan.com/tx/' || cast(call_tx_hash as varchar) || ' target=_blank>Polyscan</a>' as link,
    call_tx_hash
from profile_created
where (case when '{{name_contains}}' <> 'keyword' then short_name like '%{{name_contains}}%' else 1 = 1 end)
    and (case when cast('{{name_length}}' as integer) < 5 then 2 = 2
            when cast('{{name_length}}' as integer) >= 20 then length(short_name) >= 20
            else length(short_name) = cast('{{name_length}}' as integer)
        end)
    and (case when '{{name_pattern}}' = 'Pure Digits' then regexp_like(short_name, '^[0-9]+$')
            when '{{name_pattern}}' = 'Pure Letters' then regexp_like(short_name, '^[a-z]+$')
            else 3 = 3
        end)
order by call_block_time desc
limit 1000
```

Êàë‰ª¨ÁªôËøô‰∏™Êü•ËØ¢Â¢ûÂä†‰∏Ä‰∏™Ë°®Ê†ºÔºàTableÔºâÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®ÔºåÂπ∂Â∞ÜÂÖ∂Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÂΩìÊ∑ªÂä†‰ª£ÂèÇÊï∞ÁöÑÊü•ËØ¢Âà∞Êï∞ÊçÆÁúãÊùøÊó∂ÔºåÊâÄÊúâÁöÑÂèÇÊï∞‰πüË¢´Ëá™Âä®Ê∑ªÂä†Âà∞ÁúãÊùøÂ§¥ÈÉ®„ÄÇÊàë‰ª¨ÂèØ‰ª•ËøõÂÖ•ÁºñËæëÊ®°ÂºèÔºåÊãñÊãΩÂèÇÊï∞Âà∞ÂÖ∂Â∏åÊúõÂá∫Áé∞ÁöÑ‰ΩçÁΩÆ„ÄÇÂ∞ÜÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊïàÊûúÂõæÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇ

![image_07.png](img/image_07.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1535903](https://dune.com/queries/1535903)
- [https://dune.com/queries/1548540](https://dune.com/queries/1548540)
- [https://dune.com/queries/1548574](https://dune.com/queries/1548574)
- [https://dune.com/queries/1548614](https://dune.com/queries/1548614)

## ÊÄªÁªì

Ëá≥Ê≠§ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÂØπLensÂçèËÆÆÁöÑÂü∫Êú¨Ê¶ÇÂÜµÂíåÂàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñô„ÄÅÂüüÂêç‰ø°ÊÅØÁöÑÂàÜÊûêÔºå‰πüÊ∑ªÂä†‰∫Ü‰∏Ä‰∏™ÂüüÂêçÊêúÁ¥¢ÂäüËÉΩ„ÄÇÂâçÈù¢‚ÄúÊï∞ÊçÆÁúãÊùøÁöÑ‰∏ªË¶ÅÂàÜÊûêÂÜÖÂÆπ‚ÄùÈÉ®ÂàÜÊàë‰ª¨ÂàóÂá∫‰∫ÜÊõ¥Â§öÂèØ‰ª•ÂàÜÊûêÁöÑÂÜÖÂÆπÔºåÂú®Êú¨ÁØáÊïôÁ®ãÁöÑÁ¨¨‰∫åÈÉ®ÂàÜÔºåÊàë‰ª¨Â∞ÜÁªßÁª≠Âõ¥ÁªïÂàõ‰ΩúËÄÖÂèëÂ∏ÉÁöÑÂá∫ÁâàÁâ©„ÄÅÂÖ≥Ê≥®„ÄÅÊî∂Ëóè„ÄÅNFTÁ≠âÊñπÈù¢ËøõË°åÂàÜÊûê„ÄÇ‰Ω†‰πüÂèØ‰ª•Ëá™Ë°åÊé¢Á¥¢ÂàõÂª∫Êñ∞ÁöÑÊü•ËØ¢„ÄÇ

## ‰Ωú‰∏ö

ËØ∑ÁªìÂêàÊïôÁ®ãÂÜÖÂÆπÔºåÂà∂‰Ωú‰Ω†Ëá™Â∑±ÁöÑLens ÂçèËÆÆÊï∞ÊçÆÁúãÊùøÔºåÂèØÂèÇËÄÉ‚ÄúÊï∞ÊçÆÁúãÊùøÁöÑ‰∏ªË¶ÅÂàÜÊûêÂÜÖÂÆπ‚ÄùÈÉ®ÂàÜÊèêÁ§∫ÁöÑÂÜÖÂÆπÂ∞ùËØïÊñ∞ÁöÑÊü•ËØ¢ÂàÜÊûê„ÄÇËØ∑Â§ßÂÆ∂ÁßØÊûÅÂä®ÊâãÂÆûË∑µÔºåÂàõÂª∫Êï∞ÊçÆÁúãÊùøÂπ∂ÂàÜ‰∫´Âà∞Á§æÂå∫„ÄÇÊàë‰ª¨Â∞ÜÂØπ‰Ωú‰∏öÂÆåÊàêÊÉÖÂÜµÂíåË¥®ÈáèËøõË°åËÆ∞ÂΩïÔºå‰πãÂêéËøΩÊ∫Ø‰∏∫Â§ßÂÆ∂Êèê‰æõ‰∏ÄÂÆöÁöÑÂ•ñÂä±ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éDuneÁ§æÂå∫Ë∫´‰ªΩÔºåÂë®ËæπÂÆûÁâ©ÔºåAPIÂÖçË¥πÈ¢ùÂ∫¶ÔºåPOAPÔºåÂêÑÁ±ªÂêà‰ΩúÁöÑÊï∞ÊçÆ‰∫ßÂìÅ‰ºöÂëòÔºåÂå∫ÂùóÈìæÊï∞ÊçÆÂàÜÊûêÂ∑•‰ΩúÊú∫‰ºöÊé®ËçêÔºåÁ§æÂå∫Á∫ø‰∏ãÊ¥ªÂä®‰ºòÂÖàÊä•ÂêçËµÑÊ†º‰ª•ÂèäÂÖ∂‰ªñSixdegreeÁ§æÂå∫ÊøÄÂä±Á≠â„ÄÇ

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch09/readme.md">
---
title: 09. Lens ProtocolÊï∞ÊçÆÁúãÊùøÔºà‰∫åÔºâ
tags:
  - sixdegreelab
  - dune
  - onchain analysis
  - lens
---

# 9. ÂÆûË∑µÊ°à‰æãÔºöÂà∂‰ΩúLens ProtocolÁöÑÊï∞ÊçÆÁúãÊùøÔºà‰∫åÔºâ

Âú®Êú¨ÊïôÁ®ãÁöÑÁ¨¨‰∏ÄÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨ÁªôÂ§ßÂÆ∂‰ªãÁªç‰∫ÜLensÂçèËÆÆÔºåÂπ∂‰∏∫ÂÖ∂Âà∂‰Ωú‰∫Ü‰∏Ä‰∏™ÂàùÊ≠•ÁöÑÁúãÊùøÔºåÂàÜÊûê‰∫ÜÂåÖÊã¨ÊÄª‰∫§ÊòìÊï∞ÈáèÂíåÊÄªÁî®Êà∑Êï∞Èáè„ÄÅÊåâÂ§©ÁªüËÆ°ÁöÑ‰∫§ÊòìÊï∞ÈáèÂíåÁã¨Á´ãÁî®Êà∑Êï∞Èáè„ÄÅÂàõ‰ΩúËÄÖ‰∏™‰∫∫ËµÑÊñôÔºàProfileÔºâÂàÜÊûê„ÄÅLensÂüüÂêçÂàÜÊûê„ÄÅÂ∑≤Ê≥®ÂÜåÂüüÂêçÊêúÁ¥¢Á≠âÁõ∏ÂÖ≥ÂÜÖÂÆπ„ÄÇËÆ©Êàë‰ª¨ÁªßÁª≠ÁªôËøô‰∏™Êï∞ÊçÆÁúãÊùøÊ∑ªÂä†Êñ∞ÁöÑÊü•ËØ¢ÂíåÂèØËßÜÂåñÂõæË°®„ÄÇÊàë‰ª¨Â∞ÜÂàÜÊûêÂπ∂Ê∑ªÂä†‰ª•‰∏ãÂÜÖÂÆπÔºöÂêå‰∏Ä‰∏™Âú∞ÂùÄÂàõÂª∫Â§ö‰∏™Profile„ÄÅÂÖ≥Ê≥®Êï∞ÊçÆ„ÄÅÂèëÂ∏ñÊï∞ÊçÆ„ÄÅËØÑËÆ∫Êï∞ÊçÆ„ÄÅÊî∂ËóèÊï∞ÊçÆ„ÄÅÈïúÂÉèÊï∞ÊçÆ„ÄÅÂàõ‰ΩúËÄÖÁöÑÊìç‰ΩúÁªºÂêàÊÉÖÂÜµ„ÄÅÊôÆÈÄöÁî®Êà∑Âú∞ÂùÄÁöÑÊìç‰ΩúÁªºÂêàÊÉÖÂÜµ„ÄÇ


## Âêå‰∏Ä‰∏™Âú∞ÂùÄÂàõÂª∫Â§ö‰∏™ProfileÂàÜÊûê

LensÂçèËÆÆÂÖÅËÆ∏‰∏Ä‰∏™Âú∞ÂùÄÂàõÂª∫Â§ö‰∏™Profile„ÄÇÊàë‰ª¨ÂèØ‰ª•ÁºñÂÜô‰∏Ä‰∏™Êü•ËØ¢Êù•ÁªüËÆ°ÂàõÂª∫‰∫ÜÂ§ö‰∏™ProfileÁöÑÂú∞ÂùÄÁöÑÊï∞ÊçÆÂàÜÂ∏ÉÊÉÖÂÜµ„ÄÇÂú®‰∏ãÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨ÂÖàÁî®CTE `profile_created`ÂèñÂæóÊâÄÊúâÂ∑≤ÂàõÂª∫ÁöÑProfileÁöÑÊï∞ÊçÆËØ¶ÊÉÖÔºåÁÑ∂Âêé‰ΩøÁî®`multiple_profiles_addresses`Êù•ÁªüËÆ°ÊØè‰∏Ä‰∏™Âú∞ÂùÄÂàõÂª∫ÁöÑProfileÊï∞Èáè„ÄÇÊúÄÂêéÔºåÊàë‰ª¨‰ΩøÁî®CASEËØ≠Âè•ÔºåÊåâÊØè‰∏™Âú∞ÂùÄÂàõÂª∫ÁöÑProfileÁöÑÊï∞ÈáèÂØπÂÖ∂ËøõË°åÂΩíÁ±ªÔºåËøîÂõûÁªºÂêàÁöÑÁªüËÆ°Êï∞ÊçÆ„ÄÇ

```sql
with profile_created as (
    select json_value(vars, 'lax $.to') as user_address,
        json_value(vars, 'lax $.handle') as handle_name,
        replace(json_value(vars, 'lax $.handle'), '.lens', '') as short_name,
        call_block_time,
        output_0 as profile_id,
        call_tx_hash
    from lens_polygon.LensHub_call_createProfile
    where call_success = true    
),

multiple_profiles_addresses as (
    select user_address,
        count(profile_id) as profile_count
    from profile_created
    group by 1
    order by 2 desc
)

select (case when profile_count >= 10 then '10+ Profiles'
            when profile_count >= 3 then '5+ Profiles'
            when profile_count = 2 then '2 Profiles'
            else '1 Profile'
        end) as profile_count_type,
    count(user_address) as user_address_count,
    sum(profile_count) as profile_count
from multiple_profiles_addresses
group by 1
```

ÂÅöËøôÁ±ªÊï∞ÊçÆÁªüËÆ°Êó∂ÔºåÈÄöÂ∏∏Êàë‰ª¨‰πüÈúÄË¶ÅÂæóÂà∞‰∏Ä‰∫õCounterÁ±ªÂûãÁöÑÁªüËÆ°ÂÄºÔºåÊØîÂ¶ÇÂàõÂª∫ËøáÂ§ö‰∏™ProfileÁöÑÂú∞ÂùÄÊÄªÊï∞„ÄÅËøô‰∫õÂú∞ÂùÄ‰∏ÄÂÖ±ÂàõÂª∫‰∫ÜÂ§öÂ∞ë‰∏™ProfileÔºåËøô‰∫õProfileÂú®ÊâÄÊúâÂ∑≤ÂàõÂª∫ÁöÑProfile‰∏≠ÁöÑÂç†ÊØîÁ≠âÁ≠â„ÄÇÊü•ËØ¢Ëøô‰∫õÊï∞ÊçÆÊó∂ÂèØ‰ª•ÂÖ±Áî®‰∏äÈù¢ÁöÑCTEÂ≠êÊü•ËØ¢‰ª£Á†ÅÔºåÊâÄ‰ª•Êàë‰ª¨ÂØπÂÖ∂Â∞ëÂÅö‰øÆÊîπÔºåÊ∑ªÂä†‰∫Ü‰∏§‰∏™È¢ùÂ§ñÁöÑCTEÊù•ÁªüËÆ°Ëøô‰∫õCounterÁ±ªÂûãÁöÑÊï∞ÂÄº„ÄÇ‰∏∫Ëøô‰∏™Êü•ËØ¢Ê∑ªÂä†ÂèØËßÜÂåñÂõæË°®Âπ∂ÂàÜÂà´Âä†ÂÖ•Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠ÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_09.png](img/image_09.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1562662](https://dune.com/queries/1562662)
- [https://dune.com/queries/1553030](https://dune.com/queries/1553030)


## ÂèëÂ∏ñÊï∞ÊçÆÂàÜÊûê

### ÂèëÂ∏ñÊúÄÂ§öÁöÑË¥¶Âè∑Êï∞ÊçÆÂàÜÊûê

LensÁöÑÂàõ‰ΩúËÄÖÊúâ‰∏§ÁßçÂèëÂ∏ñÔºàPostÔºâÁöÑÊñπÂºèÔºå‰∏ÄÁõ¥ÊòØÁõ¥Êé•Áî®Ëá™Â∑±ÁöÑË¥¶Âè∑ÂèëÂ∏ÉPostÔºåÂè¶‰∏ÄÁßçÊòØÂßîÊâòÂÖ∂‰ªñË¥¶Âè∑ÊàñËÄÖÈÄöËøáAPIÁöÑÊñπÂºèÊù•ÂèëÂ∏É„ÄÇPostÊï∞ÊçÆÂàÜÂà´‰øùÂ≠òÂú®`LensHub_call_post`Âíå`LensHub_call_postWithSig`Ë°®‰∏≠„ÄÇÊØè‰∏Ä‰∏™‰∏ªÈ¢òPostÁöÑÂÜÖÂÆπ‰ª•JSONÂ≠óÁ¨¶‰∏≤ÁöÑÂΩ¢Âºè‰øùÂ≠òÂú®Â≠óÊÆµ`vars`‰∏≠ÔºåÂåÖÊã¨‰ΩúËÄÖÁöÑProfileIDÔºåÂ∏ñÂ≠êÂÜÖÂÆπÁöÑURLÁ≠â‰ø°ÊÅØ„ÄÇÂØπ‰∫éÂ≠óÁ¨¶‰∏≤ÂΩ¢ÂºèÁöÑJSONÂÜÖÂÆπÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®`:`Êìç‰ΩúÁ¨¶Êù•ËÆøÈóÆÂÖ∂‰∏≠ÁöÑÂÄº„ÄÇ‰∏ãÈù¢ÁöÑÊü•ËØ¢ÂèØ‰ª•Ëé∑ÂæóÈÉ®ÂàÜÁ§∫ËåÉÊï∞ÊçÆÔºö

```sql
select call_block_time,
    call_tx_hash,
    output_0 as post_id,
    json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
    json_value(vars, 'lax $.contentURI') as content_url,
    json_value(vars, 'lax $.collectModule') as collection_module,
    json_value(vars, 'lax $.referenceModule') as reference_module,
    vars
from lens_polygon.LensHub_call_post
where call_success = true
limit 10
```

Èâ¥‰∫éÂèëÂ∏ñÁöÑProfileÊï∞ÈáèÂæàÂ§öÔºåÊàë‰ª¨ÂèØ‰ª•ÂÉèÂâçÈù¢ÂàÜÊûê‚ÄúÂêå‰∏Ä‰∏™Âú∞ÂùÄÂàõÂª∫Â§ö‰∏™Profile‚ÄùÈÇ£Ê†∑ÔºåÂØπ‰∏çÂêåÂèëÂ∏ñÊï∞ÈáèÁöÑProfileÂÅö‰∏Ä‰∏™ÂàÜÁ±ªÁªüËÆ°ÔºåËøòÂèØ‰ª•ÂÖ≥Ê≥®Â§¥ÈÉ®Áî®Êà∑ÔºåÂç≥ÂèëÂ∏ñÊúÄÂ§öÁöÑÈÇ£‰∫õË¥¶Âè∑ÁöÑÊï∞ÊçÆ„ÄÇËøôÈáåÊàë‰ª¨ÂØπÂèëÂ∏ñÊúÄÂ§öÁöÑË¥¶Âè∑ËøõË°åÂàÜÊûêÔºåÂêåÊó∂Â∞ÜËøôÈÉ®ÂàÜË¥¶Âè∑ÁöÑÂèëÂ∏ñÊï∞ÈáèÂíåÊÄª‰ΩìÂèëÂ∏ñÊï∞ÈáèÁöÑËøõË°åÂØπÁÖßÔºåËæìÂá∫CounterÂõæË°®„ÄÇÂÆåÊï¥ÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with post_data as (
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module,
    from lens_polygon.LensHub_call_post
    where call_success = true
    
    union all
    
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module,
    from lens_polygon.LensHub_call_postWithSig
    where call_success = true
),

posts_summary as (
    select count(*) as total_post_count,
        count(distinct profile_id) as posted_profile_count
    from post_data
),

top_post_profiles as (
    select profile_id,
        count(*) as post_count
    from post_data
    group by 1
    order by 2 desc
    limit 1000
)

select profile_id,
    post_count,
    sum(post_count) over () as top_profile_post_count,
    total_post_count,
    posted_profile_count,
    cast(sum(post_count) over () as double) / total_post_count * 100 as top_profile_posts_ratio
from top_post_profiles
inner join posts_summary on true
order by 2 desc
```

‰ª•‰∏äSQLËß£ËØªÔºöÂõ†‰∏∫PostÊï∞ÊçÆÂàÜÂà´‰øùÂ≠òÂú®‰∏§‰∏™Ë°®ÈáåÔºåÂú®CTE `post_data`‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®`union all`Â∞Ü‰∏§‰∏™Ë°®‰∏≠ÂèñÂá∫ÁöÑÊï∞ÊçÆÂêàÂπ∂Âà∞‰∏ÄËµ∑„ÄÇÊàë‰ª¨ÈÄöËøá`posts_summary`Êù•ÁªüËÆ°ÊâÄÊúâÂèëÂ∏ñÁöÑProfileÊï∞ÈáèÂíå‰ªñ‰ª¨Á¥ØËÆ°ÂèëÂ∏ÉÁöÑPostÊï∞Èáè„ÄÇÂú®`top_post_profiles`‰∏≠ÔºåÊàë‰ª¨ÊåâÁÖßÊØè‰∏™ProfileÁöÑÂèëÂ∏ñÊï∞ÈáèÊúÄÂ§öÁöÑ1000‰∏™ProfileÁöÑÊï∞ÊçÆ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÂÖ≥ËÅîÊü•ËØ¢`top_post_profiles`Âíå`posts_summary`ÔºåËæìÂá∫ÂèëÂ∏ñÊúÄÂ§öÁöÑË¥¶Âè∑Êï∞ÊçÆ‰ª•ÂèäÂÆÉ‰ª¨ÂíåÊÄªÂèëÂ∏ñÊï∞ÊçÆÁöÑÂØπÊØî„ÄÇÂ∞ÜÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÂπ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_10.png](img/image_10.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1554541](https://dune.com/queries/1554541)

### ÊØèÊó•Êñ∞ÂèëÂ∏ñÊï∞ÈáèÁªüËÆ°

LensÁî®Êà∑ÊØèÊó•ÁöÑÊñ∞ÂèëÂ∏ñÊï∞ÈáèÊòØËßÇÂØüÊï¥‰ΩìÊ¥ªË∑ÉÂ∫¶ÂèòÂåñË∂ãÂäøÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊåáÊ†áÔºåÊàë‰ª¨ÁºñÂÜô‰∏Ä‰∏™Êü•ËØ¢Êù•ÁªüËÆ°ÊØèÂ§©ÁöÑÂèëÂ∏ñÊï∞Èáè„ÄÇËøô‰∏™Êü•ËØ¢‰∏≠ÁöÑ`post_data` CTE‰∏é‰πãÂâçÁöÑÂÆåÂÖ®Áõ∏ÂêåÔºåÊâÄ‰ª•Êàë‰ª¨Âú®‰∏ãÈù¢ÁöÑ‰ª£Á†Å‰∏≠ÁúÅÁï•ÂÆÉÁöÑËØ¶ÊÉÖ„ÄÇÂõ†‰∏∫Êàë‰ª¨ËøòÂ∏åÊúõÂ∞ÜÊØèÂ§©ÁöÑÂèëÂ∏ñÊï∞ÈáèËøõË°åÁ¥ØÂä†ËøîÂõûÁ¥ØËÆ°ÂèëÂ∏ñÊï∞ÈáèÔºåÊàë‰ª¨ÂÆö‰πâ`post_daily_summary` CTE‰Ωú‰∏∫‰∏≠Èó¥Ê≠•È™§Ôºå‰ª•ËÆ©SQL‰ª£Á†ÅÁÆÄÂçïÊòìÊáÇ„ÄÇÂØπÂ∫îÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with post_data as (
    -- Get post data from LensHub_call_post and LensHub_call_postWithSig tables
),

post_daily_summary as (
    select date_trunc('day', call_block_time) as block_date,
        count(*) post_count,
        count(distinct profile_id) as profile_count
    from post_data
    group by 1
)

select block_date,
    post_count,
    profile_count,
    sum(post_count) over (order by block_date) as accumulate_post_count
from post_daily_summary
order by block_date
```

Â∞ÜÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÂπ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_11.png](img/image_11.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1555124](https://dune.com/queries/1555124)


### Ëøë30Â§©ÂèëÂ∏ñÊúÄÊ¥ªË∑ÉÁöÑProfileÁªüËÆ°

ÂêåÊ†∑ÔºåÊàë‰ª¨ÂèØËÉΩÂÖ≥ÂøÉÊúÄËøë‰∏ÄÊÆµÊó∂Èó¥ÂÜÖÂèëÂ∏ñÊúÄÊ¥ªË∑ÉÁöÑProfileÁöÑÊÉÖÂÜµ„ÄÇ‰∏∫Ê≠§Êàë‰ª¨Âè™ÈúÄË¶ÅÂú®ÂâçËø∞`post_data` CTE‰∏≠ÔºåÂàÜÂà´Ê∑ªÂä†Êó•ÊúüËøáÊª§Êù°‰ª∂Êù•Á≠õÈÄâÊúÄËøë30Â§©ÂÜÖÁöÑÂèëÂ∏ñÔºåÁÑ∂ÂêéÊåâÊó•ÊúüÊ±áÊÄªÁªüËÆ°Âç≥ÂèØ„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
with post_data as (
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module
    from lens_polygon.LensHub_call_post
    where call_success = true
        and call_block_time >= now() - interval '30' day
    
    union all
    
    select call_block_time,
        call_tx_hash,
        output_0 as post_id,
        json_value(vars, 'lax $.profileId') as profile_id, -- Access element in json string
        json_value(vars, 'lax $.contentURI') as content_url,
        json_value(vars, 'lax $.collectModule') as collection_module,
        json_value(vars, 'lax $.referenceModule') as reference_module
    from lens_polygon.LensHub_call_postWithSig
    where call_success = true
        and call_block_time >= now() - interval '30' day
)

select profile_id,
    count(*) as post_count
from post_data
group by 1
order by 2 desc
limit 100
```

Êàë‰ª¨ÂèØ‰ª•ÂàÜÂà´Ê∑ªÂä†‰∏Ä‰∏™Êü±Áä∂ÂõæÊù•ÊòæÁ§∫ËøáÂéª30Â§©ÂÜÖÂèëÂ∏ñÊúÄÂ§öÁöÑ100‰∏™Ë¥¶Âè∑ÁöÑÂèëÂ∏ñÊï∞ÈáèÔºåÂêåÊó∂Ê∑ªÂä†‰∏Ä‰∏™TableÁ±ªÂûãÁöÑÂõæË°®Êù•ËæìÂá∫ËØ¶ÊÉÖ„ÄÇÁõ∏ÂÖ≥ÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_12.png](img/image_12.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1559981](https://dune.com/queries/1559981)


## ËØÑËÆ∫Êï∞ÊçÆÂàÜÊûê

### ËØÑËÆ∫ÊúÄÂ§öÁöÑË¥¶Âè∑Êï∞ÊçÆÂàÜÊûê

LensÁöÑËØÑËÆ∫Êï∞ÊçÆ‰∏éÂèëÂ∏ñÊï∞ÊçÆÁ±ª‰ººÔºåÊåâÊï∞ÊçÆ‰∫ßÁîüÊù•Ê∫ê‰∏çÂêåÔºåÂàÜÂà´‰øùÂ≠òÂú®`LensHub_call_comment`Âíå`LensHub_call_commentWithSig`Ë°®‰∏≠„ÄÇÂü∫‰∫éLensÂçèËÆÆÁõÆÂâçÁöÑÂäüËÉΩÔºåÁî®Êà∑ÂøÖÈ°ªÂ∑≤ÁªèÂàõÂª∫‰∫ÜËá™Â∑±ÁöÑProfileÊâçËÉΩÂØπÂÖ∂‰ªñ‰∫∫Âàõ‰ΩúËÄÖÂØπPostËøõË°åËØÑËÆ∫„ÄÇÂú®ËØÑËÆ∫Êï∞ÊçÆË°®‰∏≠ÔºåÊòØÈÄöËøáËØÑËÆ∫ËÄÖÁöÑProfile IDÊù•ËøõË°åËøΩË∏™ÁöÑ„ÄÇÂêåÊó∂ÔºåÊØè‰∏™Âàõ‰ΩúËÄÖÁöÑÂèëÂ∏ñÔºåÂÖ∂ÁºñÂè∑ÊòØ‰ªé1ÂºÄÂßãÁ¥ØÂä†ÁöÑ„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰∏çÂêåÂàõ‰ΩúËÄÖÁöÑÂèëÂ∏ñÔºåÂÖ∂ÁºñÂè∑ÂèØËÉΩÁõ∏Âêå„ÄÇÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜÂàõ‰ΩúËÄÖÁöÑProfile ID ÂíåÂÖ∂Publication IDÂÖ≥ËÅîËµ∑Êù•ËøôÊ†∑ÊâçËÉΩÂæóÂà∞ÂîØ‰∏ÄÁöÑÁºñÂè∑„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
select call_block_time,
    call_tx_hash,
    output_0 as comment_id, -- ËØÑËÆ∫ÁºñÂè∑
    json_value(vars, 'lax $.profileId') as profile_id_from, -- ËØÑËÆ∫ËÄÖÁöÑProfile ID
    json_value(vars, 'lax $.contentURI') as content_url, -- ËØÑËÆ∫ÂÜÖÂÆπÈìæÊé•
    json_value(vars, 'lax $.pubIdPointed') as publication_id_pointed, -- Ë¢´ËØÑËÆ∫ÁöÑPublication ID
    json_value(vars, 'lax $.profileIdPointed') as profile_id_pointed, -- Ë¢´ËØÑËÆ∫ÁöÑÂàõ‰ΩúËÄÖÁöÑProfile ID
    json_value(vars, 'lax $.profileIdPointed') || '-' || json_value(vars, 'lax $.pubIdPointed') as unique_publication_id  -- ÁªÑÂêàÁîüÊàêÂîØ‰∏ÄÁºñÂè∑
from lens_polygon.LensHub_call_comment
where call_success = true
limit 10
```

Êàë‰ª¨ÂêåÊ†∑ÈÄöËøáÂÆö‰πâÈ¢ùÂ§ñÁöÑCTEÊù•Ëé∑ÂèñÊÄªÁöÑËØÑËÆ∫Êï∞ÊçÆÔºå‰ªéËÄåÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Êü•ËØ¢‰∏≠ËæìÂá∫CounterÂõæË°®ÔºåÂØπÊØîËØÑËÆ∫ÊúÄÂ§öÁöÑ1000‰∏™Ë¥¶Âè∑ÁöÑËØÑËÆ∫Êï∞ÊçÆÂíåÊâÄÊúâË¥¶Âè∑ÁöÑËØÑËÆ∫Êï∞ÊçÆ„ÄÇÂ∞ÜÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÂπ∂Âä†ÂÖ•Âà∞Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_13.png](img/image_13.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1560028](https://dune.com/queries/1560028)

### ËØÑËÆ∫ÊúÄÂ§öÁöÑPublicationÁªüËÆ°

ÊØè‰∏™ËØÑËÆ∫ÈÉΩÊòØÈíàÂØπ‰∏Ä‰∏™ÂÖ∑‰ΩìÁöÑÂØπË±°ÔºàPublicationÔºâÔºàËøôÈáå‰ΩúËÄÖËÆ§‰∏∫Â∫îËØ•Â∞±ÊòØPostÔºåÂ¶ÇÊúâÁêÜËß£ÈîôËØØÊï¨ËØ∑ÊåáÊ≠£Ôºâ„ÄÇÂàÜÊûêË¢´ËØÑËÆ∫ÊúÄÂ§öÁöÑPublicationÂ∞±ÂÖ∑Êúâ‰∏ÄÂÆöÁöÑ‰ª∑ÂÄº„ÄÇÊàë‰ª¨ÁºñÂÜô‰∏Ä‰∏™Êü•ËØ¢Êù•ÁªüËÆ°Ââç500‰∏™Ë¢´ËØÑËÆ∫ÊúÄÂ§öÁöÑPublicationÔºåÂêåÊó∂Â∞ÜÂÖ∂‰∏éÊâÄÊúâËØÑËÆ∫Êï∞ÊçÆËøõË°åÂØπÊØî„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
with comment_data as (
    -- get comment data from LensHub_call_comment and LensHub_call_commentWithSig tables
)

select profile_id_pointed,
    publication_id_pointed,
    unique_publication_id,
    count(*) as comment_count
from comment_data
group by 1, 2, 3
order by 4 desc
limit 500
```

Â¶ÇÊ≥ïÁÇÆÂà∂ÔºåÊàë‰ª¨Ê∑ªÂä†È¢ùÂ§ñÁöÑCTEÊù•Ëé∑ÂèñÂÖ®ÈÉ®ËØÑËÆ∫ÁöÑÊï∞ÊçÆÔºåÂπ∂Â∞Ü‰∏äÈù¢ÁªüËÆ°ÁöÑÂâç500‰∏™ËØÑËÆ∫ÊúÄÂ§öÁöÑPublicationÁöÑÊï∞ÊçÆ‰∏éÂÖ®Â±ÄÊï∞ÊçÆËøõË°åÂØπÊØî„ÄÇÊ∑ªÂä†Áõ∏Â∫îÁöÑÂèØËßÜÂåñÂõæË°®Âà∞Êï∞ÊçÆÁúãÊùøÔºåÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_14.png](img/image_14.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1560578](https://dune.com/queries/1560578)

## ÈïúÂÉèÊï∞ÊçÆÂàÜÊûê

ÈïúÂÉèÊï∞ÊçÆ‰∏éËØÑËÆ∫Êï∞ÊçÆÈ´òÂ∫¶Áõ∏‰ººÔºåÁî®Êà∑‰πüÂøÖÈ°ªÂÖàÂàõÂª∫Ëá™Â∑±ÁöÑProfileÊâçËÉΩÈïúÂÉèÂÖ∂‰ªñ‰∫∫ÁöÑPublication„ÄÇÊàë‰ª¨ÂàÜÂà´ÁºñÂÜô‰∏§‰∏™Êü•ËØ¢ÔºåÁªüËÆ°Âá∫ÈïúÂÉèÊìç‰ΩúÊúÄÂ§öÁöÑÂâç1000‰∏™Ë¥¶Âè∑Êï∞ÊçÆÂíåÂâç500‰∏™Ë¢´ÈïúÂÉèÊúÄÂ§öÁöÑPublicationÊï∞ÊçÆ„ÄÇÂêåÊ†∑Â∞ÜÂÆÉ‰ª¨Ë∑üÊï¥‰ΩìÈïúÂÉèÊï∞ÊçÆËøõË°åÂØπÊØî„ÄÇÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_15.png](img/image_15.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1561229](https://dune.com/queries/1561229)
- [https://dune.com/queries/1561558](https://dune.com/queries/1561558)


## Êî∂ËóèÊï∞ÊçÆÂàÜÊûê

LensÁöÑÊî∂ËóèÊï∞ÊçÆÂêåÊ†∑ÂàÜÂà´‰øùÂ≠òÂú®`LensHub_call_collect`Âíå`LensHub_call_collectWithSig`Ëøô‰∏§‰∏™Ë°®Èáå„ÄÇ‰∏éËØÑËÆ∫ÊàñÈïúÂÉèÊï∞ÊçÆÊúâÊâÄ‰∏çÂêåÁöÑÊòØÔºåÊî∂Ëóè‰∏Ä‰∏™PublicationÊó∂Âπ∂‰∏çË¶ÅÊ±ÇÊî∂ËóèËÄÖÊã•ÊúâËá™Â∑±ÁöÑLens Profile„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰ªª‰ΩïÂú∞ÂùÄÔºàÁî®Êà∑ÔºâÈÉΩÂèØ‰ª•Êî∂ËóèÂÖ∂‰ªñProfile‰∏ãÁöÑPublication„ÄÇÊâÄ‰ª•Êàë‰ª¨Ë¶ÅÈÄöËøáÊî∂ËóèËÄÖÁöÑÂú∞ÂùÄÊù•Ë∑üË∏™ÂÖ∑‰ΩìÁöÑÊî∂ËóèÊìç‰Ωú„ÄÇÁâπÂà´‰πãÂ§ÑÂú®‰∫éÔºåÂú®`LensHub_call_collect`Ë°®‰∏≠Âπ∂Ê≤°Êúâ‰øùÂ≠òÊî∂ËóèËÄÖÁöÑÂú∞ÂùÄÊï∞ÊçÆÔºå`LensHub_call_collectWithSig`Ë°®‰∏≠ÂàôÊúâËøô‰∏™Êï∞ÊçÆ„ÄÇÊàë‰ª¨ÈúÄË¶Å‰ªé`LensHub_call_collect`Ë°®ÂÖ≥ËÅîÂà∞`transactions`Ë°®ÔºåËé∑ÂèñÂΩìÂâçÊìç‰ΩúÊî∂ËóèÁöÑÁî®Êà∑Âú∞ÂùÄ„ÄÇSQLÁ§∫‰æãÂ¶Ç‰∏ãÔºö

```sql
select call_block_time,
    t."from" as collector,
    c.profileId as profile_id,
    c.pubId as publication_id,
    cast(c.profileId as varchar) || '-' || cast(c.pubId as varchar) as unique_publication_id,
    c.output_0 as collection_id
from lens_polygon.LensHub_call_collect c
inner join polygon.transactions t on c.call_tx_hash = t.hash -- ÂÖ≥ËÅî‰∫§ÊòìË°®Ëé∑ÂèñÁî®Êà∑Âú∞ÂùÄ
where call_block_time >= date('2022-05-18') -- LensÂêàÁ∫¶ÁöÑÂèëÂ∏ÉÊó•ÊúüÔºåÊèêÂçáÊü•ËØ¢ÊïàÁéá
    and block_time >= date('2022-05-18')
    and c.call_success = true
limit 10
```

Áî±‰∫é‰∫§ÊòìË°®ËÆ∞ÂΩïÁõ∏ÂΩìÂ∫ûÂ§ßÔºåÊü•ËØ¢ËÄóÊó∂Â∞ÜÊòéÊòæÂ¢ûÂä†„ÄÇ‰∏Ä‰∏™ÁªèÈ™åÊ≥ïÂàôÊòØÔºåËÉΩÈÅøÂÖçÈíàÂØπÂéüÂßãÊï∞ÊçÆË°®Ôºàtransactions, logs, tracesÔºâÁöÑjoinÊìç‰ΩúÂ∞±Â∞ΩÈáèÈÅøÂÖç„ÄÇ

Êî∂ËóèÊï∞ÊçÆÂàÜÊûêSQLÁöÑÂÖ∂‰ªñÈÉ®ÂàÜË∑üÂâçÈù¢ÁöÑ‰æãÂ≠êÂü∫Êú¨Áõ∏ÂêåÔºåËøôÈáå‰∏çÂÜçËµòËø∞„ÄÇÂêåÊ†∑ÔºåÊàë‰ª¨‰πüÈíàÂØπË¢´Êî∂ËóèÊúÄÂ§öÁöÑPublicationËøõË°åÁªüËÆ°ÂàÜÊûê„ÄÇÁõ∏ÂÖ≥ÂèØËßÜÂåñÂõæÁâáÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_16.png](img/image_16.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1560847](https://dune.com/queries/1560847)
- [https://dune.com/queries/1561009](https://dune.com/queries/1561009)


## ÂÖ≥Ê≥®Êï∞ÊçÆÂàÜÊûê

### ÂÖ≥Ê≥®ÊúÄÂ§öÁöÑProfileÊï∞ÊçÆ

LensÂçèËÆÆÁöÑÂÖ≥Ê≥®Êï∞ÊçÆ‰ªçÁÑ∂ÊòØÂàÜÂà´‰øùÂ≠òÂú®`LensHub_call_follow`Âíå`LensHub_call_followWithSig`‰∏§‰∏™Ë°®Èáå„ÄÇ‰ªª‰ΩïÂú∞ÂùÄÔºàÁî®Êà∑ÔºâÈÉΩÂèØ‰ª•ÂÖ≥Ê≥®ÂÖ∂‰ªñProfile„ÄÇ‰∏éÊî∂ËóèÁ±ª‰ººÔºå`LensHub_call_follow`Ë°®ÈáåÊ≤°Êúâ‰øùÂ≠òÂÖ≥Ê≥®ËÄÖÁöÑÂú∞ÂùÄÔºåÊâÄ‰ª•Êàë‰ª¨‰πüÈúÄË¶ÅÈÄöËøáÂÖ≥ËÅîÂà∞`transactions`Ë°®Êù•Ëé∑ÂèñÂΩìÂâçÊìç‰ΩúÊî∂ËóèÁöÑÁî®Êà∑Âú∞ÂùÄ„ÄÇÂè¶Â§ñÔºåÂÖ≥Ê≥®ËøòÊúâ‰∏Ä‰∏™ÁâπÊÆäÁöÑÂú∞ÊñπÔºåÂ∞±ÊòØ‰∏Ä‰∏™‰∫§ÊòìÈáåÈù¢ÂèØ‰ª•ÂêåÊó∂ÊâπÈáèÂÖ≥Ê≥®Â§ö‰∏™Profile„ÄÇ`LensHub_call_follow`Ë°®‰∏≠ÔºåË¢´ÂÖ≥Ê≥®ÁöÑProfileÊï∞ÊçÆ‰øùÂ≠òÂú®Êï∞ÁªÑÁ±ªÂûãÂ≠óÊÆµ`profileIds`ÈáåÔºåËøô‰∏™Áõ∏ÂØπÂÆπÊòìÂ§ÑÁêÜ„ÄÇËÄåË°®`LensHub_call_followWithSig`‰∏≠ÔºåÂàôÊòØJSONÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÈáåÈù¢ÁöÑÊï∞ÁªÑÂÄº„ÄÇÂÖ∂‰∏≠Â≠óÊÆµ`vars`ÁöÑ‰∏Ä‰∏™ÂÆû‰æãÂ¶Ç‰∏ãÔºàÈÉ®ÂàÜÂÜÖÂÆπÂÅö‰∫ÜÁúÅÁï•ÔºâÔºö

```json
{"follower":"0xdacc5a4f232406067da52662d62fc75165f21b23","profileIds":[21884,25271,39784],"datas":["0x","0x","0x"],"sig":"..."}
```

‰ΩøÁî®Dune SQLÁöÑJSONÂáΩÊï∞ÔºåÂèØ‰ª•‰ªéJSONÂ≠óÁ¨¶‰∏≤‰∏≠ËØªÂèñÊï∞ÁªÑÂÄº„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂÖà‰ΩøÁî®`json_extract()`‰ªéjson Â≠óÁ¨¶‰∏≤‰∏≠ÊèêÂèñÈúÄË¶ÅÁöÑÂÖÉÁ¥†ÂÄºÔºåÂÜç‰ΩøÁî®`cast()`ÊñπÊ≥ïÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÊåáÂÆöÁ±ªÂûãÁöÑÊï∞ÁªÑ„ÄÇÁ§∫‰æã‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
select
json_query(vars, 'lax $.follower') AS follower, -- single value
json_query(vars, 'lax $.profileIds') AS profileIds, -- still string
from_hex(cast(json_extract(vars,'$.follower') as varchar)) as follower2, -- cast to varbinary
cast(json_extract(vars,'$.profileIds') as array(integer)) as profileIds2, -- cast to array
vars
from lens_polygon.LensHub_call_followWithSig
where cardinality(output_0) > 1
limit 10
```

ËØªÂèñÂÖ≥Ê≥®ËØ¶ÊÉÖÁöÑÂÆåÊï¥SQL‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
with follow_data as (
    select f.follower, p.profile_id
    from (
        select from_hex(cast(json_extract(vars,'$.follower') as varchar)) as follower, -- cast to varbinary
            cast(json_extract(vars,'$.profileIds') as array(integer)) as profile_ids -- cast to array
        from lens_polygon.LensHub_call_followWithSig
            
        union all
        
        select t."from" as follower,
            cast(f.profileIds as array(integer)) as profile_ids
        from lens_polygon.LensHub_call_follow f
        inner join polygon.transactions t on f.call_tx_hash = t.hash
        where call_block_time >= date('2022-05-18') -- Lens launch date
            and block_time >= date('2022-05-18')
            and call_success = true
    ) f
    cross join unnest(f.profile_ids) as p(profile_id)
)

select * from follow_data
limit 100
```

ËøôÈáåÈúÄË¶ÅËØ¥Êòé‰∏Ä‰∏ãÔºåÊàë‰ª¨‰ΩøÁî®‰∫Ü`cross join unnest(f.profile_ids) as p(profile_id)`Â≠êÂè•ÔºåÂ∞ÜÂ≠êÊü•ËØ¢‰∏≠ÁöÑÊï∞ÁªÑËøõË°åÊãÜËß£ÔºåÂπ∂Ëé∑ÂèñÊãÜÂºÄÁöÑÂçï‰∏™IDÂÄº„ÄÇÂêåÊó∂ÔºåÂõ†‰∏∫`lens_polygon.LensHub_call_follow`Ë°®‰∏≠ÁöÑÂÖÉÁ¥†Á±ªÂûã‰∏∫`uint256`ÔºåËøôÊòØ‰∏Ä‰∏™Dune ÁöÑËá™ÂÆö‰πâÁ±ªÂûãÔºåÊàë‰ª¨Êó†Ê≥ïÂú®‰ªéjsonÂ≠óÁ¨¶‰∏≤ÊèêÂèñÂÄºÊó∂‰ΩøÁî®Ëøô‰∏™Á±ªÂûãÔºåÊâÄ‰ª•Êàë‰ª¨Áî®`cast(f.profileIds as array(integer))`Â∞Ü`uint256`ËΩ¨Êç¢‰∏∫`integer`Á±ªÂûã„ÄÇ

ÂêåÊ†∑ÔºåÊàë‰ª¨‰πüÂú®‰∏äÈù¢ÁöÑÊü•ËØ¢Âü∫Á°Ä‰∏äÊ∑ªÂä†Ëé∑ÂèñÂÖ®ÈÉ®ÂÖ≥Ê≥®Êï∞ÊçÆÁöÑCTEÂÆö‰πâÔºå‰ªéËÄåÂèØ‰ª•Âú®ÂèñÂæóÊúÄÂ§öÂÖ≥Ê≥®ÁöÑProileÂàóË°®Êó∂ÔºåÂ∞ÜÂÖ∂‰∏éÊï¥‰ΩìÂÖ≥Ê≥®Êï∞ÈáèËøõË°åÂØπÊØî„ÄÇÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÂπ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_17.png](img/image_17.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1554454](https://dune.com/queries/1554454)

### ÊåâÂÖ≥Ê≥®Êï∞ÈáèËåÉÂõ¥ÁªüËÆ°ProfileÂàÜÂ∏É

Êàë‰ª¨ÁúãÂà∞Âá†‰πéÁªùÂ§ßÈÉ®ÂàÜProfileÈÉΩÊúâË¢´ÂÖ≥Ê≥®ÔºåÊàë‰ª¨ÂèØ‰ª•Áî®‰∏Ä‰∏™Êü•ËØ¢Êù•ÂØπÂêÑProfileÁöÑÂÖ≥Ê≥®ÈáèÁöÑÂàÜÂ∏ÉÊÉÖÂÜµÂÅö‰∏Ä‰∏™ÂàÜÊûê„ÄÇSQL‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
with follow_data as (
    -- Get follow data from table LensHub_call_follow and LensHub_call_followWithSig
),

profile_follower as (
    select profile_id,
        count(follower) as follower_count
    from follow_data
    group by 1
)

select (case when follower_count >= 10000 then '10K+ Followers'
            when follower_count >= 1000 then '1K+ Followers'
            when follower_count >= 100 then '100+ Followers'
            when follower_count >= 50 then '50+ Followers'
            when follower_count >= 10 then '10+ Followers'
            when follower_count >= 5 then '5+ Followers'
            else '1 - 5 Followers'
        end) as follower_count_type,
    count(profile_id) as profile_count
from profile_follower
group by 1
```

Â∞Ü‰ª•‰∏äÊü•ËØ¢ÁªìÊûú‰ΩøÁî®‰∏Ä‰∏™Pie chartÈ•ºÂõæËøõË°åÂèØËßÜÂåñ„ÄÇÂä†ÂÖ•Âà∞Êï∞ÊçÆÁúãÊùøÂêéÂà∞ÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_18.png](img/image_18.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1554888](https://dune.com/queries/1554888)

### ÊØèÊó•Êñ∞Â¢ûÂÖ≥Ê≥®Êï∞ÈáèÁªüËÆ°

LensÁî®Êà∑ÊØèÊó•ÁöÑÊñ∞Â¢ûÂÖ≥Ê≥®Êï∞Èáè‰πüÊòØËßÇÂØüÊï¥‰ΩìÊ¥ªË∑ÉÂ∫¶ÂèòÂåñÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊåáÊ†áÔºåÊàë‰ª¨ÁºñÂÜô‰∏Ä‰∏™Êü•ËØ¢Êù•ÁªüËÆ°ÊØèÂ§©ÁöÑÂèëÂ∏ñÊï∞Èáè„ÄÇËøô‰∏™Êü•ËØ¢‰∏≠ÁöÑ`follow_data` CTE‰∏é‰πãÂâçÁöÑÂÆåÂÖ®Áõ∏Âêå„ÄÇÊü•ËØ¢Â§ÑÁêÜÊñπÂºè‰πü‰∏éÂâçÈù¢ËÆ≤ËøáÁöÑÊØèÊó•ÂèëÂ∏ñÊï∞ÈáèÁªüËÆ°È´òÂ∫¶Áõ∏‰ººÔºåËøôÈáå‰∏çÂÜçËØ¶Ëø∞ÁªÜËäÇ„ÄÇÁªôÊü•ËØ¢ÁªìÊûúÊ∑ªÂä†ÂèØËßÜÂåñÂõæË°®Âπ∂Â∞ÜÂÖ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_19.png](img/image_19.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1555185](https://dune.com/queries/1555185)

## Âàõ‰ΩúËÄÖÊìç‰ΩúÁªºÂêàÂàÜÊûê

ÁªìÂêàÂâçËø∞ÂÜÖÂÆπÂèØ‰ª•ÁúãÂá∫ÔºåÂàõ‰ΩúËÄÖÔºàÊã•ÊúâProfileÁöÑÁî®Êà∑ÔºâÂèØ‰ª•ÂèëÂ∏ñÔºàPostÔºâ„ÄÅËØÑËÆ∫ÔºàCommentÔºâÊàñËÄÖÈïúÂÉèÔºàMirrorÔºâÂÖ∂‰ªñÂàõ‰ΩúËÄÖÁöÑÊï∞ÊçÆÔºåËÄåÊôÆÈÄöÁî®Êà∑ÔºàÊú™ÂàõÂª∫ProfileÔºâÂàôÂèØ‰ª•ÂÖ≥Ê≥®ÔºàFollowÔºâÂàõ‰ΩúËÄÖÂíåÊî∂ËóèÂàõ‰ΩúËÄÖÂèëÂ∏ÉÁöÑ‰ΩúÂìÅÔºàPublicationÔºâ„ÄÇÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•Â∞ÜÂàõ‰ΩúËÄÖÂèØ‰ª•Êìç‰ΩúÁöÑÊï∞ÊçÆÂêàÂπ∂Âà∞‰∏ÄËµ∑Êù•ËøõË°åÁªºÂêàÂàÜÊûê„ÄÇ

Êàë‰ª¨ÂÆö‰πâ‰∏Ä‰∏™`action_data` CTEÔºåÂú®ÂÖ∂ÂÜÖÈÉ®‰ΩøÁî®ÂµåÂ•óÂÆö‰πâCTEÁöÑÊñπÂºèÂ∞ÜÁõ∏ÂÖ≥Êï∞ÊçÆÈõÜ‰∏≠Âà∞‰∏ÄËµ∑ÔºåÂÖ∂‰∏≠post_data„ÄÅcomment_dataÂíåmirror_dataÈÉΩÂàÜÂà´Ë∑üÂâçÈù¢Áõ∏ÂÖ≥Êü•ËØ¢ÈáåÈù¢ÁöÑÂÆö‰πâÂÆåÂÖ®Áõ∏Âêå„ÄÇÊàë‰ª¨‰ΩøÁî®union allÂ∞Ü‰ª•‰∏äÊï∞ÊçÆÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºåÂêåÊó∂ÂàÜÂ∏ÉÊåáÂÆöÂØπÂ∫îÁöÑÂä®‰ΩúÁ±ªÂûãÔºåÁîüÊàê‰∏Ä‰∏™Áî®‰∫éÂàÜÁ±ªÁöÑÂ≠óÊÆµ`action_type`„ÄÇÁÑ∂ÂêéÊàë‰ª¨Âè™ÈúÄÊåâÁÖßÂàÜÁ±ªÂ≠óÊÆµËøõË°åÊ±áÊÄªÁªüËÆ°Âç≥ÂèØËÆ°ÁÆóÂá∫ÊØèÁßçÊìç‰ΩúÁ±ªÂûãÁöÑ‰∫§ÊòìÊï∞ÈáèÂíåÁõ∏Â∫îÁöÑProfileÊï∞Èáè„ÄÇSQLÁ§∫‰æãÂ¶Ç‰∏ãÔºö

```sql
with action_data as (
    with post_data as (
        -- get post data from relevant tables
    ),
    
    comment_data as (
        -- get comment data from relevant tables
    ),
    
    mirror_data as (
        -- get mirror data from relevant tables
    )
 
    select 'Post' as action_type, * from post_data
    union all
    select 'Mirror' as action_type, * from mirror_data
    union all
    select 'Comment' as action_type, * from comment_data
)

select action_type,
    count(*) as transaction_count,
    count(distinct profile_id) as profile_count
from action_data
group by 1
```

Êàë‰ª¨ÂèØ‰ª•Áî®Áõ∏‰ººÁöÑÊñπÊ≥ïÔºåÊñ∞Âª∫‰∏Ä‰∏™ÊåâÊó•ÊúüÊ±áÊÄªÊØèÊó•ÂêÑÁßçÊìç‰ΩúÊï∞ÈáèÁöÑÊü•ËØ¢„ÄÇÁ§∫‰æã‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```
with action_data as (
    -- same as above query
)

select date_trunc('day', call_block_time) as block_date,
    action_type,
    count(*) as transaction_count
from action_data
group by 1, 2
order by 1, 2
```
 
Â∞Ü‰ª•‰∏äÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÂπ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_20.png](img/image_20.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1561822](https://dune.com/queries/1561822)
- [https://dune.com/queries/1561898](https://dune.com/queries/1561898)

## ÊôÆÈÄöÁî®Êà∑Êìç‰ΩúÁªºÂêàÂàÜÊûê

‰∏éÂàõ‰ΩúËÄÖÁ±ª‰ººÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÊôÆÈÄöÁî®Êà∑ÂèØÊâßË°åÁöÑÂÖ≥Ê≥®ÂíåÊî∂ËóèÊìç‰ΩúÂêàÂπ∂Âà∞‰∏ÄËµ∑ËøõË°åÂàÜÊûê„ÄÇÊàë‰ª¨ÂêåÊ†∑ÁºñÂÜô‰∏§‰∏™Êü•ËØ¢ÔºåÂàÜÂà´ÁªüËÆ°ÊÄª‰ΩìÁöÑÊìç‰ΩúÂàÜÂ∏ÉÂíåÊåâÊó•ÊúüÁöÑÊìç‰ΩúÊï∞Èáè„ÄÇÊü•ËØ¢ÈáåÈù¢ÁöÑ`action_data`Êï∞ÊçÆÂêåÊ†∑Êù•Ê∫ê‰∫éÂâçÈù¢‰ªãÁªçËøáÁöÑÊî∂ËóèÊü•ËØ¢ÂíåÂÖ≥Ê≥®Êü•ËØ¢ÔºåÂÖ∂SQLÁ§∫‰æãÂ¶Ç‰∏ãÔºö

```sql
with action_data as (
    with follow_data as (
        -- get follow data from relevant tables
    ),
    
    collect_data as (
        -- get collect data from relevant tables
    )

    select 'Follow' as action_type, * from follow_data
    union all
    select 'Collect' as action_type, * from collect_data
)
```

Èô§‰∫ÜÊï∞ÊçÆÊù•Ê∫ê‰∏çÂêåÔºåËøô‰∏§‰∏™Êü•ËØ¢‰∏éÂàõ‰ΩúËÄÖÊìç‰ΩúÁªºÂêàÂàÜÊûêÂü∫Êú¨Áõ∏Âêå„ÄÇÂ∞ÜÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÂπ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_21.png](img/image_21.png)

‰ª•‰∏äÊü•ËØ¢Âú®Dune‰∏äÁöÑÂèÇËÄÉÈìæÊé•Ôºö
- [https://dune.com/queries/1562000](https://dune.com/queries/1562000)
- [https://dune.com/queries/1562178](https://dune.com/queries/1562178)


## ÊÄªÁªì‰∏é‰Ωú‰∏ö

ÈùûÂ∏∏Â•ΩÔºÅÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÂØπLensÂçèËÆÆÁöÑÊï¥‰ΩìÂàÜÊûê„ÄÇ‰∏çËøáÔºåÁî±‰∫éÁØáÂπÖÈóÆÈ¢òÔºå‰ªçÁÑ∂ÊúâÂæàÂ§öÂÄºÂæóÂàÜÊûêÁöÑÊåáÊ†áÊàë‰ª¨Â∞öÊú™Ê∂âÂèäÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºö‰∏âÁßçNFTÁöÑÁõ∏ÂÖ≥Êï∞ÊçÆÂàÜÊûê„ÄÅÂàõ‰ΩúËÄÖÁöÑÊî∂ÁõäÂàÜÊûê„ÄÅProfileË¥¶Âè∑ÁöÑËΩ¨ÁßªÊÉÖÂÜµÂàÜÊûêÁ≠â„ÄÇËøôÈÉ®ÂàÜÁïôÁªôÂ§ßÂÆ∂ÂéªÁªßÁª≠Êé¢Á¥¢„ÄÇ

ËØ∑ÁªìÂêàÊïôÁ®ãÂÜÖÂÆπÔºåÁªßÁª≠ÂÆåÂñÑ‰Ω†Ëá™Â∑±ÁöÑLensÂçèËÆÆÊï∞ÊçÆÁúãÊùøÔºå‰Ω†ÂèØ‰ª•ForkÊú¨ÊïôÁ®ãÁöÑÊü•ËØ¢Âéª‰øÆÊîπÔºåÂèØ‰ª•ÊåâËá™Â∑±ÁöÑÁêÜËß£ÂÅö‰ªª‰ΩïËøõ‰∏ÄÊ≠•ÁöÑÊâ©Â±ï„ÄÇËØ∑Â§ßÂÆ∂ÁßØÊûÅÂä®ÊâãÂÆûË∑µÔºåÂàõÂª∫Êï∞ÊçÆÁúãÊùøÂπ∂ÂàÜ‰∫´Âà∞Á§æÂå∫„ÄÇÊàë‰ª¨Â∞ÜÂØπ‰Ωú‰∏öÂÆåÊàêÊÉÖÂÜµÂíåË¥®ÈáèËøõË°åËÆ∞ÂΩïÔºå‰πãÂêéËøΩÊ∫Ø‰∏∫Â§ßÂÆ∂Êèê‰æõ‰∏ÄÂÆöÁöÑÂ•ñÂä±ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éDuneÁ§æÂå∫Ë∫´‰ªΩÔºåÂë®ËæπÂÆûÁâ©ÔºåAPIÂÖçË¥πÈ¢ùÂ∫¶ÔºåPOAPÔºåÂêÑÁ±ªÂêà‰ΩúÁöÑÊï∞ÊçÆ‰∫ßÂìÅ‰ºöÂëòÔºåÂå∫ÂùóÈìæÊï∞ÊçÆÂàÜÊûêÂ∑•‰ΩúÊú∫‰ºöÊé®ËçêÔºåÁ§æÂå∫Á∫ø‰∏ãÊ¥ªÂä®‰ºòÂÖàÊä•ÂêçËµÑÊ†º‰ª•ÂèäÂÖ∂‰ªñSixdegreeÁ§æÂå∫ÊøÄÂä±Á≠â„ÄÇ

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch10/ch09-useful-queries-part1.md">
# Â∏∏ËßÅÊü•ËØ¢‰∏ÄÔºöERC20‰ª£Â∏Å‰ª∑Ê†ºÊü•ËØ¢

Âú®Êó•Â∏∏ÁöÑÊï∞ÊçÆÂàÜÊûê‰∏≠ÔºåÊàë‰ª¨ÁªèÂ∏∏‰ºöÊé•Âà∞‰∏Ä‰∫õÂ∏∏ËßÅÁöÑÈúÄÊ±ÇÔºåÊØîÂ¶ÇË∑üË∏™Êüê‰∏™ERC20‰ª£Â∏ÅÁöÑ‰ª∑Ê†ºÂèòÂåñ„ÄÅÊü•ËØ¢Êüê‰∏™Âú∞ÂùÄÊåÅÊúâÁöÑÂêÑÁßçERC20‰ª£Â∏Å‰ΩôÈ¢ùÁ≠â„ÄÇÂú®DuneÂπ≥Âè∞ÁöÑÂ∏ÆÂä©ÊñáÊ°£ÈáåÈù¢Ôºå[‰∏Ä‰∫õÊúâÁî®ÁöÑÊï∞ÊçÆÁúãÊùø](https://dune.com/docs/reference/wizard-tools/helpful-dashboards/)Âíå[ÂÆûÁî®Êü•ËØ¢](https://dune.com/docs/reference/wizard-tools/utility-queries/)ÈÉ®ÂàÜÂàÜÂà´ÁªôÂá∫‰∫Ü‰∏Ä‰∫õÂÆû‰æãÔºåÂ§ßÂÆ∂ÂèØ‰ª•ÂèÇËÄÉ„ÄÇÊú¨ÁØáÊïôÁ®ã‰∏≠Êàë‰ª¨ÁªìÂêàËá™Â∑±Êó•Â∏∏ÈÅáÂà∞ÁöÑ‰∏Ä‰∫õÂÖ∏ÂûãÈúÄÊ±ÇÔºåÊï¥ÁêÜ‰∏Ä‰∫õÊü•ËØ¢Ê°à‰æãÁªôÂ§ßÂÆ∂„ÄÇ

## Êü•ËØ¢Âçï‰∏™ERC20‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†º

ÂæàÂ§öÂå∫ÂùóÈìæÈ°πÁõÆÈÉΩÊ∂âÂèäERC20‰ª£Â∏ÅÔºåDeFiÁ±ªÁöÑÈ°πÁõÆÂÖÅËÆ∏Áî®Êà∑‰∫§Êç¢‰ªñ‰ª¨ÊåÅÊúâÁöÑERC20‰ª£Â∏ÅÔºåÂÖ∂‰ªñ‰∏Ä‰∫õÈ°πÁõÆÈÄöËøáÂèëË°åERC20‰ª£Â∏ÅÊù•ÂãüÈõÜËµÑÈáëÊàñËÄÖÈÄöËøáÂàÜÈÖçËÆ°Âàí„ÄÅÁ©∫ÊäïÁ≠âÊñπÂºèÂõûÈ¶àÊäïËµÑ‰∫∫„ÄÅÊó©ÊúüÁî®Êà∑ÂíåÈ°πÁõÆÊñπÂõ¢ÈòüÁ≠â„ÄÇÂÉè[CoinGecko](https://www.coingecko.com/)ËøôÊ†∑ÁöÑÁΩëÁ´ôÊúâÊèê‰æõÂêÑÁßçERC20‰ª£Â∏ÅÁöÑ‰ª∑Ê†º‰ø°ÊÅØ„ÄÇDune‰πüÂ∞ÜÂêÑÂå∫ÂùóÈìæ‰∏äÂ∏∏ËßÅÁöÑERC20‰ª£Â∏ÅÁöÑ‰ª∑Ê†º‰ø°ÊÅØÊï¥ÁêÜÂà∞‰∫Ü`prices.usd`Ë°®Âíå`prices.usd_latest`Ë°®‰∏≠ÔºåÊñπ‰æøÊï∞ÊçÆÂàÜÊûêÂ∏à‰ΩøÁî®„ÄÇ[prices.usd](https://dune.com/docs/reference/tables/prices/)Ë°®ËÆ∞ÂΩï‰∫ÜÂêÑÁßçERC20‰ª£Â∏ÅÁöÑÊØèÂàÜÈíü‰ª∑Ê†º‰ø°ÊÅØ„ÄÇÊàë‰ª¨Âú®ÂàÜÊûêERC20‰ª£Â∏ÅÁõ∏ÂÖ≥ÁöÑÈ°πÁõÆÊó∂ÔºåÂèØ‰ª•ÁªìÂêà‰ª∑Ê†ºÊï∞ÊçÆÔºåÂ∞ÜÂêÑÁßç‰∏çÂêå‰ª£Â∏ÅÁöÑÈáëÈ¢ùËΩ¨Êç¢‰∏∫‰ª•ÁæéÂÖÉË°®Á§∫ÁöÑÈáëÈ¢ùÔºåÂ∞±ËÉΩËøõË°åÊ±áÊÄª„ÄÅÂØπÊØîÁ≠âÊìç‰Ωú„ÄÇ

**Ëé∑ÂèñÂçï‰∏™ERC20‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†º:**

`prices.usd`Ë°®‰∏≠ÁöÑ‰ª∑Ê†ºÊòØÊåâÂàÜÈíüËÆ∞ÂΩïÁöÑÔºåÊàë‰ª¨Âè™ÈúÄË¶ÅÊ†πÊçÆ‰ª£Â∏ÅÁöÑÁ¨¶Âè∑ÂèäÂÖ∂ÂΩíÂ±ûÁöÑÂå∫ÂùóÈìæÂèñÊúÄÊñ∞ÁöÑ‰∏ÄÊù°ËÆ∞ÂΩïÂç≥ÂèØÔºåÂ¶ÇÊûúÊúâÂêàÁ∫¶Âú∞ÂùÄÔºå‰πüÂèØ‰ª•‰ΩøÁî®ÂêàÁ∫¶Âú∞ÂùÄÊù•Êü•ËØ¢„ÄÇ`usd_latest`Ë°®‰∏≠ÂàôËÆ∞ÂΩï‰∫ÜÊØèÁßç‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†ºÔºåÊØè‰∏™‰ª£Â∏ÅÂè™Êúâ‰∏ÄË°åËÆ∞ÂΩï„ÄÇ‰ª•‰∏ãÂá†ÁßçÊñπÂºèÈÉΩÂèØ‰ª•Êü•ËØ¢Âçï‰∏™‰ª£Â∏ÅÔºà‰ª•WETH‰∏∫‰æãÔºâÁöÑÊúÄÊñ∞‰ª∑Ê†º„ÄÇÂõ†‰∏∫‰ª∑Ê†º‰ø°ÊÅØÊåâÊØèÂàÜÈíüÊØè‰∏™‰ª£Â∏Å‰∏ÄÊù°ËÆ∞ÂΩïÁöÑÊñπÂºè‰øùÂ≠òÔºåÂÖ∑‰ΩìÂà∞ÊØè‰∏Ä‰∏™‰ª£Â∏ÅÂÖ∂ËÆ∞ÂΩïÊï∞Èáè‰πüÂæàÂ∫ûÂ§ßÔºåÊàë‰ª¨ÈÄöËøáÈôêÂà∂ËØªÂèñÊúÄÊñ∞ÁöÑÈÉ®ÂàÜÊï∞ÊçÆÊù•ÊèêÈ´òÊü•ËØ¢ÁöÑÊïàÁéá„ÄÇÁî±‰∫éÂÅ∂Â∞îÂèØËÉΩ‰ºöÂ≠òÂú®‰∏ÄÂÆöÁöÑÂª∂ËøüÔºå‰∏ãÈù¢ÁöÑÂÆû‰æã‰∏≠Êàë‰ª¨‰ªéËøáÂéª6Â∞èÊó∂ÁöÑËÆ∞ÂΩïÈáåÈù¢ËØªÂèñÊúÄÊñ∞ÁöÑ‰∏ÄÊù°ÔºåÁ°Æ‰øùËÉΩÂèñÂà∞‰ª∑Ê†º„ÄÇ

**‰ΩøÁî®‰ª£Â∏ÅÁ¨¶Âè∑ÂÄºËØªÂèñ`prices.usd`Ë°®ÁöÑÊúÄÊñ∞‰ª∑Ê†º‰ø°ÊÅØÔºö**

```sql
select * from prices.usd
where symbol = 'WETH'
    and blockchain = 'ethereum'
    and minute >= now() - interval '6' hour
order by minute desc
limit 1
```

**‰ΩøÁî®‰ª£Â∏ÅÁöÑÂêàÁ∫¶Âú∞ÂùÄËØªÂèñ`prices.usd`Ë°®ÁöÑÊúÄÊñ∞‰ª∑Ê†ºÔºö**

```sql
select * from prices.usd
where contract_address = 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2   -- WETH
    and minute >= now() - interval '6' hour
order by minute desc
limit 1
```

**‰ªé`prices.usd_latest`Ë°®ËØªÂèñÊúÄÊñ∞‰ª∑Ê†º‰ø°ÊÅØÔºö**

```sql
select * from prices.usd_latest
where symbol = 'WETH'
    and blockchain = 'ethereum'
```

ËØªÂèñ`prices.usd_latest`Ë°®ÁöÑÊü•ËØ¢Êõ¥Âä†ÁÆÄÊ¥Å„ÄÇ‰ΩÜÊòØÂõ†‰∏∫ÂÆÉÂÆûÈôÖ‰∏äÊòØ`prices.usd`Ë°®ÁöÑ‰∏Ä‰∏™ËßÜÂõæÔºàÂèÇËÄÉÊ∫ê‰ª£Á†ÅÔºö[prices_usd_latest](https://github.com/duneanalytics/spellbook/blob/main/models/prices/prices_usd_latest.sql)ÔºâÔºåÁõ∏ÊØîÊù•ËØ¥Êü•ËØ¢ÊâßË°åÁöÑÊïàÁéáÁï•‰Ωé„ÄÇ


## Êü•ËØ¢Â§ö‰∏™ERC20‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†º

ÂΩìÊàë‰ª¨ÈúÄË¶ÅÂêåÊó∂ËØªÂèñÂ§ö‰∏™TokenÁöÑÊúÄÊñ∞‰ª∑Ê†ºÊó∂Ôºå`prices.usd_latest`Ë°®ÁöÑ‰æøÂà©ÊÄßÂ∞±‰ΩìÁé∞Âá∫Êù•‰∫Ü„ÄÇËøôÈáåÊàë‰ª¨‰ª•ÂêåÊó∂Êü•ËØ¢WETH„ÄÅWBTCÂíåUSDCÁöÑÊúÄÊñ∞‰ª∑Ê†º‰∏∫‰æã„ÄÇ


**‰ªé`prices.usd_latest`Ë°®ËØªÂèñÂ§ö‰∏™‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†º‰ø°ÊÅØÔºö**

```sql
select * from prices.usd_latest
where symbol in ('WETH', 'WBTC', 'USDC')
    and blockchain = 'ethereum'
```

**‰ªé`prices.usd`Ë°®ËØªÂèñÂ§ö‰∏™‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†º‰ø°ÊÅØÔºö**

```sql
select symbol, decimals, price, minute
from (
    select row_number() over (partition by symbol order by minute desc) as row_num, *
    from prices.usd
    where symbol in ('WETH', 'WBTC', 'USDC')
        and blockchain = 'ethereum'
        and minute >= now() - interval '6' hour
    order by minute desc
) p
where row_num = 1
```

Âõ†‰∏∫Êàë‰ª¨Ë¶ÅÂêåÊó∂ËØªÂèñÂ§ö‰∏™‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ª∑Ê†ºÔºåÂ∞±‰∏çËÉΩÁÆÄÂçïÂú∞‰ΩøÁî®`limit`Â≠êÂè•ÈôêÂà∂ÁªìÊûúÊï∞ÈáèÊù•ÂæóÂà∞ÈúÄË¶ÅÁöÑÁªìÊûú„ÄÇÂõ†‰∏∫Êàë‰ª¨ÂÆûÈôÖÈúÄË¶ÅËøîÂõûÁöÑÊòØÊØè‰∏™‰∏çÂêåÁöÑ‰ª£Â∏ÅÂàÜÂà´Êåâ`minute`Â≠óÊÆµÈôçÂ∫èÊéíÂ∫èÂêéÂèñÁ¨¨‰∏ÄÊù°ËÆ∞ÂΩï„ÄÇ‰∏äÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®‰∫Ü`row_number() over (partition by symbol order by minute desc) as row_num`Êù•ÁîüÊàê‰∏Ä‰∏™Êñ∞ÁöÑÂàóÔºåËøô‰∏™ÂàóÁöÑÂÄºÊåâÁÖß`symbol`ÂàÜÁªÑÂπ∂Êåâ`minute`Â≠óÊÆµÈôçÂ∫èÊéíÂ∫èÊù•ÁîüÊàêÔºåÂç≥ÊØè‰∏™‰∏çÂêåÁöÑ‰ª£Â∏ÅÈÉΩ‰ºöÁîüÊàêËá™Â∑±ÁöÑ1Ôºå2Ôºå3Ôºå4...ËøôÊ†∑ÁöÑË°åÂè∑Â∫èÂàóÂÄº„ÄÇÊàë‰ª¨Â∞ÜÂÖ∂ÊîæÂà∞‰∏Ä‰∏™Â≠êÊü•ËØ¢‰∏≠ÔºåÂ§ñÂ±ÇÊü•ËØ¢‰∏≠Á≠õÈÄâ`where row_num = 1`ÁöÑËÆ∞ÂΩïÔºåÂ∞±ÊòØÊØè‰∏™‰ª£Â∏ÅÊúÄÊñ∞ÁöÑËÆ∞ÂΩï„ÄÇËøôÁßçÊñπÊ≥ïÁúãËµ∑Êù•Á®çÊòæÂ§çÊùÇÔºå‰ΩÜÊòØÂÆûÈôÖÂ∫îÁî®‰∏≠ÁªèÂ∏∏ÈúÄË¶ÅÁî®Âà∞Á±ª‰ººÁöÑÊü•ËØ¢ÔºåÈÄöËøá`row_number()`ÂáΩÊï∞ÁîüÊàêÊñ∞ÁöÑÂàóÁÑ∂ÂêéÁî®‰∫éËøáÊª§Êï∞ÊçÆ„ÄÇ

## Êü•ËØ¢Âçï‰∏™ERC20‰ª£Â∏ÅÁöÑÊØèÊó•Âπ≥Âùá‰ª∑Ê†º

ÂΩìÊàë‰ª¨ÈúÄË¶ÅÊü•ËØ¢Êüê‰∏™ERC20‰ª£Â∏ÅÊØè‰∏ÄÂ§©ÁöÑÂπ≥Âùá‰ª∑Ê†ºÊó∂ÔºåÂè™ËÉΩ‰ΩøÁî®`prices.usd`Ë°®Êù•ÂÆûÁé∞„ÄÇÈÄöËøáËÆæÁΩÆË¶ÅÊü•ËØ¢‰ª∑Ê†ºÁöÑÊó•ÊúüËåÉÂõ¥ÔºàÊàñËÄÖ‰∏çÂä†Êó•ÊúüËåÉÂõ¥ÂèñÂÖ®ÈÉ®Êó•ÊúüÁöÑÊï∞ÊçÆÔºâÔºåÊåâÂ§©Ê±áÊÄªÔºå‰ΩøÁî®`avg()`ÂáΩÊï∞Ê±ÇÂæóÂπ≥ÂùáÂÄºÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞ÊåâÂ§©ÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
select date_trunc('day', minute) as block_date,
    avg(price) as price
from prices.usd
where symbol = 'WETH'
    and blockchain = 'ethereum'
    and minute >= date('2023-01-01')
group by 1
order by 1
```

Â¶ÇÊûúÊàë‰ª¨ÂêåÊó∂ËøòÈúÄË¶ÅËøîÂõûÂÖ∂‰ªñÂ≠óÊÆµÔºåÂèØ‰ª•ÊääÂÆÉ‰ª¨Âä†ÂÖ•SELECTÂàóË°®Âπ∂ÂêåÊó∂Âä†ÂÖ•Âà∞GROUP BYÈáåÈù¢„ÄÇËøôÊòØÂõ†‰∏∫ÔºåÂΩì‰ΩøÁî®`group by`Â≠êÂè•Êó∂ÔºåSELECTÂàóË°®‰∏≠Âá∫Áé∞ÁöÑÂ≠óÊÆµÂ¶ÇÊûú‰∏çÊòØÊ±áÊÄªÂáΩÊï∞Â∞±ÂøÖÈ°ªÂêåÊó∂Âá∫Áé∞Âú®GROUP BYÂ≠êÂè•‰∏≠„ÄÇSQL‰øÆÊîπÂêéÂ¶Ç‰∏ãÔºö

```sql
select date_trunc('day', minute) as block_date,
    symbol,
    decimals,
    contract_address,
    avg(price) as price
from prices.usd
where symbol = 'WETH'
    and blockchain = 'ethereum'
    and minute >= date('2023-01-01')
group by 1, 2, 3, 4
order by 1
```

## Êü•ËØ¢Â§ö‰∏™ERC20‰ª£Â∏ÅÁöÑÊØèÊó•Âπ≥Âùá‰ª∑Ê†º

Á±ª‰ººÂú∞ÔºåÊàë‰ª¨ÂèØ‰ª•ÂêåÊó∂Êü•ËØ¢‰∏ÄÁªÑERC20‰ª£Â∏ÅÊØè‰∏ÄÂ§©ÁöÑÂπ≥Âùá‰ª∑Ê†ºÔºåÂè™ÈúÄÂ∞ÜË¶ÅÊü•ËØ¢ÁöÑ‰ª£Â∏ÅÁöÑÁ¨¶Âè∑ÊîæÂÖ•`in ()`Êù°‰ª∂Â≠êÂè•ÈáåÈù¢Âç≥ÂèØ„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
select date_trunc('day', minute) as block_date,
    symbol,
    decimals,
    contract_address,
    avg(price) as price
from prices.usd
where symbol in ('WETH', 'WBTC', 'USDC')
    and blockchain = 'ethereum'
    and minute >= date('2022-10-01')
group by 1, 2, 3, 4
order by 2, 1   -- Order by symbol first
```

## ‰ªéDeFiÂÖëÊç¢ËÆ∞ÂΩïËÆ°ÁÆó‰ª∑Ê†º

Dune‰∏äÁöÑ‰ª∑Ê†ºÊï∞ÊçÆË°®`prices.usd`ÊòØÈÄöËøáspellbookÊù•Áª¥Êä§ÁöÑÔºåÈáåÈù¢Âπ∂Ê≤°ÊúâÂåÖÊã¨ÊâÄÊúâÊîØÊåÅÁöÑÂå∫ÂùóÈìæ‰∏äÈù¢ÁöÑÊâÄÊúâ‰ª£Â∏ÅÁöÑ‰ª∑Ê†º‰ø°ÊÅØ„ÄÇÁâπÂà´ÊòØÂΩìÊüê‰∏™Êñ∞ÁöÑERC20‰ª£Â∏ÅÊñ∞ÂèëË°å‰∏äÂ∏ÇÔºåÂú®DEX‰∫§ÊòìÊâÄËøõË°åÊµÅÈÄöÔºàÊØîÂ¶ÇXENÔºâÔºåÊ≠§Êó∂DuneÁöÑ‰ª∑Ê†ºË°®Âπ∂Ê≤°ÊúâËøô‰∏™‰ª£Â∏ÅÁöÑÊï∞ÊçÆ„ÄÇÊ≠§Êó∂ÔºåÊàë‰ª¨ÂèØ‰ª•ËØªÂèñDeFiÈ°πÁõÆ‰∏≠ÁöÑÂÖëÊç¢Êï∞ÊçÆÔºåÊØîÂ¶ÇUniswap‰∏≠ÁöÑSwapÊï∞ÊçÆÔºåÂ∞ÜÂØπÂ∫î‰ª£Â∏Å‰∏éUSDCÔºàÊàñËÄÖWETHÔºâ‰πãÈó¥ÁöÑÂÖëÊç¢‰ª∑Ê†ºËÆ°ÁÆóÂá∫Êù•ÔºåÂÜçÈÄöËøáUSDCÊàñWETHÁöÑ‰ª∑Ê†ºÊï∞ÊçÆÊç¢ÁÆóÂæóÂà∞ÁæéÂÖÉ‰ª∑Ê†º„ÄÇÁ§∫‰æãÊü•ËØ¢Â¶Ç‰∏ãÔºö

```sql
with xen_price_in_usdc as (
    select date_trunc('hour', evt_block_time) as block_date,
        'XEN' as symbol,
        '0x06450dee7fd2fb8e39061434babcfc05599a6fb8' as contract_address, -- XEN
        18 as decimals,
        avg(amount1 / amount0) / pow(10, (6-18)) as price   --USDC: 6 decimals, XEN: 18 decimals
    from (
        select contract_address,
            abs(amount0) as amount0,
            abs(amount1) as amount1,
            evt_tx_hash,
            evt_block_time
        from uniswap_v3_ethereum.Pair_evt_Swap
        where contract_address = '0x353bb62ed786cdf7624bd4049859182f3c1e9e5d'   -- XEN-USDC 1.00% Pair
            and evt_block_time > '2022-10-07'
            and evt_block_time > now() - interval '30 days'
    ) s
    group by 1, 2, 3, 4
),

usdc_price as (
    select date_trunc('hour', minute) as block_date,
        avg(price) as price
    from prices.usd
    where contract_address = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'   -- USDC
        and minute > '2022-10-07'
        and minute > now() - interval '30 days'
    group by 1
)

select x.block_date,
    x.price * u.price as price_usd
from xen_price_in_usdc x
inner join usdc_price u on x.block_date = u.block_date
order by x.block_date
```

‰∏äÈù¢Ëøô‰∏™Êü•ËØ¢ÊòØÊàë‰ª¨Âú®XEN CryptoÈ°πÁõÆÁöÑÊï∞ÊçÆÁúãÊùø‰∏≠ÁöÑ‰∏Ä‰∏™ÂÆûÈôÖÂ∫îÁî®ÔºåÂèÇËÄÉÈìæÊé•Â¶Ç‰∏ãÔºö
- Êï∞ÊçÆÁúãÊùøÔºö[XEN Crypto Overview](https://dune.com/sixdegree/xen-crypto-overview)
- Êü•ËØ¢Ôºö[XEN - price trend](https://dune.com/queries/1382200)

## ‰ªéDeFi‰∫§ÊòìÈ≠îÊ≥ïË°®ËÆ°ÁÆó‰ª∑Ê†º

Â¶ÇÊûúÁõ∏Â∫îÁöÑDeFi‰∫§ÊòìÊï∞ÊçÆÂ∑≤ÁªèÈõÜÊàêÂà∞‰∫Ü`dex.trades`Ë°®‰∏≠ÔºåÈÇ£‰πà‰ΩøÁî®ËØ•Ë°®Êù•ËÆ°ÁÆó‰ª∑Ê†º‰ºöÊõ¥Âä†ÁÆÄÂçï„ÄÇÊàë‰ª¨ÂèØ‰ª•Â∞Ü`amount_usd`‰∏é`token_bought_amount`ÊàñËÄÖ`token_sold_amount`Áõ∏Èô§ÔºåÂæóÂà∞ÂØπÂ∫î‰ª£Â∏ÅÁöÑUSD‰ª∑Ê†º„ÄÇ‰ª•Uniswap V3 ‰∏ãÁöÑ USDC-WETH 0.30% ‰∏∫‰æãÔºåËÆ°ÁÆóWETHÊúÄÊñ∞‰ª∑Ê†ºÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with trade_detail as (
    select block_time,
        tx_hash,
        amount_usd,
        token_bought_amount,
        token_bought_symbol,
        token_sold_amount,
        token_sold_symbol
    from dex.trades
    where project_contract_address = 0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8
        and block_date >= now() - interval '3' day
    order by block_time desc
    limit 1000
)

select avg(
    case when token_bought_symbol = 'WETH' then amount_usd / token_bought_amount
        else amount_usd / token_sold_amount
    end
    ) as price
from trade_detail
```

## ËÆ°ÁÆóÂéüÁîü‰ª£Â∏ÅÔºàETHÔºâÁöÑ‰ª∑Ê†º

‰ª•Ethereum‰∏∫‰æãÔºåÂÖ∂ÂéüÁîü‰ª£Â∏ÅETHÂπ∂‰∏çÂ±û‰∫éERC20‰ª£Â∏ÅÔºåÊâÄ‰ª•`prices.usd`Ë°®ÈáåÂπ∂Ê≤°ÊúâETHÊú¨Ë∫´ÁöÑ‰ª∑Ê†º‰ø°ÊÅØ„ÄÇ‰ΩÜÊòØÔºåWETH ‰ª£Â∏ÅÔºàWrapped ETHÔºâ‰∏éETHÊòØÁ≠âÂÄºÁöÑÔºåÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®WETHÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ„ÄÇ

## ÂÄüÁî®ÂÖ∂‰ªñÂå∫ÂùóÈìæÁöÑ‰ª∑Ê†ºÊï∞ÊçÆ

ÂΩì`prices.usd`‰∏≠Êâæ‰∏çÂà∞Êàë‰ª¨Ë¶ÅÂàÜÊûêÁöÑÂå∫ÂùóÈìæÁöÑ‰ª£Â∏Å‰ª∑Ê†ºÊï∞ÊçÆÊó∂ÔºåËøòÊúâ‰∏Ä‰∏™ÂèØ‰ª•ÂèòÈÄöÁöÑÊäÄÂ∑ß„ÄÇ‰æãÂ¶ÇÔºåAvalanche-C Èìæ‰πüÊèê‰æõUSDC„ÄÅWETH„ÄÅWBTC„ÄÅAAVEÁ≠â‰ª£Â∏ÅÁöÑ‰∫§ÊòìÔºå‰ΩÜÊòØÂÆÉ‰ª¨Áõ∏ÂØπ‰∫éEthereumÈìæÂàÜÂà´Êúâ‰∏çÂêåÁöÑ‰ª£Â∏ÅÂú∞ÂùÄ„ÄÇÂÅáÂ¶Ç`prices.usd`Êú™Êèê‰æõAvalache-CÈìæÁöÑ‰ª∑Ê†ºÊï∞ÊçÆÊó∂ÔºàÁõÆÂâçÂ∫îËØ•Â∑≤ÁªèÊîØÊåÅ‰∫ÜÔºâÔºåÊàë‰ª¨ÂèØ‰ª•Ëá™ÂÆö‰πâ‰∏Ä‰∏™CTEÔºåÂ∞Ü‰∏çÂêåÈìæ‰∏äÁöÑ‰ª£Â∏ÅÂú∞ÂùÄÊò†Â∞ÑËµ∑Êù•ÔºåÁÑ∂ÂêéËøõË°åÊü•ËØ¢Ëé∑Âèñ‰ª∑Ê†º„ÄÇ

```sql
with token_mapping_to_ethereum(aave_token_address, ethereum_token_address, token_symbol) as (
    values
    (0xfd086bc7cd5c481dcc9c85ebe478a1c0b69fcbb9, 0xdac17f958d2ee523a2206206994597c13d831ec7, 'USDT'),
    (0x2f2a2543b76a4166549f7aab2e75bef0aefc5b0f, 0x2260fac5e5542a773aa44fbcfedf7c193bc2c599, 'WBTC'),
    (0xd22a58f79e9481d1a88e00c343885a588b34b68b, 0xdb25f211ab05b1c97d595516f45794528a807ad8, 'EURS'),
    (0xff970a61a04b1ca14834a43f5de4533ebddb5cc8, 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48, 'USDC'),
    (0xf97f4df75117a78c1a5a0dbb814af92458539fb4, 0x514910771af9ca656af840dff83e8264ecf986ca, 'LINK'),
    (0x82af49447d8a07e3bd95bd0d56f35241523fbab1, 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2, 'WETH'),
    (0xda10009cbd5d07dd0cecc66161fc93d7c9000da1, 0x6b175474e89094c44da98b954eedeac495271d0f, 'DAI'),
    (0xba5ddd1f9d7f570dc94a51479a000e3bce967196, 0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9, 'AAVE')
),

latest_token_price as (
    select date_trunc('hour', minute) as price_date,
        contract_address,
        symbol,
        decimals,
        avg(price) as price
    from prices.usd
    where contract_address in (
        select ethereum_token_address
        from token_mapping_to_ethereum
    )
    and minute > now() - interval '1' day
    group by 1, 2, 3, 4
),

latest_token_price_row_num as (
    select  price_date,
        contract_address,
        symbol,
        decimals,
        price,
        row_number() over (partition by contract_address order by price_date desc) as row_num
    from latest_token_price
),

current_token_price as (
    select contract_address,
        symbol,
        decimals,
        price
    from latest_token_price_row_num
    where row_num = 1
)

select * from current_token_price
```

ËøôÊòØÊàë‰ª¨Âú®Á∫øÁöÑÁ§∫‰æãÊü•ËØ¢Ôºö[https://dune.com/queries/1042456](https://dune.com/queries/1042456)


## ‰ªé‰∫ã‰ª∂Êó•ÂøóËÆ∞ÂΩïËÆ°ÁÆó‰ª∑Ê†º

ÊèêÁ§∫ÔºöÊú¨Â∞èËäÇÁöÑÂÜÖÂÆπÁõ∏ÂØπÊØîËæÉÂ§çÊùÇÔºåÂ¶ÇÊûúËßâÂæóÊúâÈöæÂ∫¶ÔºåÂèØ‰ª•Áõ¥Êé•Ë∑≥Ëøá„ÄÇ

‰∏ÄÁßçÊØîËæÉÁâπÊÆäÁöÑÊÉÖÂÜµÊòØÂΩìÂàÜÊûê‰∏Ä‰∏™Êñ∞ÁöÑDeFiÈ°πÁõÆÊàñËÄÖ‰∏Ä‰∏™DuneÊñ∞ËøëÊîØÊåÅÁöÑÂå∫ÂùóÈìæÁöÑÊó∂ÂÄô„ÄÇÊ≠§Êó∂ËøòÊ≤°ÊúâÁõ∏Â∫îÁöÑ`prices.usd`Êï∞ÊçÆÔºåÂØπÂ∫îÈ°πÁõÆÁöÑÊô∫ËÉΩÂêàÁ∫¶ËøòÊ≤°ÊúâË¢´Êèê‰∫§Ëß£ÊûêÂÆåÊàêÔºå‰∫§ÊòìËÆ∞ÂΩï‰πüÊ≤°ÊúâË¢´ÈõÜÊàêÂà∞`dex.trades`ËøôÊ†∑ÁöÑÈ≠îÊ≥ïË°®‰∏≠„ÄÇÊ≠§Êó∂ÔºåÊàë‰ª¨ÂîØ‰∏ÄËÉΩËÆøÈóÆÁöÑÂ∞±ÊòØ`transactions`Âíå`logs`ËøôÊ†∑ÁöÑÂéüÂßãÊï∞ÊçÆË°®„ÄÇÊ≠§Êó∂ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÊâæÂà∞Âá†‰∏™‰∫§ÊòìËÆ∞ÂΩïÔºåÂàÜÊûêÂú®Âå∫ÂùóÈìæ‰∏äÊòæÁ§∫ÁöÑ‰∫ã‰ª∂Êó•ÂøóÁöÑËØ¶ÁªÜÔºåÁ°ÆÂÆö‰∫ã‰ª∂ÁöÑ`data`ÂÄºÈáåÈù¢ÂåÖÂê´ÁöÑÊï∞ÊçÆÁ±ªÂûãÂíåÁõ∏ÂØπ‰ΩçÁΩÆÔºåÂÜçÊçÆÊ≠§ÊâãÂä®Ëß£ÊûêÊï∞ÊçÆÁî®‰∫éÊç¢ÁÆó‰ª∑Ê†º„ÄÇ

ÊØîÂ¶ÇÔºåÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóOptimismÈìæ‰∏ä$OP‰ª£Â∏ÅÁöÑ‰ª∑Ê†ºÔºåÂπ∂‰∏îÂÅáÂÆöÊ≠§Êó∂Êª°Ë∂≥ÂâçËø∞ÊâÄÊúâÊÉÖÂÜµÔºåÂøÖÈ°ª‰ªé‰∫§Êòì‰∫ã‰ª∂Êó•ÂøóÂéüÂßãË°®Êù•ËÆ°ÁÆó‰ª∑Ê†º„ÄÇÊàë‰ª¨ÂÖàÊ†πÊçÆÈ°πÁõÆÊñπÊèê‰æõÁöÑÁ∫øÁ¥¢ÔºàÂêàÁ∫¶Âú∞ÂùÄ„ÄÅÊ°à‰æãÂìàÂ∏åÁ≠âÔºâÊâæÂà∞‰∏Ä‰∏™ÂÖëÊç¢‰∫§ÊòìËÆ∞ÂΩïÔºö[https://optimistic.etherscan.io/tx/0x1df6dda6a4cffdbc9e477e6682b982ca096ea747019e1c0dacf4aceac3fc532f](https://optimistic.etherscan.io/tx/0x1df6dda6a4cffdbc9e477e6682b982ca096ea747019e1c0dacf4aceac3fc532f)„ÄÇËøôÊòØ‰∏Ä‰∏™ÂÖëÊç¢‰∫§ÊòìÔºåÂÖ∂‰∏≠ÊúÄÂêé‰∏Ä‰∏™`logs`Êó•ÂøóÁöÑ`topic1`ÂÄº‚Äú0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822‚ÄùÂØπÂ∫î‚ÄúSwap(address,uint256,uint256,uint256,uint256,address)‚ÄùÊñπÊ≥ï„ÄÇËøô‰∏™ÂèØ‰ª•ÈÄöËøáÊü•ËØ¢`decoding.evm_signatures`Ë°®Êù•Ëøõ‰∏ÄÊ≠•È™åËØÅÔºàËøôÊòØÂõ†‰∏∫OptimismÊòØEVMÂÖºÂÆπÁöÑÂå∫ÂùóÈìæÔºåÂÖ∂‰ΩøÁî®ÁöÑÁõ∏ÂÖ≥ÂáΩÊï∞‰∏éEthereumÁõ∏ÂêåÔºâ„ÄÇ

Âå∫ÂùóÈìæÊµèËßàÂô®‰∏äÁöÑÊó•ÂøóÈÉ®ÂàÜÊà™ÂõæÂ¶Ç‰∏ãÔºö

![image_01.png](img/image_01.png)

evm_signaturesÁ≠æÂêçÊï∞ÊçÆÊü•ËØ¢ÁöÑÊà™ÂõæÂ¶Ç‰∏ãÔºö

![image_02.png](img/image_02.png)

‰∏äÂõæÊü•ËØ¢`evm_signatures`Êó∂Êàë‰ª¨ÂÅö‰∫Ü‰∏Ä‰∏ãÂ§ÑÁêÜ‰ª•ËÆ©Áõ∏ÂÖ≥ÂêÑÂàóÊï∞ÊçÆ‰ªé‰∏äÂà∞‰∏ãÊòæÁ§∫„ÄÇÂØπÂ∫îÁöÑSQL‰∏∫Ôºö

```sql
select 'ID:' as name, cast(id as varchar) as value
from decoding.evm_signatures
where id = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822
union all
select 'Signature:' as name, signature as value
from decoding.evm_signatures
where id = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822
union all
select 'ABI:' as name, abi as value
from decoding.evm_signatures
where id = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822
```

ÁªìÂêà‰∏äËø∞Áõ∏ÂÖ≥‰ø°ÊÅØÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÈÄöËøáËß£Êûê‰∫ã‰ª∂Êó•ÂøóÈáåÈù¢ÁöÑSwapËÆ∞ÂΩïÔºåÊç¢ÁÆóÂá∫‰ª∑Ê†º„ÄÇÂú®‰∏ãÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨ÂèñÊúÄÊñ∞1000Êù°‰∫§ÊòìËÆ∞ÂΩïÊù•ËÆ°ÁÆóÂπ≥Âùá‰ª∑Ê†º„ÄÇÂõ†‰∏∫‰∫§Êç¢ÊòØÂèåÂêëÁöÑÔºåÂèØËÉΩ‰ªé`token0` ÂÖëÊç¢‰∏∫ `token1`ÊàñËÄÖ‰∏é‰πãÁõ∏ÂèçÔºåÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™caseËØ≠Âè•Áõ∏Â∫îÂèñÂá∫‰∏çÂêåÁöÑÂÄºÁî®Êù•ËÆ°ÁÆó‰∫§ÊòìÁöÑ‰ª∑Ê†º„ÄÇÂè¶Â§ñÔºåÊàë‰ª¨Ê≤°ÊúâÂÜçËøõ‰∏ÄÊ≠•ÂèñÂæóUSDCÁöÑ‰ª∑Ê†ºÊù•Êç¢ÁÆóÔºåÊØïÁ´üÂÖ∂Êú¨Ë∫´ÊòØÁ®≥ÂÆöÂ∏ÅÔºå‰ª∑Ê†ºÊ≥¢Âä®ËæÉÂ∞è„ÄÇÈúÄË¶ÅÊõ¥Á≤æÁ°ÆÁöÑÊï∞ÊçÆÊó∂ÔºåÂèØ‰ª•ÂèÇËÄÉÂâçÈù¢ÁöÑ‰æãÂ≠êÈÄöËøáUSDCÁöÑ‰ª∑Ê†º‰ø°ÊÅØÊç¢ÁÆó„ÄÇ

```sql
with op_price as (
    select 0x4200000000000000000000000000000000000042 as token_address,
        'OP' as token_symbol,
        18 as decimals,
        avg(
            (case when amount0_in > 0 then amount1_out else amount1_in end) 
            / 
            (case when amount0_in > 0 then amount0_in else amount0_out end)
        ) as price
    from (
        select tx_hash,
            index,
            cast(bytearray_to_uint256(bytearray_substring(data, 1, 32)) as decimal(38, 0)) / 1e18 as amount0_in,
            cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) / 1e6  as amount1_in,
            cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32 * 2, 32)) as decimal(38, 0)) / 1e18  as amount0_out,
            cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32 * 3, 32)) as decimal(38, 0)) / 1e6  as amount1_out
        from optimism.logs
        where block_time >= now() - interval '2' day
            and contract_address = 0x47029bc8f5cbe3b464004e87ef9c9419a48018cd -- OP - USDC Pair
            and topic0 = 0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822   -- Swap
        order by block_time desc
        limit 1000
    )
)

select * from op_price
```

ËøôÈáåÊòØ‰∏Ä‰∏™ÂÆûÈôÖ‰ΩøÁî®ÁöÑÊ°à‰æãÔºö[https://dune.com/queries/1130354](https://dune.com/queries/1130354)

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch11/ch10-useful-queries-part2.md">
# Â∏∏ËßÅÊü•ËØ¢‰∫åÔºö‰ª£Â∏ÅÁöÑÊåÅÊúâËÄÖ„ÄÅÊÄª‰æõÂ∫îÈáè„ÄÅË¥¶Êà∑‰ΩôÈ¢ù

Âú®Â∏∏ËßÅÊü•ËØ¢ÁöÑÁ¨¨‰∏ÄÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨‰∏ªË¶ÅËÆ≤Ëß£‰∫ÜÊü•ËØ¢ERC20‰ª£Â∏Å‰ª∑Ê†ºÁöÑÂêÑÁßç‰∏çÂêåÊñπÊ≥ï„ÄÇÈÄöÂ∏∏Êàë‰ª¨ËøòÈúÄË¶ÅÊü•ËØ¢Êüê‰∏™‰ª£Â∏ÅÁöÑÊåÅÊúâËÄÖÊï∞Èáè„ÄÅ‰ª£Â∏ÅÊÄª‰æõÂ∫îÈáèÔºàÊµÅÈÄöÈáèÔºâ„ÄÅÂêÑÊåÅÊúâËÄÖÁöÑË¥¶Êà∑‰ΩôÈ¢ùÔºà‰æãÂ¶ÇÊåÅÊúâÊúÄÂ§öÁöÑË¥¶Âè∑ÁöÑ‰ΩôÈ¢ùÔºâÁ≠âÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÊé•‰∏ãÊù•Êàë‰ª¨ÈíàÂØπËøôÈÉ®ÂàÜÂÜÖÂÆπËøõË°å‰ªãÁªç„ÄÇ

‰∏éÊØîÁâπÂ∏ÅÈÄöËøáÊú™Ëä±Ë¥πÁöÑ‰∫§Êòì‰∫ßÂá∫ÔºàUTXOÔºâÊù•Ë∑üË∏™Ë¥¶Êà∑‰ΩôÈ¢ù‰∏çÂêåÔºå‰ª•Ethereum‰∏∫‰ª£Ë°®ÁöÑEVMÂÖºÂÆπÂå∫ÂùóÈìæ‰ΩøÁî®‰∫ÜË¥¶Êà∑‰ΩôÈ¢ùÁöÑÊ®°Âûã„ÄÇÊØè‰∏™Ë¥¶Âè∑Âú∞ÂùÄÊúâÈíàÂØπÊØèÁßçERC20‰ª£Â∏ÅÁöÑËΩ¨ÂÖ•ËÆ∞ÂΩïÂíåËΩ¨Âá∫ËÆ∞ÂΩïÔºåÂ∞ÜËøô‰∫õËΩ¨ÂÖ•ÂíåËΩ¨Âá∫Êï∞ÊçÆÊ±áÊÄªÂà∞‰∏ÄËµ∑ÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞Ë¥¶Êà∑ÁöÑÂΩìÂâç‰ΩôÈ¢ù„ÄÇÂõ†‰∏∫Âå∫ÂùóÈìæÊú¨Ë∫´Âπ∂Ê≤°Êúâ‰øùÂ≠òÊØè‰∏™Âú∞ÂùÄÁöÑÂΩìÂâç‰ΩôÈ¢ùÔºåÊàë‰ª¨ÂøÖÈ°ªÈÄöËøáËÆ°ÁÆóÊâçËÉΩÂæóÂà∞Ëøô‰∏™Êï∞ÊçÆ„ÄÇDune V2ÁöÑÈ≠îÊ≥ïË°®`erc20_day`„ÄÅ`erc20_latest`ÔºàË∑ØÂæÑÔºöSpells/balances/ethereum/erc20/ÔºâÁ≠âÂ∞ÜÊØè‰∏™Âú∞ÂùÄ‰∏ãÊØèÁßçERC20‰ª£Â∏ÅÁöÑÊúÄÊñ∞‰ΩôÈ¢ù„ÄÅÊØèÂ§©ÁöÑ‰ΩôÈ¢ùËøõË°å‰∫ÜÊï¥ÁêÜÊõ¥Êñ∞ÔºåÂèØ‰ª•Áî®‰∫éÊü•ËØ¢„ÄÇ‰ΩÜÊòØÊ†πÊçÆÊµãËØïÔºå‰ΩøÁî®Ëøô‰∫õÈ≠îÊ≥ïË°®ÁõÆÂâçÂ≠òÂú®‰∏§‰∏™ÈóÆÈ¢òÔºö‰∏ÄÊòØÁõÆÂâçËøòÂè™ÊúâEthereumÈìæÁöÑË¥¶Êà∑‰ΩôÈ¢ùÈ≠îÊ≥ïË°®ÔºåÂ∞ö‰∏çÊîØÊåÅÊü•ËØ¢ÂÖ∂‰ªñÈìæÁöÑÊï∞ÊçÆÔºõ‰∫åÊòØÁúãËµ∑Êù•Ëøô‰∫õË°®ÁöÑÊü•ËØ¢ÊÄßËÉΩÂπ∂‰∏çÊòØÂæàÁêÜÊÉ≥„ÄÇÊâÄ‰ª•Êàë‰ª¨ËøôÈáå‰∏ç‰ªãÁªçËøô‰∫õË°®ÁöÑ‰ΩøÁî®ÔºåÂ§ßÂÆ∂ÂèØ‰ª•Ëá™Ë°åÊé¢Á¥¢„ÄÇ

Ë¶ÅÊü•ËØ¢Âçï‰∏™ERC20‰ª£Â∏ÅÁöÑË¥¶Êà∑‰ΩôÈ¢ù‰ø°ÊÅØÔºåÈ¶ñÂÖàÊàë‰ª¨ÈúÄË¶ÅÁü•ÈÅìÂØπÂ∫î‰ª£Â∏ÅÁöÑÂêàÁ∫¶Âú∞ÂùÄ„ÄÇËøô‰∏™ÂèØ‰ª•ÈÄöËøáÊü•ËØ¢`tokens.erc20`Ë°®Êù•Ëé∑Âæó„ÄÇÊØîÂ¶ÇÊàë‰ª¨ÊÉ≥Êü•ËØ¢FTT TokenÁöÑ‰ø°ÊÅØÔºåÂèØ‰ª•ÊâßË°å‰∏ãÈù¢ÁöÑÊü•ËØ¢Ôºå‰ªéÊü•ËØ¢ÁªìÊûúÊàë‰ª¨ÂæóÂà∞FTT TokenÁöÑÂêàÁ∫¶Âú∞ÂùÄÊòØÔºö 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9 „ÄÇ

```sql
select * from tokens.erc20
where symbol = 'FTT'
    and blockchain = 'ethereum'
```

## Êü•ËØ¢‰ª£Â∏ÅÊåÅÊúâËÄÖÊï∞ÈáèÂíå‰ª£Â∏ÅÁöÑÊÄªÊµÅÈÄöÈáè

Â¶ÇÂâçÊâÄËø∞Ôºå‰∏çÁÆ°ÊòØË¶ÅËÆ°ÁÆóÊüê‰∏™Ë¥¶Êà∑‰∏ãÊüê‰∏™‰ª£Â∏ÅÁöÑ‰ΩôÈ¢ùÔºåËøòÊòØËÆ°ÁÆóÊüê‰∏™‰ª£Â∏ÅÂÖ®ÈÉ®ÊåÅÊúâËÄÖË¥¶Êà∑‰∏ãÁöÑ‰ΩôÈ¢ùÔºåÊàë‰ª¨ÈÉΩÈúÄË¶ÅÂ∞ÜËΩ¨ÂÖ•ËΩ¨Âá∫Êï∞ÊçÆÂêàÂπ∂Âà∞‰∏ÄËµ∑„ÄÇÂØπ‰∫éËΩ¨ÂÖ•Êï∞ÊçÆÔºåÊàë‰ª¨Âèñ`to`‰∏∫Áî®Êà∑ÁöÑÂú∞ÂùÄÔºåÈáëÈ¢ù‰∏∫Ê≠£Êï∞„ÄÇÂØπ‰∫éËΩ¨Âá∫Êï∞ÊçÆÔºåÂàôÂèñ`from`‰∏∫Áî®Êà∑Âú∞ÂùÄÔºåÂêåÊó∂ÈáëÈ¢ù‰πò‰ª•‚Äú-1‚Äù‰ΩøÂÖ∂ÂèòÊàêË¥üÊï∞„ÄÇ‰ΩøÁî®`union all`Â∞ÜÊâÄÊúâËÆ∞ÂΩïÂêàÂπ∂Âà∞‰∏ÄËµ∑„ÄÇ‰ª•‰∏ãÁ§∫‰æã‰ª£Á†ÅËÄÉËôëÊâßË°åÊÄßËÉΩÈóÆÈ¢òÔºåÁâπÊÑèÂ¢ûÂä†‰∫Ü`limit 10`ÈôêÂà∂Êù°‰ª∂Ôºö

```sql
select * from (
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "to" as address,
        cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9

    union all
    
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9
)
limit 10    -- for performance
```

Âú®‰∏äÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®`union all`Â∞ÜÊØè‰∏™Ë¥¶Êà∑Âú∞ÂùÄ‰∏≠ËΩ¨ÂÖ•ÁöÑÂíåËΩ¨Âá∫ÁöÑFTT TokenÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºåÂπ∂‰∏îÂè™Âèñ‰∫Ü10Êù°Ê†∑Êú¨Êï∞ÊçÆ„ÄÇÊ≥®ÊÑèÊàë‰ª¨‰ΩøÁî®`value::decimal(38, 0)`ÂØπ`value`Â≠óÊÆµÂØπÂÄºËøõË°å‰∫ÜÂº∫Âà∂ËΩ¨Êç¢ÔºåÂõ†‰∏∫Áé∞Âú®Ëøô‰∏™Â≠óÊÆµÊòØ‰ª•Â≠óÁ¨¶‰∏≤ÂΩ¢Âºè‰øùÂ≠òÁöÑÔºå‰∏çÂÅöËΩ¨Êç¢‰ºöÂú®ËÆ°ÁÆóÊó∂ÈÅáÂà∞‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇËøôÈáåÁöÑÊï∞Â≠ó38ÊòØÁõÆÂâçDuneÁöÑÂ∫ïÂ±ÇÊï∞ÊçÆÂ∫ìÊîØÊåÅÁöÑÊúÄÂ§ßÊï¥Êï∞‰ΩçÊï∞Ôºå0Ë°®Á§∫‰∏çÂê´Â∞èÊï∞‰Ωç„ÄÇ

ËøôÈáåÂêàÂπ∂Âà∞‰∏ÄËµ∑ÁöÑÊòØÊòéÁªÜËΩ¨Ë¥¶Êï∞ÊçÆÔºåÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÁöÑË¥¶Êà∑‰ΩôÈ¢ùÊòØÊ±áÊÄªÊï∞ÊçÆÔºåÂèØ‰ª•Âú®‰∏äËø∞Êü•ËØ¢Âü∫Á°Ä‰∏äÔºåÂ∞ÜÂÖ∂ÊîæÂÖ•‰∏Ä‰∏™CTEÂÆö‰πâ‰∏≠ÔºåÁÑ∂ÂêéÈíàÂØπCTEÊâßË°åÊ±áÊÄªÁªüËÆ°„ÄÇËÄÉËôëÂà∞ÂæàÂ§ö‰ª£Â∏ÅÁöÑÊåÅÊúâ‰∫∫Âú∞ÂùÄÊï∞ÈáèÂèØËÉΩÂæàÂ§öÔºàÂá†‰∏áÁîöËá≥Êõ¥Â§öÔºâÔºåÊàë‰ª¨ÈÄöÂ∏∏ÂÖ≥Ê≥®ÁöÑÊòØÊÄªÊåÅÊúâ‰∫∫Êï∞„ÄÅÊÄªÊµÅÈÄöÈáèÂíåÊåÅÊúâÈáèÊúÄÂ§öÁöÑÈÇ£ÈÉ®ÂàÜÂú∞ÂùÄÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÊåâÂú∞ÂùÄÊ±áÊÄªÁöÑÊü•ËØ¢‰πüÊîæÂÖ•‰∏Ä‰∏™CTE‰∏≠ÔºåÊñπ‰æøÂú®Ê≠§Âü∫Á°Ä‰∏äÊ†πÊçÆÈúÄË¶ÅÂÅöËøõ‰∏ÄÊ≠•ÁöÑÁªüËÆ°„ÄÇËøôÈáåÊàë‰ª¨È¶ñÂÖàÁªüËÆ°ÊåÅÊúâËÄÖÊÄªÊï∞ÔºåÊü•ËØ¢Êó∂ÊéíÈô§ÈÇ£‰∫õÂΩìÂâç‰ª£Â∏Å‰ΩôÈ¢ù‰∏∫0ÁöÑÂú∞ÂùÄ„ÄÇÊñ∞ÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with transfer_detail as (
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "to" as address,
        cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9
    
    union all
    
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = 0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9
),

address_balance as (
    select address,
        sum(amount) as balance_amount
    from transfer_detail
    group by address
)

select count(*) as holder_count,
    sum(balance_amount / 1e18) as supply_amount
from address_balance
where balance_amount > 0
```

‰∏äÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨Âú®`address_balance`Ëøô‰∏™CTEÈáåÈù¢ÊåâÂú∞ÂùÄÁªüËÆ°‰∫ÜË¥¶Êà∑‰ΩôÈ¢ùÔºåÁÑ∂ÂêéÂú®ÊúÄÂêéÁöÑÊü•ËØ¢‰∏≠ËÆ°ÁÆóÂΩìÂâç‰ΩôÈ¢ùÂ§ß‰∫é0ÁöÑÂú∞ÂùÄÊï∞ÈáèÔºàÊåÅÊúâËÄÖÊï∞ÈáèÔºâÂíåÊâÄÊúâË¥¶Êà∑ÁöÑ‰ΩôÈ¢ùÊ±áÊÄªÔºàÊµÅÈÄöÊÄªÈáèÔºâ„ÄÇÂõ†‰∏∫FTT‰ª£Â∏ÅÁöÑÂ∞èÊï∞‰ΩçÊï∞ÊòØ18‰ΩçÔºåÊàë‰ª¨Âú®ËÆ°ÁÆó`supply_amount`Êó∂ÔºåÂ∞ÜÂéüÂßãÈáëÈ¢ùÈô§‰ª•`1e18`Â∞±Êç¢ÁÆóÊàê‰∫ÜÂ∏¶ÊúâÂ∞èÊï∞‰ΩçÊï∞ÁöÑÈáëÈ¢ùÔºåËøô‰∏™Â∞±ÊòØFTT‰ª£Â∏ÅÁöÑÊÄªÊµÅÈÄöÈáè„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÔºå‰∏çÂêåÁöÑERC20‰ª£Â∏ÅÊúâ‰∏çÂêåÁöÑÂ∞èÊï∞‰ΩçÊï∞ÔºåÂâçÈù¢Êü•ËØ¢`tokens.erc20`Ë°®ÁöÑËøîÂõûÁªìÊûúÊúâËøô‰∏™Êï∞ÊçÆ„ÄÇ`1e18`ÊòØ`power(10, 18)`ÁöÑ‰∏ÄÁßçÁ≠â‰ª∑Áº©ÂÜôÔºåË°®Á§∫Ê±Ç10ÁöÑ18Ê¨°Êñπ„ÄÇÁî±‰∫éFTT‰ª£Â∏ÅÊúâ2‰∏áÂ§ö‰∏™ÊåÅÊúâÂú∞ÂùÄÔºåËøô‰∏™Êü•ËØ¢Áõ∏ÂØπËÄóÊó∂ËæÉÈïøÔºåÂèØËÉΩÈúÄË¶ÅÂá†ÂàÜÈíüÊâçËÉΩÊâßË°åÂÆåÊØï„ÄÇ

Êü•ËØ¢ÁªìÊûúÊòæÁ§∫Â¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇÂØπÊØîEtherscan‰∏äÈù¢ÁöÑÊï∞ÊçÆ[https://etherscan.io/token/0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9](https://etherscan.io/token/0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9)ÂèØ‰ª•ÁúãÂà∞Ôºå‰ª£Â∏ÅÁöÑÊµÅÈÄöÊÄªÈáèÈáèÂü∫Êú¨ÂêªÂêàÔºå‰ΩÜÊòØÊåÅÊúâ‰∫∫Êï∞ÈáèÊúâ‰∏ÄÂÆöÁöÑÂ∑ÆÂºÇ„ÄÇËøôÁßçÂ∑ÆÂºÇÊòØÁî±‰∫éÂØπ‰ΩôÈ¢ùÁâπÂà´Â∞ëÁöÑË¥¶Êà∑ÁöÑÂà§ÂÆöÊ†áÂáÜÁöÑ‰∏çÂêåËÄåÂºïËµ∑ÁöÑÔºåÊàë‰ª¨ÂèØ‰ª•Âú®Ê±áÊÄªÊØè‰∏™Âú∞ÂùÄÁöÑ‰ΩôÈ¢ùÊó∂Â∞±Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Â∏¶ÊúâÂ∞èÊï∞‰ΩçÊï∞ÁöÑÂÄºÔºåÊúÄÂêéÁªüËÆ°ÊåÅÊúâËÄÖÊï∞ÈáèÂíåÊÄªÊµÅÈÄöÈáèÊó∂ÂøΩÁï•‰ΩôÈ¢ùÁâπÂà´Â∞èÁöÑÈÇ£ÈÉ®ÂàÜË¥¶Êà∑„ÄÇ‰∏Ä‰∏™ÁªèÈ™åÊ≥ïÂàôÊòØÂèØ‰ª•ÂøΩÁï•‰ΩôÈ¢ùÂ∞è‰∫é`0.001`ÊàñËÄÖ`0.0001`ÁöÑÂú∞ÂùÄ„ÄÇ

![image_03.png](img/image_03.png)

ÂèÇËÄÉÊü•ËØ¢Á§∫‰æãÔºö[https://dune.com/queries/1620179](https://dune.com/queries/1620179)

## Êü•ËØ¢ÊåÅÊúâ‰ª£Â∏ÅÊúÄÂ§öÁöÑÂú∞ÂùÄ

Âú®ÂâçÈù¢Êü•ËØ¢‰ª£Â∏ÅÊåÅÊúâËÄÖÊï∞ÈáèÂíåÊµÅÈÄöÈáèÁöÑQuery‰∏≠ÔºåÊàë‰ª¨Â∑≤ÁªèÊåâÂú∞ÂùÄÊ±áÊÄªÁªüËÆ°‰∫ÜÊØè‰∏™ÊåÅÊúâËÄÖÂΩìÂâçÁöÑ‰ª£Â∏Å‰ΩôÈ¢ù„ÄÇÂõ†Ê≠§ÂèØ‰ª•ÂæàÂÆπÊòìÂú®Ê≠§Âü∫Á°Ä‰∏äÊü•ËØ¢Âá∫ÈÇ£‰∫õÊåÅÊúâ‰ª£Â∏ÅÊï∞ÈáèÊúÄÂ§öÁöÑÁî®Êà∑Âú∞ÂùÄ‰ª•Âèä‰ªñ‰ª¨ÂêÑËá™ÁöÑÊåÅÊúâÊï∞Èáè„ÄÇËøôÈáåÂèØ‰ª•ForkËøô‰∏™Êü•ËØ¢ËøõË°å‰øÆÊîπÔºå‰πüÂèØ‰ª•Â§çÂà∂Êü•ËØ¢‰ª£Á†ÅÂÜçÊñ∞Âª∫Êü•ËØ¢„ÄÇÂõ†‰∏∫Êàë‰ª¨Êü•ËØ¢ÁöÑÊòØÂçï‰∏™‰ª£Â∏ÅÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÁ°¨ÁºñÁ†ÅÁöÑ‰ª£Â∏ÅÂú∞ÂùÄÊõøÊç¢‰∏∫‰∏Ä‰∏™Êü•ËØ¢ÂèÇÊï∞`{{token_contract_address}}`ÔºåÂπ∂Â∞Ü‰∏äÈù¢FTT‰ª£Â∏ÅÁöÑÂêàÁ∫¶Âú∞ÂùÄËÆæÁΩÆ‰∏∫ÈªòËÆ§ÂÄºÔºåËøôÊ†∑Â∞±ÂèØ‰ª•ÁÅµÊ¥ªÂú∞Êü•ËØ¢‰ªªÊÑè‰ª£Â∏ÅÁöÑÊï∞ÊçÆ‰∫Ü„ÄÇ‰∏ãÈù¢ÁöÑÊü•ËØ¢ËøîÂõûÊåÅÊúâ‰ª£Â∏ÅÊï∞ÈáèÊúÄÂ§öÁöÑ100‰∏™Âú∞ÂùÄÔºö

```sql
with transfer_detail as (
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "to" as address,
        cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = {{token_contract_address}}
    
    union all
    
    select evt_block_time,
        evt_tx_hash,
        contract_address,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as amount
    from erc20_ethereum.evt_Transfer
    where contract_address = {{token_contract_address}}
),

address_balance as (
    select address,
        sum(amount / 1e18) as balance_amount
    from transfer_detail
    group by address
)

select address,
    balance_amount
from address_balance
order by 2 desc
limit 100
```

‰ΩøÁî®FTT‰ª£Â∏ÅÂêàÁ∫¶Âú∞ÂùÄÈªòËÆ§ÂèÇÊï∞Ôºå‰∏äÈù¢ÁöÑÊü•ËØ¢ËøîÂõûÊåÅÊúâFTTÊï∞ÈáèÊúÄÂ§öÁöÑ100‰∏™Âú∞ÂùÄ„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂèØËßÜÂåñ‰∏Ä‰∏™Êü±Áä∂ÂõæÔºåÂØπÊØîÂâç100ÂêçÊåÅÊúâËÄÖÁöÑÊåÅÊúâÈáëÈ¢ùÊÉÖÂÜµ„ÄÇÂõ†ÈáëÈ¢ùÂ∑ÆÂºÇÊòéÊòæÔºåÊàë‰ª¨ÈÄâÊã©Â∞ÜYËΩ¥Êï∞ÊçÆÂØπÊï∞ÂåñÂ§ÑÁêÜÔºåÂãæÈÄâLogarithmicÈÄâÈ°π„ÄÇÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_04.png](img/image_04.png)

ÂèÇËÄÉÊü•ËØ¢Á§∫‰æãÔºö[https://dune.com/queries/1620917](https://dune.com/queries/1620917)

## Êü•ËØ¢‰∏çÂêå‰ª£Â∏ÅÊåÅÊúâËÄÖÁöÑÊåÅÊúâÈáëÈ¢ùÂàÜÂ∏É

Â¶ÇÊûúÊàë‰ª¨ÈúÄË¶Å‰∫ÜËß£ÊåÅÊúâÊüê‰∏™ERC20‰ª£Â∏ÅÁöÑÊâÄÊúâÁî®Êà∑Âú∞ÂùÄÁöÑË¥¶Êà∑‰ΩôÈ¢ùÁöÑÂàÜÂ∏ÉÊÉÖÂÜµÔºåÊúâ‰∏§ÁßçÂèØÈÄâÁöÑÊñπÂºèÔºå‰∏ÄÁßçÊñπÂºè‰ΩøÁî®ÁªèÈ™åÊ≥ïÂàôËÆæÁΩÆÂàÜÂå∫ÔºåÂæóÂà∞ÁöÑÁªìÊûúÁõ∏ÂØπÊØîËæÉÁ≤óÁï•ÔºåÂèØËÉΩ‰ºöÈîôËøá‰∏Ä‰∫õÂÖ≥ÈîÆÁâπÂæÅÔºåËÄå‰∏îÂú®ÈúÄË¶ÅÂêåÊó∂ÊîØÊåÅÂàÜÊûêÂ§öÁßç‰∏çÂêåÁöÑ‰ª£Â∏ÅÊó∂‰πü‰∏çÂ§üÁÅµÊ¥ª„ÄÇÂè¶‰∏ÄÁßçÊñπÂºèÂàôÊØîËæÉÁ≤æÁ°ÆÔºå‰ΩÜÂêåÊó∂‰πüÊõ¥Âä†Â§çÊùÇ„ÄÇÊàë‰ª¨ÂàÜÂà´ËøõË°å‰ªãÁªç„ÄÇ

**ÊåâÁªèÈ™åÊ≥ïÂàôÁªüËÆ°ÂàÜÂ∏ÉÊÉÖÂÜµÔºö** Âõ†‰∏∫ÁªüËÆ°ÁöÑÊòØÈáëÈ¢ùÁöÑÂå∫Èó¥ÂàÜÂ∏ÉÔºàÁªüËÆ°Êï∞ÈáèÂàÜÂ∏ÉÊó∂‰πüÁ±ª‰ººÔºâÊàë‰ª¨ÂèØ‰ª•ÈÄâÊã©ÂÖ∏ÂûãÁöÑÈáëÈ¢ùËøõË°åÂàÜÂå∫Ôºö10000‰ª•‰∏äÔºå1000-10000‰πãÈó¥Ôºå500-1000‰πãÈó¥Ôºå100-500‰πãÈó¥Ôºå10-100‰πãÈó¥Ôºå1-10‰πãÈó¥Ôºå‰ª•ÂèäÂ∞è‰∫é1Á≠â„ÄÇÂΩìÁÑ∂‰Ω†ÂèØ‰ª•Ê†πÊçÆÂàÜÊûêÁöÑÂÖ∑‰Ωì‰ª£Â∏ÅÁöÑÊÄªÂèëË°åÈáèËøõË°åË∞ÉÊï¥Â∑≤Êª°Ë∂≥ÈúÄÊ±Ç„ÄÇÊü•ËØ¢‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
with transfer_detail as (
    -- Same as previous sample
),

address_balance as (
    select address,
        sum(amount / 1e18) as balance_amount
    from transfer_detail
    group by address
)

select (case when balance_amount >= 10000 then '>= 10000'
            when balance_amount >= 1000 then '>= 1000'
            when balance_amount >= 500 then '>= 500'
            when balance_amount >= 100 then '>= 100'
            when balance_amount >= 10 then '>= 10'
            when balance_amount >= 1 then '>= 1'
            else '< 1.0'
        end) as amount_area_type,
        (case when balance_amount >= 10000 then 10000
            when balance_amount >= 1000 then 1000
            when balance_amount >= 500 then 500
            when balance_amount >= 100 then 100
            when balance_amount >= 10 then 10
            when balance_amount >= 1 then 1
            else 0
        end) as amount_area_id,
    count(address) as holder_count,
    avg(balance_amount) as average_balance_amount
from address_balance
group by 1, 2
order by 2 desc
```

ËøôÁßçÊåâÂ∞ëÈáèÊåáÂÆöÂå∫Èó¥ÁªüËÆ°ÂàÜÂ∏ÉÁöÑÊÉÖÂÜµÔºåÊúÄÈÄÇÂêàÁöÑÂèØËßÜÂåñÂõæË°®ÊòØÈ•ºÂõæÔºàPie ChartÔºâÔºå‰ΩÜÊòØ‰ΩøÁî®È•ºÂõæÂ≠òÂú®‰∏Ä‰∏™Áº∫ÁÇπÔºåÂ∞±ÊòØÊï∞ÊçÆÂæÄÂæÄ‰∏ç‰ºöÊåâÁÖß‰Ω†ÊúüÊúõÁöÑÈ°∫Â∫èÊéíÂ∫è„ÄÇÊâÄ‰ª•Âú®‰∏äÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨ËøòÁî®‰∫ÜÂè¶Â§ñ‰∏Ä‰∏™Â∞èÊäÄÂ∑ßÔºå‰ΩøÁî®Âè¶‰∏Ä‰∏™CASEËØ≠Âè•ËæìÂá∫‰∫Ü‰∏Ä‰∏™Áî®‰∫éÊéíÂ∫èÁöÑÂ≠óÊÆµ`amount_area_id`„ÄÇÂú®È•ºÂõæ‰πãÂ§ñÔºåÊàë‰ª¨‰πüËæìÂá∫‰∏Ä‰∏™Áõ¥ÊñπÂõæÔºåÂõ†‰∏∫Áõ¥ÊñπÂõæÊîØÊåÅË∞ÉÊï¥ÊéíÂ∫èÔºàÈªòËÆ§ÊéíÂ∫èÔºåÂèØ‰ª•ÂèñÊ∂àÊéíÂ∫èÊàñËÄÖÂÄíËΩ¨ÊéíÂ∫èÔºâÔºåÁî®‰∫éÂØπÊØîÁõ∏ÈÇªÂå∫Èó¥ÁöÑÊï∞ÈáèÂèòÂåñÊõ¥‰∏∫Áõ¥ËßÇ„ÄÇÂú®Ëøô‰∏™Áõ¥ÊñπÂõæ‰∏≠ÔºåÊàë‰ª¨ÂèñÊ∂àÊéíÂ∫èÈÄâÈ°πÂêåÊó∂ÂãæÈÄâÂÄíËΩ¨ÁªìÊûúÈõÜÁöÑÈÄâÈ°πÔºåËøôÊ†∑Â∞±ÂèØ‰ª•ÊåâÈáëÈ¢ùÂå∫Èó¥ÂÄº‰ªéÂ∞èÂà∞Â§ßÈ°∫Â∫èÁªòÂà∂Áõ¥ÊñπÂõæ„ÄÇÂèØËßÜÂåñÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_05.png](img/image_05.png)

ÂèÇËÄÉÊü•ËØ¢Á§∫‰æãÔºö[https://dune.com/queries/1621478](https://dune.com/queries/1621478)

**ÊåâÂØπÊï∞ÂàÜÂå∫Âå∫Èó¥ÁªüËÆ°ÂàÜÂ∏ÉÊÉÖÂÜµÔºö**

Âè¶‰∏ÄÁßçÊõ¥ÂêàÁêÜÁöÑÁªüËÆ°ÂàÜÂ∏ÉÂÅöÊ≥ïÊòØÔºåÊåâ‰∏ÄÂÆöÁöÑËßÑÂàôÂ∞ÜÊï∞ÊçÆÂêàÁêÜÂàíÂàÜ‰∏∫Áõ∏Â∫îÁöÑÂàÜÂå∫Âå∫Èó¥ÔºåÁÑ∂ÂêéÁªüËÆ°ÂΩíÂ±û‰∫éÊØè‰∏Ä‰∏™Âå∫Èó¥ÁöÑÊåÅÊúâËÄÖÂú∞ÂùÄÊï∞Èáè„ÄÇÂØπ‰∫éÂÉè‰ª£Â∏Å‰ΩôÈ¢ùËøôÁßçÈáëÈ¢ùÂ∑ÆÂà´Â∑®Â§ßÁöÑÊÉÖÂÜµÔºà‰ΩôÈ¢ùÂ∞ëÁöÑË¥¶Êà∑‰∏çÂà∞1‰∏™‰ª£Â∏ÅÔºå‰ΩôÈ¢ùÂ§öÁöÑÂèØËÉΩÊúâ‰∏ä‰∫ø‰∏™‰ª£Â∏ÅÔºâÔºå‰ΩøÁî®ÂØπÊï∞Êù•ÂÅöÂàÜÂå∫ÊòØ‰∏Ä‰∏™Áõ∏ÂØπÂèØË°åÁöÑÊñπÊ°à„ÄÇÂ¶ÇÊûúÂàÜÊûêÁöÑÊòØÊüê‰∏Ä‰∏™Êó∂Èó¥ÊÆµÂÜÖÁöÑ‰ª∑Ê†º„ÄÅÊàê‰∫§ÈáëÈ¢ùÁ≠âÁõ∏ÂØπÂèòÂåñ‰∏çÊòØÁâπÂà´ÂâßÁÉàÁöÑÊÉÖÂÜµÔºå‰ΩøÁî®Á≠âÂàÜÊñπÊ≥ï‰πüÂèØË°åÔºåÂÖ∑‰ΩìÂ∞±ÊòØËÆ°ÁÆóÊúÄÂ§ßÂÄºÂíåÊúÄÂ∞èÂÄº‰πãÂ∑ÆÔºåÂ∞ÜÂÖ∂ÂùáÂàÜ‰∏∫NÁ≠â‰ªΩÔºåÊØè‰∏™Âå∫Èó¥Âú®Ê≠§Âü∫Á°Ä‰∏äÈÄíÂ¢ûÁõ∏Â∫îÁöÑÂÄº„ÄÇËøôÈáåÊàë‰ª¨‰ΩøÁî®`log2()`Ê±ÇÂØπÊï∞ÁöÑÊñπÊ≥ïÊù•ÊºîÁ§∫„ÄÇÊ†πÊçÆ‰Ω†ÂÖ∑‰ΩìÂàÜÊûêÁöÑÊï∞ÊçÆÁöÑÁâπÂæÅÔºåÂèØËÉΩÊúâÂÖ∂‰ªñÊõ¥ÂêàÈÄÇÁöÑÂàÜÂå∫ÊñπÊ≥ï„ÄÇ

```sql
with transfer_detail as (
    -- Same as previous sample
),

address_balance as (
    select address,
        floor(log2(sum(amount / 1e18))) as log_balance_amount,
        sum(amount / 1e18) as balance_amount
    from transfer_detail
    group by address
    having balance_amount >= pow(10, -4)
)

select (case when log_balance_amount <= 0 then 0 else pow(2, log_balance_amount) * 1.0 end) as min_balance_amount,
    count(*) as holder_count
from address_balance
group by 1
order by 1
```

Êàë‰ª¨‰ΩøÁî®`floor(log2(sum(amount / 1e18)))`Â∞ÜÊâÄÊúâÊåÅÊúâËÄÖÁöÑ‰ΩôÈ¢ùÊ±ÇÂØπÊï∞Âπ∂Âêë‰∏ãÂèñÊï¥ÔºåÂæóÂà∞‰∏Ä‰∏™Êï¥Êï∞ÂÄº„ÄÇÂêåÊó∂‰πüËÆ°ÁÆóÊ≠£Â∏∏ÁöÑ‰ΩôÈ¢ùÂÄºÂπ∂‰∏îÁî®`having balance_amount >= pow(10, -4)`ËøáÊª§Êéâ‰ΩôÈ¢ùÂ∞è‰∫é0.0001ÁöÑÈÇ£‰∫õË¥¶Êà∑„ÄÇÂú®ÊúÄÂêéËæìÂá∫ÁªìÊûúÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™CASEËØ≠Âè•ÔºåÂ∞Ü`log_balance_amount <= 0`ÁöÑÂÄºÂΩì‰Ωú0ÂØπÂæÖÔºåË°®Á§∫Ë¥¶Êà∑‰ΩôÈ¢ù‰ªã‰∫é0-2‰πãÈó¥„ÄÇÂØπ‰∫éÂÖ∂‰ªñÂÄºÔºåÂàô‰ΩøÁî®`pow()`ÂáΩÊï∞ËøòÂéü‰∏∫Ê≠£Â∏∏ÁöÑÈáëÈ¢ùÂÄº„ÄÇËøôÊ†∑Êàë‰ª¨Â∞±ÂÆûÁé∞‰∫ÜÊåâÂØπÊï∞ÂàÜÂå∫ÁªüËÆ°‰∏çÂêåÈáëÈ¢ùÂå∫Èó¥ÁöÑÂú∞ÂùÄÊï∞Èáè„ÄÇÂ∞ÜÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÁîüÊàê‰∏Ä‰∏™Áõ¥ÊñπÂõæÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö

![image_06.png](img/image_06.png)

ÂèÇËÄÉÊü•ËØ¢Á§∫‰æãÔºö
- ÊåâÂØπÊï∞ÂàÜÂå∫ÁªüËÆ°ÂàÜÂ∏ÉÔºö[https://dune.com/queries/1622137](https://dune.com/queries/1622137)
- ÊåâÁ≠âÂàÜÊñπÊ≥ïÁªüËÆ°ÂàÜÂ∏ÉÔºö[https://dune.com/queries/1300399](https://dune.com/queries/1300399)

## Êü•ËØ¢ERC20‰ª£Â∏ÅÊåÅÊúâËÄÖÊï∞ÈáèÈöèÊó•ÊúüÁöÑÂèòÂåñÊÉÖÂÜµ

ÂØπ‰∫éÂ∑≤ÁªèËß£ÊûêÁöÑÊô∫ËÉΩÂêàÁ∫¶ÔºåÈô§‰∫ÜÊü•ËØ¢`evt_Transfer`Ë°®ÔºåÊàë‰ª¨ËøòÂèØ‰ª•Áõ¥Êé•Êü•ËØ¢Áõ∏Â∫îÁöÑËß£ÊûêË°®„ÄÇ‰æãÂ¶ÇÔºåÂØπ‰∫éÊàë‰ª¨ÂâçÈù¢Êü•ËØ¢ÁöÑFTT TokenÔºåÂÆÉÁöÑÂêàÁ∫¶Â∑≤ÁªèËß£ÊûêÔºåËøõÂÖ•DuneÁöÑÊü•ËØ¢ÁºñËæëÂô®È°µÈù¢ÔºåÁÇπÂáª‚ÄúDecoded Projects‚ÄùÂêéÔºåÊêúÁ¥¢‚Äúftt‚ÄùÔºåÂÜçÈÄâÊã©‚ÄúFTT_Token‚ÄúÔºåÂú®ÂàóË°®‰∏≠ÂèØ‰ª•ÁúãÂà∞‰∏Ä‰∏™Âè´‚ÄúTransfer‚ÄùÁöÑ`event`Á±ªÂûãÁöÑË°®ÔºåÁÇπÂáªÂè≥ËæπÁöÑÂèåÁÆ≠Â§¥Á¨¶Âè∑ÂèØ‰ª•Â∞ÜÂÆåÊï¥ÁöÑË°®ÂêçÊèíÂÖ•Êü•ËØ¢ÁºñËæëÂô®Á™óÂè£ÔºåËøô‰∏™Ë°®ÁöÑÂÖ®ÂêçÊòØ`ftt_ethereum.FTT_Token_evt_Transfer`„ÄÇ‰ΩøÁî®Ëß£ÊûêË°®ÁöÑÂ•ΩÂ§ÑÊòØÊü•ËØ¢ËØªÂèñÁöÑÊï∞ÊçÆÈáèÂ∞ëÊâÄ‰ª•ÊÄßËÉΩËæÉÂ•Ω„ÄÇ

ÂÅáËÆæÁé∞Âú®Êàë‰ª¨ÁöÑÁõÆÊ†áÊòØË¶ÅË∑üË∏™FTT‰ª£Â∏ÅÊØè‰∏™ÊòüÊúüÁöÑÊåÅÊúâËÄÖÊï∞ÈáèÁöÑÂèòÂåñÊÉÖÂÜµÔºå‰πüÂ∞±ÊòØÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÂá∫ÊØè‰∏ÄÂë®ÂàÜÂà´ÊúâÂ§öÂ∞ë‰∫∫ÊåÅÊúâFTT‰ª£Â∏Å‰ΩôÈ¢ù„ÄÇ‰∏ãÈù¢ÂÖàÁªôÂá∫Êü•ËØ¢‰ª£Á†ÅÔºåÂÜçÂä†‰ª•Ëß£ËØ¥Ôºö

```sql
with transfer_detail as (
    select evt_block_time,
        "to" as address,
        cast(value as decimal(38, 0)) as value,
        evt_tx_hash
    from ftt_ethereum.FTT_Token_evt_Transfer
    
    union all
    
    select evt_block_time,
        "from" as address,
        -1 * cast(value as decimal(38, 0)) as value,
        evt_tx_hash
    from ftt_ethereum.FTT_Token_evt_Transfer
),

holder_balance_weekly as (
    select date_trunc('week', evt_block_time) as block_date,
        address,
        sum(value/1e18) as balance_amount
    from transfer_detail
    group by 1, 2
),

holder_summary_weekly as (
    select block_date,
        address,
        sum(balance_amount) over (partition by address order by block_date) as balance_amount
    from holder_balance_weekly
    order by 1, 2
),

min_max_date as (
    select min(block_date) as start_date,
        max(block_date) as end_date
    from holder_balance_weekly
),

date_series as (
    SELECT dt.block_date 
    FROM min_max_date as mm
    CROSS JOIN unnest(sequence(date(mm.start_date), date(mm.end_date), interval '7' day)) AS dt(block_date)
),

holder_balance_until_date as (
    select distinct d.block_date,
        w.address,
        -- get the last balance of same address on same date or before (when no date on same date)
        first_value(balance_amount) over (partition by w.address order by w.block_date desc) as last_balance_amount
    from date_series d
    inner join holder_summary_weekly w on w.block_date <= d.block_date
),

holder_count_summary as (
    select block_date,
        count(address) as holder_count,
        sum(last_balance_amount) as balance_amount
    from holder_balance_until_date
    where last_balance_amount > 0
    group by block_date
)

select block_date,
    holder_count,
    balance_amount,
    (holder_count - lag(holder_count, 1) over (order by block_date)) as holder_count_change,
    (balance_amount - lag(balance_amount, 1) over (order by block_date)) as balance_amount_change
from holder_count_summary
order by block_date
```

‰∏äÈù¢Ëøô‰∏™Êü•ËØ¢ËØ¥ÊòéÂ¶Ç‰∏ãÔºö
1. CTE `transfer_detail`‰∏éÂâçÈù¢ÁöÑ‰æãÂ≠êÂü∫Êú¨Áõ∏ÂêåÔºåÂå∫Âà´Âú®‰∫éÁé∞Âú®Êàë‰ª¨‰ªéFTT‰ª£Â∏Å‰∏ìÂ±ûÁöÑ`FTT_Token_evt_Transfer`Ë°®ËØªÂèñÊï∞ÊçÆÔºåÂõ†Ê≠§Êó†ÈúÄÈ¢ùÂ§ñÊ∑ªÂä†ËøáÊª§Êù°‰ª∂„ÄÇ
2. Âú®`holder_balance_weekly`Ëøô‰∏™CTE‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®`date_trunc('week', evt_block_time)`Â∞ÜÊó•ÊúüËΩ¨Êç¢‰∏∫ÊØèÂë®ÂºÄÂßãÁöÑÊó•ÊúüÔºåÁªìÂêàÁî®Êà∑Âú∞ÂùÄÔºåÂàÜÁªÑÁªüËÆ°ÊØè‰∏ÄÂë®ÊØè‰∏™Âú∞ÂùÄÁöÑ‰ΩôÈ¢ùÂèòÂåñÔºåÊ≥®ÊÑèËøôÈáåËÆ°ÁÆóÂá∫Êù•ÁöÑÊòØÊØè‰∏ÄÂë®ÂèòÂåñÁöÑÈáëÈ¢ùÔºå‰∏çÊòØÂΩìÊó∂ÁöÑÂÆûÈôÖ‰ΩôÈ¢ù„ÄÇ
3. Âú®`holder_summary_weekly`‰∏≠ÔºåÊàë‰ª¨Âü∫‰∫éÊØèÂë®ÁöÑ‰ΩôÈ¢ùÂèòÂåñÔºå‰ΩøÁî®`sum(balance_amount) over (partition by address order by block_date)`Ê±áÊÄªÂæóÂà∞ÊØè‰∏™Âú∞ÂùÄÊà™Ê≠¢Âà∞ÊØè‰∏™Êó•ÊúüÁöÑË¥¶Êà∑‰ΩôÈ¢ù„ÄÇËøôÈáåÂæóÂà∞ÁöÑÊòØÂØπÂ∫îÂÖ∑‰ΩìÊó•ÊúüÁöÑÁúüÊ≠£ÁöÑ‰ΩôÈ¢ùÂÄº„ÄÇ
4. CTE `min_max_date` Áî®‰∫é‰ªéÂâç‰∏Ä‰∏™CTE‰∏≠ÊâæÂá∫ÂºÄÂßãÊó•ÊúüÂíåÁªìÊùüÊó•Êúü„ÄÇÂõ†‰∏∫Êàë‰ª¨Ë¶ÅÁªüËÆ°ÊØè‰∏ÄÂë®ÁöÑÊåÅÊúâËÄÖÊï∞ÈáèÔºåÊâÄ‰ª•ÈúÄË¶ÅÁî®Ëøô‰∏™Êó•ÊúüËåÉÂõ¥ÁîüÊàê‰∏Ä‰∏™Êó•ÊúüÂ∫èÂàó„ÄÇ
5. ÁÑ∂ÂêéÊàë‰ª¨Âú®`date_series`‰∏≠‰ΩøÁî®ÂºÄÂßãÊó•ÊúüÂíåÁªìÊùüÊó•ÊúüÁîüÊàê‰∏Ä‰∏™Êó•ÊúüÂ∫èÂàóÔºå‰ª•7Â§©‰∏∫Èó¥Èöî„ÄÇËøôÊ†∑Â∞±ÂæóÂà∞‰∫Ü‰∏§‰∏™Êó•Êúü‰πãÈó¥ÁöÑÊØè‰∏ÄÂë®ÁöÑÂºÄÂßãÊó•Êúü„ÄÇ
6. Êé•‰∏ãÊù•Âú®`holder_balance_until_date`‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®Êó•ÊúüÂ∫èÂàóÂíåÊØèÂë®‰ΩôÈ¢ù‰∏§‰∏™CTEÂÅö‰∏Ä‰∏™ÂÖ≥ËÅîÊü•ËØ¢ÔºåÊù•ËÆ°ÁÆóÊà™Ê≠¢Âà∞`date_series`‰∏≠ÊØè‰∏Ä‰∏™Êó•Êúü‰∏∫Ê≠¢Êó∂ÊØè‰∏Ä‰∏™Âú∞ÂùÄÁöÑÁ¥ØËÆ°Ë¥¶Êà∑‰ΩôÈ¢ù„ÄÇÊ≥®ÊÑè`from date_series d inner join holder_summary_weekly w on w.block_date <= d.block_date`ËøôÈáåÁöÑÊù°‰ª∂ÔºåÊàë‰ª¨‰ΩøÁî®‰∫Ü `<=` Êù•Êää`holder_summary_weekly`Ë°®‰∏≠ÊâÄÊúâÂú®ÂΩìÂâç`date_series`Êó•Êúü‰πãÂâçÔºàÂåÖÊã¨ÂΩìÂ§©ÔºâÁöÑËÆ∞ÂΩïÂåπÈÖçÂá∫Êù•„ÄÇ‰πüÂ∞±ÊòØÂØπ‰∫éÊØè‰∏Ä‰∏™`date_series`ÁöÑÊó•ÊúüÂÄºÔºåÂ∞ÜÂåπÈÖçÂà∞`holder_summary_weekly`‰∏≠ÁöÑ‰∏ÄÊâπËÆ∞ÂΩï„ÄÇËøôÁßçÊìç‰ΩúÊúâÁÇπÁ±ª‰ºº‰∫éÁ¨õÂç°Â∞î‰πòÁßØ„ÄÇÂè¶Â§ñÊ≥®ÊÑèÔºåÂú®SELECTÂ≠êÂè•‰∏≠ÔºåÊàë‰ª¨ÂèñÁöÑÊòØ`d.block_date`ËÄå‰∏çÊòØ`w.block_date`ÔºåËøô‰∏ÄÁÇπÂØπ‰∫éÊ≠£Á°ÆÊ±áÊÄªÊï∞ÊçÆÈùûÂ∏∏ÂÖ≥ÈîÆ„ÄÇ
7. ÁÑ∂ÂêéÔºåÂú®`holder_count_summary`‰∏≠ÔºåÊàë‰ª¨ÊåâÊó•ÊúüÁªüËÆ°‰ΩôÈ¢ùÂ§ß‰∫é0ÁöÑÂú∞ÂùÄÊï∞ÈáèÔºåËøôÊ†∑Êàë‰ª¨Â∞±ÂæóÂà∞‰∫ÜÊØè‰∏Ä‰∏™Êó•ÊúüÔºàÊØèÂë®Á¨¨‰∏ÄÂ§©ÔºâË¥¶Êà∑‰∏≠ÊúâFTT Token‰ΩôÈ¢ùÁöÑÂú∞ÂùÄÊï∞Èáè„ÄÇ
8. ÊúÄÂêéËæìÂá∫Êü•ËØ¢ÁªìÊûúÊó∂ÔºåÊàë‰ª¨ÁªìÂêà‰ΩøÁî®`lag()`ÂáΩÊï∞Êù•ËæìÂá∫ÊØèÊó•ÊåÅÊúâËÄÖÊï∞ÈáèÁöÑÂèòÂåñÂíåÊâÄÊúâË¥¶Êà∑ÊÄª‰ΩôÈ¢ùÁöÑÂèòÂåñ„ÄÇ

Â∞ÜÊü•ËØ¢ÁªìÊûúÂèØËßÜÂåñÁîüÊàê‰∏§‰∏™ÂõæË°®ÔºåÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_07.png](img/image_07.png)

Dune‰∏äÁöÑÁ§∫‰æãÔºö[https://dune.com/queries/1625278](https://dune.com/queries/1625278)

## Êü•ËØ¢ÊåáÂÆöÁî®Êà∑Âú∞ÂùÄÁöÑË¥¶Êà∑‰ΩôÈ¢ù

Âú®ÂâçÈù¢ÁöÑÊü•ËØ¢Á§∫‰æãÂü∫Á°Ä‰∏äÔºåÂèØ‰ª•ÂæàÂÆπÊòìÁöÑ‰øÆÊîπÊù•Êü•ËØ¢ÊåáÂÆöÁöÑÊüê‰∏Ä‰∏™Áî®Êà∑Âú∞ÂùÄÊàñËÄÖ‰∏ÄÁªÑÁî®Êà∑Âú∞ÂùÄÁöÑ‰ΩôÈ¢ù‰ø°ÊÅØ„ÄÇÊàë‰ª¨Âè™ÈúÄË¶ÅÊ∑ªÂä†ËøáÊª§Êù°‰ª∂Êù•Á≠õÈÄâÊª°Ë∂≥Êù°‰ª∂ÁöÑ`address`ËÆ∞ÂΩïÂç≥ÂèØÔºåËøôÈáåÂ∞±‰∏çÂÜçÂçïÁã¨‰∏æ‰æã‰∫Ü„ÄÇ

## Êü•ËØ¢ÂéüÁîü‰ª£Â∏ÅÁöÑÊåÅÊúâËÄÖÔºàETHÔºâ

ETH Â±û‰∫éEthereumÂå∫ÂùóÈìæÁöÑÂéüÁîü‰ª£Â∏ÅÔºå‰∏çÊòØERC20‰ª£Â∏ÅÔºåÂÖ∂‰∫§ÊòìÊï∞ÊçÆÊ≤°Êúâ‰øùÂ≠òÂú®`evt_Transfer`Ë°®‰∏≠ÔºåÊâÄ‰ª•‰∏çËÉΩÁî®ERC20‰ª£Â∏ÅÁöÑÊñπÂºèÊù•ËÆ°ÁÆóETH‰ΩôÈ¢ùÂíåÊåÅÊúâËÄÖÁ≠â‰ø°ÊÅØ„ÄÇÊô∫ËÉΩÂêàÁ∫¶ÂèØ‰ª•Âú®Ë∞ÉÁî®ÊîØÊåÅËΩ¨Ë¥¶ÁöÑÊñπÊ≥ïÊó∂ÂêåÊó∂ËøõË°åETHËΩ¨Ë¥¶ÔºåÁîöËá≥Âú®ÂàõÂª∫ÔºàÈÉ®ÁΩ≤ÔºâÊñ∞ÁöÑÊô∫ËÉΩÂêàÁ∫¶Êó∂ÊàñËÄÖÊô∫ËÉΩÂêàÁ∫¶ËøõË°åËá™ÊàëÈîÄÊØÅÊó∂Ôºå‰πüÂèØËÉΩÂèëÁîüETHÁöÑËΩ¨Ë¥¶„ÄÇEthereumÂå∫ÂùóÈìæÁöÑÁáÉÊñôË¥π‰πüÊòØÁî®ETHÊù•ÊîØ‰ªòÁöÑ„ÄÇÊâÄÊúâËøô‰∫õETHËΩ¨Ë¥¶ÁöÑ‰ø°ÊÅØÂÖ®ÈÉ®ËÆ∞ÂΩïÂú®`ethereum.traces`Ë°®‰∏≠ÔºåËÄåÂú®`ethereum.transactions`Ë°®‰∏≠ÂàôÂè™ÊúâÈÇ£‰∫õÁõ¥Êé•ËΩ¨Ë¥¶‰∫§ÊòìÁöÑ‰ø°ÊÅØ„ÄÇÂõ†Ê≠§ÔºåËÆ°ÁÆóETHÁöÑ‰ΩôÈ¢ùÊàñËÄÖÁªüËÆ°ÊåÅÊúâËÄÖÊï∞ÈáèÊó∂ÔºåÊàë‰ª¨ÂøÖÈ°ª‰ΩøÁî®`traces`Ë°®„ÄÇÈô§‰∫ÜÊï∞ÊçÆÊ∫ê‰∏çÂêåÔºåÂÆûÁé∞ÊñπÂºèË∑üËÆ°ÁÆóERC20‰ª£Â∏Å‰ΩôÈ¢ùÊòØÁõ∏‰ººÁöÑ„ÄÇËøôÈáåÊúâ‰∏Ä‰∏™Êàë‰πãÂâçÂàõÂª∫ÁöÑË∑üË∏™ETHË¥¶Êà∑‰ΩôÈ¢ùÁöÑÊï∞ÊçÆÁúãÊùøÔºåÈáåÈù¢ÁöÑÁõ∏ÂÖ≥Êü•ËØ¢ÊºîÁ§∫‰∫ÜÂÖ∑‰ΩìÁöÑÂÆûÁé∞„ÄÇ

ÂèÇËÄÉÊï∞ÊçÆÁúãÊùøÔºö[ETH Whales Tracking](https://dune.com/springzhang/eth-whales-top-1000-eth-holders)

## Êé®ËçêÂèÇËÄÉ

Ëøô‰∏™‚ÄúTips and Tricks for Query and Visualization in Dune V2 Engine‚ÄùÊï∞ÊçÆÁúãÊùøÊî∂ÈõÜÊï¥ÁêÜ‰∫Ü‰∏Ä‰∫õÊü•ËØ¢ÊäÄÂ∑ßÔºåÂ§ßÂÆ∂ÂèØ‰ª•‰Ωú‰∏∫Êâ©Â±ïÈòÖËØªÂèÇËÄÉ„ÄÇÂêéÁª≠Ëøò‰ºöÁªßÁª≠Ë°•ÂÖÖÊõ¥Êñ∞Êõ¥Â§öÊäÄÂ∑ßÔºåÊ¨¢ËøéÊî∂Ëóè„ÄÇ

ÁúãÊùøÂú∞ÂùÄÔºö[Dune V2 Êü•ËØ¢ÂíåÂèØËßÜÂåñÊèêÁ§∫‰∏éÊäÄÂ∑ß](https://dune.com/springzhang/tips-and-tricks-for-query-and-visualization-in-v2-engine)

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch12/ch11-useful-queries-part3.md">
# Â∏∏ËßÅÊü•ËØ¢‰∏âÔºöËá™ÂÆö‰πâÊï∞ÊçÆ„ÄÅÊï∞Â≠óÂ∫èÂàó„ÄÅÊï∞ÁªÑ„ÄÅJSONÁ≠â

Âú®Â∏∏ËßÅÊü•ËØ¢ÁöÑÂâçÈù¢‰∏§‰∏™ÈÉ®ÂàÜÔºåÊàë‰ª¨ÂàÜÂà´‰ªãÁªç‰∫ÜERC20‰ª£Â∏ÅÁöÑ‰ª∑Ê†ºÊü•ËØ¢„ÄÅÊåÅÊúâËÄÖ„ÄÅÊåÅÊúâ‰ΩôÈ¢ùÁ≠âÂ∏∏ËßÅÁöÑ‰∏Ä‰∫õÊü•ËØ¢ÊñπÊ≥ï„ÄÇÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºåÊàë‰ª¨ÂÜç‰ªãÁªç‰∏Ä‰∫õÂÖ∂‰ªñÊñπÈù¢ÁöÑÂ∏∏Áî®Êü•ËØ¢„ÄÇ

## ‰ΩøÁî®CTEËá™ÂÆö‰πâÊï∞ÊçÆË°®

Dune V2ÁõÆÂâçËøò‰∏çÊîØÊåÅÁî®Êà∑Ëá™ÂÆö‰πâË°®ÂíåËßÜÂõæÔºåÂØπ‰∫é‰∏Ä‰∫õÊù•Ê∫êÂ§ñÈÉ®Êï∞ÊçÆÊ∫êÁöÑÊï∞ÊçÆÊàñËÄÖÊâãÂä®Êï¥ÁêÜÁöÑÂ∞ëÈáèÊï∞ÊçÆÔºåÊàë‰ª¨ÂèØ‰ª•ËÄÉËôëÂú®Êü•ËØ¢ÂÜÖ‰ΩøÁî®CTEÊù•ÁîüÊàêËá™ÂÆö‰πâÊï∞ÊçÆÂàóË°®„ÄÇÁªèËøáÊµãËØïÔºåÂØπ‰∫éÂè™ÂåÖÊã¨Âá†‰∏™Â≠óÊÆµÁöÑÊÉÖÂÜµÔºåÂèØ‰ª•ÊîØÊåÅÂåÖÂê´‰∏äÂçÉË°åÊï∞ÊçÆÁöÑËá™ÂÆö‰πâCTEÊï∞ÊçÆË°®ÔºåÂè™Ë¶Å‰∏çË∂ÖËøáDuneÊü•ËØ¢ËØ∑Ê±ÇÁöÑÊúÄÂ§ßÊï∞ÊçÆÈáèÈôêÂà∂ÔºåÂ∞±ËÉΩÊàêÂäüÊâßË°å„ÄÇ‰∏ãÈù¢‰ªãÁªç‰∏§ÁßçËá™ÂÆö‰πâCTEÊï∞ÊçÆË°®ÁöÑÊñπÂºèÔºö

Á¨¨‰∏ÄÁßçËØ≠Ê≥ïÁ§∫‰æãÔºö
```sql
with raydium_lp_pairs(account_key, pair_name) as (
    values
    ('58oQChx4yWmvKdwLLZzBi4ChoCc2fqCUWBkwMihLYQo2', 'SOL/USDC'),
    ('7XawhbbxtsRcQA8KTkHT9f9nc6d69UwqCDh6U5EEbEmX', 'SOL/USDT'),
    ('AVs9TA4nWDzfPJE9gGVNJMVhcQy3V9PGazuz33BfG2RA', 'RAY/SOL'),
    ('6UmmUiYoBjSrhakAobJw8BvkmJtDVxaeBtbt7rxWo1mg', 'RAY/USDC'),
    ('DVa7Qmb5ct9RCpaU7UTpSaf3GVMYz17vNVU67XpdCRut', 'RAY/USDT'),
    ('GaqgfieVmnmY4ZsZHHA6L5RSVzCGL3sKx4UgHBaYNy8m', 'RAY/SRMSOL'),
    ('6a1CsrpeZubDjEJE9s1CMVheB6HWM5d7m1cj2jkhyXhj', 'STSOL/USDC'),
    ('43UHp4TuwQ7BYsaULN1qfpktmg7GWs9GpR8TDb8ovu9c', 'APEX4/USDC')
)

select * from raydium_lp_pairs
```

Á¨¨‰∫åÁßçËØ≠Ê≥ïÁ§∫‰æãÔºö

```sql
with token_plan as (
    select token_name, hook_amount from (
        values
        ('Token Type','BEP-20 on BNB Chain'),
        ('Total Token Supply','500,000,000 HOOK'),
        ('Private Sale Allocation','100,000,000 HOOK'),
        ('Private Sale Token Price','0.06 USD to 0.12 USD / HOOK'),
        ('Private Sale Amount Raised','~ 6,000,000 USD'),
        ('Binance Launchpad Sale Allocation','25,000,000 HOOK'),
        ('Binance Launchpad Sale Price','0.10 USD / HOOK'),
        ('Binance Launchpad Amount to be Raised','2,500,000 USD'),
        ('Initial Circ. Supply When Listed on Binance','50,000,000 HOOK (10.00%)')
    ) as tbl(token_name, hook_amount)
)

select * from token_plan
```

ÂΩìÁÑ∂ÔºåÂØπ‰∫éÁ¨¨‰∫åÁßçËØ≠Ê≥ïÔºåÂ¶ÇÊûúÁ¢∞Â∑ß‰Ω†Âè™ÈúÄË¶ÅËøîÂõûËøôÈÉ®ÂàÜËá™ÂÆö‰πâÁöÑÊï∞ÊçÆÔºåÂàôÂèØ‰ª•ÁúÅÁï•CTEÂÆö‰πâÔºåÁõ¥Êé•‰ΩøÁî®ÂÖ∂‰∏≠ÁöÑSELECTÊü•ËØ¢„ÄÇ

‰ª•‰∏äÊü•ËØ¢ÁöÑÁ§∫‰æãÈìæÊé•Ôºö
- [https://dune.com/queries/781862](https://dune.com/queries/781862)
- [https://dune.com/queries/1650640](https://dune.com/queries/1650640)

Áî±‰∫éÂâçÈù¢ÊèêÂà∞ÁöÑÂ±ÄÈôêÊÄßÔºåÊï∞ÊçÆË°åÂ§™Â§öÊó∂ÂèØËÉΩÊó†Ê≥ïÊâßË°åÊàêÂäüÔºåËÄå‰∏î‰Ω†ÈúÄË¶ÅÂú®ÊØè‰∏Ä‰∏™Êü•ËØ¢‰∏≠Â§çÂà∂ÂêåÊ†∑ÁöÑCTE‰ª£Á†ÅÔºåÁõ∏ÂØπÊù•ËØ¥Âæà‰∏çÊñπ‰æø„ÄÇÂØπ‰∫éÊï∞ÊçÆÈáèÂ§ß„ÄÅÈúÄË¶ÅÂ§öÊ¨°„ÄÅÈïøÊúü‰ΩøÁî®Á≠âÊÉÖÂÜµÔºåËøòÊòØÂ∫îËØ•ËÄÉËôëÈÄöËøáÊèê‰∫§spellbook PRÊù•ÁîüÊàêÈ≠îÊ≥ïË°®„ÄÇ

## ‰ªé‰∫ã‰ª∂Êó•ÂøóÂéüÂßãË°®Ëß£ÊûêÊï∞ÊçÆ

‰πãÂâçÂú®ËÆ≤Ëß£ËÆ°ÁÆóERC20‰ª£Â∏Å‰ª∑Ê†ºÊó∂ÔºåÊàë‰ª¨‰ªãÁªçËøá‰ªé‰∫ã‰ª∂Êó•ÂøóÂéüÂßãË°®ÔºàlogsÔºâËß£ÊûêËÆ°ÁÆó‰ª∑Ê†ºÁöÑ‰æãÂ≠ê„ÄÇËøôÈáåÂÜç‰∏æ‰æãËØ¥Êòé‰∏Ä‰∏ãÂÖ∂‰ªñÈúÄË¶ÅÁõ¥Êé•‰ªélogsËß£ÊûêÊï∞ÊçÆÁöÑÊÉÖÂÜµ„ÄÇÂΩìÈÅáÂà∞Êô∫ËÉΩÂêàÁ∫¶Êú™Ë¢´DuneËß£ÊûêÔºåÊàñËÄÖÂõ†‰∏∫Ëß£ÊûêÊó∂‰ΩøÁî®ÁöÑABIÊï∞ÊçÆ‰∏çÂÆåÊï¥ÂØºËá¥Ê≤°ÊúâÁîüÊàêÂØπÂ∫î‰∫ã‰ª∂ÁöÑËß£ÊûêË°®ÁöÑÊÉÖÂÜµÔºåÊàë‰ª¨Â∞±ÂèØËÉΩÈúÄË¶ÅÁõ¥Êé•‰ªé‰∫ã‰ª∂Êó•ÂøóË°®Ëß£ÊûêÊü•ËØ¢Êï∞ÊçÆ„ÄÇ‰ª•Lens ÂçèËÆÆ‰∏∫‰æãÔºåÊàë‰ª¨ÂèëÁé∞Âú®LensÁöÑÊô∫ËÉΩÂêàÁ∫¶Ê∫ê‰ª£Á†Å‰∏≠Ôºà[Lens Core](https://github.com/lens-protocol/core)ÔºâÔºåÂá†‰πéÊØè‰∏™Êìç‰ΩúÈÉΩÊúâÂèëÁîüÁîüÊàê‰∫ã‰ª∂Êó•ÂøóÔºå‰ΩÜÊòØDuneËß£ÊûêÂêéÁöÑÊï∞ÊçÆË°®ÈáåÈù¢‰ªÖÊúâÂ∞ëÊï∞Âá†‰∏™EventÁõ∏ÂÖ≥ÁöÑË°®„ÄÇËøõ‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÂèëÁé∞Êó∂Âõ†‰∏∫Ëß£ÊûêÊó∂‰ΩøÁî®ÁöÑABIÁº∫Â∞ë‰∫ÜËøô‰∫õ‰∫ã‰ª∂ÁöÑÂÆö‰πâ„ÄÇÊàë‰ª¨ÂΩìÁÑ∂ÂèØ‰ª•ÈáçÊñ∞ÁîüÊàêÊàñËÄÖÊâæLensÂõ¢ÈòüËé∑ÂèñÂÆåÊï¥ÁöÑABIÔºåÊèê‰∫§ÁªôDuneÂéªÂÜçÊ¨°Ëß£Êûê„ÄÇ‰∏çËøáËøôÈáåÁöÑÈáçÁÇπÊòØÂ¶Ç‰Ωï‰ªéÊú™Ëß£ÊûêÁöÑÊó•ÂøóÈáåÈù¢ÊèêÂèñÊï∞ÊçÆ„ÄÇ

Âú®LensÊô∫ËÉΩÂêàÁ∫¶ÁöÑÊ∫ê‰ª£Á†ÅÈáåÔºåÊàë‰ª¨ÁúãÂà∞‰∫Ü`FollowNFTTransferred`‰∫ã‰ª∂ÂÆö‰πâÔºå[‰ª£Á†ÅÈìæÊé•](https://github.com/lens-protocol/core/blob/main/contracts/libraries/Events.sol#L347)„ÄÇ‰ª£Á†ÅÈáåÈù¢‰πüÊúâ`Followed`‰∫ã‰ª∂Ôºå‰ΩÜÊòØÂõ†‰∏∫ÂÖ∂ÂèÇÊï∞Áî®Âà∞‰∫ÜÊï∞ÁªÑÔºåËß£ÊûêÂèòÂæóÂ§çÊùÇÔºåÊâÄ‰ª•ËøôÈáåÁî®Ââç‰∏Ä‰∏™‰∫ã‰ª∂‰∏∫‰æã„ÄÇ‰ªé‰∫ã‰ª∂ÂêçÁß∞ÂèØ‰ª•Êé®Êñ≠ÔºåÂΩì‰∏Ä‰∏™Áî®Êà∑ÂÖ≥Ê≥®Êüê‰∏™Lens ProfileÊó∂ÔºåÂ∞Ü‰ºöÁîüÊàê‰∏Ä‰∏™ÂØπÂ∫îÁöÑÂÖ≥Ê≥®NFT ÔºàFollowNFTÔºâÂπ∂ÊääËøô‰∏™NFTËΩ¨ÁßªÂà∞ÂÖ≥Ê≥®ËÄÖÁöÑÂú∞ÂùÄ„ÄÇÈÇ£Êàë‰ª¨ÂèØ‰ª•ÊâæÂà∞‰∏Ä‰∏™ÂÖ≥Ê≥®ÁöÑ‰∫§ÊòìËÆ∞ÂΩïÔºåÊù•ÁúãÁúãÈáåÈù¢ÁöÑlogsÔºåÁ§∫‰æã‰∫§ÊòìÔºö[https://polygonscan.com/tx/0x30311c3eb32300c8e7e173c20a6d9c279c99d19334be8684038757e92545f8cf](https://polygonscan.com/tx/0x30311c3eb32300c8e7e173c20a6d9c279c99d19334be8684038757e92545f8cf)„ÄÇÂú®ÊµèËßàÂô®ÊâìÂºÄËøô‰∏™‰∫§ÊòìËÆ∞ÂΩïÈ°µÈù¢Âπ∂ÂàáÊç¢Âà∞‚ÄúLogs‚ÄùÊ†áÁ≠æÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞‰∏ÄÂÖ±Êúâ4‰∏™‰∫ã‰ª∂Êó•Âøó„ÄÇÂØπ‰∫é‰∏Ä‰∫õ‰∫ã‰ª∂ÔºåÂå∫ÂùóÈìæÊµèËßàÂô®ÂèØ‰ª•ÊòæÁ§∫ÂéüÂßãÁöÑ‰∫ã‰ª∂ÂêçÁß∞„ÄÇÊàë‰ª¨Êü•ÁúãÁöÑËøô‰∏™Lens‰∫§ÊòìÊ≤°ÊúâÊòæÁ§∫ÂéüÂßãÁöÑÂêçÁß∞ÔºåÈÇ£Êàë‰ª¨ÊÄé‰πàÁ°ÆÂÆöÂì™‰∏Ä‰∏™ÊòØÂØπÂ∫î`FollowNFTTransferred`‰∫ã‰ª∂Êó•ÂøóËÆ∞ÂΩïÁöÑÂë¢ÔºüËøôÈáåÊàë‰ª¨ÂèØ‰ª•ÁªìÂêàÁ¨¨‰∏âÊñπÁöÑÂ∑•ÂÖ∑ÔºåÈÄöËøáÁîüÊàê‰∫ã‰ª∂ÂÆö‰πâÁöÑkeccak256ÂìàÂ∏åÂÄºÊù•ÊØîËæÉ„ÄÇ[Keccak-256](https://emn178.github.io/online-tools/keccak_256.html)Ëøô‰∏™È°µÈù¢ÂèØ‰ª•Âú®Á∫øÁîüÊàêKeccak-256ÂìàÂ∏åÂÄº„ÄÇÊàë‰ª¨Â∞ÜÊ∫ê‰ª£Á†Å‰∏≠`FollowNFTTransferred`‰∫ã‰ª∂ÁöÑÂÆö‰πâÊï¥ÁêÜ‰∏∫Á≤æÁÆÄÊ®°ÂºèÔºàÂéªÈô§ÂèÇÊï∞ÂêçÁß∞ÔºåÂéªÈô§Á©∫Ê†ºÔºâÔºåÂæóÂà∞`FollowNFTTransferred(uint256,uint256,address,address,uint256)`ÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂Á≤òË¥¥Âà∞Keccak-256Â∑•ÂÖ∑È°µÈù¢ÔºåÁîüÊàêÁöÑÂìàÂ∏åÂÄº‰∏∫`4996ad2257e7db44908136c43128cc10ca988096f67dc6bb0bcee11d151368fb`„ÄÇÔºàÊúÄÊñ∞ÁöÑDuneËß£ÊûêË°®Â∑≤ÁªèÊúâLensÈ°πÁõÆÁöÑÂÆåÊï¥‰∫ã‰ª∂Ë°®ÔºåËøôÈáå‰ªÖ‰ΩúÁ§∫‰æãÁî®ÈÄîÔºâ

![image_08.png](img/image_08.png)

‰ΩøÁî®Ëøô‰∏™ÂìàÂ∏åÂÄºÂú®PolygonscanÁöÑ‰∫§ÊòìÊó•ÂøóÂàóË°®‰∏≠ÊêúÁ¥¢ÔºåÂç≥ÂèØÊâæÂà∞ÂåπÈÖçÈ°π„ÄÇÂèØ‰ª•ÁúãÂà∞Á¨¨‰∏Ä‰∏™Êó•ÂøóËÆ∞ÂΩïÊ≠£Â•ΩÂ∞±ÊòØÊàë‰ª¨Ë¶ÅÊâæÁöÑ„ÄÇ

![image_09.png](img/image_09.png)

ÊâæÂà∞‰∫ÜÂØπÂ∫îÁöÑÊó•ÂøóËÆ∞ÂΩïÔºåÂâ©‰∏ãÁöÑÂ∞±ÁÆÄÂçï‰∫Ü„ÄÇÁªìÂêà‰∫ã‰ª∂ÁöÑÂÆö‰πâÔºåÊàë‰ª¨ÂèØ‰ª•ÂæàÂÆπÊòìÁöÑËøõË°åÊï∞ÊçÆËß£ÊûêÔºö

```sql
select block_time,
    tx_hash,
    bytearray_to_uint256(topic1) as profile_id, -- ÂÖ≥Ê≥®ÁöÑProfile ID
    bytearray_to_uint256(topic2) as follower_token_id, -- ÂÖ≥Ê≥®ËÄÖÁöÑNFT Token ID
    bytearray_ltrim(bytearray_substring(data, 1, 32)) as from_address2, -- NFTËΩ¨Âá∫Âú∞ÂùÄ
    bytearray_ltrim(bytearray_substring(data, 1 + 32, 32)) as to_address2 -- NFTËΩ¨ÂÖ•Âú∞ÂùÄÔºà‰πüÂ∞±ÊòØÂÖ≥Ê≥®ËÄÖÁöÑÂú∞ÂùÄÔºâ
from polygon.logs
where contract_address = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d -- LensÂêàÁ∫¶Âú∞ÂùÄ
    and block_time >= date('2022-05-01') -- LensÂêàÁ∫¶ÈÉ®ÁΩ≤Âú®Ê≠§Êó•Êúü‰πãÂêéÔºåÊ≠§Êù°‰ª∂Áî®‰∫éÊîπÂñÑÊü•ËØ¢ÈÄüÂ∫¶
    and topic0 = 0x4996ad2257e7db44908136c43128cc10ca988096f67dc6bb0bcee11d151368fb   -- ‰∫ã‰ª∂‰∏ªÈ¢ò FollowNFTTransferred
limit 10
```

‰ª•‰∏äÊü•ËØ¢ÁöÑÁ§∫‰æãÈìæÊé•Ôºö
- [https://dune.com/queries/1652759](https://dune.com/queries/1652759)
- [Keccak-256 Tool](https://emn178.github.io/online-tools/keccak_256.html)

## ‰ΩøÁî®Êï∞Â≠óÂ∫èÂàóÁÆÄÂåñÊü•ËØ¢

Á†îÁ©∂NFTÈ°πÁõÆÊó∂ÔºåÊàë‰ª¨ÂèØËÉΩÈúÄË¶ÅÂàÜÊûêÊüê‰∏™Êó∂Èó¥ÊÆµÂÜÖÊüê‰∏™NFTÈ°πÁõÆÁ≠âÊâÄÊúâ‰∫§ÊòìÁöÑ‰ª∑Ê†ºÂàÜÂ∏ÉÊÉÖÂÜµÔºå‰πüÂ∞±ÊòØÁúã‰∏ãÊØè‰∏Ä‰∏™‰ª∑Ê†ºÂå∫Èó¥ÂÜÖÊúâÂ§öÂ∞ëÁ¨î‰∫§ÊòìËÆ∞ÂΩï„ÄÇÈÄöÂ∏∏Êàë‰ª¨‰ºöËÆæÁΩÆÊúÄÂ§ßÊàê‰∫§‰ª∑Ê†ºÂíåÊúÄÂ∞èÊàê‰∫§‰ª∑Ê†ºÔºàÈÄöËøáËæìÂÖ•ÊàñËÄÖ‰ªéÊàê‰∫§Êï∞ÊçÆ‰∏≠Êü•ËØ¢Âπ∂ÂØπÂºÇÂ∏∏ÂÄºÂÅöÈÄÇÂΩìÂ§ÑÁêÜÔºâÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∏™ËåÉÂõ¥ÂÜÖÁöÑ‰ª∑Ê†ºÂàíÂàÜ‰∏∫N‰∏™Âå∫Èó¥ÔºåÂÜçÁªüËÆ°ÊØè‰∏™Âå∫Èó¥ÂÜÖÁöÑ‰∫§ÊòìÊï∞Èáè„ÄÇ‰∏ãÈù¢ÊòØÈÄªËæëÁÆÄÂçï‰ΩÜÊòØÊØîËæÉÁπÅÁêêÁöÑÊü•ËØ¢Á§∫‰æãÔºö

```sql
-- nftÊåÅ‰ªìÊàêÊú¨ÂàÜÂ∏É
-- 0x306b1ea3ecdf94ab739f1910bbda052ed4a9f949 beanz
-- 0xED5AF388653567Af2F388E6224dC7C4b3241C544 azuki
with contract_transfer as (
    select * 
    from nft.trades
    where nft_contract_address = 0xe361f10965542ee57D39043C9c3972B77841F581
        and tx_to != 0x0000000000000000000000000000000000000000
        and amount_original is not null
),

transfer_rn as (
    select row_number() over (partition by token_id order by block_time desc) as rn, *
    from contract_transfer
),

latest_transfer as (
    select * from transfer_rn
    where rn = 1 
),

min_max as (
    select (cast({{max_price}} as double) - cast({{min_price}} as double))/20.0 as bin
),

bucket_trade as (select *,
    case 
      when amount_original between {{min_price}}+0*bin and {{min_price}}+1*bin then 1*bin
      when amount_original between {{min_price}}+1*bin and {{min_price}}+2*bin then 2*bin
      when amount_original between {{min_price}}+2*bin and {{min_price}}+3*bin then 3*bin
      when amount_original between {{min_price}}+3*bin and {{min_price}}+4*bin then 4*bin
      when amount_original between {{min_price}}+4*bin and {{min_price}}+5*bin then 5*bin
      when amount_original between {{min_price}}+5*bin and {{min_price}}+6*bin then 6*bin
      when amount_original between {{min_price}}+6*bin and {{min_price}}+7*bin then 7*bin
      when amount_original between {{min_price}}+7*bin and {{min_price}}+8*bin then 8*bin
      when amount_original between {{min_price}}+8*bin and {{min_price}}+9*bin then 9*bin
      when amount_original between {{min_price}}+9*bin and {{min_price}}+10*bin then 10*bin
      when amount_original between {{min_price}}+10*bin and {{min_price}}+11*bin then 11*bin
      when amount_original between {{min_price}}+11*bin and {{min_price}}+12*bin then 12*bin
      when amount_original between {{min_price}}+12*bin and {{min_price}}+13*bin then 13*bin
      when amount_original between {{min_price}}+13*bin and {{min_price}}+14*bin then 14*bin
      when amount_original between {{min_price}}+14*bin and {{min_price}}+15*bin then 15*bin
      when amount_original between {{min_price}}+15*bin and {{min_price}}+16*bin then 16*bin
      when amount_original between {{min_price}}+16*bin and {{min_price}}+17*bin then 17*bin
      when amount_original between {{min_price}}+17*bin and {{min_price}}+18*bin then 18*bin
      when amount_original between {{min_price}}+18*bin and {{min_price}}+19*bin then 19*bin
      when amount_original between {{min_price}}+19*bin and {{min_price}}+20*bin then 20*bin
      ELSE 21*bin
    end as gap
  from latest_transfer,min_max
 )

select gap, count(*) as num
from bucket_trade
group by gap
order by gap 
```

Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏§‰∏™ÂèÇÊï∞`min_price`Âíå`max_price`ÔºåÂ∞Ü‰ªñ‰ª¨ÁöÑÂ∑ÆÂÄºÁ≠âÂàÜ‰∏∫20‰ªΩ‰Ωú‰∏∫ÂàÜÁªÑ‰ª∑Ê†ºÂå∫Èó¥ÔºåÁÑ∂Âêé‰ΩøÁî®‰∫Ü‰∏Ä‰∏™ÂÜóÈïøÁöÑCASEËØ≠Âè•Êù•ÁªüËÆ°ÊØè‰∏™Âå∫Èó¥ÂÜÖÁöÑ‰∫§ÊòìÊï∞Èáè„ÄÇÊÉ≥Ë±°‰∏Ä‰∏ãÂ¶ÇÊûúÈúÄË¶ÅÂàÜÊàê50ÁªÑÁöÑÊÉÖÂÜµ„ÄÇÊúâÊ≤°ÊúâÊõ¥ÁÆÄÂçïÁöÑÊñπÊ≥ïÂë¢ÔºüÁ≠îÊ°àÊòØÊúâ„ÄÇÂÖàÁúã‰ª£Á†ÅÔºö

```sql
with contract_transfer as (
    select * 
    from nft.trades
    where nft_contract_address = 0xe361f10965542ee57D39043C9c3972B77841F581
        and tx_to != 0x0000000000000000000000000000000000000000
        and amount_original is not null
),

transfer_rn as (
    select row_number() over (partition by token_id order by block_time desc) as rn, *
    from contract_transfer
),

latest_transfer as (
    select *
    from transfer_rn
    where rn = 1 
),

min_max as (
    select (cast({{max_price}} as double) - cast({{min_price}} as double))/20.0 as bin
),

-- ÁîüÊàê‰∏Ä‰∏™1Âà∞20Êï∞Â≠óÁöÑÂçïÂàóË°®
num_series as (
    select num from unnest(sequence(1, 20)) as tbl(num)
),

-- ÁîüÊàêÂàÜÁªÑ‰ª∑Ê†ºÂå∫Èó¥ÁöÑÂºÄÂßãÂíåÁªìÊùü‰ª∑Ê†º
bin_gap as (
    select (num - 1) * bin as gap,
        (num - 1) * bin as price_lower,
        num * bin as price_upper
    from num_series
    join min_max on true
    
    union all
    
    -- Ë°•ÂÖÖ‰∏Ä‰∏™È¢ùÂ§ñÁöÑÂå∫Èó¥Ë¶ÜÁõñÂÖ∂‰ªñÊï∞ÊçÆ
    select num * bin as gap,
        num * bin as price_lower,
        num * 1e4 * bin as price_upper
    from num_series
    join min_max on true
    where num = 20
),

bucket_trade as (
    select t.*,
        b.gap
      from latest_transfer t
      join bin_gap b on t.amount_original >= b.price_lower and t.amount_original < b.price_upper
 )

select gap, count(*) as num
from bucket_trade
group by gap
order by gap
```

Âú®CTE`num_series`‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®`unnest(sequence(1, 20)) as tbl(num)`Êù•ÁîüÊàê‰∫Ü‰∏Ä‰∏™‰ªé1Âà∞20ÁÇπÊï∞Â≠óÂ∫èÂàóÂπ∂‰∏îËΩ¨Êç¢‰∏∫20Ë°åÔºåÊØèË°å‰∏Ä‰∏™Êï∞Â≠ó„ÄÇÁÑ∂ÂêéÂú®`bin_gap`‰∏≠ÔºåÊàë‰ª¨ÈÄöËøáJOIN‰∏§‰∏™CTEËÆ°ÁÆóÂæóÂà∞‰∫ÜÊØè‰∏Ä‰∏™Âå∫Èó¥ÁöÑ‰ΩéÁÇπ‰ª∑Ê†ºÂÄºÂíåÈ´òÁÇπ‰ª∑Ê†ºÂÄº„ÄÇ‰ΩøÁî®`union all`ÈõÜÂêàÊ∑ªÂä†‰∫Ü‰∏Ä‰∏™È¢ùÂ§ñÁöÑÈ´òÁÇπ‰ª∑Ê†ºÂÄºË∂≥Â§üÂ§ßÁöÑÂå∫Èó¥Êù•Ë¶ÜÁõñÂÖ∂‰ªñ‰∫§ÊòìËÆ∞ÂΩï„ÄÇÊé•‰∏ãÊù•`bucket_trade`Â∞±ÂèØ‰ª•ÁÆÄÂåñ‰∏∫Âè™ÈúÄË¶ÅÁÆÄÂçïÂÖ≥ËÅî`bin_gap`Âπ∂ÊØîËæÉ‰ª∑Ê†ºËêΩÂÖ•ÂØπÂ∫îÂå∫Èó¥Âç≥ÂèØ„ÄÇÊï¥‰Ωì‰∏äÈÄªËæëÂæóÂà∞‰∫ÜÁÆÄÂåñËÄåÊòæÂæóÊõ¥Âä†Ê∏ÖÊô∞ÊòìÊáÇ„ÄÇ

‰ª•‰∏äÊü•ËØ¢ÁöÑÁ§∫‰æãÈìæÊé•Ôºö
- [https://dune.com/queries/1054461](https://dune.com/queries/1054461)
- [https://dune.com/queries/1654001](https://dune.com/queries/1654001)

## ËØªÂèñÊï∞ÁªÑArrayÂíåÁªìÊûÑStructÂ≠óÊÆµ‰∏≠ÁöÑÊï∞ÊçÆ

ÊúâÁöÑÊô∫ËÉΩÂêàÁ∫¶ÂèëÂá∫ÁöÑ‰∫ã‰ª∂Êó•Âøó‰ΩøÁî®Êï∞ÁªÑÁ±ªÂûãÁöÑÂèÇÊï∞ÔºåÊ≠§Êó∂DuneËß£ÊûêÂêéÁîüÊàêÁöÑÊï∞ÊçÆË°®‰πüÊòØ‰ΩøÁî®Êï∞ÁªÑÊù•Â≠òË¥ÆÁöÑ„ÄÇSolanaÂå∫ÂùóÈìæÁöÑÂéüÂßã‰∫§ÊòìÊï∞ÊçÆË°®Êõ¥ÊòØÂ§ßÈáè‰ΩøÁî®‰∫ÜÊï∞ÁªÑÊù•Â≠òË¥ÆÊï∞ÊçÆ„ÄÇ‰πüÊúâ‰∫õÊï∞ÊçÆÊòØ‰øùÂ≠òÂú®ÁªìÊûÑÁ±ªÂûãÁöÑÔºåÊàñËÄÖÊàë‰ª¨Âú®ÊèêÂèñÊï∞ÊçÆÊó∂ÈúÄË¶ÅÂÄüÁî®ÁªìÊûÑÁ±ªÂûãÔºà‰∏ãÊñáÊúâ‰æãÂ≠êÔºâ„ÄÇÊàë‰ª¨‰∏ÄËµ∑Êù•Áúã‰∏ãÂ¶Ç‰ΩïËÆøÈóÆ‰øùÂ≠òÁùÄÊï∞ÁªÑÂ≠óÊÆµÂíåÁªìÊûÑÂ≠óÊÆµ‰∏≠ÁöÑÊï∞ÊçÆ„ÄÇ

```sql
select tokens, deltas, evt_tx_hash
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

‰∏äÈù¢Êü•ËØ¢ËøîÂõûÁöÑÂâç‰∏§‰∏™Â≠óÊÆµÈÉΩÊòØÊï∞ÁªÑÁ±ªÂûãÔºàÊàëÂ§ÑÁêÜ‰∫Ü‰∏Ä‰∏ãÔºåÊòæÁ§∫Â¶Ç‰∏ãÂõæÔºâÔºö

![image_10.png](img/image_10.png)

Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®`cross join unnest(tokens) as tbl1(token)`Êù•Â∞Ü`tokens`Êï∞ÁªÑÂ≠óÊÆµÊãÜÂàÜ‰∏∫Â§öË°åÔºö

```sql
select evt_tx_hash, deltas, token   -- ËøîÂõûÊãÜÂàÜÂêéÁöÑÂ≠óÊÆµ
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
cross join unnest(tokens) as tbl1(token)   -- ÊãÜÂàÜ‰∏∫Â§öË°åÔºåÊñ∞Â≠óÊÆµÂëΩÂêç‰∏∫ token
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

ÂêåÊ†∑Êàë‰ª¨ÂèØ‰ª•ÂØπ`deltas`Â≠óÊÆµËøõË°åÊãÜÂàÜ„ÄÇ‰ΩÜÊòØÂõ†‰∏∫ÊØè‰∏Ä‰∏™`cross join`ÈÉΩ‰ºöÂ∞ÜÊãÜÂàÜÂæóÂà∞ÁöÑÂÄºÂàÜÂà´ÈôÑÂä†Âà∞Êü•ËØ¢ÂéüÊù•ÁöÑÁªìÊûúÈõÜÔºåÂ¶ÇÊûúÂêåÊó∂ÂØπËøô‰∏§‰∏™Â≠óÊÆµÊâßË°åÊìç‰ΩúÔºåÊàë‰ª¨Â∞±‰ºöÂæóÂà∞‰∏Ä‰∏™Á±ª‰ººÁ¨õÂç°Â∞î‰πòÁßØÁöÑÈîôËØØÁªìÊûúÈõÜ„ÄÇÊü•ËØ¢‰ª£Á†ÅÂíåËæìÂá∫ÁªìÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

```sql
select evt_tx_hash, token, delta
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
cross join unnest(tokens) as tbl1(token)   -- ÊãÜÂàÜ‰∏∫Â§öË°åÔºåÊñ∞Â≠óÊÆµÂëΩÂêç‰∏∫ token
cross join unnest(deltas) as tbl2(delta)   -- ÊãÜÂàÜ‰∏∫Â§öË°åÔºåÊñ∞Â≠óÊÆµÂëΩÂêç‰∏∫ delta
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

![image_11.png](img/image_11.png)

Ë¶ÅÈÅøÂÖçÈáçÂ§çÔºåÊ≠£Á°ÆÁöÑÂÅöÊ≥ïÊòØÂú®Âêå‰∏Ä‰∏™`unnest()`ÂáΩÊï∞ÈáåÈù¢ÂêåÊó∂ÂØπÂ§ö‰∏™Â≠óÊÆµËøõË°åÊãÜÂàÜÔºåËøîÂõû‰∏Ä‰∏™ÂåÖÊã¨Â§ö‰∏™ÂØπÂ∫îÊñ∞Â≠óÊÆµÁöÑ‰∏¥Êó∂Ë°®„ÄÇ

```sql
select evt_tx_hash, token, delta
from balancer_v2_arbitrum.Vault_evt_PoolBalanceChanged
cross join unnest(tokens, deltas) as tbl(token, delta)   -- ÊãÜÂàÜ‰∏∫Â§öË°åÔºåÊñ∞Â≠óÊÆµÂëΩÂêç‰∏∫ token Âíå delta
where evt_tx_hash = 0x65a4f35d81fd789d93d79f351dc3f8c7ed220ab66cb928d2860329322ffff32c
```

ÁªìÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_12.png](img/image_12.png)

‰ª•‰∏äÊü•ËØ¢ÁöÑÁ§∫‰æãÈìæÊé•Ôºö
- [https://dune.com/queries/1654079](https://dune.com/queries/1654079)


## ËØªÂèñJSONÂ≠óÁ¨¶‰∏≤Êï∞ÊçÆ

ÊúâÁöÑÊô∫ËÉΩÂêàÁ∫¶ÁöÑËß£ÊûêË°®ÈáåÔºåÂåÖÂê´Â§ö‰∏™ÂèÇÊï∞ÂÄºÁöÑÂØπË±°Ë¢´Â∫èÂàóÂåñ‰∏∫jsonÂ≠óÁ¨¶‰∏≤Ê†ºÂºè‰øùÂ≠òÔºåÊØîÂ¶ÇÊàë‰ª¨‰πãÂâç‰ªãÁªçËøáLensÁöÑÂàõÂª∫Profile‰∫ã‰ª∂„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®`:`Êù•Áõ¥Êé•ËØªÂèñjsonÂ≠óÁ¨¶‰∏≤‰∏≠ÁöÑÂèòÈáè„ÄÇ‰æãÂ¶ÇÔºö

```sql
select  json_value(vars, 'lax $.to') as user_address, -- ËØªÂèñjsonÂ≠óÁ¨¶‰∏≤‰∏≠ÁöÑÁî®Êà∑Âú∞ÂùÄ
     json_value(vars, 'lax $.handle') as handle_name, -- ËØªÂèñjsonÂ≠óÁ¨¶‰∏≤‰∏≠ÁöÑÁî®Êà∑ÊòµÁß∞
    call_block_time,
    output_0 as profile_id,
    call_tx_hash
from lens_polygon.LensHub_call_createProfile
where call_success = true   
limit 100
```

Âè¶Â§ñÁöÑÊñπÂºèÊòØ‰ΩøÁî®`json_query()`Êàñ`json_extract()`ÂáΩÊï∞Êù•ÊèêÂèñÂØπÂ∫îÊï∞ÊçÆ„ÄÇÂΩìÈúÄË¶Å‰ªéJSONÂ≠óÁ¨¶‰∏≤‰∏≠ÊèêÂèñÊï∞ÁªÑÁ±ªÂûãÁöÑÂÄºÊó∂Ôºå‰ΩøÁî®`json_extract()`ÂáΩÊï∞ÊâçËÉΩÊîØÊåÅÁ±ªÂûãËΩ¨Êç¢„ÄÇ‰∏æ‰æãÂ¶Ç‰∏ãÔºö

```sql
select
json_query(vars, 'lax $.follower') AS follower, -- single value
json_query(vars, 'lax $.profileIds') AS profileIds, -- still string
from_hex(cast(json_extract(vars,'$.follower') as varchar)) as follower2, -- cast to varbinary
cast(json_extract(vars,'$.profileIds') as array(integer)) as profileIds2, -- cast to array
vars
from lens_polygon.LensHub_call_followWithSig
where cardinality(output_0) > 1
limit 10
```

‰ª•‰∏äÊü•ËØ¢ÁöÑÁ§∫‰æãÈìæÊé•Ôºö
- [https://dune.com/queries/1562662](https://dune.com/queries/1562662)
- [https://dune.com/queries/941978](https://dune.com/queries/941978)
- [https://dune.com/queries/1554454](https://dune.com/queries/1554454)

Dune SQL (Trino ÂºïÊìé) JSONÁõ∏ÂÖ≥ÂáΩÊï∞ÁöÑËØ¶ÁªÜÂ∏ÆÂä©ÂèØ‰ª•Êü•ÁúãÔºöhttps://trino.io/docs/current/functions/json.html 

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch13/ch12-nft-analysis.md">
# NFTÊï∞ÊçÆÂàÜÊûê

## ËÉåÊôØÁü•ËØÜ

[NFT(Non-Fungable Token)](https://ethereum.org/zh/nft/)ÈùûÂêåË¥®Âåñ‰ª£Â∏ÅÔºå‰ªñÊòØ‰∏Ä‰∏™ÈÅµÂæ™[ERC721](https://eips.ethereum.org/EIPS/eip-721)Ê†áÂáÜÁöÑ‰ª£Â∏ÅÔºåÁõ∏ÊØî‰∫éÈÅµ‰ªéERC20Ê†áÂáÜÁöÑÂêåË¥®Âåñ‰ª£Â∏ÅËÄåË®ÄÔºå‰º†Áªü‰∏äNFTÊúÄÂÖ∏ÂûãÁöÑÁâπÁÇπÊòØÊØè‰∏™‰ª£Â∏ÅÈÉΩÂÖ∑Êúâ‰∏çÂèØÂàÜÂâ≤„ÄÅ‰∏çÂèØÊõø‰ª£„ÄÅÁã¨‰∏ÄÊó†‰∫åÁ≠âÁâπÁÇπ„ÄÇNFTÁöÑÁî®ÈÄî‰∏ÄËà¨ÊúâÔºö

- Êï∞Â≠óËâ∫ÊúØÂìÅ/ËóèÂìÅ
- Ê∏∏ÊàèÂÜÖÁâ©ÂìÅ
- ÂüüÂêç
- ÂèØ‰ª•ÂèÇÂä†ÊüêÈ°πÊ¥ªÂä®ÁöÑÈó®Á•®Êàñ‰ºòÊÉ†Âà∏
- Êï∞Â≠óË∫´‰ªΩ
- ÊñáÁ´†

ÊØîÂ¶ÇÂú®Êï∞Â≠óËâ∫ÊúØÂìÅ‰∏≠Ôºå‰∏çÂêåÁöÑNFTÊòØÂÖ∑Êúâ‰∏çÂêåÁöÑÊ†∑ÂºèÈ£éÊ†ºÁöÑÔºõÂÜçÊØîÂ¶ÇENSÂüüÂêç‰∏≠ÔºåÊØè‰∏Ä‰∏™ÂüüÂêçÈÉΩÊòØÁã¨‰∏ÄÊó†‰∫åÁöÑÔºå‰∏çÂèØÈáçÂ§çÁöÑÔºõ‰ΩÜÊòØÂØπ‰∫éÈó®Á•®ËÄåË®ÄÔºåÊØè‰∏ÄÂº†Èó®Á•®ÈÉΩÊúâÂõ∫ÂÆöÁöÑÂ∫ß‰ΩçÔºå‰∏çÂêåÁöÑÂ∫ß‰Ωç‰πüÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑÁºñÂè∑„ÄÇ

ÈöèÁùÄNFTÁöÑÂèëÂ±ïËøòË°çÁîüÂá∫‰∫ÜÂÖ∂ÂÆÉÊ†áÂáÜÁöÑNFTÔºö

- ERC-1155ÔºöÈùûÂêåË¥®Âåñ‰ª£Â∏ÅÔºåÊØè‰∏™token‰∏ç‰∏ÄÊ†∑Ôºå‰ΩÜÂèàÂèØ‰ª•ÂÅöÊï∞ÈáèËΩ¨Áßª
- SBT: ‰∏çÂèØËΩ¨ÁßªÁöÑToken
- ERC-3235: ÂçäÂêåË¥®ÂåñÔºåÊØè‰∏™token‰∏ç‰∏ÄÊ†∑ÔºåÂèàÊîØÊåÅÁªìÁÆó

![](img/ERC-Standard.jpeg)

## ÂêàÁ∫¶ËØ¥Êòé

NFTÁõ∏ÂÖ≥ÁöÑÂêàÁ∫¶ÈÄöÂ∏∏ÂàÜ‰∏∫‰∏§Á±ªÔºö‰∏ÄÁ±ªÊòØÈ°πÁõÆÊñπÁöÑÂêàÁ∫¶Ôºå‰∫åÊòØÁî®Êù•‰∫§ÊòìNFTÁöÑÁ¨¨‰∏âÊñπ‰∫§ÊòìÂπ≥Âè∞ÂêàÁ∫¶„ÄÇ

### ERC721ÂêàÁ∫¶

Êàë‰ª¨‰ª•ERC721ÁöÑNFT‰∏∫‰æãËØ¥ÊòéÂÖ∂ÂêàÁ∫¶ÁâπÁÇπÔºåÂÖ∂ÂÆÉÂèØËá™Ë°åÊ†πÊçÆÈúÄÊ±ÇÂÜçÂéªÊ∑±ÂÖ•‰∫ÜËß£ÔºåÊàë‰ª¨Âú®NFTÂ∏ÇÂú∫Opensea‰∏ä‰ª•[azuki](https://opensea.io/collection/azuki)Ëøô‰∏™NFT‰∏∫‰æãÔºåËØ¥ÊòéÂêàÁ∫¶ÈÉΩÊúâÂì™‰∫õ‰∫ã‰ª∂Ôºö

```solidity
interface ERC721 {
    /// @dev ÂΩì‰ªª‰ΩïNFTÁöÑÊâÄÊúâÊùÉÊõ¥ÊîπÊó∂Ôºà‰∏çÁÆ°Âì™ÁßçÊñπÂºèÔºâÔºåÂ∞±‰ºöËß¶ÂèëÊ≠§‰∫ã‰ª∂„ÄÇ
    ///  ÂåÖÊã¨Âú®ÂàõÂª∫Êó∂Ôºà`from` == 0ÔºâÂíåÈîÄÊØÅÊó∂(`to` == 0), ÂêàÁ∫¶ÂàõÂª∫Êó∂Èô§Â§ñ„ÄÇ
    event Transfer(address indexed _from, address indexed _to, uint256 indexed _tokenId);

    /// @dev ÂΩìÊõ¥ÊîπÊàñÁ°ÆËÆ§NFTÁöÑÊéàÊùÉÂú∞ÂùÄÊó∂Ëß¶Âèë„ÄÇ
    ///  Èõ∂Âú∞ÂùÄË°®Á§∫Ê≤°ÊúâÊéàÊùÉÁöÑÂú∞ÂùÄ„ÄÇ
    ///  ÂèëÁîü `Transfer` ‰∫ã‰ª∂Êó∂ÔºåÂêåÊ†∑Ë°®Á§∫ËØ•NFTÁöÑÊéàÊùÉÂú∞ÂùÄÔºàÂ¶ÇÊûúÊúâÔºâË¢´ÈáçÁΩÆ‰∏∫‚ÄúÊó†‚ÄùÔºàÈõ∂Âú∞ÂùÄÔºâ„ÄÇ
    event Approval(address indexed _owner, address indexed _approved, uint256 indexed _tokenId);

    /// @dev ÊâÄÊúâËÄÖÂêØÁî®ÊàñÁ¶ÅÁî®Êìç‰ΩúÂëòÊó∂Ëß¶Âèë„ÄÇÔºàÊìç‰ΩúÂëòÂèØÁÆ°ÁêÜÊâÄÊúâËÄÖÊâÄÊåÅÊúâÁöÑNFTsÔºâ
    event ApprovalForAll(address indexed _owner, address indexed _operator, bool _approved);

    /// @notice Â∞ÜNFTÁöÑÊâÄÊúâÊùÉ‰ªé‰∏Ä‰∏™Âú∞ÂùÄËΩ¨ÁßªÂà∞Âè¶‰∏Ä‰∏™Âú∞ÂùÄ
    /// @dev Â¶ÇÊûú`msg.sender` ‰∏çÊòØÂΩìÂâçÁöÑÊâÄÊúâËÄÖÔºàÊàñÊéàÊùÉËÄÖÔºâÊäõÂá∫ÂºÇÂ∏∏
    /// Â¶ÇÊûú `_from` ‰∏çÊòØÊâÄÊúâËÄÖ„ÄÅ`_to` ÊòØÈõ∂Âú∞ÂùÄ„ÄÅ`_tokenId` ‰∏çÊòØÊúâÊïàid ÂùáÊäõÂá∫ÂºÇÂ∏∏„ÄÇ
    ///  ÂΩìËΩ¨ÁßªÂÆåÊàêÊó∂ÔºåÂáΩÊï∞Ê£ÄÊü•  `_to` ÊòØÂê¶ÊòØÂêàÁ∫¶ÔºåÂ¶ÇÊûúÊòØÔºåË∞ÉÁî® `_to`ÁöÑ `onERC721Received` Âπ∂‰∏îÊ£ÄÊü•ËøîÂõûÂÄºÊòØÂê¶ÊòØ `0x150b7a02` (Âç≥Ôºö`bytes4(keccak256("onERC721Received(address,address,uint256,bytes)"))`)  Â¶ÇÊûú‰∏çÊòØÊäõÂá∫ÂºÇÂ∏∏„ÄÇ
    /// @param _from ÔºöÂΩìÂâçÁöÑÊâÄÊúâËÄÖ
    /// @param _to ÔºöÊñ∞ÁöÑÊâÄÊúâËÄÖ
    /// @param _tokenId ÔºöË¶ÅËΩ¨ÁßªÁöÑtoken id.
    /// @param data : ÈôÑÂä†È¢ùÂ§ñÁöÑÂèÇÊï∞ÔºàÊ≤°ÊúâÊåáÂÆöÊ†ºÂºèÔºâÔºå‰º†ÈÄíÁªôÊé•Êî∂ËÄÖ„ÄÇ
    function safeTransferFrom(address _from, address _to, uint256 _tokenId, bytes data) external payable;

    /// @notice ËΩ¨ÁßªÊâÄÊúâÊùÉ -- Ë∞ÉÁî®ËÄÖË¥üË¥£Á°ÆËÆ§`_to`ÊòØÂê¶ÊúâËÉΩÂäõÊé•Êî∂NFTsÔºåÂê¶ÂàôÂèØËÉΩÊ∞∏‰πÖ‰∏¢Â§±„ÄÇ
    /// @dev Â¶ÇÊûú`msg.sender` ‰∏çÊòØÂΩìÂâçÁöÑÊâÄÊúâËÄÖÔºàÊàñÊéàÊùÉËÄÖ„ÄÅÊìç‰ΩúÂëòÔºâÊäõÂá∫ÂºÇÂ∏∏
    /// Â¶ÇÊûú `_from` ‰∏çÊòØÊâÄÊúâËÄÖ„ÄÅ`_to` ÊòØÈõ∂Âú∞ÂùÄ„ÄÅ`_tokenId` ‰∏çÊòØÊúâÊïàid ÂùáÊäõÂá∫ÂºÇÂ∏∏„ÄÇ
    function transferFrom(address _from, address _to, uint256 _tokenId) external payable;

    /// @notice Êõ¥ÊîπÊàñÁ°ÆËÆ§NFTÁöÑÊéàÊùÉÂú∞ÂùÄ
    /// @dev Èõ∂Âú∞ÂùÄË°®Á§∫Ê≤°ÊúâÊéàÊùÉÁöÑÂú∞ÂùÄ„ÄÇ
    ///  Â¶ÇÊûú`msg.sender` ‰∏çÊòØÂΩìÂâçÁöÑÊâÄÊúâËÄÖÊàñÊìç‰ΩúÂëò
    /// @param _approved Êñ∞ÊéàÊùÉÁöÑÊéßÂà∂ËÄÖ
    /// @param _tokenId Ôºö token id
    function approve(address _approved, uint256 _tokenId) external payable;

    /// @notice ÂêØÁî®ÊàñÁ¶ÅÁî®Á¨¨‰∏âÊñπÔºàÊìç‰ΩúÂëòÔºâÁÆ°ÁêÜ `msg.sender` ÊâÄÊúâËµÑ‰∫ß
    /// @dev Ëß¶Âèë ApprovalForAll ‰∫ã‰ª∂ÔºåÂêàÁ∫¶ÂøÖÈ°ªÂÖÅËÆ∏ÊØè‰∏™ÊâÄÊúâËÄÖÂèØ‰ª•ÊúâÂ§ö‰∏™Êìç‰ΩúÂëò„ÄÇ
    /// @param _operator Ë¶ÅÊ∑ªÂä†Âà∞ÊéàÊùÉÊìç‰ΩúÂëòÂàóË°®‰∏≠ÁöÑÂú∞ÂùÄ
    /// @param _approved True Ë°®Á§∫ÊéàÊùÉ, false Ë°®Á§∫Êí§ÈîÄ
    function setApprovalForAll(address _operator, bool _approved) external;

    ...
}
```

ÂØπ‰∫éÊï∞ÊçÆÂàÜÊûêÔºå‰∏äËø∞ÂáΩÊï∞‰∏≠ÊúÄÈáçË¶ÅÁöÑÊòØTransferËøô‰∏™event‰∫ã‰ª∂ÔºåÂú®ÊØèÁ¨î‰∫§ÊòìÊó∂ÈÉΩ‰ºöËß¶ÂèëËØ•‰∫ã‰ª∂Âπ∂ËÆ∞ÂΩïÂà∞Èìæ‰∏äÔºåÈô§‰∫ÜTransferÔºåËøòÊúâMint‰∫ã‰ª∂Ôºå‰∏ÄËà¨Áî®Âú®È°πÁõÆÂèëÂîÆÊó∂ÊúüÁî®Êù•Èì∏ÈÄ†‰∏Ä‰∏™Êñ∞ÁöÑNFT„ÄÇDuneÁöÑÈ≠îÊ≥ïË°®Êèê‰æõ‰∫ÜERC721ÔºåERC1155Á±ªÂûãÁöÑTransferË°®ÔºåÂ¶Ç`erc721_ethereum.evt_Transfer`Ôºå`erc1155_ethereum.evt_Transfer`Á≠âÔºà‰∏çÂêåÂå∫ÂùóÈìæ‰∏ãÂêçÁß∞‰∏çÂêåÔºâÔºåÊàë‰ª¨ÂèØ‰ª•‰ªé‰∏≠Êü•ËØ¢Êüê‰∏™ÂêàÁ∫¶ÊàñËÄÖÊüê‰∏™EOAÂú∞ÂùÄÁöÑÁõ∏ÂÖ≥NFT‰º†Ëæì‰∫ã‰ª∂„ÄÇ

Âú®Transfer‰∫ã‰ª∂‰∏≠Ôºå‰∏ªË¶ÅÊúâ‰∏â‰∏™ÂèÇÊï∞ÂèëÈÄÅÊñπÂú∞ÂùÄ`from`, Êé•Êî∂ÊñπÂú∞ÂùÄ`to`ÂíåNFTÁöÑÁºñÂè∑`tokenId`„ÄÇ‰∫§ÊòìÁöÑÊÉÖÂÜµ‰∏ãÔºåfromÂíåtoÈÉΩÊòØ‰∏Ä‰∏™Ê≠£Â∏∏ÁöÑÂú∞ÂùÄÔºåÂ¶ÇÊûúÊòØÈì∏ÈÄ†mintÈÇ£‰πàfromÂú∞ÂùÄÂàôÂÖ®ÊòØ0ÔºåÂ¶ÇÊûúÊòØÈîÄÊØÅburnÂàôtoÁöÑÂú∞ÂùÄÂÖ®ÊòØ0ÔºåDune‰∏äÁöÑnft.mintË°®Âíånft.burnË°®‰πüÊòØÈÄöËøáËß£ÊûêËØ•event‰∫ã‰ª∂ÔºåÂæóÂà∞ÊúÄÁªàÁöÑ‰∫§Êòì‰ø°ÊÅØ„ÄÇ
![](img/nft-transfer-etherscan.png)

### ‰∫§ÊòìÂ∏ÇÂú∫ÂêàÁ∫¶

Âú®‰∫§ÊòìÂ∏ÇÂú∫ÂêàÁ∫¶‰∏≠ÔºåÂ∏∏ËßÅÁöÑÊúâOpensea„ÄÅX2Y2„ÄÅBlurÁ≠âÔºåËøôÈáåÊàë‰ª¨‰ª•OpenseaÁöÑSeaport1.1ÂêàÁ∫¶‰∏∫‰æãËØ¥ÊòéÔºåseaportÂêàÁ∫¶ÁöÑÂèØÂÜôÂáΩÊï∞Â¶Ç‰∏ãÔºåÂíå‰∫§ÊòìÁõ∏ÂÖ≥ÁöÑÂáΩÊï∞ÈÉΩ‰ºöËß¶ÂèëOrderFulfilledËøô‰∏™event‰∫ã‰ª∂Ôºå‰ªéËÄåÂ∞ÜÊï∞ÊçÆËÆ∞ÂΩïÂà∞Èìæ‰∏äÔºåDune‰∏äÁöÑnft.trades‰πüÊòØÈÄöËøáËß£ÊûêËØ•event‰∫ã‰ª∂ÔºåÂæóÂà∞ÊúÄÁªàÁöÑ‰∫§Êòì‰ø°ÊÅØ„ÄÇ

![](img/seaport1.1.png)

```solidity
uint256 constant receivedItemsHash_ptr = 0x60;

/*
 *  Memory layout in _prepareBasicFulfillmentFromCalldata of
 *  data for OrderFulfilled
 *
 *   event OrderFulfilled(
 *     bytes32 orderHash,
 *     address indexed offerer,
 *     address indexed zone,
 *     address fulfiller,
 *     SpentItem[] offer,
 *       > (itemType, token, id, amount)
 *     ReceivedItem[] consideration
 *       > (itemType, token, id, amount, recipient)
 *   )
 *
```

ÊØîÂ¶ÇÂº†‰∏â‰ª•10ETHÊåÇÂçï‰∫Ü‰∏Ä‰∏™ÁºñÂè∑[3638](https://opensea.io/assets/ethereum/0xed5af388653567af2f388e6224dc7c4b3241c544/3638)ÁöÑAzukiÁöÑNFTÔºåÈÇ£‰πà‰ªñ‰ºöËß¶ÂèëÂèëfulfillBasicOrderÂáΩÊï∞Ôºå‰∫§ÊòìÊàêÂäüÂêéÔºå‰ºöÂá∫ÂèëOrderFulfilledËøô‰∏™event‰∫ã‰ª∂ÔºåÂêåÊó∂ËÆ∞ÂΩïÂà∞Èìæ‰∏äÔºåÂÖ∑‰Ωì‰ø°ÊÅØÊü•ÁúãÔºõ[EtherscanÈìæÊé•](https://etherscan.io/tx/0x9beb69ec6505e27f845f508169dae4229e851a8d7c7b580abef110bf831dc338https://etherscan.io/tx/0x9beb69ec6505e27f845f508169dae4229e851a8d7c7b580abef110bf831dc338) Âíå[duneÈìæÊé•](https://dune.com/queries/1660679)„ÄÇ



## Â∏∏Áî®Ë°®ËØ¥Êòé

- ÂéüÂßãÂü∫Á°ÄË°®ÔºöÂú®DuneÂπ≥Âè∞‰∏≠‰Ωç‰∫é`Raw`-->`transactions`Âíå`logs`Ë°®‰∏≠Ôºõ
- ÂÖ∑‰ΩìÁöÑÈ°πÁõÆË°®ÔºöÂú®DuneÂπ≥Âè∞‰∏≠‰Ωç‰∫é`Decoded Projects`-->ÊêúÁ¥¢ÂÖ∑‰ΩìÈ°πÁõÆË°®ÂêçÁß∞Ôºå‰ª•Âèä‰∫§ÊòìÂπ≥Âè∞ÂêçÁß∞Ôºõ
- ËÅöÂêàË°®Ôºö
  - Spells-->erc721: ËÆ∞ÂΩïerc721ÊâÄÊúâÁöÑtransferËÆ∞ÂΩï
  - Spells-->nft: ÂåÖÂê´‰∫Ü‰∫§Êòìtrade„ÄÅÈì∏ÈÄ†mint„ÄÅËΩ¨Áßªtransfer„ÄÅÊâãÁª≠Ë¥πfeeÂíåÈîÄÊØÅburnsÁ≠â‰ø°ÊÅØÔºåÂÖ∂‰∏≠ÊúÄÈáçË¶ÅÁöÑÊòØtradesË°®ÔºåÂÆÉËÅöÂêà‰∫Ü‰∏ªÊµÅ‰∫§ÊòìÊâÄÁöÑÊâÄÊúâ‰∫§ÊòìÊï∞ÊçÆ„ÄÇ

![](img/dune-nft-related.png)

ÈáçË¶ÅÁöÑnft.tradesË°®ÁöÑËØ¶ÊÉÖÂ¶Ç‰∏ãÔºö

| Â≠óÊÆµ                       | ËØ¥Êòé                                  |
| ------------------------ | ----------------------------------- |
| blockchain               | Âå∫ÂùóÈìæÔºåÂ§ö‰∏™ÈìæÁöÑÊï∞ÊçÆÈÉΩËÅöÈõÜÂà∞Ëøô‰∏™Ë°®‰∫Ü                  |
| project                  | ‰∫§ÊòìÂπ≥Âè∞ÂêçÁß∞                              |
| version                  | ‰∫§ÊòìÂπ≥Âè∞ÁâàÊú¨                              |
| block_time               | Âå∫ÂùóÊó∂Èó¥                                |
| token_id                 | NFT Token ID                        |
| collection               | NFTÁöÑÂêçÁß∞                              |
| amount_usd               | ‰∫§ÊòìÊó∂ÁöÑÁæéÂÖÉ‰ª∑ÂÄº                            |
| token_standard           | TokenÁöÑÊ†áÂáÜÔºå                           |
| trade_type               | ‰∫§ÊòìÁ±ªÂûãÔºåÊòØÂçïNFT‰∫§ÊòìËøòÊòØÂ§öNFT‰∫§Êòì                |
| number_of_items          | ‰∫§ÊòìÁöÑNFTÊï∞Èáè                            |
| trade_category           | ‰∫§ÊòìÁ±ªÂûã¬† (Direct buy, auction, etc...) |
| evt_type                 | evtÁ±ªÂûã(Trade, Mint, Burn)            |
| seller                   | ÂçñÊñπÈí±ÂåÖÂú∞ÂùÄ                              |
| buyer                    | ‰π∞ÊñπÈí±ÂåÖÂú∞ÂùÄ                              |
| amount_original          | ‰∫§ÊòìÁöÑÂéüÂßãÈáëÈ¢ùÔºàÂú®ÂéüÂßãÁöÑ‰ª£Â∏ÅtokenÂçï‰Ωç‰∏ãÔºâ             |
| amount_raw               | Êú™ÂÅöÊï∞ÂÄºÂåñÁöÑÂéüÂßã‰∫§ÊòìÈáëÈ¢ù                        |
| currency_symbol          | ‰∫§ÊòìÁöÑ‰ª£Â∏ÅÁ¨¶Âè∑ÔºàÁî®‰ªÄ‰πàtoken‰Ωú‰∏∫ËÆ°‰ª∑Âçï‰ΩçÊîØ‰ªòÔºâ           |
| currency_contract        | ÂéüÂßã‰∫§ÊòìÁöÑ‰ª£Â∏ÅÂêàÁ∫¶Âú∞ÂùÄÔºå<br>ETHÁöÑÂêàÁ∫¶Âú∞ÂùÄÁî®WETH       |
| nft_contract_address     | NFTÁöÑÂêàÁ∫¶Âú∞ÂùÄ                            |
| project_contract_address | ‰∫§ÊòìÂπ≥Âè∞ÂêàÁ∫¶Âú∞ÂùÄ                            |
| aggregator_name          | ËÅöÂêàÂπ≥Âè∞ÂêçÁß∞ÔºåÂ¶ÇÊûú‰∫§ÊòìÊòØ‰ªéËÅöÂêàÂπ≥Âè∞ÂèëËµ∑ÁöÑÔºåÊØîÂ¶Çgem          |
| aggregator_address       | ËÅöÂêàÂπ≥Âè∞ÂêàÁ∫¶Âú∞ÂùÄ                            |
| tx_hash                  | ‰∫§ÊòìÂìàÂ∏å                                |
| block_number             | ‰∫§ÊòìÂå∫Âùó                                |
| tx_from                  | ‰∫§ÊòìÁöÑÂèëËµ∑Âú∞ÂùÄÔºåÈÄöÂ∏∏ÊòØË¥≠‰π∞ËÄÖ                      |
| tx_to                    | ‰∫§ÊòìÁöÑÊé•ÂèóÂú∞ÂùÄÔºåÈÄöÂ∏∏ÊòØ‰∫§ÊòìÂπ≥Âè∞                     |
| unique_trade_id          | ‰∫§ÊòìÁöÑid                               |

## ÈáçÁÇπÂÖ≥Ê≥®ÊåáÊ†á

‰∏ÄËà¨Êù•ËØ¥Ôºå‰∏Ä‰∏™NFTÁöÑÈ°πÁõÆÈÄöÂ∏∏‰ºöÂÖ≥Ê≥®‰ª•‰∏ãÂü∫Êú¨ÊåáÊ†áÔºö

**Êàê‰∫§‰ª∑Ê†ºËµ∞Âäø**
  
ÈúÄË¶ÅÂ∞ÜÊâÄÊúâ‰∫§ÊòìÂ∏ÇÂú∫ÁöÑ‰∫§ÊòìÈáëÈ¢ùÈÉΩÊü•ËØ¢Âá∫Êù•ÔºåÁî®Êï£ÁÇπÂõæË°®ËææÊâÄÊúâÊàê‰∫§ÔºåÂêåÊó∂ÂèØ‰ª•ÈÄöËøáÊó∂Èó¥ËåÉÂõ¥ÈÄâÊã©‰∏çÂêåÁöÑËåÉÂõ¥ÔºåÊØîÂ¶ÇÊúÄËøë24hÔºåÊúÄËøë7Â§©ÔºåÊúÄËøë1ÊúàÁ≠âÁ≠â„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåÂØπ‰∫é‰∏Ä‰∫õÊàê‰∫§‰ª∑Ê†ºËøáÈ´òÁöÑ‰∫§ÊòìÔºåÈúÄË¶ÅÊääËøô‰∫õËøáÊª§ÊéâÔºå‰∏çÁÑ∂Âú®Êï£ÁÇπÂõæ‰∏äÂ∞±‰ºöÊå§ÂéãÂÖ∂ÂÆÉÊàê‰∫§‰ª∑Ê†ºÔºåÊó†Ê≥ïÂá∏ÊòæÂ§ßÂ§öÊï∞ÁöÑÊàê‰∫§‰ª∑Ê†º„ÄÇ

![](img/history-price.png)

ÂèÇËÄÉÈìæÊé•Ôºöhttps://dune.com/queries/1660237

**Âú∞Êùø‰ª∑**
  
Âõ†‰∏∫Êàë‰ª¨Âè™ËÉΩËé∑ÂæóÈìæ‰∏äÂ∑≤ÁªèÊàê‰∫§ÁöÑÊï∞ÊçÆÔºåÊó†Ê≥ïËé∑Âæó‰∫§ÊòìÂ∏ÇÂú∫ÁöÑÊåÇÂçïÊï∞ÊçÆÔºåÊâÄ‰ª•‰∏ÄËà¨‰ºöÁî®ÊúÄËøë10Á¨î‰∫§Êòì‰∏≠ÁöÑÊúÄÂ∞èÊàê‰∫§ÈáëÈ¢ùÊù•‰Ωú‰∏∫Âú∞Êùø‰ª∑Ôºå‰∏éÊåÇÂçï‰ª∑Ê†ºÁõ∏Â∑Æ‰∏çÂ§ßÔºåÈô§ÈùûÁâπÂà´ÂÜ∑Èó®ÁöÑÈ°πÁõÆ

```sql
-- ÊåâÊó∂Èó¥ÊéíÂ∫èÔºåÊâæÂá∫ËØ•ÂêàÁ∫¶ÊúÄËøëÁöÑ10Á¨î‰∫§Êòì
with lastest_trades as (
    select * 
    from nft.trades 
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544 -- azuki NFTÁöÑÂêàÁ∫¶Âú∞ÂùÄ
    -- and block_time > now() - interval '24' hour --‰Ω†‰πüÂèØ‰ª•ÊåâÊó∂Èó¥ÊéíÂ∫è
    order by block_time desc
    limit 10
)

select min(amount_original) as floor_price --Áõ¥Êé•Ëé∑ÂèñÊúÄÂ∞èÂÄº
    -- percentile_cont(.05) within GROUP (order by amount_original) as floor_price --Ëøô‰πàÂÅöÊòØÂèñÊúÄ‰ΩéÂíåÊúÄÈ´ò‰ª∑‰πãÈó¥5%ÂàÜ‰ΩçÊï∞ÔºåÈò≤Ê≠¢‰∏Ä‰∫õËøá‰ΩéÁöÑ‰ª∑Ê†º‰∫§ÊòìÂΩ±Âìç
from lastest_trades
where  currency_symbol IN ('ETH', 'WETH')
    and cast(number_of_items as integer) = 1 -- ËøôÈáåÂèØ‰ª•Êåâ‰∏çÂêåÁöÑÈìæÔºå‰∏çÂêåÁöÑ‰∫§ÊòìtokenËøõË°åËøáÊª§
```

ÂèÇËÄÉÈìæÊé•Ôºöhttps://dune.com/queries/1660139

**Êàê‰∫§Èáè„ÄÅÊÄªÊàê‰∫§È¢ùÂ∫¶„ÄÅÊÄª‰∫§ÊòìÁ¨îÊï∞Á≠â„ÄÅ24Â∞èÊó∂/7Â§©/1ÊúàÊàê‰∫§È¢ùÂ∫¶** 
  
```sql
with total_volume as(
    SELECT
        sum(amount_original) as "Total Trade Volume(ETH)", --ÊÄªÊàê‰∫§ÈáèETH
        sum(amount_usd) as "Total Trade Volume(USD)",      --ÊÄªÊàê‰∫§ÈáèUSD
        count(amount_original) as "Total Trade Tx"         --ÊÄª‰∫§ÊòìÁ¨îÊï∞
    FROM nft.trades
    WHERE nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
        -- AND currency_symbol IN ('ETH', 'WETH') 
),

total_fee as (
    select 
        sum(royalty_fee_amount) as "Total Royalty Fee(ETH)",      --ÊÄªÁâàÊùÉÁ®éETH
        sum(royalty_fee_amount_usd) as "Total Royalty Fee(USD)",  --ÊÄªÁâàÊùÉÁ®éUSD
        sum(platform_fee_amount) as "Total Platform Fee(ETH)",    --ÊÄªÂπ≥Âè∞ÊäΩÊàêETH
        sum(platform_fee_amount_usd) as "Total Platform Fee(USD)" --ÊÄªÂπ≥Âè∞ÊäΩÊàêUSD
    from nft.fees 
    WHERE nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
    -- AND royalty_fee_currency_symbol IN ('ETH', 'WETH') 
)

select * from total_volume, total_fee
```

ÂèÇËÄÉÈìæÊé•Ôºöhttps://dune.com/queries/1660292
  
**ÊØèÊó•/ÊØèÊúà/ÊØèÂë®Êàê‰∫§Èáè**

```sql
with hourly_trade_summary as (
    select date_trunc('day', block_time) as block_date, 
        sum(number_of_items) as items_traded,
        sum(amount_raw) / 1e18 as amount_raw_traded,
        sum(amount_usd) as amount_usd_traded
    from opensea.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
    -- and block_time > now() - interval '90' day
    group by 1
    order by 1
)

select block_date, 
    items_traded,
    amount_raw_traded,
    amount_usd_traded,
    sum(items_traded) over (order by block_date asc) as accumulate_items_traded,
    sum(amount_raw_traded) over (order by block_date asc) as accumulate_amount_raw_traded,
    sum(amount_usd_traded) over (order by block_date asc) as accumulate_amount_usd_traded
from hourly_trade_summary
order by block_date
```

![](./img/daily-trade-volune.png)

ÂèÇËÄÉÈìæÊé•Ôºöhttps://dune.com/queries/1664420


**ÂΩìÂâçÊåÅÊúâ‰∫∫Êï∞ÔºåÊÄªtokenÊï∞ÈáèÔºåholderÁöÑÂàÜÂ∏ÉÁ≠â**
```sql
with nft_trade_details as ( --Ëé∑Âèñ‰∫§ÊòìÁöÑ‰π∞ÂÖ•ÂçñÂá∫ÊñπËØ¶ÁªÜ‰ø°ÊÅØË°®ÔºåÂçñÂá∫ÊñπÊòØË¥üÊï∞Ôºå‰π∞ÂÖ•ÊñπÊòØ
    select seller as trader,
        -1 * cast(number_of_items as integer) as hold_item_count
    from nft.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544

    union all
    
    select buyer as trader,
        cast(number_of_items as integer) as hold_item_count
    from nft.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
),

nft_traders as (
    select trader,
    sum(hold_item_count) as hold_item_count
    from nft_trade_details
    group by trader
    having sum(hold_item_count) > 0
    order by 2 desc
),

nft_traders_summary as (
    select (case when hold_item_count >= 100 then 'Hold >= 100 NFT'
                when hold_item_count >= 20 and hold_item_count < 100 then 'Hold 20 - 100'
                when hold_item_count >= 10 and hold_item_count < 20 then 'Hold 10 - 20'
                when hold_item_count >= 3 and hold_item_count < 10 then 'Hold 3 - 10'
                else 'Hold 1 or 2 NFT'
            end) as hold_count_type,
        count(*) as holders_count
    from nft_traders
    group by 1
    order by 2 desc
),

total_traders_count as (
    select count(*) as total_holders_count,
        max(hold_item_count) as max_hold_item_count
    from nft_traders
),

total_summary as (
    select 
        0 as total_nft_count,
        count(*) as transaction_count,
        sum(number_of_items) as number_of_items_traded,
        sum(amount_raw) / 1e18 as eth_amount_traded,
        sum(amount_usd) as usd_amount_traded
    from opensea.trades
    where nft_contract_address = 0xed5af388653567af2f388e6224dc7c4b3241c544
)

select *
from nft_traders_summary
join total_traders_count on true
join total_summary on true
```

ÂèÇËÄÉÈìæÊé•Ôºöhttps://dune.com/queries/1300500/2228120


## NFTÁªºÂêàÁúãÊùøÁ§∫‰æã

Êàë‰ª¨Âà∂‰Ωú‰∫Ü‰∏Ä‰∏™ÂèØ‰ª•ËæìÂÖ•NFTÂêàÁ∫¶Âú∞ÂùÄÔºåÊü•ÁúãÈ°πÁõÆÂêÑÁßç‰ø°ÊÅØÁöÑÁúãÊùøÔºåÂ§ßÂÆ∂ÂèØ‰ª•ÈÄöËøáÊ≠§ÁúãÊùøÁöÑquery‰∫ÜËß£Êõ¥Â§öÊü•ËØ¢Áî®Ê≥ï:

https://dune.com/sixdegree/nft-collections-metrics-custom-dashboard 

![](./img/nft-all-in-one.png)


## ÂèÇËÄÉ

- https://mirror.xyz/0x07599B7E947A4F6240F826F41768F76149F490D5/CHcwsp_d0AINEalFq_0FcqkLeEyeeGpYDDtw82TyMes
- https://github.com/cryptochou/seaport-analysis
- https://dune.com/sixdegree/soulda-nft-soulda16club
- https://dune.com/sixdegree/digidaigaku-nft-by-limit-break

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch14/ch13-lending-analysis.md">
# ÂÄüË¥∑ÂçèËÆÆÊï∞ÊçÆÂàÜÊûê

## ËÉåÊôØÁü•ËØÜ

Âéª‰∏≠ÂøÉÂåñÈáëËûçÔºàDeFiÔºâÊòØÂå∫ÂùóÈìæÁöÑÈáëËûçÂàõÊñ∞„ÄÇÈÄöËøáÂêÑÂçèËÆÆ‰πãÈó¥ÁöÑÂèØÁªÑÂêàÊÄß„ÄÅ‰∫íÊìç‰ΩúÊÄßÔºåDeFi‰πêÈ´òÂ∞±Ê≠§ËØûÁîü„ÄÇ2020Âπ¥6ÊúàÔºåDeFiÂÄüË¥∑ÂçèËÆÆCompoundÂºÄÂêØÊµÅÂä®ÊÄßÊåñÁüøÔºå‰∏ç‰ªÖÊãâÂºÄ‰∫ÜDeFi SummerÁöÑÂ∫èÂπïÔºå‰πüÁªôDeFiÂÄüË¥∑ËµõÈÅìÊ≥®ÂÖ•Êñ∞Ê¥ªÂäõ„ÄÅÊñ∞ÊÄùË∑Ø„ÄÅÊñ∞Áî®Êà∑ÔºåÂÄüË¥∑‰∏öÂä°Êàê‰∏∫DeFiÁöÑ‰∏âÂ§ßÊ†∏ÂøÉ‰πã‰∏Ä„ÄÇ

### ÂÄüË¥∑ÂçèËÆÆÁöÑÊÑè‰πâ

ÂÄüË¥∑ÂçèËÆÆÊòØDeFiÁöÑÈì∂Ë°å„ÄÇ‰º†ÁªüÈì∂Ë°å‰∏≠ÔºåÁî®Êà∑ÂèØ‰ª•ÂêëÈì∂Ë°åÂ≠òÊ¨æÊî∂ÂèñÂà©ÊÅØÔºå‰πüÂèØ‰ª•ÂêëÈì∂Ë°åÂÄüÊ¨æÔºåÊúÄÂêéËøûÊú¨Â∏¶Âà©‰∏ÄËµ∑ÂΩíËøò„ÄÇÁ±ª‰ººÁöÑÔºåÂú®DeFiÁöÑÂÄüË¥∑ÂçèËÆÆ‰∏≠Áî®Êà∑ÂèØ‰ª•ÂêëÂçèËÆÆÂ≠òÈí±„ÄÅÂÄüÈí±Ôºå‰∏çÂêåÁöÑÊòØÊ≤°Êúâ‰∫Ü‰∏≠ÂøÉÂåñÁöÑÊâòÁÆ°Êú∫ÊûÑÔºåËÄåÊòØÁî®Êà∑ÂíåÂÄüË¥∑ÂçèËÆÆÁöÑÊô∫ËÉΩÂêàÁ∫¶Áõ¥Êé•‰∫§‰∫íÔºåÈù†‰ª£Á†ÅÁöÑËøêË°åÁ°Æ‰øù‰∏ÄÂàáÊúâÊù°‰∏çÁ¥äÂú∞ËøõË°å„ÄÇCeFi‰∏≠ÁöÑÂÄüË¥∑ÔºåË¥∑Ê¨æÊãÖ‰øùÊñπÂºèÂàÜ‰∏∫‰ø°Áî®„ÄÅ‰øùËØÅ‰ª•ÂèäÊäµÊäºË¥∑Ê¨æ„ÄÇÈì∂Ë°åÁöÑÈ£éÈô©ÂÅèÂ•ΩËæÉ‰ΩéÔºåÊäµÊäºË¥∑Ê¨æÂú®ÂêÑÁ±ªË¥∑Ê¨æ‰∏≠ÊòØÂç†ÊØîÊúÄÈ´òÁöÑ„ÄÇÂæóÁõä‰∫éÂ§ßÊï∞ÊçÆ‰ø°Áî®‰ΩìÁ≥ªÂª∫ËÆæÔºå‰ø°Áî®ÂÄüË¥∑Ë∂äÊù•Ë∂äÊôÆÈÅçÔºå‰∏çËøáÈúÄË¶ÅÂ§ßÈáèÁöÑÂÆ°Êü•„ÄÅËµÑË¥®ËØÅÊòéÁ≠â„ÄÇ

![](img/bank.jpeg)

ËÄåDeFi‰∏≠ÁöÑÂÄüË¥∑ÊòØÂåøÂêçÁöÑÔºåÊó†ÈúÄ‰ø°‰ªªÁöÑ„ÄÇ‰ªéÊ®°Âºè‰∏äËÆ≤Âü∫Êú¨ÈÉΩÂ§Ñ‰∫éÊäµÊäºË¥∑Ê¨æÊñπÂºèÔºåÊôÆÈÅçÈááÁî®ÁöÑÊñπÂºèÊòØË∂ÖÈ¢ùÊäµÊäº„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÊàëÊäµÊäº200ÂùóÁöÑËµÑ‰∫ßÔºåÂèØ‰ª•‰ªéÂÄüË¥∑ÂçèËÆÆËøôÂÄüËµ∞‰∏çË∂≥200ÂùóÁöÑËµÑÈáëÔºåËøôÊ†∑Â∞±Êó†ÈúÄÊãÖÂøÉÊàëÂÄüÈí±‰∏çËøòË∑ëË∑ØÔºåÂèØ‰ª•ÊîæÂøÉÂú∞ÂÄüÈí±ÁªôÊàë‰∫Ü„ÄÇËøôÁßç‰ª•Â∏ÅÂÄüÂ∏ÅÔºåÁîöËá≥Ë∂äÂÄüË∂äÂ∞ëÁöÑË°å‰∏∫Áúã‰ººÈùûÂ∏∏ÊÑöË†¢Ôºå‰ΩÜÊòØÂÆûÈôÖ‰∏äÂÆÉËß£ÂÜ≥ÁöÑÊòØÂ∏ÇÂú∫ÂàáÂÆûÂ≠òÂú®ÁöÑÈúÄÊ±ÇÔºö

1. ‰∫§ÊòìÊ¥ªÂä®ÁöÑÈúÄÊ±ÇÔºöÂåÖÊã¨Â•óÂà©„ÄÅÊù†ÊùÜ„ÄÅÂÅöÂ∏ÇÁ≠â‰∫§ÊòìÊ¥ªÂä®„ÄÇ‰æãÂ¶ÇÂÅöÂ∏ÇÂïÜÈúÄË¶ÅÂÄüËµÑÈáëÊù•Êª°Ë∂≥Â§ßÈáèÁöÑ‰∫§ÊòìÔºõÂú®DEX‰∏ä‰π∞Â∏ÅÂè™ËÉΩÂÅöÂ§öÔºå‰ΩÜÊòØÈÄöËøáÂÄüÂ∏ÅÂèØ‰ª•ÂÅöÁ©∫ÔºõÈÄöËøáÊäµÊäºËµÑ‰∫ßÂä†Êù†ÊùÜÔºåÁîöËá≥ÂèØ‰ª•ÈÄöËøáÂæ™ÁéØË¥∑‰∏çÊñ≠Â¢ûÂä†Êù†ÊùÜÔºàÊäµÊäºETHÂÄüUSDC‰π∞ETHÂÜçÊäµÊäºÂÜçÂÄüÂÜç‰π∞‚Ä¶Ôºâ

2. Ëé∑ÂæóË¢´Âä®Êî∂ÂÖ•ÔºöÈó≤ÁΩÆËµÑÈáë/Â±ØÂ∏ÅÂÖöÂú®Â±ØÂ∏ÅÁöÑËøáÁ®ã‰∏≠ÂèØ‰ª•ÈÄöËøáÂÄüÂá∫ËµÑ‰∫ßËé∑ÂæóÈ¢ùÂ§ñÊî∂Áõä

3. ‰ª£Â∏ÅÊøÄÂä±ÔºöÈô§‰∫ÜÊµÅÂä®ÊÄßÊåñÁüøÔºåÂ§¥ÈÉ® DeFi ÂçèËÆÆÊé®Âá∫Âü∫‰∫éÂÖ∂ÂéüÁîü‰ª£Â∏ÅÁöÑË¥®ÊäºÊúçÂä°Ôºå‰ª£Â∏ÅÊåÅÊúâËÄÖÂèØË¥®ÊäºËé∑ÂæóÊõ¥Â§öÂéüÁîü‰ª£Â∏Å„ÄÇ‰ª£Â∏ÅÊøÄÂä±ÊòØÈù¢ÂØπÂÄüË¥∑ÂçèËÆÆÊâÄÊúâÂèÇ‰∏éËÄÖÁöÑÔºåÂÄüÊñπÂèØ‰ª•ÈÄöËøá‰∫§‰∫íËé∑Âæó‰ª£Â∏ÅÂ•ñÂä±ÔºåÈÄöËøá‰∫§ÊòìËé∑ÂæóÁöÑ‰ª£Â∏ÅÔºåÂÅøËøò‰∏ÄÈÉ®ÂàÜÂÄ∫Âä°

Áõ∏ÊØî‰º†ÁªüÊàøËΩ¶Á±ªÂûãÊäµÊäºË¥∑Ê¨æÔºåÈúÄË¶Å‰∫∫ÂäõÈ™åËØÅËµÑ‰∫ßÊâÄÊúâ‰∫∫ÔºåËøòÊ¨æËøùÁ∫¶ËøòÈúÄË¶Å‰∫∫ÂäõÂèäÊó∂Èó¥ËøõË°åËµÑ‰∫ßÊãçÂçñ„ÄÇDeFi‰∏≠ÁöÑÂΩìÈì∫Ê®°ÂºèÂè™ÈúÄË¶ÅÂú®ÊäµÊäºÁéáËøá‰ΩéÂÅúÊ≠¢ÊäµÊäºÔºåÂØπËµÑ‰∫ßÊ∏ÖÁÆóÂç≥ÂèØÁªìÊùüË¥∑Ê¨æÂêàÂêå„ÄÇ

### ÂÄüË¥∑ÂçèËÆÆÁöÑËøê‰ΩúÊ®°Âºè

Âú®Âå∫ÂùóÈìæ‰∏äÊäµÊäºÂÄüË¥∑ÔºåËÉΩÂÄüÂ§öÂ∞ë‰ª£Â∏Å„ÄÅ‰ªÄ‰πàÊó∂ÂÄôÊ∏ÖÁÆóÔºåÈÉΩÊòØÁî±Êô∫ËÉΩÂêàÁ∫¶‰∏≠ÁöÑ‰∏ÄÁ≥ªÂàóÂèÇÊï∞ËÆæÂÆöÂ•ΩÁöÑ„ÄÇ

![](img/loan.png)

Max LTVÔºàLoan to ValueÔºâÔºöÊúÄÂ§ßË¥∑Ê¨æ‰ª∑ÂÄºÊØîÔºåÂÜ≥ÂÆöÂÄüÊ¨æÂèëÁîüÊó∂ÂÄ∫Âä°/ ÊäµÊäºÂìÅ‰ª∑ÂÄºÁöÑÊúÄÂ§ßÊØî‰æã„ÄÇ

Liquidation thresholdÔºöÊ∏ÖÁÆóÈó®ÊßõÔºåÊòØ‰∏Ä‰∏™Ê∏ÖÁÆóÂà§ÂÆöÊù°‰ª∂ÔºåÂÄ∫Âä°/ ÊäµÊäºÂìÅ‰ª∑ÂÄºÂçáËá≥Ëøô‰∏™ÊØî‰æãÊó∂ÂèëÁîüÊ∏ÖÁÆó„ÄÇ

Liquidation penaltyÔºöÂº∫Âπ≥ÁΩöÊ¨æÔºåÂΩìÊ∏ÖÁÆóÂèëÁîüÊó∂Ôºå‰ª•ËØ•ËµÑ‰∫ß‰∏∫ÊäµÊäºÂìÅÈúÄË¶ÅÊâ£Èô§ÁöÑÁΩöÈáëÊØî‰æã„ÄÇ

ÊØîÂ¶ÇÔºåAave V2‰∏≠USDC ÁöÑMax LTV‰∏∫87%ÔºåLiquidation threshold ‰∏∫89%ÔºåLiquidation penalty ‰∏∫4.5%ÔºåÂ∞±‰ª£Ë°®ÊØèÊúâ1 USDC ÁöÑÊäµÊäºÂìÅÔºåÊúÄÈ´òÂèØ‰ª•ÂÄüÂÖ•0.87 ÁæéÂÖÉÂÖ∂ÂÆÉ‰ª£Â∏ÅÔºåÂΩìÂÄüÂÖ•ÁöÑ‰ª£Â∏ÅÂçáÂÄºËá≥0.89 ÁæéÂÖÉÊó∂ÂèëÁîüÊ∏ÖÁÆóÔºåÈ°∫Âà©Ê∏ÖÁÆóÁöÑÊÉÖÂÜµ‰∏ãÂ∞ÜË¢´Êâ£Èô§4.5% ÁöÑÁΩöÈáë„ÄÇ

Âä†ÂØÜËµÑ‰∫ßÁöÑ‰ª∑Ê†ºÊµÆÂä®ÂæÄÂæÄ‰ºöÊØîËæÉÂâßÁÉàÔºåÂÄüË¥∑ÂçèËÆÆÈááÁî®ÁöÑË∂ÖÈ¢ùÊäµÊäºÊñπÂºèÊúâÂä©‰∫éÈÅøÂÖçËµÑ‰∏çÊäµÂÄ∫ÁöÑÊÉÖÂÜµÂèëÁîüÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö‰∏çÂêåÁöÑÊäµÊäºÁéáÂØπÂ∫î‰∏çÂêåÁöÑË¥πÁéáÂíåË¥®ÊäºË¶ÅÊ±Ç„ÄÇ

![](img/2.png)

ÂΩìÊäµÊäºËµÑ‰∫ßÊàñËÄÖÂÄüÂá∫ËµÑ‰∫ßÂèëÁîüÂ§ßÂπÖÊ≥¢Âä®Êó∂Âà∞Ëææ‰∏ÄÂÆöÁ®ãÂ∫¶Êó∂ÔºåÂÄüË¥∑ÂçèËÆÆ‰∏∫‰∫ÜÈÅøÂÖçÂùèË¥¶Ë¶ÅÊâßË°åÊ∏ÖÁÆó„ÄÇ
Êàë‰ª¨‰ª•AAVE‰∏∫‰æãÔºåÁúãÂÄüË¥∑ÂçèËÆÆÊòØÂ¶Ç‰ΩïËøõË°åÊ∏ÖÁÆóÁöÑ„ÄÇ
È¶ñÂÖà‰ªãÁªç‰∏Ä‰∏™Ê¶ÇÂøµÂè´ÂÅ•Â∫∑Âõ†Â≠êÔºàHealth FactorÔºâÔºåÂÅ•Â∫∑Âõ†Â≠êÂíåË¥¶Êà∑ÁöÑÊäµÊäºÁâ©„ÄÅÂÄüÊ¨æÈáëÈ¢ùÊúâÂÖ≥ÔºåË°®ËææËµÑ‰∏çÊäµÂÄ∫ÁöÑÂèØËÉΩÊÄß„ÄÇÂ¶Ç‰ΩïËÆ°ÁÆóÂÅ•Â∫∑Âõ†Â≠êÔºü

1„ÄÅÊü•ÁúãÊäµÊäºÁâ©ÁöÑÊ∏ÖÁÆóÁ∫øÔºàLiquidationThresholdÔºâÔºåÊØîÂ¶ÇÊ≠§Êó∂USDCÊòØ0.89Ôºõ

![](img/hf1.png)

2„ÄÅÂÅ•Â∫∑Âõ†Â≠ê = ÊäµÊäºÈáëÈ¢ù * Ê∏ÖÁÆóÁ∫ø/ ÂÄüÂá∫ËµÑ‰∫ßÔºå‰ª•Ê≠§Âàª‰∏∫‰æãÔºå5794 * 0.89/ 4929 = 1.046Ôºõ

![](img/hf2.png)

3„ÄÅÂ¶ÇÊûúÊäµÊäºÁâ©‰ª∑Ê†º‰∏ãË∑åÔºåÊàñËÄÖÂÄüÂá∫ËµÑ‰∫ß‰ª∑Ê†º‰∏äÊ∂®ÔºåÂØºËá¥ÂÅ•Â∫∑Âõ†Â≠ê<1ÔºåÂàô‰ºöÊâßË°åÊ∏ÖÁÆóLiquidationÔºåÂÖ∑‰ΩìÊ∏ÖÁÆóËøáÁ®ãÂ¶Ç‰∏ãÔºö

![](img/hf3.png)

ÈÇ£‰πàÂÆûÈôÖÁöÑ‰∏çÁ≠âÂºèÊòØÔºöÂÄüÂá∫ËµÑ‰∫ßÈáëÈ¢ù <= ÊäµÊäºÈáëÈ¢ù * LTV < ÊäµÊäºÈáëÈ¢ù * Ê∏ÖÁÆóÁ∫ø„ÄÇ
Ê∏ÖÁÆóÊó∂ÔºåË∂ÖÂá∫Ê∏ÖÁÆóÁ∫øÁöÑÈÉ®ÂàÜ‰ºöÊãøÂéªÊãçÂçñÔºåÊ∏ÖÁÆóËÄÖÔºàliquidatorsÔºâË¥≠‰π∞ÊäµÊäºÁâ©ÔºåÊãçÂçñËé∑ÂæóÁöÑËµÑÈáëÁî®‰∫éÂΩíËøòË¥üÂÄ∫ÔºåÂ§öÂá∫ÈÉ®ÂàÜÂ∞±‰Ωú‰∏∫Ê∏ÖÁÆóËÄÖÁöÑÂ•ñËµè„ÄÇ
Ê∏ÖÁÆóËøáÁ®ã‰æùËµñ‰∫éÈ¢ÑË®ÄÊú∫ÁöÑÂñÇ‰ª∑ÔºåÁõÆÂâçAAVEÂèñÁöÑÊòØChainlink„ÄÇ

ÊúâÊÑèÊÄùÁöÑÊòØÔºåËôΩÁÑ∂Ë∂ÖÈ¢ùÊäµÊäºÁöÑÊÄùË∑ØÁúãËµ∑Êù•ÈùûÂ∏∏Èù†Ë∞±ÔºåÂÄüË¥∑ÂçèËÆÆÂ∫îËØ•Ê≤°ÊúâÂùèË¥¶È£éÈô©Ôºå‰ΩÜÊòØÂÆûÈôÖ‰∏äÊòØËøôÊ†∑ÂêóÔºüÊúÄËøëEisenberg‰ªéAAVE V2ÂÄüÂ∏ÅÂÅöÁ©∫CRVÁöÑ‰∫ã‰ª∂‰∏≠ÔºåÂ∞±‰∫ßÁîü‰∫ÜÁ∫¶170 ‰∏áÁæéÂÖÉÁöÑÂùèË¥¶„ÄÇÊúÄ‰∏ªË¶ÅÁöÑÂéüÂõ†ÂèØËÉΩÊòØËØ•Â∑®È≤∏ÁöÑÂ§¥ÂØ∏ËøáÂ§ßÔºåÂ∏ÇÂú∫‰∏äÂπ∂Ê≤°ÊúâË∂≥Â§üÂ§öÁöÑÊµÅÂä®ÊÄßËÆ©Ê∏ÖÁÆó‰∫∫‰π∞ÂÖ•„ÄÇ‰ªé‰∏ãÂõæÂèØ‰ª•ÁúãÂà∞ÔºåËØ•Â∑®È≤∏Âú®Aave ‰∏≠Â≠òÂÖ•‰∫Ü5794 ‰∏áUSDCÔºåÂÄüÂÖ•‰∫Ü8342 ‰∏áCRV„ÄÇ

![](img/crv1.jpg)

ËÄå‰ªéCoinGecko ÂíåÂå∫ÂùóÈìæÊµèËßàÂô®‰∏≠ÂèØ‰ª•ÁúãÂá∫ÔºåCRV ‰ª£Â∏ÅÁöÑÊµÅÈÄöÈáèÂè™Êúâ6.37 ‰∫øÔºåÂ∑®È≤∏ÂÄüÂá∫ÁöÑCRV Êï∞ÈáèÈ´ò‰∫éÊâÄÊúâÂ§ñÈÉ®Â∏êÊà∑ÊåÅÊúâËÄÖ„ÄÇ‰æãÂ¶ÇÔºåÊà™Ëá≥11 Êúà25 Êó•ÔºåAave ÁöÑÂêàÁ∫¶‰∏≠Âè™Êúâ4212 ‰∏áCRVÔºåÊåÅÂ∏ÅÈáèÁ¨¨8 ÁöÑBinance 14 Âú∞ÂùÄ‰∏≠‰πüÂè™Êúâ2021 ‰∏áCRV„ÄÇ

![](img/crv2.png)

Âú®DEX ‰∏≠ÔºåUniswap V3 ÁöÑÁõ∏ÂÖ≥‰∫§ÊòìÂØπ‰∏≠ÊµÅÂä®ÊÄßÊúÄÈ´òÁöÑETH/CRV ‰∫§ÊòìÂØπ‰∏≠ÔºåÊµÅÂä®ÊÄßÂÖ±176 ‰∏áÁæéÂÖÉÔºåÂè™Êúâ148 ‰∏áCRV„ÄÇÂõ†Ê≠§ÔºåÂ∏ÇÂú∫‰∏äÂπ∂Ê≤°ÊúâË∂≥Â§üÁöÑÊµÅÂä®ÊÄß‰æõÊ∏ÖÁÆó‰∫∫‰π∞ÂÖ•ÔºåÂÆåÊàêÊ∏ÖÁÆó„ÄÇÊØè‰∏ÄÊ¨°Ê∏ÖÁÆóÂêéÔºåÂâ©‰ΩôÁöÑËµÑÈáë‰ºöË°•ÂÖÖÂà∞ÊäµÊäºÂìÅ‰∏≠Ôºå‰ΩøÂâ©‰ΩôÂÄ∫Âä°ÁöÑÊ∏ÖÁÆó‰ª∑Ê†º‰∏äÂçá„ÄÇ‰ΩÜÊòØÂú®Ê∏ÖÁÆóËøáÁ®ã‰∏≠ÔºåCRV ÁöÑ‰ª∑Ê†ºÁªßÁª≠‰∏äÊ∂®ÔºåÊúÄÁªàÂØºËá¥Aave ‰∫ßÁîüÂùèÂ∏ê„ÄÇ

ÁÆÄÂçïÊÄªÁªìÔºåÂ§ßÈÉ®ÂàÜÁöÑÂÄüË¥∑ÂçèËÆÆÁõÆÂâçÈááÁî®ÁöÑÊñπÂºèÊòØË∂ÖÈ¢ùÊäµÊäºÔºåÂΩì‰ª∑Ê†ºÊ≥¢Âä®Êó∂Áî±ÂÅ•Â∫∑Âõ†Â≠êÁõëÊéßÊòØÂê¶ÈúÄË¶ÅÊ∏ÖÁÆóÔºå‰ª•ÂèäÊ∏ÖÁÆóÂ§öÂ∞ë„ÄÇËøôÈáåÊàë‰ª¨Âè™ËÆ≤‰∫ÜÊúÄÁÆÄÂçïÊúÄÂü∫Êú¨ÁöÑÂÄüË¥∑‰∏öÂä°ÔºåÂÆûÈôÖ‰∏äÂêÑ‰∏™ÂçèËÆÆ‰πãÈó¥‰πüÂêÑÊúâÁâπËâ≤ÔºåÂ¶ÇCompoundÊòØÂéª‰∏≠ÂøÉÂåñÁöÑÁÇπÂØπÁÇπÊ®°ÂºèÔºåËµÑÈáëÊ±†ËøêÁî®Ê®°Âºè‰ΩøÊ±†ÂÜÖËµÑÈáëËææÂà∞‰∫ÜÊûÅÈ´òÁöÑÂà©Áî®ÂÄºÔºõAAVEÈ¶ñÂÖàÊèêÂá∫‰∫ÜÈó™ÁîµË¥∑ÔºåÂÄüÊ¨æ+Êìç‰Ωú+ËøòÊ¨æÂú®‰∏Ä‰∏™Âå∫ÂùóÂÜÖÂÆåÊàêÔºåÂéüÂ≠êÊÄßÂÜ≥ÂÆö‰∫ÜËøôÁ¨î‰∫§ÊòìË¶Å‰πàÂÖ®ÈÉ®ÊàêÂäüÔºåË¶Å‰πàÂÖ®ÈÉ®Â§±Ë¥•ÔºõAAVE V3Êõ¥ÊèêÂá∫‰∫ÜËµÑ‰∫ßË∑®ÈìæÊµÅÂä®ÁöÑÂäüËÉΩÔºõËÄåEulerÔºåKashiÂíåRariÁ≠âÂÄüË¥∑Âπ≥Âè∞ÈÄöËøáÊó†ËÆ∏ÂèØÁöÑÂÄüË¥∑Ê±†Êõ¥Â•ΩÂú∞Êª°Ë∂≥ÈïøÂ∞æËµÑ‰∫ßÁöÑÈúÄÊ±Ç„ÄÇ


## ÈáçÁÇπÂÖ≥Ê≥®ÊåáÊ†á
ÊêûÊòéÁôΩÈìæ‰∏äÂÄüË¥∑ÂçèËÆÆÁöÑ‰∏öÂä°ÈÄªËæë‰πãÂêéÔºåÂ∞±ÂèØ‰ª•ÁùÄÊâãÂàÜÊûê‰∫ÜÔºåÊé•‰∏ãÊù•ÊàëÂ∞ÜÂàóÂá∫‰∏Ä‰∫õÂ∏∏Áî®‰∫éËØÑ‰º∞ÂÄüË¥∑ÂçèËÆÆÁöÑ‰∏Ä‰∫õÊåáÊ†á„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåÂú®Êô∫ËÉΩÂêàÁ∫¶‰∏≠ËµÑÈáëÁöÑÊµÅÂä®ËôΩÁÑ∂Âè™ÊúâÂÖ•„ÄÅÂá∫‰∏§‰∏™ÊñπÂêëÔºå‰ΩÜÊòØÊâÄ‰ª£Ë°®ÁöÑÊÑè‰πâÊúâÊâÄ‰∏çÂêåÔºåÈúÄË¶ÅÁªìÂêàÊô∫ËÉΩÂêàÁ∫¶„ÄÅÂå∫ÂùóÈìæÊµèËßàÂô®Êù•ËæÖÂä©Âà§Êñ≠„ÄÇ

### 1.ÊÄªÈîÅ‰ªìÈáè TVLÔºàTotal Value LockedÔºâ

Âç≥ÊúâÂ§öÂ∞ëÈáëÈ¢ùÈîÅÂÆöÂú®ÂÄüË¥∑ÂçèËÆÆÁöÑÊô∫ËÉΩÂêàÁ∫¶‰∏≠ÔºåTVL‰ª£Ë°®‰∫ÜÂçèËÆÆÁöÑÊµÅÂä®ÊÄß„ÄÇ‰ªé[defillama](https://defillama.com/protocols/lending)Êï∞ÊçÆÊù•ÁúãÔºåÊï¥‰ΩìÂÄüË¥∑Â∏ÇÂú∫TVLË∂ÖËøá$10 BÔºåÂâç‰∫îÁöÑTVLÊÄªÂíåÁ∫¶‰∏∫$9.5 BÔºåÂÖ∂‰∏≠AAVEÁã¨Âç†$3.9 B„ÄÇ

![](img/tvl.png)

‰ª•Arbitrum‰∏äÁöÑAAVE V3‰∏∫‰æãÔºåÂÅö[TVL](https://dune.com/queries/1042816/1798270)ÁöÑÊü•ËØ¢„ÄÇ

Âü∫Êú¨ÊÄùË∑ØÊòØÔºöÂ∞ÜAAVEÊô∫ËÉΩÂêàÁ∫¶‰∏≠ÔºåÂÆö‰πâ‰∏∫'Supply'ÁöÑÂ≠òÂÖ•ËµÑÈáëÔºåÂáèÂéªÂÆö‰πâ‰∏∫'Withdraw'ÁöÑÊèêÂèñËµÑÈáëÔºåÂ∞±ÊòØÈîÅÂÆöÂú®ÂêàÁ∫¶‰∏≠ÁöÑÊÄª‰ª∑ÂÄº„ÄÇÊâìÂºÄ[Arbscan](https://arbiscan.io/address/0x794a61358d6845594f94dc1db02a252b5b4814ad)ÊâæÂà∞‰∏ÄÁ¨î[AAVEÁöÑ‰∫§Êòì](https://arbiscan.io/tx/0x6b8069b62dc762e81b41651538d211f9a1a33009bcb41798e673d715867b2f29#eventlog)ÔºåÁÇπÂºÄlogÂèØ‰ª•ÁúãÂà∞ topic0 = '0x2b627736bca15cd5381dcf80b0bf11fd197d01a037c52b927a881a10fb73ba61' ÂØπÂ∫îÊô∫ËÉΩÂêàÁ∫¶‰∏≠'Supply'ÁöÑË°å‰∏∫„ÄÇ

![](img/arbscan1.png)

![](img/tvl2.png)

Á±ª‰ººÁöÑÔºåtopic0 = '0x3115d1449a7b732c986cba18244e897a450f61e1bb8d589cd2e69e6c8924f9f7' Êó∂ÂØπÂ∫î'Withdraw'ÁöÑË°å‰∏∫ÔºàÊ≥®ÔºåÂú®Dune‰∏≠topic1ÊåáÁöÑÊòØetherscan‰∏≠ÁöÑtopic0Ôºâ„ÄÇÂú®DuneÈáåÔºå‰ªéArbitrumÁöÑlogË°®‰∏≠ÈÄâÊã©ÂèëÂæÄAAVE V3ÂêàÁ∫¶ÁöÑ‰∫§ÊòìÔºåÊ†πÊçÆtopicÂÆö‰πâ‚ÄúÂ≠òÂÖ•‚ÄúÂíå‚ÄùÊèêÂèñ‚ÄúËøô‰∏§‰∏™Âä®‰ΩúÔºàaction_typeÔºâ„ÄÇÂ≠òÂÖ•‰∏∫Ê≠£ÊèêÊ¨æ‰∏∫Ë¥üÔºåÁõ∏Âä†‰πãÂêéÂ∞±ÊòØÂú®ÂêàÁ∫¶ÂÜÖÈîÅÂÆöÁöÑ‰ª£Â∏Å„ÄÇÁî®`bytearray_ltrim(topic1)`ÂáΩÊï∞ÂæóÂà∞ËΩ¨Ë¥¶tokenÁöÑÂú∞ÂùÄÔºåÁî®`bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32))`ÂáΩÊï∞ÂæóÂà∞ËΩ¨Ë¥¶tokenÂØπÂ∫îÁöÑÊï∞ÈáèÔºàÈùûusdËÆ°‰ª∑ÈáëÈ¢ùÔºâ„ÄÇ

```sql
with aave_v3_transactions as (
    select 'Supply' as action_type,
        block_time,
        bytearray_ltrim(topic1) as token_address,
        bytearray_ltrim(topic2) as user_address,
        cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
        tx_hash
    from arbitrum.logs
    where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
        and topic0 = 0x2b627736bca15cd5381dcf80b0bf11fd197d01a037c52b927a881a10fb73ba61 -- Supply
        and block_time > date('2022-03-16') -- First transaction date
    
    union all
    
    select 'Withdraw' as action_type,
        block_time,
        bytearray_ltrim(topic1) as token_address,
        bytearray_ltrim(topic2) as user_address,
        -1 * cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
        tx_hash
    from arbitrum.logs
    where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
        and topic0 = 0x3115d1449a7b732c986cba18244e897a450f61e1bb8d589cd2e69e6c8924f9f7 -- Withdraw
        and block_time > date('2022-03-16') -- First transaction date
),

aave_v3_transactions_daily as (
    select date_trunc('day', block_time) as block_date,
        token_address,
        sum(raw_amount) as raw_amount_summary
    from aave_v3_transactions
    group by 1, 2
    order by 1, 2
)

select * from aave_v3_transactions_daily
```

Âà∞Ê≠§Êàë‰ª¨ÂæóÂà∞‰∫ÜÈîÅÂÆöÂú®Êô∫ËÉΩÂêàÁ∫¶‰∏≠ÁöÑtokenÊï∞ÈáèÔºåË¶ÅÂæóÂà∞ÁæéÂÖÉËÆ°‰ª∑ÁöÑTVLÔºåÊàë‰ª¨ËøòÈúÄË¶ÅÂ∞ÜtokenÂíåÂÖ∂‰ª∑Ê†ºÂåπÈÖçÔºåËøôÈáåÊàë‰ª¨ÊâãÂä®ÈÄâÂèñ‰∫Ü‰∏Ä‰∫õ‰∏ªÊµÅÁöÑÂ∏ÅÁßçÔºö

```sql
token_mapping_to_ethereum(aave_token_address, ethereum_token_address, token_symbol) as (
    values
    (0xfd086bc7cd5c481dcc9c85ebe478a1c0b69fcbb9, 0xdac17f958d2ee523a2206206994597c13d831ec7, 'USDT'),
    (0x2f2a2543b76a4166549f7aab2e75bef0aefc5b0f, 0x2260fac5e5542a773aa44fbcfedf7c193bc2c599, 'WBTC'),
    (0xd22a58f79e9481d1a88e00c343885a588b34b68b, 0xdb25f211ab05b1c97d595516f45794528a807ad8, 'EURS'),
    (0xff970a61a04b1ca14834a43f5de4533ebddb5cc8, 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48, 'USDC'),
    (0xf97f4df75117a78c1a5a0dbb814af92458539fb4, 0x514910771af9ca656af840dff83e8264ecf986ca, 'LINK'),
    (0x82af49447d8a07e3bd95bd0d56f35241523fbab1, 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2, 'WETH'),
    (0xda10009cbd5d07dd0cecc66161fc93d7c9000da1, 0x6b175474e89094c44da98b954eedeac495271d0f, 'DAI'),
    (0xba5ddd1f9d7f570dc94a51479a000e3bce967196, 0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9, 'AAVE')
),

latest_token_price as (
    select date_trunc('hour', minute) as price_date,
        contract_address,
        symbol,
        decimals,
        avg(price) as price
    from prices.usd
    where contract_address in (
        select ethereum_token_address
        from token_mapping_to_ethereum
    )
    and minute > now() - interval '1' day
    group by 1, 2, 3, 4
),

latest_token_price_row_num as (
    select  price_date,
        contract_address,
        symbol,
        decimals,
        price,
        row_number() over (partition by contract_address order by price_date desc) as row_num
    from latest_token_price
),

current_token_price as (
    select contract_address,
        symbol,
        decimals,
        price
    from latest_token_price_row_num
    where row_num = 1
),
```

Áî®raw amountÈô§‰ª•ÂØπÂ∫îtokenÁöÑÂ∞èÊï∞‰ΩçÔºàdecimalÔºâÔºà‰æãÂ¶ÇETHÁöÑdecimalÊòØ18ÔºåUSDTÁöÑÊòØ6ÔºâÔºåÂæóÂà∞ÂÆûÈôÖtokenÊúâÂ§öÂ∞ëÊûöÔºåÂÜçÂíåÂØπÂ∫î‰ª∑Ê†ºÁõ∏‰πòÂæóÂà∞‰ª•usd‰∏∫ËÆ°‰ª∑Âçï‰ΩçÁöÑÈáëÈ¢ùÔºåÊ±ÇÂíåÂêéÂæóÂà∞ÊÄªÁöÑTVL„ÄÇ

```sql
daily_liquidity_change as (
    select d.block_date,
        p.symbol,
        d.token_address,
        d.raw_amount_summary / power(10, coalesce(p.decimals, 0)) as original_amount,
        d.raw_amount_summary / power(10, coalesce(p.decimals, 0)) * coalesce(p.price, 1) as usd_amount
    from aave_v3_transactions_daily d
    inner join token_mapping_to_ethereum m on d.token_address = m.aave_token_address
    left join current_token_price p on m.ethereum_token_address = p.contract_address
    order by 1, 2
)

select sum(usd_amount) / 1e6 as total_value_locked_usd
from daily_liquidity_change
```
ÂèÇËÄÉÔºöhttps://dune.com/queries/1037796/1798021„ÄÇ

### 2.Êú™ÂÅøË¥∑Ê¨æÔºàOutstanding LoanÔºâ

Âç≥Â§ñÂÄüÂá∫ÂéªÂ∞öÊú™ÂΩíËøòÁöÑÈáëÈ¢ù„ÄÇ‰∏éËÆ°ÁÆóTVLÊó∂Á±ª‰ººÔºåÂèÇËÄÉÂå∫ÂùóÈìæÊµèËßàÂô®ÁöÑÊï∞ÊçÆÔºåÊâæÂá∫topic0Ôºà1ÔºâÊâÄÂØπÂ∫îÁöÑÂêàÁ∫¶ÂäüËÉΩÔºåÁî®ÂÄüÂá∫ÁöÑÔºà‚ÄòBorrow‚ÄôÔºâÂáèÂéªÂ∑≤ÂÅøËøòÔºà‚ÄòRepay‚ÄôÔºâÁöÑ„ÄÇ

ÂèÇËÄÉÔºöhttps://dune.com/queries/1037796/1798021

```sql
 select 'Borrow' as action_type,
    block_time,
    bytearray_ltrim(topic1) as token_address,
    bytearray_ltrim(topic2) as user_address,
    cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
    tx_hash
from arbitrum.logs
where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
    and topic0 = 0xb3d084820fb1a9decffb176436bd02558d15fac9b0ddfed8c465bc7359d7dce0 -- Borrow
    and block_time > date('2022-03-16') -- First transaction date

union all

select 'Repay' as action_type,
    block_time,
    bytearray_ltrim(topic1) as token_address,
    bytearray_ltrim(topic2) as user_address,
    -1 * cast(bytearray_to_uint256(bytearray_substring(data, 1 + 32, 32)) as decimal(38, 0)) as raw_amount,
    tx_hash
from arbitrum.logs
where contract_address = 0x794a61358d6845594f94dc1db02a252b5b4814ad   -- Aave: Pool V3
    and topic0 = 0xa534c8dbe71f871f9f3530e97a74601fea17b426cae02e1c5aee42c96c784051 -- Repay
    and block_time > date('2022-03-16') -- First transaction date

limit 100
```


### 3.ËµÑÊú¨ÊïàÁéáÔºàUtilization RatioÔºâ

ÁÆÄÂçïÁêÜËß£Â∞±ÊòØÂ≠òÂÖ•ÂçèËÆÆ‰∏≠ÁöÑËµÑÈáëÊúâÂ§öÂ∞ëË¢´ÁúüÊ≠£Âà©Áî®Ëµ∑Êù•ÔºàÂÄüËµ∞Ôºâ‰∫ÜÔºåÂΩìÂâçArbitrum‰∏äAAVE V3ÁöÑËµÑÊú¨ÊïàÁéáÂ§ßÁ∫¶Âú®30%ÔºåÂ§Ñ‰∫é‰∏Ä‰∏™‰ΩéÊù†ÊùÜÊ∞¥Âπ≥ÔºåÂØπÊØî21Âπ¥ÁâõÂ∏ÇÊó∂ÔºåËµÑÈáëÂà©Áî®ÁéáÂú®40%-80%‰πãÈó¥„ÄÇÊúâ‰∫ÜÂâç‰∏§ÊÆµÁöÑÂü∫Á°ÄÔºåËÆ°ÁÆóËøôÈÉ®ÂàÜÂπ∂‰∏çÂõ∞ÈöæÔºåÂèÇËÄÉhttps://dune.com/queries/1037796/1798141„ÄÇ

![](img/ur.png)

![](img/ur.jpg)


### 4.ËØ¶ÁªÜÂàÜÁ±ª

ÂåÖÊã¨ÂêàÁ∫¶ÈîÅÂÆöËµÑ‰∫ßÊûÑÊàêÂíåÁî®Êà∑Ë°å‰∏∫ÂàÜÂ∏ÉÔºåÂèÇËÄÉÔºöhttps://dune.com/queries/1026402/1771390„ÄÇ

![](img/4.1.png)

AAVEÂú®Arbitrum‰∏äËµÑÈáëÊ±†‰∏≠Âç†ÊØîÂâç‰∏âÁöÑÊòØWETHÔºà37.6%Ôºâ„ÄÅUSDCÔºà29.5%ÔºâÂíåWBTCÔºà22.6%Ôºâ„ÄÇÁõÆÂâçËøòÂ§Ñ‰∫éÁÜäÂ∏ÇÔºåÁî®Êà∑ÂØπÊù†ÊùÜÈúÄÊ±Ç‰∏çÂº∫ÁÉàÔºåÊï¥‰Ωì‰ª•Â≠òÊ¨æÂêÉÊÅØ‰∏∫‰∏ª„ÄÇ

![](img/4.2.png)

### 5.Âü∫Á°ÄÊåáÊ†á 

‰∏Ä‰∫õÂü∫Á°ÄÁöÑÂçèËÆÆÂàÜÊûêÊåáÊ†áÔºåÂ¶ÇÁî®Êà∑Êï∞Ôºå‰∫§ÊòìÊï∞ÔºåÊó•ÂùáÂèòÂåñÈáèÊÉÖÂÜµÔºåÂèÇËÄÉÔºöhttps://dune.com/queries/1026141/1771147„ÄÇ

![](img/dunedata.png)

## ÂÄüË¥∑ÁöÑÁªºÂêàÁúãÊùø

1. Arbitrum‰∏äAAVE V3ÁöÑÁªºÂêàdashboard„ÄÇ

https://dune.com/sixdegree/aave-on-arbitrum-overview

![](img/dashboard.png)

2. Â∞Ü‰ª•Â§™Âùä‰∏ä‰∏âÂ§ßÁªèÂÖ∏ÂÄüË¥∑ÂçèËÆÆMakerÔºåAAVEÂíåCompoundËøõË°åÂØπÊØîÁöÑdashboard„ÄÇ‰∏çËøáËøô‰∏™dashboardÊØîËæÉËÄÅÔºåÁî®ÁöÑÊòØDune V1ÂºïÊìéÔºåDuneÂç≥Â∞Ü‰∏ãÊû∂V1Ôºå‰ªäÂêéÂè™‰ΩøÁî®V2ÔºåÊâÄ‰ª•Â§ßÂÆ∂Â≠¶‰π†Êó∂ÂÄüÈâ¥ÊÄùË∑ØÂç≥ÂèØ„ÄÇ

https://dune.com/datanut/Compound-Maker-and-Aave-Deposits-Loans-LTV

![](img/dashboard2.png)

## ÂèÇËÄÉ
1. https://foresightnews.pro/article/detail/17638
2. https://learnblockchain.cn/article/5036
3. https://twitter.com/0xhiger/status/1595076528697905157
4. https://www.blocktempo.com/why-do-defi-lending-protocols-generate-bad-debts/
5. https://www.panewslab.com/zh/articledetails/k1ep9df5.html
6. https://new.qq.com/rain/a/20201121A096UF00

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch15/ch14-defi-analysis.md">
# DeFiÊï∞ÊçÆÂàÜÊûê

DeFiÊåáÁöÑÊòØDecentralized FinanceÔºåÂç≥Âéª‰∏≠ÂøÉÂåñÈáëËûç„ÄÇDeFiÂ∫îËØ•ÁÆóÊòØÁõÆÂâçÂå∫ÂùóÈìæÊòØÊ¥ªË∑ÉÂ∫¶ÊúÄÈ´òÁöÑÈ¢ÜÂüü‰∫ÜÔºåÂΩìÊàë‰ª¨ÈúÄË¶ÅÂ∞Ü‰∏ÄÁßçERC20‰ª£Â∏ÅÂÖëÊç¢‰∏∫Âè¶‰∏ÄÁßçÊó∂ÔºåÂ∞±ÂèØ‰ª•ÈÄöËøáDeFiÂ∫îÁî®Êù•ÂÆåÊàêÂÖëÊç¢„ÄÇDEXÊòØÊåáDecentralized ExchangeÔºåÂç≥Âéª‰∏≠ÂøÉÂåñ‰∫§ÊòìÊâÄ„ÄÇUniswapÔºåPancakeSwapÔºåCurveFiÁ≠âÈÉΩÊòØÂæàÊµÅË°åÁöÑDEX‰∫§ÊòìÊâÄ„ÄÇÊú¨ÁØáÊïôÁ®ã‰∏≠Êàë‰ª¨‰∏ÄËµ∑Êù•Êé¢Á¥¢‰∏Ä‰∏ãDeFiÈ°πÁõÆÁöÑÂàÜÊûêÊñπÊ≥ïÔºåÊàë‰ª¨‰ΩøÁî®EthereumÂå∫ÂùóÈìæ‰∏äÁöÑÊï∞ÊçÆÊù•ÂÅöÊ°à‰æã„ÄÇ

Êú¨ÊïôÁ®ãÁöÑÊï∞ÊçÆÁúãÊùøÔºö[DeFi Analysis Tutorial](https://dune.com/sixdegree/defi-analysis-tutorial)

## DeFiÈ≠îÊ≥ïË°®

Èâ¥‰∫éDeFiÂ∫îÁî®Âú®CryptoÈ¢ÜÂüüÁöÑÈáçË¶ÅÁ®ãÂ∫¶ÔºåDuneÁ§æÂå∫‰∏∫ÂÖ∂Âª∫Á´ã‰∫Ü‰∏∞ÂØåÁöÑÈ≠îÊ≥ïË°®ÔºàSpellsÔºâ„ÄÇÈ≠îÊ≥ïË°®`dex.trades`ËÅöÂêà‰∫ÜÊù•Ëá™Uniswap„ÄÅpancakeswap„ÄÅtrader_joe„ÄÅvelodrome„ÄÅsushiswapÁ≠âËøë30‰∏™‰∏çÂêåDEXÂ∫îÁî®ÁöÑ‰∫§ÊòìÊï∞ÊçÆ„ÄÇÈÄöËøá`dex.trades`Ë°®ÁöÑ[ÂÆö‰πâ](https://github.com/duneanalytics/spellbook/blob/main/models/dex/dex_trades.sql)Êàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÂÖ∂Êï∞ÊçÆÊù•Ê∫ê‰∫éÂÖ∂‰ªñÈ≠îÊ≥ïË°®ÔºåÊØîÂ¶Ç`uniswap.trades`„ÄÅ`sushiswap.trades`„ÄÅ`curvefi.trades`Á≠â„ÄÇÂ¶ÇÊûú‰Ω†Âè™ÊòØÈúÄË¶ÅÂàÜÊûêÂÖ∑‰ΩìÁöÑÊüê‰∏™DEXÁöÑÊï∞ÊçÆÔºåÈÇ£‰πàÊé®Ëçê‰ºòÂÖà‰ΩøÁî®Ëøô‰∫õÂ∫îÁî®Áã¨ÊúâÁöÑtradesÈ≠îÊ≥ïË°®ÔºåÂõ†‰∏∫‰ºöÊúâÊõ¥Â•ΩÁöÑÊü•ËØ¢ÊâßË°åÊÄßËÉΩ„ÄÇ‰∏éÊ≠§Á±ª‰ººÔºåÂØπ‰∫éÂÉèUniswapËøôÊ†∑Â∑≤ÁªèÂÖàÂêéÂèëÂ∏ÉËøáÂ§ö‰∏™ÁâàÊú¨Êô∫ËÉΩÂêàÁ∫¶ÔºàÂåÖÊã¨Âêå‰∏Ä‰∏™Âå∫ÂùóÈìæ‰∏äÂçáÁ∫ßÂêàÁ∫¶ÁâàÊú¨„ÄÅÊàñËÄÖÂú®‰∏çÂêåÁöÑÂå∫ÂùóÈìæ‰∏äÈÉ®ÁΩ≤Êô∫ËÉΩÂêàÁ∫¶ÔºâÁöÑDeFiÈ°πÁõÆÔºåÂÆÉÁöÑ`uniswap.trades`Ë°®‰πüÊòØ‰ªéÂÖ∂‰ªñÈ≠îÊ≥ïË°®ËÅöÂêàÁîüÊàêÁöÑ„ÄÇÂ¶ÇÊûúÊàë‰ª¨Âè™ÊòØÂØπÂÖ∂‰∏≠ÁöÑÊüê‰∏™ÁâàÊú¨ÊàñËÄÖÊüê‰∏™ÈìæÁöÑÊï∞ÊçÆÊÑüÂÖ¥Ë∂£Ôºå‰πüÂèØ‰ª•‰ΩøÁî®ÂØπÂ∫îÁöÑÈ≠îÊ≥ïË°®„ÄÇÊØîÂ¶ÇÔºåÂ¶ÇÊûúÂè™ÊÉ≥ÂàÜÊûêEthereum‰∏äÁöÑUniswap V3ÁöÑ‰∫§ÊòìÊï∞ÊçÆÔºåÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®`uniswap_v3_ethereum.trades`Ë°®ÔºåÊÉ≥ÂàÜÊûêOptimismÈìæ‰∏äÁöÑCurveFiÁöÑ‰∫§ÊòìÊï∞ÊçÆÔºåÂàôÂèØ‰ª•‰ΩøÁî®`curvefi.trades`È≠îÊ≥ïË°®„ÄÇ

```sql
select blockchain, 
    project, 
    project || '_' || blockchain || '.trades' as spell_table_name,
    count(*) as trade_count
from dex.trades
group by 1, 2, 3
order by 1 asc, 4 desc
```

Ëøô‰∏™Êü•ËØ¢ÂàóÂá∫‰∫ÜÂΩìÂâç`dex.trades`Ë°®ÂåÖÊã¨ÁöÑÈ°πÁõÆÂèäÂÖ∂ÂØπÂ∫îÁöÑÂå∫ÂùóÈìæÔºåÂØπÂ∫îÁöÑÊï∞ÊçÆÊ∫êÈ≠îÊ≥ïË°®ÂêçÁß∞„ÄÇÁõÆÂâç`dex.trades`ËÅöÂêàÊï∞ÊçÆÁöÑÁõ∏ÂÖ≥È≠îÊ≥ïË°®Â¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_01.png](img/image_01.png)

Êü•ËØ¢ÈìæÊé•Ôºö[https://dune.com/queries/1750008](https://dune.com/queries/1750008)

Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®ÂÖ∂‰∏≠ÁöÑ`spell_table_name`ÁöÑÂÄº‰Ωú‰∏∫Ë°®ÂêçÊù•ËÆøÈóÆÂØπÂ∫îÈ°πÁõÆÁöÑ‰∫§ÊòìÊï∞ÊçÆtradesÈ≠îÊ≥ïË°®„ÄÇ‰æãÂ¶ÇÔºö

```sql
select * from 
kyberswap_avalanche_c.trades
limit 1
```

## DeFiË°å‰∏öÊï¥‰ΩìÂàÜÊûê

### DeFiÊ¶ÇÂÜµ

Â¶ÇÂâçÊâÄËø∞È≠îÊ≥ïÊï∞ÊçÆË°®``‰∏≠ËÅöÂêà‰∫ÜÊù•Ëá™UniswapÁ≠âÂçÅÂá†‰∏™DeFiÈ°πÁõÆÁöÑ‰∫§ÊòìÊï∞ÊçÆÔºåÂü∫Êú¨Ê∂µÁõñ‰∫Ü‰∏ªÊµÅÁöÑDeFiÈ°πÁõÆ„ÄÇÊàë‰ª¨È¶ñÂÖàÁúã‰∏Ä‰∏ãÊ¶ÇÂÜµ„ÄÇËÄÉËôëÂè™ÊòØÊïôÂ≠¶ÁõÆÁöÑÔºåÊàë‰ª¨ÁöÑÊü•ËØ¢‰∏≠ÈôêÂà∂Âè™ÂèñËøëÊúüÁöÑÊï∞ÊçÆ‰∏∫‰æã„ÄÇ

```sql
select block_date,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from dex.trades
where block_date >= date('2022-10-01')
group by 1
order by 1
```

‰ΩøÁî®‰∏äÈù¢ÁöÑÊü•ËØ¢ÂèØ‰ª•ÂæóÂà∞ÊØèÂ§©ÁöÑ‰∫§ÊòìÊï∞ÈáèÂíåÁã¨Á´ãÁî®Êà∑Êï∞„ÄÇDeFiÈ°πÁõÆÁöÑÂÜÖÈÉ®ÈÄªËæëÊØîËæÉÂ§çÊùÇÔºå`taker`Â≠óÊÆµÂ≠òË¥ÆÁöÑÊòØ‰∫§ÊòìÁöÑÊî∂Ê¨æ‰∫∫Ôºå‰ΩøÁî®ÂÆÉÊù•ËÆ°ÁÆóÊâçËÉΩÊ≠£Á°ÆÂèçÂ∫îÁúüÊ≠£ÁöÑÁã¨Á´ãÁî®Êà∑Êï∞Èáè„ÄÇÊàë‰ª¨ËøòÂ∏åÊúõÂêåÊó∂ÁªüËÆ°Âá∫ÊØèÊó•‰∫§ÊòìÊï∞ÈáèÁöÑÁ¥ØËÆ°ÔºåÊØèÊó•Êñ∞Áî®Êà∑Êï∞ÈáèÂèäÂÖ∂Á¥ØËÆ°ÂÄºÔºå‰ª•ÂèäÊÄª‰∫§ÊòìÊï∞ÈáèÂíåÁî®Êà∑Êï∞ÈáèÔºåÂØπ‰∏äÈù¢ÁöÑÊü•ËØ¢ËøõË°å‰øÆÊîπË∞ÉÊï¥Êù•ÂÆûÁé∞„ÄÇ‰øÆÊîπÂêéÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with trade_summary as (
    select block_date,
        count(*) as trade_count,
        count(distinct taker) as active_user_count,
        sum(amount_usd) as trade_amount
    from dex.trades
    where blockchain = 'ethereum'
        and block_date >= date('2021-01-01')
        and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
    group by 1
    order by 1
),

user_initial_trade as (
    select taker,
        min(block_date) as initial_trade_date
    from dex.trades
    where blockchain = 'ethereum'
        and block_date >= date('2021-01-01')
        and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
    group by 1
),

new_user_summary as (
    select initial_trade_date,
        count(taker) as new_user_count
    from user_initial_trade
    group by 1
    order by 1
)

select t.block_date,
    trade_count,
    active_user_count,
    trade_amount,
    new_user_count,
    active_user_count - new_user_count as existing_user_count,
    sum(trade_count) over (order by t.block_date) as accumulate_trade_count,
    sum(trade_amount) over (order by t.block_date) as accumulate_trade_amount,
    sum(new_user_count) over (order by u.initial_trade_date) as accumulate_new_user_count,
    (sum(trade_count) over ()) / 1e6 as total_trade_count,
    (sum(trade_amount) over ()) / 1e9 total_trade_amount,
    (sum(new_user_count) over ()) / 1e6 as total_new_user_count
from trade_summary t
left join new_user_summary u on t.block_date = u.initial_trade_date
order by t.block_date
```

Êü•ËØ¢ÂÜÖÂÆπËß£ËØªÔºö
1. Êàë‰ª¨Â∞ÜÂéüÊù•ÁöÑÊü•ËØ¢ÊîæÂÖ•`trade_summary` CTE‰∏≠‰ª•Êñπ‰æøÂêéÈù¢‰ΩøÁî®Á™óÂè£ÂáΩÊï∞„ÄÇÊü•ËØ¢‰∏≠Êàë‰ª¨ÂèëÁé∞‚ÄúPOP-WETH‚ÄùËøô‰∏™POOLÁöÑÊï∞ÊçÆÂºÇÂ∏∏ÔºåÊâÄ‰ª•ËøôÈáåÁõ¥Êé•Â∞ÜÂÖ∂ÊéíÈô§„ÄÇ
2. CTE `user_initial_trade` ÁªüËÆ°ËÆ°ÁÆóÊØè‰∏Ä‰∏™‰∫§ÊòìÊî∂Ê¨æ‰∫∫ÔºàtakerÔºâÁöÑÂàùÊ¨°‰∫§ÊòìÊó•Êúü„ÄÇÊ≥®ÊÑèËøôÈáå‰∏∫‰∫ÜÊÄßËÉΩËÄÉËôëÈôêÂà∂‰∫Ü‰∫§ÊòìÊó•ÊúüÔºåÊâÄ‰ª•Âπ∂‰∏çÊòØÁúüÊ≠£ÊÑè‰πâ‰∏äÁöÑÂàùÊ¨°‰∫§ÊòìÊó•Êúü„ÄÇ
3. CTE `new_user_summary` ÂàôÂú®`user_initial_trade`Âü∫Á°Ä‰∏äÔºåÊåâÁî®Êà∑ÁöÑÂàùÊ¨°‰∫§ÊòìÊó•ÊúüËøõË°åÊ±áÊÄªËÆ°ÁÆóÂá∫ÊØèÂ§©ÁöÑÊñ∞Â¢ûÁî®Êà∑Êï∞Èáè„ÄÇ
4. ÊúÄÂêéËæìÂá∫ÁªìÊûúÁöÑÊü•ËØ¢‰ª£Á†Å‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®`sum(field_name1) over (order by field_name2)`ÁöÑÁ™óÂè£ÂáΩÊï∞ËØ≠Ê≥ïËÆ°ÁÆóÊåâÊó•ÊúüÁ¥ØÂä†ÁöÑÊï∞ÊçÆ„ÄÇÂÖ∂‰∏≠Èô§‰ª• 1e6 ÊàñËÄÖ 1e9 ÊòØÂ∞ÜÂ§ßÊï∞Â≠óËΩ¨Êç¢‰∏∫‚ÄúÁôæ‰∏á‚Äù„ÄÅ‚Äú‰∫ø‚ÄùÁöÑÂØπÂ∫îÂÄº„ÄÇ

Âú®Ëøô‰∏™Êü•ËØ¢ÁªìÊûú‰∏≠ÔºåÊàë‰ª¨Ê∑ªÂä†Â¶Ç‰∏ãÂèØËßÜÂåñÂõæË°®Ôºö
1. ‰∏∫total_trade_count„ÄÅtotal_trade_amount„ÄÅtotal_new_user_count ‰∏â‰∏™ËæìÂá∫ÂÄºÂàÜÂà´Ê∑ªÂä†CounterÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇ
2. ÂàÜÂà´ÈíàÂØπtrade_count„ÄÅnew_user_count Ê∑ªÂä†Bar ChartÁ±ªÂûãÁöÑÊù°ÂΩ¢Âõæ„ÄÇ
3. ÂàÜÂà´ÈíàÂØπtrade_amount„ÄÅactive_user_countÊ∑ªÂä†Area ChartÁ±ªÂûãÁöÑÈù¢ÁßØÂõæ„ÄÇ
4. Ê∑ªÂä†‰∏Ä‰∏™ÂØπÊØînew_user_count Âíå existing_user_countÂç†ÊØîÁöÑÁôæÂàÜÊØîÁ±ªÂûãÈù¢ÁßØÂõæ„ÄÇ
5. Ê∑ªÂä†‰∏Ä‰∏™Table Á±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®ÔºåËæìÂá∫Êü•ËØ¢ÁªìÊûú„ÄÇ

Êñ∞Âª∫‰∏Ä‰∏™DashboardÔºåÂ∞ÜÁõ∏ÂÖ≥ÂõæË°®Âä†ÂÖ•ÂÖ∂‰∏≠„ÄÇÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_02.png](img/image_02.png)

Á±ª‰ººÁöÑÔºåÊàë‰ª¨ÂèØ‰ª•ÊåâÊúàÂ∫¶ËøõË°åÊ±áÊÄªÔºåÁªüËÆ°ÊØè‰∏™ÊúàÁöÑÁõ∏ÂÖ≥Êï∞ÊçÆÂπ∂Ê∑ªÂä†ÂèØËßÜÂåñÂõæË°®Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇ

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1661180](https://dune.com/queries/1661180)
- [https://dune.com/queries/1663358](https://dune.com/queries/1663358)

### ÊåâÈ°πÁõÆÁöÑÁªüËÆ°ÂàÜÊûê

ÂâçÈù¢ÊèêÂà∞Ôºå`dex.trades`È≠îÊ≥ïË°®Ê±áÊÄª‰∫ÜÊù•Ëá™Â§ö‰∏™È°πÁõÆÂú®‰∏çÂêåÂå∫ÂùóÈìæ‰∏äÁöÑ‰∫§ÊòìÊï∞ÊçÆ„ÄÇÊàë‰ª¨ÂèØ‰ª•Áî®‰∏Ä‰∏™Êü•ËØ¢Êù•ÂØπÊØîÂêÑÈ°πÁõÆÁöÑ‰∫§ÊòìÊï∞ÊçÆÔºåÂàÜÊûê‰ªñ‰ª¨ÁöÑÂ∏ÇÂú∫Âç†ÊØî„ÄÇ

```sql
select block_date,
    project,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from dex.trades
where blockchain = 'ethereum'
    and block_date >= date('2021-01-01')
    and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
group by 1, 2
order by 1, 2
```

ËøôÈáåÂè™ÂØπÊØîÊ¥ªË∑ÉÁî®Êà∑Êï∞Èáè„ÄÅ‰∫§ÊòìÊï∞ÈáèÂíå‰∫§ÊòìÈáëÈ¢ù„ÄÇÂàÜÂà´ÈíàÂØπÁªìÊûúÈõÜÁöÑ‰∏çÂêåÂ≠óÊÆµÊ∑ªÂä†Êù°ÂΩ¢ÂõæÂíåÈ•ºÂõæÔºåÂä†ÂÖ•Êï∞ÊçÆÁúãÊùø„ÄÇ‰Ω†ÂèØËÉΩÂ∑≤ÁªèÊ≥®ÊÑèÂà∞ÔºåÊàë‰ª¨ÁöÑÊü•ËØ¢ÁªìÊûúÊï∞ÊçÆÊòØÊåâÂ§©ÂíåÈ°πÁõÆ‰∏§‰∏™Áª¥Â∫¶ËøõË°åÊ±áÊÄªÁöÑ„ÄÇÂΩìÊàë‰ª¨ÂàõÂª∫Pie Chart È•ºÂõæÂõæË°®Êó∂ÔºåÂ¶ÇÊûúÂè™ÈÄâÊã© Project Áª¥Â∫¶‰Ωú‰∏∫ X ColumnÔºåÈÄâÊã© trade_count ‰∏∫ Y Column 1Ôºå‰∏çÈÄâÊã©Group ByÂàÜÁªÑÁöÑÂ≠óÊÆµÔºåÊ≠§Êó∂ÊØè‰∏ÄÂ§©ÁöÑtrade_countÂÄº‰ºöËá™Âä®Ë¢´Á¥ØÂä†Âà∞‰∏ÄËµ∑ÔºåÂÖ∂ÊÄªÂíåÂÄºË¢´Â±ïÁ§∫Âú®È•ºÂõæ‰∏≠„ÄÇËøôÊ†∑Êàë‰ª¨Â∞±‰∏çÁî®ÂçïÁã¨ÂÜô‰∏Ä‰∏™Êü•ËØ¢Êù•ÁîüÊàêÈ•ºÂõæ‰∫Ü„ÄÇËøô‰πüÁÆóÊòØ‰∏Ä‰∏™Â∫îÁî®ÊäÄÂ∑ß„ÄÇÊï∞ÊçÆÁúãÊùøÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÔºö

![image_03.png](img/image_03.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1669861](https://dune.com/queries/1669861)


### Êåâ‰ª£Â∏Å‰∫§ÊòìÂØπÔºàToken PairÔºâËøõË°åÂàÜÁ±ªÊ±áÊÄª

Âá†‰πéÊØè‰∏Ä‰∏™DeFiÈ°πÁõÆÈÉΩÊîØÊåÅÂ§öÁßç‰ª£Â∏Å‰πãÈó¥ÁöÑÂÖëÊç¢ÔºåËøôÈÄöÂ∏∏ÊòØÈÄöËøá‰∏∫‰∏çÂêåÁöÑ‰ª£Â∏Å‰∫§ÊòìÂØπÂª∫Á´ãÂçïÁã¨ÁöÑ‰∫§ÊòìÊµÅÂä®ËµÑÈáëÊ±†ÔºàPoolÔºâÊù•ÂÆûÁé∞ÁöÑ„ÄÇÊØîÂ¶ÇÔºåUniswapÊîØÊåÅÂ§öÁßçERC20‰ª£Â∏ÅÁöÑÁõ∏‰∫íÂÖëÊç¢ÔºåÊµÅÂä®ÊÄßÊèê‰æõÂïÜÔºàLPÔºåÂç≥Liquidity ProviderÔºâÂèØ‰ª•ÈÄâÊã©‰ªªÊÑè‰∏§ÁßçERC20‰ª£Â∏ÅÂàõÂª∫ÊµÅÂä®ËµÑÈáëÊ±†ÔºåÊôÆÈÄöÁî®Êà∑ÂàôÂèØ‰ª•‰ΩøÁî®ÊµÅÂä®ËµÑÈáëÊ±†ÂÆåÊàê‰ª£Â∏ÅÁöÑÂÖëÊç¢ÔºàÂÖëÊç¢Êó∂ÊîØ‰ªò‰∏ÄÂÆöÊØî‰æãÁöÑ‰∫§ÊòìÊâãÁª≠Ë¥πÔºâ„ÄÇ‰ª•USDCÂíåWETH‰ª£Â∏Å‰∏∫‰æãÔºåÂú®Uniswap V3‰∏ãÔºå‰∏ÄÂÖ±Êúâ4Áßç‰∏çÂêåÁöÑË¥πÁéáÁ≠âÁ∫ßÔºåLPÁî®Êà∑ÂèØ‰ª•‰∏∫ËøôÂõõÁßçË¥πÁéáÁ≠âÁ∫ßÂàÜÂà´ÂàõÂª∫‰∏Ä‰∏™ÊµÅÂä®ËµÑÈáëÊ±†ÔºåÂ¶Ç‚ÄúUSDC/WETH 0.3%‚Äù„ÄÇÈâ¥‰∫éÁªÑÊàê‰∏çÂêåÁöÑ‰∫§ÊòìÂØπÁöÑToken‰ª£Â∏ÅÁöÑÊµÅË°åÁ®ãÂ∫¶‰∏çÂêå„ÄÅÊµÅÈÄöÈáè‰∏çÂêå„ÄÅÊîØÊåÅÁöÑÂπ≥Âè∞‰∏çÂêå„ÄÅ‰∫§ÊòìÊâãÁª≠Ë¥πÁöÑË¥πÁéá‰πü‰∏çÂêåÔºåÊàë‰ª¨ÂèØËÉΩÈúÄË¶ÅÂØπÊØîÂàÜÊûêÂì™‰∫õ‰∫§ÊòìÂØπÊõ¥ÂèóÊ¨¢Ëøé„ÄÅÊúâÊõ¥È´òÁöÑ‰∫§ÊòìÊï∞Èáè„ÄÇ

```sql
with top_token_pair as (
    select token_pair,
        count(*) as transaction_count
    from dex.trades
    where blockchain = 'ethereum'
        and block_date >= date('2021-01-01')
        and token_pair <> 'POP-WETH' -- Exclude outlier that has wrong amount
    group by 1
    order by 2 desc
    limit 20
)

select date_trunc('month', block_date) as block_date,
    token_pair,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from dex.trades
where blockchain = 'ethereum'
    and block_date >= date('2021-01-01')
    and token_pair in (
        select token_pair from top_token_pair
    )
group by 1, 2
order by 1, 2
```

Âú®‰∏äÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàÂÆö‰πâ‰∏Ä‰∏™`top_token_pair` CTEÔºåÊåâ‰∫§ÊòìÊï∞ÈáèÊü•Âá∫ÊéíÂêçÂâç20‰ΩçÁöÑ‰∫§ÊòìÂØπ„ÄÇÁÑ∂ÂêéÊàë‰ª¨ÈíàÂØπËøô20‰∏™‰∫§ÊòìÂØπÔºåÊåâÊúàÁªüËÆ°Ê±áÊÄª‰ªñ‰ª¨ÁöÑ‰∫§ÊòìÊï∞Èáè„ÄÅÊ¥ªË∑ÉÁî®Êà∑Êï∞ÈáèÂíå‰∫§ÊòìÈáëÈ¢ù„ÄÇ‰∏∫Ê≠§Êü•ËØ¢Ê∑ªÂä†Áõ∏Â∫îÁöÑÂèØËßÜÂåñÂõæË°®Âπ∂Âä†ÂÖ•Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ

![image_04.png](img/image_04.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1670196](https://dune.com/queries/1670196)

## Âçï‰∏™DeFiÈ°πÁõÆÁöÑÂàÜÊûê

ÈíàÂØπÂÖ∑‰ΩìÁöÑÂçï‰∏™DeFiÈ°πÁõÆÔºåÊàë‰ª¨ÂèØ‰ª•ÂàÜÊûêÂÖ∂Ê¥ªË∑É‰∫§ÊòìÂØπ„ÄÅÊñ∞ÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞Èáè„ÄÅ‰∫§ÊòìÈáè„ÄÅÊ¥ªË∑ÉÁî®Êà∑Á≠âÁõ∏ÂÖ≥Êï∞ÊçÆÊåáÊ†á„ÄÇ‰ª•Uniswap ‰∏∫‰æãÔºå‰ªéÂâçÈù¢‚ÄúDeFiÈ≠îÊ≥ïË°®‚ÄùÈÉ®ÂàÜÁöÑÊü•ËØ¢ÂèØ‰ª•ÊâæÂà∞UniswapÂú®EthereumÈìæ‰∏äÂØπÂ∫îÁöÑÈ≠îÊ≥ïË°®ÊòØ`uniswap_ethereum.trades`Ë°®„ÄÇ

### ‰∫§ÊòìÊ¨°Êï∞„ÄÅÊ¥ªË∑ÉÁî®Êà∑„ÄÅ‰∫§ÊòìÈáëÈ¢ù

ÂèØ‰ª•ÊåâÂ§©ÁªüËÆ°‰∫§ÊòìÊ¨°Êï∞„ÄÅÊ¥ªË∑ÉÁî®Êà∑„ÄÅ‰∫§ÊòìÈáëÈ¢ù„ÄÇSQL Â¶Ç‰∏ãÔºö

```sql
select block_date,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from uniswap_ethereum.trades
where block_date >= date('2022-01-01')
group by 1
order by 1
```

Êü•ËØ¢ÈìæÊé•‰∏∫Ôºö
- [https://dune.com/queries/1750266](https://dune.com/queries/1750266)

### Ê¥ªË∑É‰∫§ÊòìÂØπÂàÜÊûê

ÂàÜÊûêUniswapÈ°πÁõÆ‰∏≠ÊúÄÊ¥ªË∑É‰∫§ÊòìÂØπÔºàUniswap‰∏≠‰πüÁß∞‰∏∫PoolÔºåÊµÅÂä®ËµÑÈáëÊ±†ÔºâÁöÑSQLÂ¶Ç‰∏ãÔºö

```sql
with top_token_pair as (
    select token_pair,
        count(*) as transaction_count
    from uniswap_ethereum.trades
    where blockchain = 'ethereum'
        and block_date >= date('2022-01-01')
    group by 1
    order by 2 desc
    limit 20
)

select date_trunc('month', block_date) as block_date,
    token_pair,
    count(*) as trade_count,
    count(distinct taker) as active_user_count,
    sum(amount_usd) as trade_amount
from uniswap_ethereum.trades
where blockchain = 'ethereum'
    and block_date >= date('2022-01-01')
    and token_pair in (
        select token_pair from top_token_pair
    )
group by 1, 2
order by 1, 2
```

ÂàÜÂà´ÁîüÊàê‰∏Ä‰∏™Èù¢ÁßØÂõæÂíåÈ•ºÂõæÔºåÂä†ÂÖ•Êï∞ÊçÆÁúãÊùø„ÄÇÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞Ôºå2022Âπ¥‰ª•Êù•Ôºå‚ÄúUSDC-WETH‚Äù‰∫§ÊòìÂØπÁöÑÊàê‰∫§ÈáëÈ¢ùÂç†ÊØîËææÂà∞‰∫Ü58%„ÄÇÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_05.png](img/image_05.png)

Êü•ËØ¢ÈìæÊé•‰∏∫Ôºö
- [https://dune.com/queries/1751001](https://dune.com/queries/1751001)

### Êñ∞ËµÑÈáëÊ±†ÂàÜÊûê

Âú®Êàë‰ª¨ÂâçÊúüÁöÑÊïôÁ®ãÊñáÁ´†‚ÄúÂàõÂª∫Á¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùø‚Äù‰∏≠ÔºåÊàë‰ª¨Âõ¥ÁªïUniswap V3ÁöÑËµÑÈáëÊ±†ÂÅö‰∫Ü‰∏Ä‰∫õÊü•ËØ¢ÂàÜÊûê„ÄÇËøôÈáå‰∏çÂÜçÂ±ïÂºÄ‰∏æ‰æã„ÄÇÊàë‰ª¨Âè¶Â§ñËøòÊúâ‰∏Ä‰∏™Êï∞ÊçÆÁúãÊùøÔºåÂèØ‰æõÁõëÊéßUniswap‰∏≠Êñ∞Âª∫ÁöÑÊµÅÂä®ËµÑÈáëÊ±†„ÄÇÂ§ßÂÆ∂ËØ∑Ëá™Ë°åÂèÇËÄÉÁÜüÊÇâ„ÄÇ

ÂèÇËÄÉÊï∞ÊçÆÁúãÊùøÔºö
- [Uniswap New Pool Filter](https://dune.com/sixdegree/uniswap-new-pool-metrics)
- [Uniswap V3 Pool Tutorial](https://dune.com/sixdegree/uniswap-v3-pool-tutorial)

### Ê¥ªË∑ÉÁî®Êà∑ÂàÜÊûê

Êàë‰ª¨ÈíàÂØπ`uniswap_v3_ethereum.trades`È≠îÊ≥ïË°®ÔºåÂàÜÊûêUniswap V3Âú®EthereumÈìæ‰∏äÁöÑÊúàÂ∫¶Ê¥ªË∑ÉÁî®Êà∑„ÄÅÊñ∞Áî®Êà∑„ÄÅÊµÅÂ§±Áî®Êà∑„ÄÅÁïôÂ≠òÁî®Êà∑„ÄÇÂÖàÁúãQuery‰ª£Á†ÅÔºö

```sql
with monthly_active_user as (
    select distinct taker as address,
        date_trunc('month', block_date) as active_trade_month
    from uniswap_v3_ethereum.trades
),

user_initial_trade as (
    select taker as address,
        min(date_trunc('month', block_date)) as initial_trade_month
    from uniswap_v3_ethereum.trades
    group by 1
),

user_status_detail as (
    select coalesce(c.active_trade_month, date_trunc('month', p.active_trade_month + interval '45' day)) as trade_month,
        coalesce(c.address, p.address) as address,
        (case when n.address is not null then 1 else 0 end) as is_new,
        (case when n.address is null and c.address is not null and p.address is not null then 1 else 0 end) as is_retained,
        (case when n.address is null and c.address is null and p.address is not null then 1 else 0 end) as is_churned,
        (case when n.address is null and c.address is not null and p.address is null then 1 else 0 end) as is_returned
    from monthly_active_user c
    full join monthly_active_user p on p.address = c.address and p.active_trade_month = date_trunc('month', c.active_trade_month - interval '5' day)
    left join user_initial_trade n on n.address = c.address and n.initial_trade_month = c.active_trade_month
    where coalesce(c.active_trade_month, date_trunc('month', p.active_trade_month + interval '45' day)) < current_date
),

user_status_summary as (
    select trade_month,
        address,
        (case when sum(is_new) >= 1 then 'New'
            when sum(is_retained) >= 1 then 'Retained'
            when sum(is_churned) >= 1 then 'Churned'
            when sum(is_returned) >= 1 then 'Returned'
        end) as user_status
    from user_status_detail
    group by 1, 2
),

monthly_summary as (
    select trade_month,
        user_status,
        count(address) as user_count
    from user_status_summary
    group by 1, 2
)

select trade_month,
    user_status,
    (case when user_status = 'Churned' then -1 * user_count else user_count end) as user_count
from monthly_summary
order by 1, 2
```

Ê≠§Êü•ËØ¢Ëß£ËØªÂ¶Ç‰∏ãÔºö
1. CTE `monthly_active_user`‰∏≠Â∞ÜÊó•ÊúüËΩ¨Âåñ‰∏∫ÊØèÊúàÁöÑÁ¨¨‰∏ÄÂ§©ÔºåÊü•ËØ¢Âá∫ÊØèÊúàÊúâ‰∫§ÊòìËÆ∞ÂΩïÁöÑÊâÄÊúâÁî®Êà∑Âú∞ÂùÄ„ÄÇ
2. CTE `user_initial_trade`‰∏≠Êü•ËØ¢ÊØè‰∏™Âú∞ÂùÄÁöÑÂàùÊ¨°‰∫§ÊòìÊó•ÊúüÔºå‰πüËΩ¨Êç¢‰∏∫ÂΩìÊúàÁöÑÁ¨¨‰∏ÄÂ§©„ÄÇ
3. CTE `user_status_detail`‰∏≠Ôºö
    - Êàë‰ª¨‰ΩøÁî®Full JoinÊñπÂºèÂ∞Ü`monthly_active_user`ËøõË°åËá™ËøûÊé•ÔºåËøûÊé•Êù°‰ª∂ËÆæÁΩÆ‰∏∫Áõ∏ÂêåÁöÑ‰∫§ÊòìÁî®Êà∑Âú∞ÂùÄÔºåÊúà‰ªΩÁõ∏ÈÇª„ÄÇÁî®Âà´Âêç‚Äúc‚Äù‰ª£Ë°®ÂΩìÂâçÊúàÂ∫¶ÁöÑÊï∞ÊçÆÔºåÂà´Âêç‚Äúp‚Äù‰ª£Ë°®Ââç‰∏Ä‰∏™ÊúàÂ∫¶ÁöÑÊï∞ÊçÆ„ÄÇÂõ†‰∏∫Êó•ÊúüÂ∑≤ÁªèÂú®ÂâçÈù¢Â§ÑÁêÜ‰∏∫ÊØè‰∏™ÊúàÁöÑÁ¨¨‰∏ÄÂ§©‰∫ÜÔºåËøôÈáåÊàë‰ª¨‰ΩøÁî®`date_trunc('month', c.active_trade_month - interval '5 days')`ÔºåÂú®‰ª£Ë°®ÂΩìÂâçÊúàÂ∫¶Êï∞ÊçÆÁöÑË°®ÁöÑÂéüÊúâÊó•ÊúüÔºàËØ•ÊúàÁ¨¨‰∏ÄÂ§©Ôºâ‰∏äÂáèÂéª5Â§©ÁÑ∂ÂêéÂÜçËΩ¨Êç¢‰∏∫ÂΩìÊúàÁöÑÁ¨¨‰∏ÄÂ§©ÔºåÂ∞±Á°Æ‰øùÊàë‰ª¨ÂæóÂà∞‰∫Ü‚ÄúÂâç‰∏Ä‰∏™ÊúàÂ∫¶ÁöÑÁ¨¨‰∏ÄÂ§©ÁöÑÊó•Êúü‚Äù„ÄÇ‰∫éÊòØÂèØ‰ª•Â∞Ü‰∏§‰∏™Êúà‰ªΩÁöÑÊï∞ÊçÆÂÖ≥ËÅîÂà∞‰∏ÄËµ∑„ÄÇ
    - ÂêåÊó∂ÔºåÁî±‰∫é‰ΩøÁî®ÁöÑÊòØFull JoinÔºå`c.active_trade_month`ÂèØËÉΩÊòØÁ©∫ÂÄºÔºåÊàë‰ª¨‰ΩøÁî®coalesce()ÂáΩÊï∞Â∞ÜÂâç‰∏ÄÊúà‰ªΩÁöÑÊó•ÊúüÂä†‰∏ä45Â§©‰Ωú‰∏∫Êõø‰ª£Êó•ÊúüÔºå‰ª•‰øùËØÅÊÄªÊòØËÉΩÂæóÂà∞Ê≠£Á°ÆÁöÑÊúà‰ªΩ„ÄÇ
    - Êàë‰ª¨‰πüÂ∞Ü`user_initial_trade`‰ΩøÁî®Left Join ÁöÑÊñπÂºèÂÖ≥ËÅîËµ∑Êù•ÔºåËøôÊ†∑Â∞±ËÉΩÂà§Êñ≠Âá∫Êüê‰∏™Áî®Êà∑ÊòØÂê¶Âú®Êüê‰∏™Êúà‰ªΩËøõË°å‰∫ÜÁ¨¨‰∏ÄÊ¨°‰∫§Êòì„ÄÇ
    - Êàë‰ª¨‰ΩøÁî®Â§ö‰∏™‰∏çÂêåÁöÑCASEÊù°‰ª∂Âà§Êñ≠ËØ≠Âè•ÔºåÊù•Âà§Êñ≠Âú®Êüê‰∏™Êúà‰ªΩ‰∏≠ÔºåÁî®Êà∑ÊòØÊñ∞Áî®Êà∑ÔºàÂΩìÊúàÁ¨¨‰∏ÄÊ¨°‰∫§ÊòìÔºâ„ÄÅÁïôÂ≠òÁî®Êà∑ÔºàÈùûÊñ∞Áî®Êà∑ÔºåÂΩìÊúàÂíåÂâç‰∏Ä‰∏™ÊúàÈÉΩÊúâ‰∫§ÊòìÔºâ„ÄÅÊµÅÂ§±Áî®Êà∑ÔºàÈùûÊñ∞Áî®Êà∑ÔºåÂΩìÊúàÊó†‰∫§ÊòìÔºåÂâç‰∏Ä‰∏™ÊúàÊúâ‰∫§ÊòìÔºâËøòÊòØÂõûÂΩíÁî®Êà∑ÔºàÈùûÊñ∞Áî®Êà∑ÔºåÂΩìÊúàÊúâ‰∫§ÊòìÔºåÂâç‰∏Ä‰∏™ÊúàÊó†‰∫§ÊòìÔºâ„ÄÇ
4. CTE `user_status_summary`‰∏≠ÔºåÊàë‰ª¨Êåâ‰∫§ÊòìÊúà‰ªΩÂíåÂú∞ÂùÄÔºåÊ±áÊÄªÁªüËÆ°ÊØè‰∏™Âú∞ÂùÄÂè™ÂΩìÊúàÂ±û‰∫éÂì™ÁßçÁä∂ÊÄÅÁ±ªÂûã„ÄÇ
5. CTE `monthly_summary`‰∏≠ÔºåÊàë‰ª¨Êåâ‰∫§ÊòìÊúà‰ªΩÂíåÁî®Êà∑Áä∂ÊÄÅÁªüËÆ°Áî®Êà∑Êï∞Èáè„ÄÇ
6. ÊúÄÂêéËæìÂá∫ÁªìÊûúÊó∂ÔºåÊàë‰ª¨Â∞Ü‚ÄúCburned‚ÄùÔºàÊµÅÂ§±Áî®Êà∑ÔºâÁ±ªÂûãÁöÑÂÄºÊç¢ÊàêË¥üÊï∞‰ª•‰æøÂú®ÂõæË°®‰∏äÂèØ‰ª•Êõ¥Áõ¥ËßÇÂØπÁÖß„ÄÇ

ÂàÜÂà´Ê∑ªÂä†‰∏§‰∏™Êù°ÂΩ¢ÂõæÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÈÄâÊã©‚ÄúEnable stacking‚ÄùÂè†Âä†Âà∞‰∏ÄËµ∑„ÄÇÂ∞ÜÂõæË°®Âä†ÂÖ•Âà∞Êï∞ÊçÆÁúãÊùøÔºåÊàë‰ª¨ÂèØ‰ª•ÂèëÁé∞ÔºåÊØè‰∏™ÊúàÁöÑÊµÅÂ§±Áî®Êà∑Êï∞ÈáèËøòÊòØÁõ∏ÂΩìÂ§öÁöÑ„ÄÇÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_06.png](img/image_06.png)

Êü•ËØ¢ÈìæÊé•‰∏∫Ôºö
- [https://dune.com/queries/1751216](https://dune.com/queries/1751216)


Ëøô‰∏™Êü•ËØ¢ÂÄüÈâ¥‰∫Ü [@danning.sui](https://dune.com/danning.sui) ÁöÑÊü•ËØ¢[Uniswap LP - MAU Breakdown](https://dune.com/queries/9796)ÔºåÁâπÊ≠§ÊÑüË∞¢ÔºÅ

## ÂÖ∑‰ΩìPairÁöÑÂàÜÊûê

Êàë‰ª¨ÂèØËÉΩËøòÈúÄË¶ÅÈíàÂØπÂÖ∑‰ΩìÁöÑÊµÅÂä®ËµÑÈáëÊ±†ËøõË°åÊõ¥Âä†Ê∑±ÂÖ•ÁöÑÂàÜÊûêÔºåÂåÖÊã¨ÂÖ∂‰∫§ÊòìÊï∞ÊçÆ„ÄÅÊµÅÂä®ÊÄßÊï∞ÊçÆÁ≠â„ÄÇÁî±‰∫éÁØáÂπÖÂéüÂõ†ÔºåËøôÈáå‰∏çÂÖ∑‰ΩìÂ±ïÂºÄ‰ªãÁªçÔºå‰ªÖÊèê‰æõÈÉ®ÂàÜÁõ∏ÂÖ≥ÁöÑÊü•ËØ¢ÂíåÊï∞ÊçÆÁúãÊùø‰æõÂ§ßÂÆ∂ÂèÇËÄÉÔºö

Êü•ËØ¢Á§∫‰æãÔºö
- [uniswap-v3-pool](https://dune.com/queries/1174517)
- [XEN - Uniswap trading pool overview](https://dune.com/queries/1382063)
- [optimism uniswap lp users](https://dune.com/queries/1584678)

Êï∞ÊçÆÁúãÊùøÁ§∫‰æãÔºö
- [Uniswap V3 Pool Structure And Dynamics](https://dune.com/springzhang/uniswap-v3-pool-structure-and-dynamics)
- [Uniswap V3 On Optimism Liquidity Mining Program Performance](https://dune.com/springzhang/uniswap-optimism-liquidity-mining-program-performance)

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch16/ch15-dunesql-introduction.md">
# Dune SQL Êü•ËØ¢ÂºïÊìéÂÖ•Èó®

Dune Â∑≤ÁªèÊ≠£ÂºèÊé®Âá∫‰∫ÜÂÖ∂Âõ¢ÈòüÂü∫‰∫éTrinoÔºà[https://trino.io/](https://trino.io/)ÔºâËá™Á†îÁöÑÊü•ËØ¢ÂºïÊìéDune SQL„ÄÇÊú¨Êñá‰ªãÁªçDune SQLÁöÑ‰∏Ä‰∫õÂ∏∏ËßÅÊü•ËØ¢ËØ≠Ê≥ï„ÄÅÊ≥®ÊÑè‰∫ãÈ°πÂíåÁªÜËäÇ„ÄÇ

Ê≥®ÔºöÁî±‰∫éDuneÂ∑≤ÁªèÂÆ£Â∏É2023Âπ¥‰∏ãÂçäÂπ¥Ëµ∑Â∞ÜÂÖ®Èù¢ËøáÊ∏°Âà∞Dune SQLÊü•ËØ¢ÂºïÊìéÔºåÊâÄ‰ª•Êú¨ÁØáÊïôÁ®ãÂ∞ÜÂéüÊúâÁöÑÊâÄÊúâQueryÂÖ®ÈÉ®ÂçáÁ∫ßÂà∞‰∫ÜDune SQL ÁâàÊú¨„ÄÇ

## Dune SQL ËØ≠Ê≥ïÊ¶ÇËßà

Dune SQLÈúÄË¶ÅÊ≥®ÊÑèÁöÑ‰π¶ÂÜôËØ≠Ê≥ïË¶ÅÁÇπÊúâÂá†‰∏™Ôºö
- Dune SQL ‰ΩøÁî®ÂèåÂºïÂè∑Êù•ÂºïÁî®ÂåÖÂê´ÁâπÊÆäÂ≠óÁ¨¶ÊàñËÄÖÊú¨Ë∫´ÊòØÂÖ≥ÈîÆÂ≠óÁöÑÂ≠óÊÆµÂêçÊàñË°®ÂêçÔºåÂ¶Ç` "from", "to" `„ÄÇ
- Dune SQLÁöÑÂ≠óÁ¨¶‰∏≤Á±ªÂûãÂíåÂ∏∏Áî®Êï∞ÂÄºÁ±ªÂûãÂàÜÂà´ÊòØ`varchar`„ÄÅ`double`Âíå`decimal(38, 0)`„ÄÇ
- Dune SQL ‰∏çÊîØÊåÅÈöêÂºèÁ±ªÂûãËΩ¨Êç¢„ÄÇÊØîÂ¶ÇÔºåDune SQL‰∏≠Ôºå‰∏çËÉΩÂ∞Ü`'2022-10-01'`Áõ¥Êé•‰∏é block_time ËøõË°åÊØîËæÉÔºåÈúÄË¶ÅÁî® `date('2022-10-01')`Á≠âÂáΩÊï∞ÊòæÂºèËΩ¨Êç¢‰∏∫Êó•ÊúüÂêéÊâçËÉΩÊØîËæÉ„ÄÇ‰∏çËÉΩÁõ¥Êé•Â∞ÜÊï∞ÂÄºÁ±ªÂûãÂíåÂ≠óÁ¨¶‰∏≤ËøûÊé•ÔºåË¶ÅÁî®`cast(number_value as varchar)`ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÂêéÊâçËÉΩËøûÊé•„ÄÇ

Dune ÊñáÊ°£Êèê‰æõ‰∫Ü‰∏Ä‰ªΩÊØîËæÉËØ¶ÁªÜÁöÑËØ≠Ê≥ïÂØπÁÖßË°®Ë°®ÔºåÈìæÊé•ÊòØÔºö[Syntax Comparison](https://dune.com/docs/reference/dune-v2/query-engine/#syntax-comparison)ÔºåÂ§ßÂÆ∂ÂèØ‰ª•ÂèÇËÄÉ„ÄÇ‰∏ãÂõæÂàóÂá∫‰∫ÜÈÉ®ÂàÜÂ∑ÆÂºÇÂØπÁÖßÔºö

![image_01.png](img/image_01.png)


## Dune SQL ÂÆû‰æã

### Dune SQL‰ΩøÁî®ÂèåÂºïÂè∑ÂºïÁî®ÁâπÊÆäÂ≠óÊÆµÂêçÂíåË°®Âêç

Dune SQL‰ΩøÁî®ÂèåÂºïÂè∑

```sql
select "from" as address, gas_price, gas_used
from ethereum.transactions
where success = true
limit 10
```

### Êó•ÊúüÊó∂Èó¥

Dune SQL ‰∏çÊîØÊåÅÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÁöÑÊó•ÊúüÂÄºÈöêÂºèËΩ¨Êç¢‰∏∫Êó•ÊúüÊó∂Èó¥Á±ªÂûãÁöÑÂÄºÔºåÂøÖÈ°ª‰ΩøÁî®ÊòæÂºèËΩ¨Êç¢„ÄÇÂèØ‰ª•‰ΩøÁî®Êó•ÊúüÊó∂Èó¥ÂáΩÊï∞ÊàñËÄÖÊó•ÊúüÊó∂Èó¥Êìç‰ΩúÁ¨¶„ÄÇ

1. ‰ΩøÁî®Êó•ÊúüÂÄº

Dune SQL‰ΩøÁî®date()ÂáΩÊï∞

```sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= date('2022-12-18')
limit 10
```

2. ‰ΩøÁî®Êó•ÊúüÊó∂Èó¥ÂÄº

Dune SQL‰ΩøÁî®timestamp Êìç‰ΩúÁ¨¶

```sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= timestamp '2022-12-18 05:00:00'
limit 10
```

3. ‰ΩøÁî®interval

Dune SQL‰ΩøÁî®`interval '12' hour`

```sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= now() - interval '12' hour
limit 10
```

### Âú∞ÂùÄÂíå‰∫§ÊòìÂìàÂ∏å

Dune SQL Êü•ËØ¢‰∏≠ÔºåÂú∞ÂùÄÂíåÂìàÂ∏åÂÄºÂèØ‰ª•‰∏çÊîæÂÖ•ÂçïÂºïÂè∑‰∏≠Áõ¥Êé•‰ΩøÁî®ÔºåÊ≠§Êó∂Â§ßÂ∞èÂÜô‰∏çÊïèÊÑüÔºåÂèØ‰ª•‰∏çÊòæÁ§∫ËΩ¨Êç¢‰∏∫Â∞èÂÜôÊ†ºÂºè„ÄÇ

```sql
select block_time, hash, "from" as address, "to" as contract_address
from ethereum.transactions
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
    and (
        hash = 0x2a5ca5ff26e33bec43c7a0609670b7d7db6f7d74a14d163baf6de525a166ab10
        or "from" = 0x76BE685c0C8746BBafECD1a578fcaC680Db8242E
        )
```

### Dune SQLÁöÑÂ≠óÁ¨¶‰∏≤Á±ªÂûã varchar ÂíåÊï∞ÂÄºÁ±ªÂûã double

Dune SQL‰∏≠ÁöÑÂ≠óÁ¨¶‰∏≤ÂíåÂ∏∏Áî®Êï∞ÂÄºÁ±ªÂûãÊòØ`varchar`Âíå`double`„ÄÇDune SQL‰∏≠ÁöÑÊï¥Êï∞ÂÄºÈªòËÆ§ÊòØ`bigint`Á±ªÂûãÔºåÂú®ÂÅö‰∏Ä‰∫õÂ§ßÊï∞Â≠óÁöÑ‰πòÊ≥ïÊó∂ÔºåÂÆπÊòì‰∫ßÁîüÊ∫¢Âá∫ÈîôËØØÔºåÊ≠§Êó∂ÂèØ‰ª•Âº∫Âà∂ËΩ¨Êç¢‰∏∫`double`Á±ªÂûãÊàñËÄÖ`decimal(38, 0)`Á±ªÂûã„ÄÇDune SQL‰∏≠ËøõË°åÊï¥Êï∞Èô§Ê≥ï‰πü‰∏ç‰ºöÈöêÂºèËΩ¨Êç¢‰∏∫ÊµÆÁÇπÊï∞ÂÜçËøõË°åÁõ∏Èô§ÔºåËÄåÊòØÁõ¥Êé•ËøîÂõû‰∏Ä‰∏™Êï¥Êï∞ÔºåËøôÁÇπ‰πüÈúÄË¶ÅÊ≥®ÊÑè„ÄÇ

1. ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤

Dune SQL

```sql
select block_time, hash, "from" as address, "to" as contract_address,
    cast(value / 1e9 as varchar) || ' ETH' as amount_value,
    format('%,.2f', value / 1e9) || ' ETH' as amount_value_format
from ethereum.transactions
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
    and (
        hash = 0x2a5ca5ff26e33bec43c7A0609670b7d7db6f7d74a14d163baf6de525a166ab10
        or "from" = 0x76BE685c0C8746BBafECD1a578fcaC680Db8242E
        )
```

Ê£ÄÊü•‰∏äÈù¢ÁöÑSQLËæìÂá∫ÔºåÂèØ‰ª•ÁúãÂà∞ÂΩìÂ∞ÜÊØîËæÉÂ§ßÊàñËÄÖÊØîËæÉÂ∞èÁöÑÊï∞Â≠óÁõ¥Êé•cast()ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤Êó∂Ôºå‰ºöË¢´Â§ÑÁêÜ‰∏∫ÁßëÂ≠¶ËÆ°Êï∞Ê≥ïÁöÑËæìÂá∫Ê†ºÂºèÔºåÊïàÊûú‰∏çÂ§™ÁêÜÊÉ≥„ÄÇ‰ΩøÁî®`format()`ÂàôÂèØ‰ª•Á≤æÁ°ÆÊéßÂà∂ËæìÂá∫ÁöÑÂ≠óÁ¨¶‰∏≤ÁöÑÊ†ºÂºèÔºåÊâÄ‰ª•Êé®ËçêÁî®ËøôÁßçÊñπÂºè„ÄÇ

2. ËΩ¨Êç¢‰∏∫Êï∞ÂÄº

Ê≥®ÊÑèÔºåË°®`erc20_ethereum.evt_Transfer`‰∏≠Ôºå`value`Â≠óÊÆµÁöÑÁ±ªÂûãÊòØÂ≠óÁ¨¶‰∏≤„ÄÇÂèØ‰ª•‰ΩøÁî®`cast()`ÂáΩÊï∞Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫double ÊàñËÄÖ decimal(38, 0) Êï∞ÂÄºÁ±ªÂûã„ÄÇ

```sql
select evt_block_time, evt_tx_hash, "from", "to", 
    cast(value as double) as amount,
    cast(value as decimal(38, 0)) as amount2
from erc20_ethereum.evt_Transfer
where evt_block_time >= date('2022-12-18') and evt_block_time < date('2022-12-19')
    and evt_tx_hash in (
        0x2a5ca5ff26e33bec43c7a0609670b7d7db6f7d74a14d163baf6de525a166ab10,
        0xb66447ec3fe29f709c43783621cbe4d878cda4856643d1dd162ce875651430fc
    )
```

### Âº∫Âà∂Á±ªÂûãËΩ¨Êç¢

Â¶ÇÂâçÊâÄËø∞ÔºåDune SQL‰∏çÊîØÊåÅÈöêÂºèÁ±ªÂûãËΩ¨Êç¢ÔºåÂΩìÊàë‰ª¨ÈúÄË¶ÅÂ∞Ü‰∏§Áßç‰∏çÂêåÁ±ªÂûãÁöÑÂÄºËøõË°åÊØîËæÉÊàñËÄÖÊâßË°åÊüê‰∫õÊìç‰ΩúÁöÑÊó∂ÂÄôÔºåÂ∞±ÈúÄË¶ÅÁ°Æ‰øùÂÆÉ‰ª¨ÊòØÁõ∏ÂêåÁöÑÔºàÂÖºÂÆπÁöÑÔºâÊï∞ÊçÆÁ±ªÂûãÔºåÂ¶ÇÊûú‰∏çÊòØÔºåÂàôÈúÄË¶Å‰ΩøÁî®Áõ∏ÂÖ≥ÁöÑÂáΩÊï∞ÊàñËÄÖÊìç‰ΩúÁ¨¶ËøõË°åÊòæÂºèÁöÑÁ±ªÂûãËΩ¨Êç¢„ÄÇÂê¶ÂàôÂèØËÉΩ‰ºöÈÅáÂà∞Á±ªÂûã‰∏çÂåπÈÖçÁõ∏ÂÖ≥ÁöÑÈîôËØØ„ÄÇËøôÈáåÂÜç‰∏æ‰∏Ä‰∏™ÁÆÄÂçï‰æãÂ≠êÔºö

Dune SQLÊú™ÂÅöÁ±ªÂûãËΩ¨Êç¢Êó∂Ôºå‰∏ãÈù¢ÁöÑSQL‰ºöÊä•ÈîôÔºö

```sql
select 1 as val
union all
select '2' as val
```

Dune SQLÊòæÂºèÁ±ªÂûãËΩ¨Êç¢ÔºåÂèØ‰ª•ÊâßË°å

```sql
select 1 as val
union all
select cast('2' as int) as val
```

ÂΩìÊàë‰ª¨ÈÅáÂà∞Á±ª‰ºº"Error: Line 47:1: column 1 in UNION query has incompatible types: integer, varchar(1) at line 47, position 1."ËøôÁßçÈîôËØØÊó∂ÔºåÂ∞±ÈúÄË¶ÅÂ§ÑÁêÜÁõ∏Â∫îÂ≠óÊÆµÁöÑÁ±ªÂûãÂÖºÂÆπÈóÆÈ¢ò„ÄÇ

### ËΩ¨Êç¢‰∏∫doubleÁ±ªÂûãËß£ÂÜ≥Êï∞ÂÄºËåÉÂõ¥Ê∫¢Âá∫ÈîôËØØ

Dune SQL ÊîØÊåÅÊï¥Êï∞Á±ªÂûã `int` Âíå `bigint`Ôºå‰ΩÜÊòØÁî±‰∫éEVMÁ≠âÂå∫ÂùóÈìæ‰∏çÊîØÊåÅÂ∞èÊï∞ÂØºËá¥Êï∞ÂÄºÁªèÂ∏∏ÂæàÂ§ßÔºåÊØîÂ¶ÇÂΩìÊàë‰ª¨ËÆ°ÁÆógas Ë¥πÁöÑÊó∂ÂÄôÔºåÂ∞±ÂèØËÉΩÈÅáÂà∞Êï∞ÂÄºÊ∫¢Âá∫ÁöÑÈîôËØØ„ÄÇ‰∏ãÈù¢ÁöÑSQLÔºå‰∏∫‰∫ÜÊïÖÊÑèÂØºËá¥ÈîôËØØÔºåÊàë‰ª¨Â∞ÜËÆ°ÁÆóÁöÑgas fee‰πò‰ª•1000ÂÄç‰∫ÜÔºö

```sql
select hash, gas_price * gas_used * 1000 as gas_fee
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
order by gas_used desc
limit 10
```

ÊâßË°å‰∏äÈù¢ÁöÑSQLÂ∞Ü‰ºöÈÅáÂà∞ÈîôËØØÔºö
```
Error: Bigint multiplication overflow: 15112250000000000 * 1000.
```

‰∏∫‰∫ÜÈÅøÂÖçÁ±ªÂûãÊ∫¢Âá∫ÈîôËØØÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞ÊòæÂºèËΩ¨Êç¢‰∏∫doubleÁ±ªÂûã„ÄÇ‰∏ãÈù¢ÁöÑSQLÂèØ‰ª•Ê≠£Á°ÆÊâßË°åÔºö

```sql
select hash, cast(gas_price as double) * gas_used * 1000 as gas_fee
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
order by gas_used desc
limit 10
```

### ËΩ¨Êç¢‰∏∫doubleÁ±ªÂûãËß£ÂÜ≥Êï¥Êï∞Áõ∏Èô§‰∏çËÉΩËøîÂõûÂ∞èÊï∞‰ΩçÁöÑÈóÆÈ¢ò

ÂêåÊ†∑ÔºåÂ¶ÇÊûú‰∏§‰∏™Êï∞ÂÄºÊòØbigint Á±ªÂûãÔºå‰∫åËÄÖÁõ∏Èô§ÈªòËÆ§ËøîÂõûÁöÑ‰πüÊòØÊï¥Êï∞Á±ªÂûãÔºåÂ∞èÊï∞ÈÉ®ÂàÜ‰ºöË¢´ËàçÂºÉ„ÄÇÂ¶ÇÊûúÂ∏åÊúõËøîÂõûÂ∞èÊï∞ÈÉ®ÂàÜÔºåÂèØ‰ª•Â∞ÜË¢´Èô§Êï∞ÊòæÂºèËΩ¨Êç¢‰∏∫doubleÁ±ªÂûã„ÄÇ

```sql
select hash, gas_used, gas_limit,
    gas_used / gas_limit as gas_used_percentage
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
limit 10
```

ÊâßË°å‰∏äÈù¢ÁöÑSQLÔºågas_used_percentageÁöÑÂÄºÂ∞Ü‰ºöÊòØ0ÊàñËÄÖ1ÔºåÂ∞èÊï∞ÈÉ®ÂàÜË¢´ËàçÂºÉÂèñÊï¥ÔºåÊòæÁÑ∂Ëøô‰∏çÊòØÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÁªìÊûú„ÄÇÂ∞ÜË¢´Èô§Êï∞gas_usedÊòæÂºèËΩ¨Êç¢‰∏∫doubleÁ±ªÂûãÔºåÂèØ‰ª•ÂæóÂà∞Ê≠£Á°ÆÁªìÊûúÔºö

```sql
select hash, gas_used, gas_limit,
    cast(gas_used as double) / gas_limit as gas_used_percentage
from ethereum.transactions 
where block_time >= date('2022-12-18') and block_time < date('2022-12-19')
limit 10
```

### ‰ªéHexÂçÅÂÖ≠ËøõÂà∂ËΩ¨Êç¢Âà∞ÂçÅËøõÂà∂

Dune SQL ÂÆö‰πâ‰∫Ü‰∏ÄÁªÑÊñ∞ÁöÑÂáΩÊï∞Êù•Â§ÑÁêÜÂ∞ÜvarbinaryÁ±ªÂûãÂ≠óÁ¨¶‰∏≤ËΩ¨Êç¢Âà∞ÂçÅËøõÂà∂Êï∞ÂÄºÁöÑËΩ¨Êç¢ÔºåÂ≠óÁ¨¶‰∏≤ÂøÖÈ°ª‰ª•`0x`ÂâçÁºÄÂºÄÂßã„ÄÇ

```sql
select bytearray_to_uint256('0x00000000000000000000000000000000000000000000005b5354f3463686164c') as amount_raw
```

ËØ¶ÁªÜÂ∏ÆÂä©ÂèØ‰ª•ÂèÇËÄÉÔºö[Byte Array to Numeric Functions](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/varbinary/#byte-array-to-numeric-functions)


### ÁîüÊàêÊï∞ÂÄºÂ∫èÂàóÂíåÊó•ÊúüÂ∫èÂàó

1. Êï∞ÂÄºÂ∫èÂàó

Dune SQLÁîüÊàêÊï∞ÂÄºÂ∫èÂàóÁöÑËØ≠Ê≥ïÔºö

```sql
select num from unnest(sequence(1, 10)) as t(num)
-- select num from unnest(sequence(1, 10, 2)) as t(num) -- step 2
```

2. Êó•ÊúüÂ∫èÂàó

Duen SQL‰ΩøÁî®`unnest()`Êê≠ÈÖç`sequence()`Êù•ÁîüÊàêÊó•ÊúüÂ∫èÂàóÂÄºÂπ∂ËΩ¨Êç¢‰∏∫Â§öË°åËÆ∞ÂΩï„ÄÇ

Dune SQLÁîüÊàêÊó•ÊúüÂ∫èÂàóÁöÑËØ≠Ê≥ïÔºö

```sql
select block_date from unnest(sequence(date('2022-01-01'), date('2022-01-31'))) as s(block_date)
-- select block_date from unnest(sequence(date('2022-01-01'), date('2022-01-31'), interval '7' day)) as s(block_date)
```

### Êï∞ÁªÑÊü•ËØ¢

1. Dune SQL ‰ΩøÁî®`cardinality()`Êü•ËØ¢Êï∞ÁªÑÂ§ßÂ∞è„ÄÇ

Dune SQLËØ≠Ê≥ïÔºö

```sql
select evt_block_time, evt_tx_hash, profileIds
from lens_polygon.LensHub_evt_Followed
where cardinality(profileIds) = 2
limit 10
```

2. Dune SQL Êï∞ÁªÑÁöÑÁ¥¢Âºï‰ªé 1 ÂºÄÂßãËÆ°Êï∞

Dune SQLËÆøÈóÆÊï∞ÁªÑÂÖÉÁ¥†Ôºö

```sql
select evt_block_time, evt_tx_hash, profileIds,
    profileIds[1] as id1, profileIds[2] as id2
from lens_polygon.LensHub_evt_Followed
where cardinality(profileIds) = 2
limit 10
```

3. Â∞ÜÊï∞ÁªÑÂÖÉÁ¥†ÊãÜÂàÜÂà∞Â§öË°åËÆ∞ÂΩï„ÄÇ

Dune SQLÊãÜÂàÜÊï∞ÁªÑÂÖÉÁ¥†Âà∞Â§öË°åÔºö

```sql
select evt_block_time, evt_tx_hash, profileIds,	tbl.profile_id
from lens_polygon.LensHub_evt_Followed
cross join unnest(profileIds) as tbl(profile_id)
where cardinality(profileIds) = 3
limit 20
```

4. ÂêåÊó∂Â∞ÜÂ§ö‰∏™Êï∞ÁªÑÂ≠óÊÆµÊãÜÂàÜÂà∞Â§öË°åËÆ∞ÂΩï„ÄÇ

Ë¶ÅÂêåÊó∂Â∞ÜÂ§ö‰∏™Êï∞ÁªÑÂ≠óÊÆµÊãÜÂàÜÂà∞Â§öË°åÔºàÂâçÊèêÊòØÂÆÉ‰ª¨ÂøÖÈ°ªÂÖ∑ÊúâÁõ∏ÂêåÁöÑÈïøÂ∫¶ÔºâÔºåDune SQL‰∏≠ÂèØ‰ª•Âú®`unnest()`ÂáΩÊï∞‰∏≠ÂåÖÊã¨Â§ö‰∏™Â≠óÊÆµÔºåÂêåÊó∂ËæìÂá∫Â§ö‰∏™ÂØπÂ∫îÂ≠óÊÆµ„ÄÇ

Dune SQLÊãÜÂàÜÂ§ö‰∏™Êï∞ÁªÑÂÖÉÁ¥†Âà∞Â§öË°åÔºö

```sql
SELECT evt_block_time, evt_tx_hash, ids, "values", tbl.id, tbl.val
FROM erc1155_polygon.evt_TransferBatch
cross join unnest(ids, "values") as tbl(id, val)
WHERE evt_tx_hash = 0x19972e0ac41a70752643b9f4cb453e846fd5e0a4f7a3205b8ce1a35dacd3100b
AND evt_block_time >= date('2022-12-14')
```

## ‰ªéSpark SQLËøÅÁßªÊü•ËØ¢Âà∞Dune SQL Á§∫‰æã

Â∞ÜÂ∑≤ÁªèÂ≠òÂú®ÁöÑSpark SQLÂºïÊìéÁºñÂÜôÁöÑqueryËøÅÁßªÂà∞Dune SQLÁöÑËøáÁ®ãÊòØÈùûÂ∏∏‰æøÂà©ÁöÑ„ÄÇ‰Ω†ÂèØ‰ª•Áõ¥Êé•ËøõÂÖ•QueryÁöÑEditÁïåÈù¢Ôºå‰ªéÂ∑¶ËæπÁöÑÊï∞ÊçÆÈõÜ‰∏ãÊãâÂàóË°®‰∏≠ÂàáÊç¢Âà∞‚Äú1. v2 Dune SQL‚ÄùÔºåÂêåÊó∂ÂØπQueryÁöÑÂÜÖÂÆπÂÅöÁõ∏Â∫îÁöÑË∞ÉÊï¥ÔºåÊ∂âÂèäÁöÑ‰∏ªË¶Å‰øÆÊîπÂ∑≤ÁªèÂú®Êú¨ÊñáÂâçÈù¢ÂêÑËäÇÂàÜÂà´ËøõË°å‰∫Ü‰ªãÁªç„ÄÇËøôÈáå‰∏æ‰∏Ä‰∏™ÂÆûÈôÖÁöÑ‰æãÂ≠êÔºö

Spark SQL ÁâàÊú¨Ôºö[https://dune.com/queries/1773896](https://dune.com/queries/1773896)
Dune SQL ÁâàÊú¨Ôºö[https://dune.com/queries/1000162](https://dune.com/queries/1000162)

ËøÅÁßªÊó∂‰øÆÊîπÂÜÖÂÆπÂØπÁÖßÔºö

![image_02.png](img/image_02.png)


## ÂÖ∂‰ªñ

Dune SQL ËøòÊúâ‰∏Ä‰∏™ÊΩúÂú®ÁöÑÈ´òÁ∫ßÂäüËÉΩÔºåÂ∞±ÊòØÂÖÅËÆ∏ÈíàÂØπ‰∏Ä‰∏™Â∑≤‰øùÂ≠òÁöÑÊü•ËØ¢ËøõË°åÊü•ËØ¢ÔºàQuery of QueryÔºâ„ÄÇËøô‰∏™ÂäüËÉΩÊúâÂæàÂ§öÁöÑÊÉ≥Ë±°Á©∫Èó¥ÔºåÂèØÁÆÄÂåñÊü•ËØ¢ÈÄªËæëÔºå‰ºòÂåñÁºìÂ≠ò‰ΩøÁî®Á≠â„ÄÇÊØîÂ¶ÇÔºå‰Ω†ÂèØ‰ª•Â∞Ü‰∏Ä‰∏™Â§çÊùÇÁöÑÊü•ËØ¢ÁöÑÂü∫Á°ÄÈÉ®ÂàÜ‰øùÂ≠ò‰∏∫‰∏Ä‰∏™queryÔºåÁÑ∂ÂêéÂü∫‰∫éÊ≠§queryÊù•Ëøõ‰∏ÄÊ≠•ÁöÑÊ±áÊÄªÁªüËÆ°„ÄÇËøô‰∏™ÂäüËÉΩË≤å‰ººÊúâÊó∂Ëøò‰∏çÂ§™Á®≥ÂÆö„ÄÇ‰∏çËøáÂ§ßÂÆ∂ÂèØ‰ª•ËØïËØï„ÄÇ

```sql
-- original query: https://dune.com/queries/1752041
select * from query_1752041
where user_status = 'Retained'
```

```sql
-- original query: https://dune.com/queries/1752041
select * from query_1752041
where user_status = 'Churned'
```

## ÂèÇËÄÉÈìæÊé•

1. [Syntax and operator differences](https://dune.com/docs/reference/dune-v2/query-engine/#syntax-and-operator-differences)
2. [Trino Functions and operators](https://trino.io/docs/current/functions.html)


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch17/ch16-blockchain-analysis-polygon.md">
# PolygonÂå∫ÂùóÈìæÊ¶ÇÂÜµÂàÜÊûê

Dune Âπ≥Âè∞‰∏ÄÁõ¥Âú®Âø´ÈÄüÂèëÂ±ï‰πã‰∏≠ÔºåÁõÆÂâçÂ∑≤ÁªèÊîØÊåÅ10‰∏™‰∏ªÊµÅÂå∫ÂùóÈìæÔºåÂåÖÊã¨EthereumÔºåBNBÔºåPolygonÔºåFantomÁ≠âLayer 1ÂÖ¨ÈìæÂíåArbitrumÔºåOptimismÁ≠âËá¥Âäõ‰∫éÊâ©Â±ïEthereumÁöÑLayer 2Âå∫ÂùóÈìæ„ÄÇÊú¨ÊïôÁ®ã‰∏≠Êàë‰ª¨‰∏ÄËµ∑Êù•Êé¢ËÆ®Â¶Ç‰ΩïÂÖ•ÊâãÂàÜÊûê‰∏Ä‰∏™Âå∫ÂùóÈìæÁöÑÊ¶ÇÂÜµÔºå‰ª•PolygonÂå∫ÂùóÈìæ‰∏∫ÂàÜÊûêÂØπË±°„ÄÇ

PolygonÁöÑÂè£Âè∑ÊòØ‚ÄúÂ∞Ü‰∏ñÁïåÂ∏¶ÂÖ•‰ª•Â§™Âùä‚ÄùÔºåPolygon Áõ∏‰ø°ÊâÄÊúâ‰∫∫ÈÉΩÂèØ‰ª•‰ΩøÁî® Web3„ÄÇPolygonÊòØ‰∏Ä‰∏™Âéª‰∏≠ÂøÉÂåñÁöÑ‰ª•Â§™ÂùäÊâ©Â±ïÂπ≥Âè∞Ôºå‰ΩøÂºÄÂèë‰∫∫ÂëòËÉΩÂ§ü‰ª•‰Ωé‰∫§ÊòìË¥πÁî®ÊûÑÂª∫ÂèØÊâ©Â±ïÁöÑÁî®Êà∑ÂèãÂ•ΩÂûãDAPPÔºåËÄå‰∏ç‰ºöÁâ∫Áâ≤ÂÆâÂÖ®ÊÄß„ÄÇ

Êú¨ÊïôÁ®ãÁöÑÊï∞ÊçÆÁúãÊùøÔºö[Polygon Chain Overview](https://dune.com/sixdegree/polygon-chain-overview)

## Âå∫ÂùóÈìæÊ¶ÇÂÜµÂàÜÊûêÊ∂âÂèäÁöÑÂÜÖÂÆπ

Êàë‰ª¨ÁöÑÁõÆÊ†áÊòØÂØπÊï¥‰∏™PolygonÂå∫ÂùóÈìæËøõË°åÂÖ®Èù¢ÁöÑÂàÜÊûê‰ª•ÊéåÊè°ÂÖ∂ÂΩìÂâçÂèëÂ±ïÁä∂ÊÄÅ„ÄÇÂàÜÊûêÂÜÖÂÆπÂåÖÊã¨Ôºö
- **Âå∫ÂùóÂàÜÊûê**ÔºöÊÄªÂå∫ÂùóÊï∞„ÄÅÊØèÂàÜÈíüÂá∫ÂùóÊï∞Èáè„ÄÅGasÊ∂àËÄóÊÄªÈáè„ÄÅÂπ≥ÂùáGasÊ∂àËÄó„ÄÅÊØèÊó•ÔºàÊØèÊúàÔºâÂå∫ÂùóÁîüÊàêÊï∞ÈáèË∂ãÂäøÁ≠â
- **‰∫§ÊòìÂíåÁî®Êà∑ÂàÜÊûê**ÔºöÊÄª‰∫§ÊòìÈáè„ÄÅÊÄªÁî®Êà∑Êï∞„ÄÅÊØèÂå∫Âùó‰∫§ÊòìÊï∞Èáè„ÄÅÊàêÂäü/Â§±Ë¥•‰∫§ÊòìÂØπÊØî„ÄÅÊØèÊó•ÔºàÊØèÊúàÔºâ‰∫§ÊòìÊï∞ÈáèË∂ãÂäø„ÄÅÊØèÊó•ÔºàÊØèÊúàÔºâÊ¥ªË∑ÉÁî®Êà∑Êï∞Ë∂ãÂäø„ÄÅÊØèÊó•ÔºàÊØèÊúàÔºâÊØèÊó•Êñ∞Áî®Êà∑Ë∂ãÂäø„ÄÅÊñ∞Áî®Êà∑‰∏éÊ¥ªË∑ÉÁî®Êà∑ÂØπÊØîÁ≠â
- **ÂéüÁîü‰ª£Â∏ÅMATICÂàÜÊûê**ÔºöÊµÅÈÄöÊÄªÈáè„ÄÅÊåÅÊúâËÄÖÂàÜÊûê„ÄÅÂ§¥ÈÉ®ÊåÅÊúâËÄÖ„ÄÅ‰ª∑Ê†ºËµ∞ÂäøÁ≠â
- **Êô∫ËÉΩÂêàÁ∫¶ÂàÜÊûê**ÔºöÂ∑≤ÈÉ®ÁΩ≤Êô∫ËÉΩÂêàÁ∫¶ÊÄªÈáè„ÄÅÊØèÊó•ÔºàÊØèÊúàÔºâÊñ∞ÂêàÁ∫¶ÈÉ®ÁΩ≤ÈáèË∂ãÂäø„ÄÅÊúÄÁÉ≠Èó®Êô∫ËÉΩÂêàÁ∫¶‰∫§ÊòìÈáèÂØπÊØîÂíåÂèëÂ±ïË∂ãÂäøÂàÜÊûê

## Âå∫ÂùóÂíåGasÊ∂àËÄóÂàÜÊûê

### Âå∫ÂùóÊÄªÊï∞ÂíåGasÊ∂àËÄóÊÄªÈáè

‰∏∫‰∫Ü‰∫ÜËß£Êï¥‰∏™PolygonÂå∫ÂùóÈìæÁõÆÂâçÁöÑÊÄªÂå∫ÂùóÊï∞Èáè‰ª•ÂèäÁõ∏Â∫îÁöÑGasÊ∂àËÄóÊ¶ÇÂÜµÔºåÊàë‰ª¨ÂèØ‰ª•ÁºñÂÜô‰∏Ä‰∏™ÁÆÄÂçïÁöÑSQLÔºåÊü•ËØ¢ÊÄªÁöÑÂå∫ÂùóÊï∞Èáè„ÄÅÂàõ‰∏ñÂå∫ÂùóÁöÑÂá∫ÂùóÊó•ÊúüÊó∂Èó¥„ÄÅÂπ≥ÂùáÊØèÂàÜÈíüÁöÑÊñ∞Âå∫ÂùóÊï∞Èáè„ÄÅÊÄªÁöÑGasÊ∂àËÄóÊï∞ÈáèÔºåÂπ≥ÂùáÊØè‰∏™Âå∫ÂùóÁöÑGasÊ∂àËÄóÁ≠â„ÄÇ

```sql
select count(*) / 1e6 as blocks_count,
   min(time) as min_block_time,
   count(*) / ((to_unixtime(Now()) - to_unixtime(min(time))) / 60) as avg_block_per_minute,
   sum(gas_used * coalesce(base_fee_per_gas, 1)) / 1e18 as total_gas_used,
   avg(gas_used * coalesce(base_fee_per_gas, 1)) / 1e18 as average_gas_used
from polygon.blocks
```

SQLËØ¥ÊòéÔºö
1. ‰ΩøÁî®`to_unixtime()`ÂáΩÊï∞ÔºåÂèØ‰ª•Â∞ÜÊó•ÊúüÊó∂Èó¥ËΩ¨Êç¢‰∏∫Unix Timestamp Êï∞ÂÄºÔºåÊàë‰ª¨Â∞±ËÉΩËÆ°ÁÆóÂá∫‰∏§‰∏™Êó•ÊúüÊó∂Èó¥ÂÄº‰∏≠Èó¥ÁöÑÁßíÊï∞ÔºåÁÑ∂ÂêéÁî®ÂÆÉÊù•ËÆ°ÁÆóÂπ≥ÂùáÊØèÂàÜÈíüÁöÑÊñ∞Âå∫ÂùóÊï∞Èáè„ÄÇ‰∏é‰πãÂØπÂ∫îÁöÑÂáΩÊï∞ÊòØ`from_unixtime()`„ÄÇ
2. `gas_used`ÊòØÊ∂àËÄóÁöÑgas Êï∞ÈáèÔºå`base_fee_per_gas`ÊòØÊØèÂçï‰ΩçgasÁöÑÂçï‰ª∑Ôºå‰∫åËÄÖÁõ∏‰πòÂèØ‰ª•ÂæóÂà∞Ê∂àËÄóÁöÑgasË¥πÁî®„ÄÇPolygonÁöÑÂéüÁîü‰ª£Â∏ÅMATICÁöÑÂ∞èÊï∞‰ΩçÊï∞ÊòØ18‰ΩçÔºåÈô§‰ª•`1e18`ÂàôÂæóÂà∞ÊúÄÁªàÁöÑMATICÈáëÈ¢ù„ÄÇ

Â∞ÜÊ≠§Êü•ËØ¢ÁªìÊûúÂàÜÂà´Ê∑ªÂä†‰∏∫CounterÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇÊ∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_01.png](img/image_01.png)

Êü•ËØ¢ÈìæÊé•Ôºö[https://dune.com/queries/1835390](https://dune.com/queries/1835390)

### ÊØèÊó•ÔºàÊØèÊúàÔºâÊñ∞Âå∫ÂùóÁîüÊàêË∂ãÂäøÂíåGasÊ∂àËÄó

Êàë‰ª¨ÂèØ‰ª•ÊåâÊó•ÊúüÊ±áÊÄªÔºåÂàÜÂà´ÁªüËÆ°ÊØèÂ§©ÁîüÊàêÁöÑÂå∫ÂùóÊï∞ÈáèÂíåÂØπÂ∫îÁöÑGasÊ∂àËÄó„ÄÇ‰∏∫‰∫ÜË∑üË∏™ÂèòÂåñË∂ãÂäøÔºåÊàë‰ª¨È¶ñÂÖàÂÆö‰πâ‰∏Ä‰∏™CTEÊù•ÂÆåÊàêÊØèÊó•Êï∞ÊçÆÁªüËÆ°ÔºåÁÑ∂ÂêéÂú®Ê≠§CTEÂü∫Á°Ä‰∏äÔºå‰ΩøÁî®`avg(blocks_count) over (order by rows between 6 preceding and current row)`ËøôÊ†∑ÁöÑÁ™óÂè£ÂáΩÊï∞Êù•ÁªüËÆ°7Â§©ÁöÑÁßªÂä®Âπ≥ÂùáÂÄº„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
with block_daily as (
    select date_trunc('day', time) as block_date,
        count(*) as blocks_count,
        sum(gas_used * coalesce(base_fee_per_gas, 1)) / 1e18 as gas_used
    from polygon.blocks
    group by 1
)

select block_date,
    blocks_count,
    gas_used,
    avg(blocks_count) over (order by block_date rows between 6 preceding and current row) as ma_7_days_blocks_count,
    avg(blocks_count) over (order by block_date rows between 29 preceding and current row) as ma_30_days_blocks_count,
    avg(gas_used) over (order by block_date rows between 6 preceding and current row) as ma_7_days_gas_used
from block_daily
order by block_date
```

‰∏∫Ëøô‰∏™Êü•ËØ¢ÁªìÊûúÊ∑ªÂä†‰∏§‰∏™Bar ChartÁ±ªÂûãÁöÑÂõæË°®ÔºåÂàÜÂà´Â±ïÁ§∫‚ÄúÊØèÊó•Âå∫ÂùóÊï∞Èáè„ÄÅ7Â§©ÁßªÂä®Âπ≥ÂùáÂíå30Â§©ÁßªÂä®Âπ≥ÂùáÂå∫ÂùóÊï∞Èáè‚ÄùÂíå‚ÄúÊØèÊó•GasÊ∂àËÄóÊÄªÈáèÂíå7Â§©ÁßªÂä®Âπ≥Âùá‚ÄùÂÄº„ÄÇÊ∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùø‰∏≠„ÄÇ

Â∞Ü‰ª•‰∏äqueryÂÅö‰∏Ä‰∏™ForkÔºåÁ®ç‰Ωú‰øÆÊîπÔºåÊîπÊàêÊåâÊúàÊ±áÊÄªÁªüËÆ°ÔºåÁßªÂä®Âπ≥ÂùáÂÄº‰πüÊîπÊàêÂèñ12‰∏™ÊúàÁöÑÂÄº„ÄÇËøôÊ†∑Êàë‰ª¨Â∞±ÂæóÂà∞‰∫ÜÊØèÊúàÊñ∞Âå∫ÂùóÁîüÊàêË∂ãÂäøÂõæ„ÄÇ

‰ª•‰∏ä‰∏§‰∏™SQLÁöÑÂèØËßÜÂåñÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÔºåÊñ∞Âå∫ÂùóÁöÑÂá∫ÂùóÊï∞ÈáèÂü∫Êú¨Á®≥ÂÆöÔºå‰ΩÜÊòØGasË¥πÂú®2022Âπ¥‰ª•Êù•ÊúâÂ§ßÂπÖÂ∫¶ÁöÑÊèêÂçáÔºå‰∏≠Èó¥Áü≠ÊöÇÂõûËêΩÔºåÁõÆÂâçÂèàÊé•Ëøë‰∫ÜÂâçÈ´ò„ÄÇ

![image_01.png](img/image_02.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1835421](https://dune.com/queries/1835421)
- [https://dune.com/queries/1835445](https://dune.com/queries/1835445)


## ‰∫§ÊòìÂíåÁî®Êà∑ÂàÜÊûê

### ‰∫§ÊòìÊÄªÈáèÂíåÁî®Êà∑ÊÄªÊï∞

Êàë‰ª¨Â∏åÊúõÁªüËÆ°ÊÄª‰∫§ÊòìÊ¨°Êï∞ÂíåÊÄªÁöÑÁã¨Á´ãÁî®Êà∑Âú∞ÂùÄÊï∞Èáè„ÄÇÂèØ‰ª•ÂÆö‰πâ‰∏Ä‰∏™CTEÔºåÂ∞Ü‰∫§ÊòìÁöÑÂèëËµ∑‰∫∫Âú∞ÂùÄ`from`ÂíåÊé•ÂèóËÄÖÂú∞ÂùÄ`to`‰ΩøÁî®union allÂêàÂπ∂Âà∞‰∏ÄËµ∑ÔºåÂÜçÁªüËÆ°Áã¨Á´ãÂú∞ÂùÄÁöÑÊÄªÊï∞„ÄÇÊ≥®ÊÑèËøôÈáåÊàë‰ª¨Âπ∂Ê≤°ÊúâÊéíÈô§ÂêàÁ∫¶Âú∞ÂùÄ„ÄÇÂ¶ÇÊûúÈúÄË¶ÅÊéíÈô§ÂêàÁ∫¶Âú∞ÂùÄÔºåÂèØ‰ª•Âä†‰∏Ä‰∏™Â≠êÊü•ËØ¢ÔºåÊéíÈô§ÈÇ£‰∫õÂ≠òÂú®‰∫éË°®`polygon.creation_traces`‰∏≠ÁöÑÂú∞ÂùÄ„ÄÇÂõ†‰∏∫Êï∞ÊçÆÈáèÊØîËæÉÂ§ßÂ§ßÔºåÊàë‰ª¨Êç¢ÁÆó‰∏∫Áôæ‰∏áÔºàMÔºâÂçï‰Ωç„ÄÇÊ∑ªÂä†Counter ÂèØËßÜÂåñÂõæË°®Âπ∂ÂàÜÂà´Âä†ÂÖ•Âà∞Êï∞ÊçÆÁúãÊùø„ÄÇ

```sql
with transactions_detail as (
    select block_time,
        hash,
        "from" as address
    from polygon.transactions

    union all

    select block_time,
        hash,
        "to" as address
    from polygon.transactions
)

select count(distinct hash) / 1e6 as transactions_count,
    count(distinct address) / 1e6 as users_count
from transactions_detail
```

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1836022](https://dune.com/queries/1836022)


### ÊØèÊó•ÔºàÊØèÊúàÔºâ‰∫§ÊòìÂíåÊ¥ªË∑ÉÁî®Êà∑ÂàÜÊûê

Á±ª‰ººÁöÑÔºåÂè™ÈúÄË¶ÅÊåâÊó•ÊúüËøõË°åÊ±áÊÄªÔºåÂç≥ÂèØÁîüÊàêÊØèÊó•‰∫§ÊòìÈáèÂíåÊ¥ªË∑ÉÁî®Êà∑Êï∞ÈáèÁöÑÁªüËÆ°Êä•Ë°®„ÄÇÊåâÊúàÂ∫¶Ê±áÊÄªÔºåÂàôÂèØÂæóÂà∞ÊØèÊúàÁöÑÊï∞ÊçÆ„ÄÇ‰∏ãÈù¢ÊòØÊåâÊó•ÁªüËÆ°ÁöÑSQLÔºö

```sql
with transactions_detail as (
    select block_time,
        hash,
        "from" as address
    from polygon.transactions

    union all

    select block_time,
        hash,
        "to" as address
    from polygon.transactions
)

select date_trunc('day', block_time) as block_date,
    count(distinct hash) as transactions_count,
    count(distinct address) as users_count
from transactions_detail
group by 1
order by 1
```

ÂàÜÂà´‰∏∫ÊØèÊó•‰∫§ÊòìÊï∞ÊçÆÂíåÊØèÊúà‰∫§ÊòìÊï∞ÊçÆÊ∑ªÂä†Bar ChartÁ±ªÂûãÁöÑÂõæË°®ÔºåÂêåÊó∂Â±ïÁ§∫‰∫§ÊòìÊï∞ÈáèÂíåÊ¥ªË∑ÉÁî®Êà∑Êï∞„ÄÇÊ¥ªË∑ÉÁî®Êà∑Êï∞ÂèØ‰ª•‰ΩøÁî®Á¨¨‰∫å‰∏™YËΩ¥ÔºåÂõæË°®Á±ªÂûãÂèØ‰ª•ÈÄâÊã©Line ÊàñËÄÖAreaÁ±ªÂûã„ÄÇÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_03.png](img/image_03.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1835817](https://dune.com/queries/1835817)
- [https://dune.com/queries/1836624](https://dune.com/queries/1836624)


### Ê¥ªË∑ÉÁî®Êà∑ÂíåÊñ∞Áî®Êà∑ÁªüËÆ°ÂàÜÊûê

ÂØπ‰∫é‰∏Ä‰∏™ÂÖ¨ÈìæÔºåÂÖ∂Êñ∞Áî®Êà∑Â¢ûÈïøË∂ãÂäøÊòØ‰∏Ä‰∏™ÊØîËæÉÂÖ≥ÈîÆÁöÑÂàÜÊûêÊåáÊ†áÔºåÂèØ‰ª•ÂèçÂ∫îÂå∫ÂùóÈìæÂèóÊ¨¢ËøéÁöÑÁ®ãÂ∫¶„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂÖàÊâæÂá∫ÊØè‰∏Ä‰∏™Âú∞ÂùÄÁöÑÁ¨¨‰∏ÄÁ¨î‰∫§ÊòìÂèëÁîüÁöÑÊó•ÊúüÔºà‰∏ãÊñπÊü•ËØ¢‰∏≠ÁöÑ`users_initial_transaction` CTEÔºâÔºåÁÑ∂ÂêéÂ∞±ÂèØ‰ª•Âú®Ê≠§Âü∫Á°Ä‰∏äÁªüËÆ°Âá∫ÊØè‰∏ÄÂ§©ÁöÑÊñ∞Áî®Êà∑„ÄÇÂ∞ÜÊØèÊó•ÁöÑÊ¥ªË∑ÉÁî®Êà∑Êï∞ÊçÆ‰∏éÊØèÊó•Êñ∞Áî®Êà∑Êï∞ÊçÆÂÖ≥ËÅîÂà∞‰∏ÄËµ∑ÔºåÂç≥ÂèØÁîüÊàêÂØπÁÖßÂõæË°®„ÄÇÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞ÈáèÂáèÂéªÂΩìÂ§©ÁöÑÊñ∞Áî®Êà∑Êï∞ÈáèÔºåÂ∞±ÊòØÂΩìÂ§©Ê¥ªË∑ÉÁöÑÂ≠òÈáèÁî®Êà∑Êï∞Èáè„ÄÇËÄÉËôëÂà∞ÊûÅÁ´ØÊÉÖÂÜµ‰∏ãÔºåÊüê‰∏™Êó•ÊúüÂèØËÉΩÊ≤°Êúâ‰ªª‰ΩïÊñ∞Áî®Êà∑ÔºåÊâÄ‰ª•Êàë‰ª¨‰ΩøÁî®LEFT JOINÔºåÂêåÊó∂‰ΩøÁî®`coalesce()`ÂáΩÊï∞Êù•Â§ÑÁêÜÂèØËÉΩÂá∫Áé∞ÁöÑÁ©∫ÂÄº„ÄÇSQL Â¶Ç‰∏ãÔºö

```sql
with users_details as (
    select block_time,
        "from" as address
    from polygon.transactions
    
    union all
    
    select block_time,
        "to" as address
    from polygon.transactions
),

users_initial_transaction as (
    select address,
        min(date_trunc('day', block_time)) as min_block_date
    from users_details
    group by 1
),

new_users_daily as (
    select min_block_date as block_date,
        count(address) as new_users_count
    from users_initial_transaction
    group by 1
),

active_users_daily as (
    select date_trunc('day', block_time) as block_date,
        count(distinct address) as active_users_count
    from users_details
    group by 1
)

select u.block_date,
    active_users_count,
    coalesce(new_users_count, 0) as new_users_count,
    active_users_count - coalesce(new_users_count, 0) as existing_users_count
from active_users_daily u
left join new_users_daily n on u.block_date = n.block_date
order by u.block_date
```

FORKËøô‰∏™ÊØèÊó•Áî®Êà∑ÁªüËÆ°ÁöÑÊü•ËØ¢ÔºåÂ∞ÜÊó•ÊúüÁ∫¨Â∫¶Ë∞ÉÊï¥‰∏∫ÊåâÊúàÁªüËÆ°ÔºåÂç≥`date_trunc('month', block_time)`ÔºåÂ∞±ÂèØ‰ª•ÁªüËÆ°Âá∫ÊØèÊúàÁöÑÊ¥ªË∑ÉÁî®Êà∑Êï∞ÂíåÊñ∞Áî®Êà∑Êï∞ÊçÆ„ÄÇ

‰∏∫Ëøô‰∏§‰∏™Êü•ËØ¢ÂàÜÂà´Ê∑ªÂä†‰ª•‰∏ãÂèØËßÜÂåñÂõæË°®Ôºö
1. Bar ChartÔºåÊòæÁ§∫ÊØèÊó•ÔºàÊØèÊúàÔºâÁöÑÊ¥ªË∑ÉÁî®Êà∑Êï∞ÈáèÂíåÊñ∞Áî®Êà∑Êï∞Èáè„ÄÇÈâ¥‰∫éÊñ∞Áî®Êà∑ÁöÑÂç†ÊØîËæÉ‰ΩéÔºåËÆæÁΩÆÂÖ∂‰ΩøÁî®Âè≥ËæπÁöÑYËΩ¥ÂùêÊ†áÁ≥ª„ÄÇ
2. Area ChartÔºåÂØπÊØîÊñ∞Áî®Êà∑ÂíåÂ≠òÈáèÁî®Êà∑ÊâÄÂç†ÁöÑÊØî‰æã„ÄÇ

Â∞ÜÁõ∏Â∫îÂèØËßÜÂåñÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÔºö

![image_04.png](img/image_04.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1836744](https://dune.com/queries/1836744)
- [https://dune.com/queries/1836854](https://dune.com/queries/1836854)


## Âå∫ÂùóÈìæÂéüÁîü‰ª£Â∏ÅÂàÜÊûê

### MATIC ‰ª∑Ê†ºËµ∞Âäø

Dune ÁöÑÈ≠îÊ≥ïË°®`prices.usd`Êèê‰æõ‰∫ÜPolygonÈìæTokenÁöÑ‰ª∑Ê†ºÊï∞ÊçÆÔºåÂÖ∂‰∏≠‰πüÂåÖÊã¨ÂÖ∂ÂéüÁîü‰ª£Â∏ÅMATICÁöÑÊï∞ÊçÆ„ÄÇÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•Áõ¥Êé•ÊåâÂ§©ÁªüËÆ°Âπ≥Âùá‰ª∑Ê†º„ÄÇ

```sql
select date_trunc('day', minute) as block_date,
    avg(price) as price
from prices.usd
where blockchain = 'polygon'
    and symbol = 'MATIC'
group by 1
order by 1
```

Âõ†‰∏∫Êü•ËØ¢ÁªìÊûúÊòØÊåâÊó•ÊúüÂçáÂ∫èÊéíÂ∫èÁöÑÔºåÊúÄÂêé‰∏ÄÊù°ËÆ∞ÂΩïÂ∞±ÊòØÊúÄÊñ∞Êó•ÊúüÁöÑÂπ≥Âùá‰ª∑Ê†ºÔºåÂèØ‰ª•ÂΩì‰Ωú‚ÄúÂΩìÂâç‰ª∑Ê†º‚ÄùÊù•‰ΩøÁî®„ÄÇÊàë‰ª¨‰∏∫ÂÖ∂ÁîüÊàê‰∏Ä‰∏™CounterÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®Ôºå‚ÄúRow Number‚ÄùÂÄºËÆæÁΩÆ‰∏∫‚Äú-1‚ÄùÔºåË°®Á§∫ÂèñÊúÄÂêé‰∏ÄË°åÁöÑÂÄº„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨Ê∑ªÂä†‰∏Ä‰∏™Line Á±ªÂûãÁöÑÂõæË°®Êù•Â±ïÁ§∫MATIC TokenÁöÑÊØèÊó•Âùá‰ª∑Ëµ∞Âäø„ÄÇÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùøÂêéÊòæÁ§∫Â¶Ç‰∏ãÔºö

![image_05.png](img/image_05.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1836933](https://dune.com/queries/1836933)

### ÊåÅÊúâÊúÄÂ§öMATIC TokenÁöÑÂú∞ÂùÄ

Êàë‰ª¨ÂèØËÉΩ‰ºöÂÖ≥Ê≥®ÈÇ£‰∫õÊåÅÊúâÊúÄÂ§öÂéüÁîü‰ª£Â∏ÅMATICÁöÑÂú∞ÂùÄÔºåÂõ†‰∏∫‰ªñ‰ª¨ÂæÄÂæÄÂèØ‰ª•ÂΩ±ÂìçToken ÁöÑ‰ª∑Ê†ºËµ∞Âäø„ÄÇ‰∏ãÈù¢ÁöÑÊü•ËØ¢Êü•Âá∫Ââç1000‰∏™Âú∞ÂùÄ„ÄÇMATICÊòØPolygonÈìæÁöÑÂéüÁîü‰ª£Â∏ÅÔºåÂéüÁîü‰ª£Â∏ÅÁöÑËΩ¨Ë¥¶Ë∑üERC20‰ª£Â∏ÅÁöÑËΩ¨Ë¥¶Â§ÑÁêÜÊñπÂºè‰∏ç‰∏ÄÊ†∑ÔºåËØ¶ÁªÜ‰ø°ÊÅØÊòØÂ≠òË¥ÆÂú®`polygon.traces`Ë°®‰∏≠„ÄÇÊ≥®ÊÑèÔºåËøôÈáåÊàë‰ª¨ÂêåÊ†∑Ê≤°ÊúâÂå∫ÂàÜÊòØÂê¶‰∏∫ÂêàÁ∫¶Âú∞ÂùÄ„ÄÇÂõ†‰∏∫PolygonÁöÑ‰∫§ÊòìGasË¥πÂæà‰ΩéÔºåËøôÈáåÂá∫‰∫éÊü•ËØ¢ÊâßË°åÊÄßËÉΩÁöÑËÄÉËôëÔºåÊàë‰ª¨‰πüÊ≤°ÊúâËÆ°ÁÆóGasË¥πÁöÑÊ∂àËÄó„ÄÇ

```sql
with polygon_transfer_raw as (
    select "from" as address, (-1) * cast(value as decimal) as amount
    from polygon.traces
    where call_type = 'call'
        and success = true
        and value > uint256 '0'
    
    union all
    
    select "to" as address, cast(value as decimal) as amount
    from polygon.traces
    where call_type = 'call'
        and success = true
        and value > uint256 '0'
)

select address,
    sum(amount) / 1e18 as amount
from polygon_transfer_raw
group by 1
order by 2 desc
limit 1000
```

‰∏äÈù¢Êü•ËØ¢‰∏≠ÁöÑÊ≥®ÊÑè‰∫ãÈ°πÔºö`polygon.traces`Ë°®‰∏≠ÁöÑ`value`Â≠óÊÆµÊòØ`uint256`Á±ªÂûãÔºåËøôÊòØDune SQLËá™ÂÆö‰πâÁöÑÁ±ªÂûãÔºåÂ¶ÇÊûúÁõ¥Êé•ÂíåÊï∞ÂÄº0ËøõË°åÊØîËæÉÂ∞Ü‰ºöÈÅáÂà∞Á±ªÂûã‰∏çÂåπÈÖç‰∏çËÉΩÊØîËæÉÁöÑÈîôËØØ„ÄÇÊâÄ‰ª•Êàë‰ª¨Áî®`uint256 '0'`ËøôÊ†∑ÁöÑËØ≠Ê≥ïÂ∞ÜÊï∞ÂÄº0ËΩ¨Êç¢‰∏∫Áõ∏ÂêåÁ±ªÂûãÂÜçÊØîËæÉ„ÄÇ‰πüÂèØ‰ª•Áî®`cast(0 as uint256)`ËøôÊ†∑ÁöÑÁ±ªÂûãËΩ¨Êç¢ÂáΩÊï∞„ÄÇÂΩìÁÑ∂‰πüÂèØ‰ª•Êää`value`ÁöÑÂÄºËΩ¨Êç¢‰∏∫double„ÄÅdecimal„ÄÅbigintÁ≠âÂÜçÊØîËæÉÔºå‰ΩÜÊòØÊ≠§Êó∂ÈúÄË¶ÅÊ≥®ÊÑèÂèØËÉΩÂá∫Áé∞Êï∞ÊçÆÊ∫¢Âá∫ÁöÑÈóÆÈ¢ò„ÄÇ

Êàë‰ª¨ËøòÂèØ‰ª•Âú®‰∏äÈù¢Êü•ËØ¢ÁöÑÂü∫Á°Ä‰∏äÔºåÂàÜÊûê‰∏Ä‰∏ãËøôÂ§¥ÈÉ®1000‰∏™Âú∞ÂùÄÊåÅÊúâMATIC Token ÁöÑÂàÜÂ∏ÉÊÉÖÂÜµ„ÄÇFork‰∏äÈù¢ÁöÑÊü•ËØ¢ÔºåÁ®ç‰Ωú‰øÆÊîπ„ÄÇ

```sql
with polygon_transfer_raw as (
    -- same as above
),

polygon_top_holders as (
    select address,
        sum(amount) / 1e18 as amount
    from polygon_transfer_raw
    group by 1
    order by 2 desc
    limit 1000
)

select (case when amount >= 10000000 then '>= 10M'
             when amount >= 1000000 then '>= 1M'
             when amount >= 500000 then '>= 500K'
             when amount >= 100000 then '>= 100K'
             else '< 100K'
        end) as amount_segment,
    count(*) as holders_count
from polygon_top_holders
group by 1
order by 2 desc
```

‰∏∫‰ª•‰∏ä‰∏§‰∏™Êü•ËØ¢ÂàÜÂà´ÁîüÊàê Bar Chart Âíå Pie Chart ÂèØËßÜÂåñÂõæË°®„ÄÇÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_06.png](img/image_06.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1837046](https://dune.com/queries/1837046)
- [https://dune.com/queries/1837144](https://dune.com/queries/1837144)


## Êô∫ËÉΩÂêàÁ∫¶ÂàÜÊûê

### ÂàõÂª∫ÂíåÂ∑≤ÈîÄÊØÅÁöÑÂêàÁ∫¶Êï∞Èáè

```sql
select type,
    count(*) / 1e6 as transactions_count
from polygon.traces
where type in ('create', 'suicide')
    and block_time >= date('2023-01-01') -- ËøôÈáå‰∏∫‰∫ÜÊÄßËÉΩËÄÉËôëÂä†‰∫ÜÊó•ÊúüÊù°‰ª∂
group by 1
order by 1
```

Âõ†‰∏∫Êàë‰ª¨ÈôêÂÆö‰∫Ü`type`ÁöÑÂÄºÔºåÂπ∂‰∏îÊåáÂÆö‰∫ÜÊéíÂ∫èÈ°∫Â∫èÔºåÂèØ‰ª•Á°Æ‰øùËøîÂõû‰∏§Êù°ËÆ∞ÂΩïÂπ∂‰∏îÈ°∫Â∫èÂõ∫ÂÆö„ÄÇÊâÄ‰ª•ÔºåÂèØ‰ª•ÂàÜÂà´‰∏∫Á¨¨‰∏ÄË°åÂíåÁ¨¨‰∫åË°åËÆ∞ÂΩïÂÄºÁîüÊàêCounterÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇ

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1837749](https://dune.com/queries/1837749)

### ÊØèÊó•ÔºàÊØèÊúàÔºâÂêàÁ∫¶ÂàõÂª∫ÂíåÈîÄÊØÅÊï∞Èáè

Êàë‰ª¨ÂèØ‰ª•ÊåâÊó•ÊúüÁªüËÆ°Êñ∞ÂàõÂª∫ÂíåÂ∑≤ÈîÄÊØÅÁöÑÂêàÁ∫¶Êï∞Èáè„ÄÇËÄÉËôëÂà∞Á¥ØËÆ°Êï∞Èáè‰πüÊØîËæÉÊúâÂèÇËÄÉ‰ª∑ÂÄºÔºåÊàë‰ª¨ÂÖàÁî®‰∏Ä‰∏™CTEÁªüËÆ°Âá∫ÊØèÊó•Êï∞ÊçÆÔºåÁÑ∂Âêé‰ΩøÁî®Á™óÂè£ÂáΩÊï∞`sum() over (partition by type order by block_date)`Êù•ÁªüËÆ°ÊåâÊó•ÊúüÁ¥ØËÆ°ÁöÑÊÄªÊï∞„ÄÇÂÖ∂‰∏≠ÁöÑ`partition by type`Áî®‰∫éÊåáÂÆöÊåâÁ±ªÂûãÂàÜÂà´Ê±áÊÄª„ÄÇ

```sql
with polygon_contracts as (
    select date_trunc('day', block_time) as block_date,
        type,
        count(*) as transactions_count
    from polygon.traces
    where type in ('create', 'suicide')
    group by 1, 2
)

select block_date, 
    type,
    transactions_count,
    sum(transactions_count) over (partition by type order by block_date) as accumulate_transactions_count
from polygon_contracts
order by block_date
```

ÂêåÊ†∑ÔºåÊàë‰ª¨ËøòÂèØ‰ª•Â∞ÜÁªüËÆ°ÁöÑÊó•ÊúüÁ∫¨Â∫¶Ë∞ÉÊï¥‰∏∫ÊåâÊúàÁªüËÆ°ÔºåÂæóÂà∞ÊØèÊúàÊñ∞ÂàõÂª∫ÂíåÈîÄÊØÅÁöÑÂêàÁ∫¶Êï∞Èáè„ÄÇ

‰ª•‰∏äÊü•ËØ¢ÂàÜÂà´ÁîüÊàêBar ChartÂíåArea ChartÁ±ªÂûãÁöÑÂõæË°®ÔºåÊ∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_07.png](img/image_07.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1837749](https://dune.com/queries/1837749)
- [https://dune.com/queries/1837150](https://dune.com/queries/1837150)
- [https://dune.com/queries/1837781](https://dune.com/queries/1837781)


### ‰∫§ÊòìÊ¨°Êï∞ÊúÄÂ§öÁöÑÊô∫ËÉΩÂêàÁ∫¶ÁªüËÆ°

ÊØè‰∏™ÂÖ¨ÈìæÁöÑÂ§¥ÈÉ®Êô∫ËÉΩÂêàÁ∫¶ÂæÄÂæÄÁîüÊàê‰∫ÜÂ§ßÈÉ®ÂàÜÁöÑ‰∫§ÊòìÊï∞Èáè„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂàÜÊûê‰∫§ÊòìÊ¨°Êï∞ÊúÄÂ§öÁöÑÂâç100‰∏™Êô∫ËÉΩÂêàÁ∫¶„ÄÇËøôÈáåÊàë‰ª¨Âú®ËæìÂá∫ÁªìÊûúÊó∂ÔºåÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™ÈìæÊé•Â≠óÊÆµÔºåÊñπ‰æøÁÇπÂáªÈìæÊé•Áõ¥Êé•Êü•ËØ¢ËØ•Êô∫ËÉΩÂêàÁ∫¶ÁöÑ‰∫§ÊòìÂàóË°®„ÄÇ

```sql
with contract_summary as (
    select "to" as contract_address,
        count(*) as transaction_count
    from polygon.transactions
    where success = true
    group by 1
    order by 2 desc
    limit 100
)

select contract_address,
    '<a href=https://polygonscan.com/address/' || cast(contract_address as varchar) || ' target=_blank>PolygonScan</a>' as link,
    transaction_count
from contract_summary
order by transaction_count desc
```

‰∏∫Ëøô‰∏™Êü•ËØ¢ÂàÜÂà´ÁîüÊàê‰∏Ä‰∏™Bar ChartÁ±ªÂûãÁöÑÂõæË°®ÂíåTableÁ±ªÂûãÁöÑÂõæË°®„ÄÇÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_08.png](img/image_08.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1838001](https://dune.com/queries/1838001)


### ÊúÄÊ¥ªË∑ÉÊô∫ËÉΩÂêàÁ∫¶ÊØèÊó•‰∫§ÊòìÊï∞ÈáèÂàÜÊûê

Êàë‰ª¨ÂèØ‰ª•ÈíàÂØπÁ¥ØËÆ°‰∫§ÊòìÊï∞ÈáèÊúÄÂ§öÁöÑÂ§¥ÈÉ®Êô∫ËÉΩÂêàÁ∫¶ÔºåÂØπÁÖßÂàÜÊûêÂÆÉ‰ª¨ÁöÑÊØèÊó•‰∫§ÊòìÊï∞ÈáèÔºå‰ª•Ê≠§ÂèØ‰ª•ÁúãÂá∫‰∏çÂêåÈò∂ÊÆµÁöÑÁÉ≠Èó®Êô∫ËÉΩÂêàÁ∫¶Ôºå‰ª•ÂèäÂÆÉ‰ª¨ÂêÑËá™ÁöÑÁîüÂëΩÂë®ÊúüÁöÑÈïøÁü≠Á≠â‰ø°ÊÅØ„ÄÇËÄÉËôëÂà∞Êï∞ÊçÆÈáèÊØîËæÉÂ§ßÔºåËøôÈáåÊàë‰ª¨Âè™ÂØπÂâç20‰∏™ÂêàÁ∫¶ËøõË°åÂàÜÊûê„ÄÇ

```sql
with top_contracts as (
    select "to" as contract_address,
        count(*) as transaction_count
    from polygon.transactions
    where success = true
    group by 1
    order by 2 desc
    limit 20
)

select date_trunc('day', block_time) as block_date, 
    contract_address,
    count(*) as transaction_count
from polygon.transactions t
inner join top_contracts c on t."to" = c.contract_address
group by 1, 2
order by 1, 2
```

Êàë‰ª¨ÂÖàÊü•ËØ¢ÂæóÂà∞ÂéÜÂè≤‰∫§ÊòìÈáèÊúÄÂ§öÁöÑÂâç20‰∏™Êô∫ËÉΩÂêàÁ∫¶„ÄÇÁÑ∂ÂêéÈíàÂØπËøô‰∫õÊô∫ËÉΩÂêàÁ∫¶ÁªüËÆ°ÂÆÉ‰ª¨ÊØèÊó•ÁöÑ‰∫§ÊòìÊï∞Èáè„ÄÇ‰∏∫Êü•ËØ¢ÁªìÊûúÊ∑ªÂä†3‰∏™‰∏çÂêåÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®Ôºö
1. Bar ChartÔºåÂ∞Ü‰∏çÂêåÊô∫ËÉΩÂêàÁ∫¶ÁöÑÊØèÊó•‰∫§ÊòìÊï∞ÈáèÂè†Âä†ÊòæÁ§∫„ÄÇ
2. Area ChartÔºåÂ∞Ü‰∏çÂêåÊô∫ËÉΩÂêàÁ∫¶ÁöÑÊØèÊó•‰∫§ÊòìÊï∞ÈáèÂè†Âä†ÊòæÁ§∫ÔºåÂêåÊó∂ËÆæÁΩÆ‚ÄúNormalize to percentage‚ÄùÂ∞ÜÂõæË°®Ë∞ÉÊï¥‰∏∫ÊåâÁôæÂàÜÊØîÊòæÁ§∫„ÄÇ
3. Pie ChartÔºåÂØπÊØîËøô20‰∏™Â§¥ÈÉ®Êô∫ËÉΩÂêàÁ∫¶ÁöÑÁ¥ØËÆ°‰∫§ÊòìÊï∞ÈáèÂç†ÊØî„ÄÇ

Áõ∏ÂÖ≥ÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![image_09.png](img/image_09.png)

Êü•ËØ¢ÈìæÊé•‰∏∫Ôºö
- [https://dune.com/queries/1838060](https://dune.com/queries/1838060)

### ÊúÄËøë30Â§©ÊúÄÊ¥ªË∑ÉÊô∫ËÉΩÂêàÁ∫¶

Èô§‰∫ÜÈíàÂØπÊâÄÊúâÂéÜÂè≤‰∫§ÊòìÊï∞ÊçÆËøõË°åÂàÜÊûê‰πãÂ§ñÔºåÊàë‰ª¨‰πüÂèØ‰ª•ÂØπËøëÊúüÊúÄÊ¥ªË∑ÉÁöÑÊô∫ËÉΩÂêàÁ∫¶ËøõË°åÁÆÄÂçïÂàÜÊûê„ÄÇÊØîÂ¶Ç30Â§©ÂÜÖÊúÄÊ¥ªË∑ÉÁöÑTop 50Êô∫ËÉΩÂêàÁ∫¶„ÄÇ

```
select "to" as contract_address,
    '<a href=https://polygonscan.com/address/' || cast("to" as varchar) || ' target=_blank>PolygonScan</a>' as link,
    count(*) as transaction_count
from polygon.transactions
where block_time >= now() - interval '30' day
group by 1, 2
order by 3 desc
limit 50
```

Âõ†‰∏∫ÊòØËøëÊúüÊ¥ªË∑ÉÈ°πÁõÆÔºåÊúâÂèØËÉΩÊòØÊñ∞ËøëÂàöÈÉ®ÁΩ≤‰∏äÁ∫øÔºåÊâÄ‰ª•Êàë‰ª¨‰∏∫Ëøô‰∏™Êü•ËØ¢ËæìÂá∫Ë∂ÖÈìæÊé•ÔºåÊ∑ªÂä†‰∏Ä‰∏™TableÁ±ªÂûãÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_10.png](img/image_10.png)

Êü•ËØ¢ÈìæÊé•‰∏∫Ôºö
- [https://dune.com/queries/1838077](https://dune.com/queries/1838077)


## ÊÄªÁªì

‰ª•‰∏äÊàë‰ª¨ÂàÜÂà´‰ªéÂå∫Âùó„ÄÅÁáÉÊñôÊ∂àËÄó„ÄÅ‰∫§Êòì„ÄÅÁî®Êà∑„ÄÅÂéüÁîü‰ª£Â∏Å„ÄÅÊô∫ËÉΩÂêàÁ∫¶Âá†‰∏™ÊñπÈù¢ÈíàÂØπPolygonÂå∫ÂùóÈìæÂÅö‰∫Ü‰∏Ä‰∏™ÂàùÊ≠•ÁöÑÂàÜÊûê„ÄÇÈÄöËøáËøô‰∏™Êï∞ÊçÆÁúãÊùøÔºåÊàë‰ª¨ÂèØ‰ª•ÂØπPolygonÂå∫ÂùóÈìæÊúâ‰∏Ä‰∏™Â§ßËá¥ÁöÑ‰∫ÜËß£„ÄÇÁâπÂà´Âú∞ÔºåÈÄöËøáÂØπÂ§¥ÈÉ®Êô∫ËÉΩÂêàÁ∫¶ÁöÑÂàÜÊûêÔºåÊàë‰ª¨ÂèØ‰ª•ÊâæÂà∞ÈÇ£‰∫õÁÉ≠Èó®ÁöÑÈ°πÁõÆ„ÄÇÁÑ∂ÂêéÂ∞±ÂèØ‰ª•ÈÄâÊã©ÊÑüÂÖ¥Ë∂£ÁöÑÁÉ≠Èó®È°πÁõÆÔºåËøõË°åÊõ¥ÊúâÈíàÂØπÊÄßÁöÑÈ°πÁõÆÂàÜÊûê„ÄÇ

ËøÑ‰ªä‰∏∫Ê≠¢ÔºåSixdegreeLabÂ∑≤ÁªèÂÆåÊàê‰∫ÜÂ§ö‰∏™Âå∫ÂùóÈìæÁöÑÊ¶ÇËßàÂàÜÊûêÔºå‰Ω†ÂèØ‰ª•Âú®ËøôÈáåÊâæÂà∞Ôºö
- [Blockchain Overview Series](https://dune.com/sixdegree/blockchain-overview-series)


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch18/ch17-mev-analysis-uniswap.md">
# MEVÊï∞ÊçÆÂàÜÊûê‚Äî‚Äî‰ª•Uniswap‰∏∫‰æã

## ‰ªÄ‰πàÊòØMEVÔºü

MEVÔºàminer-extractable valueÔºâÁöÑÊ¶ÇÂøµÊúÄÊó©Âá∫Áé∞Âú®2019Âπ¥ÁöÑFlashboy 2.0‰∏ÄÊñá‰∏≠ÔºåÊåáÁöÑÊòØÁüøÂ∑•ÈÄöËøáÂåÖÂê´„ÄÅÈáçÊñ∞ÊéíÂ∫è„ÄÅÊèíÂÖ•ÊàñÂøΩÁï•‰∫§ÊòìÂèØ‰ª•Ëé∑ÂæóÁöÑÈ¢ùÂ§ñÂà©Ê∂¶„ÄÇÈöèÁùÄËøë‰∏§Âπ¥Âå∫ÂùóÈìæÁöÑÂèëÂ±ïÂíåÈìæ‰∏äÁ†îÁ©∂Ê¥ªÂä®ÁöÑÊé®ËøõÔºåMEVÁé∞Âú®Â∑≤ÁªèÂª∂‰º∏Âà∞ÊúÄÂ§ßÂèØÊèêÂèñ‰ª∑ÂÄºÔºàmaximal extractable valueÔºâ„ÄÇ

Áõ¥ËßÇÂú∞ÈÄöËøáÊï∞ÊçÆÊù•ÁúãÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫ÔºåÂú®ËøáÂéª30Â§©‰∏≠ÔºåÈÄöËøáÂ•óÂà©Ëé∑ÂæóÁöÑMEVÂà©Ê∂¶Ëææ$1.44 MÔºåËøôËøòÊòØÂú®ÁÜäÂ∏Ç‰∫§ÊòìÈáèËæÉ‰∏∫‰ΩéËø∑ÁöÑÈò∂ÊÆµ„ÄÇ‰πãÂâçFTXÊö¥Èõ∑‰∫ã‰ª∂Â∏¶Êù•ÁöÑÂ∏ÇÂú∫ÈúáËç°ÔºåÊ≠£Â•ΩÊòØ[MEVÁöÑ‚ÄúÁâõÂ∏Ç‚Äù](https://twitter.com/lviswang/status/1591664260987641856?s=20&t=YPM1Qwt_-K8IJGHxxu2gnA)ÔºåÂâßÁÉàÁöÑ‰ª∑Ê†ºÊ≥¢Âä®Â∏¶Êù•Â•óÂà©„ÄÅÊ∏ÖÁÆóÊú∫‰ºöÁöÑÁàÜÂèëÔºå‰ªÖ7Â§©Â∞±‰∫ßÁîüÊúâ$5 MÁöÑÂ•óÂà©Êî∂Áõä„ÄÇÊâÄ‰ª•MEVÂÖ∂ÂÆû‰∏ÄÁõ¥Â∏∏‰º¥Â∏ÇÂú∫ÔºåÊôÆÈÄöÁî®Êà∑ÂèØËÉΩ‰∏çÊÉ≥Âç¥Êó†Ê≥ïÈÅøÂÖçÂú∞Ë¢´Âä®Âç∑ÂÖ•ËøôÈªëÊöóÊ£ÆÊûóÁöÑ‰∏ÄËßíÔºåËá≥Â∞ëÊàë‰ª¨Â∫îËØ•Â§ßËá¥‰∫ÜËß£MEVÁ©∂Á´üÊòØÊÄé‰πàÂõû‰∫ã„ÄÇ

![ep_mev_ov.jpg](img/ep_mev_ov.jpg)

‰ª•Â§™ÂùäÊòØÈìæ‰∏äÊ¥ªÂä®ÊúÄ‰∏∞ÂØå„ÄÅÊúÄÊ¥ªË∑ÉÁöÑ‰∏ªÁΩëÔºåËÆ®ËÆ∫‰ª•Â§™Âùä‰∏äMEVËØûÁîüÁöÑÂá†‰∏™ÂâçÊèêÔºö

1. ‰ª•Â§™ÂùäÁöÑGasÊú∫Âà∂Êú¨Ë¥®‰∏äÊòØÊãçÂçñÊú∫Âà∂Ôºå‰ª∑È´òËÄÖÂæóÔºå‰∏îËÆæËÆ°‰∫§ÊòìÊòØ‰∏≤Ë°åÁöÑ„ÄÇÂç≥Ë∞ÅÂá∫ÁöÑgasÈ´òÔºåÁüøÂ∑•/È™åËØÅËÄÖ‰ºöÂÖàÊâìÂåÖÂì™‰∏™‰∫§ÊòìËøõÂùóÔºå‰ª•Ê≠§ËææÂà∞Êî∂ÁõäÊúÄÂ§ßÂåñ„ÄÇËøôÊòØ‰ª•Â§™Âùä‰∏∫‰∫∫ËØüÁóÖÁöÑgasÊòÇË¥µ„ÄÅÊã•Â†µÁöÑÂéüÂõ†‰πã‰∏ÄÔºå‰πü‰∏∫MEVÁöÑÂá∫Áé∞Â∏¶Êù•ÂèØËÉΩÔºö‰∏ÄÊó¶ÂèëÁé∞ÊúâÂà©ÂèØÂõæÁöÑ‰∫§ÊòìÔºåÂèØ‰ª•ÈÄöËøáË¥øËµÇÁüøÂ∑•ÔºàÊèêÈ´ògasÔºâÁöÑÊñπÊ≥ïÁéáÂÖàÊâßË°å„ÄÇ

2. Âå∫ÂùóÈìæÂÜÖÂ≠òÊ±†MempoolÁöÑËÆæËÆ°„ÄÇÊâÄÊúâÂèëÈÄÅÂá∫ÂéªÁöÑ‰∫§ÊòìÈÉΩÈúÄË¶ÅÊöÇÊó∂ËøõÂÖ•ÂÜÖÂ≠òÊ±†ÔºåËÄå‰∏çÊòØÁî±ÁüøÂ∑•Áõ¥Êé•ÊâìÂåÖ„ÄÇÂÜÖÂ≠òÊ±†‰∏≠ÂÖÖÊª°‰∫ÜÂæÖÂ§ÑÁêÜÁöÑ‰∫§ÊòìÔºåÂπ∂‰∏îÊòØÂÖ¨ÂºÄÁöÑÔºåËøôÊÑèÂë≥ÁùÄ‰ªª‰Ωï‰∫∫ÈÉΩÂèØ‰ª•ÁõëÊéßÂÜÖÂ≠òÊ±†‰∏≠ÁöÑÊØèÁ¨î‰∫§ÊòìÂíåË∞ÉÁî®ÁöÑÊØè‰∏™ÂáΩÊï∞ÔºåËøô‰∏∫ÊîªÂáªËÄÖÊèê‰æõ‰∫ÜÁõëËßÜ‰∫§ÊòìÁöÑÊù°‰ª∂„ÄÇ

![mempool.jpg](img/mempool.jpg)

3. Ê†πÊçÆ [Etherscan](https://etherscan.io/blocks) Êï∞ÊçÆÔºåÂú®POSÂêàÂπ∂‰πãÂêéÂá∫Âá∫ÂùóÊó∂Èó¥Âõ∫ÂÆö‰∏∫12 sÔºåÂú®POSÂêàÂπ∂‰πãÂâçÊòØ13.5 sÂ∑¶Âè≥„ÄÇËæÉÈïøÁöÑÂá∫ÂùóÊó∂Èó¥Âá∫‰∫éËäÇÁÇπÂêåÊ≠•ÁöÑÂÆâÂÖ®ÊÄßËÄÉËôëÔºå‰πü‰∏∫ÊîªÂáªËÄÖÊèê‰æõ‰∫ÜÊâßË°åÊó∂Èó¥„ÄÇ

ÊÄªÁªìÊù•ËØ¥Ôºå**MEVÊîªÂáªËÄÖÂèØ‰ª•Âú®ÂÖ¨ÂºÄÁöÑmempool‰∏≠ÁúãÂà∞ÊâÄÊúâÂæÖÊâßË°åÁöÑ‰∫§ÊòìÔºåÊúâÂÖÖË∂≥ÁöÑÊó∂Èó¥ÂéªËøõË°åÈ¢ÑÊºîÔºåÁúãËøôÁ¨î‰∫§ÊòìÊòØÂê¶ËÉΩÂ∏¶Êù•Âà©Ê∂¶ÔºåÂ¶ÇÊûúÁ°ÆÂÆöÊúâÂà©ÂèØÂõæÔºåÂèØ‰ª•ÈÄöËøáÊä¨È´ògasË¥πÁî®Êù•ËææÂà∞‰ºòÂÖàÊâßË°åÁöÑÊïàÊûúÔºå‰ªéËÄåÁ™ÉÂèñÂà´‰∫∫ÁöÑÂà©Áõä„ÄÇ**

![mev_process.jpg](img/mev_process.jpg)

ËøôÈáåÊúâ‰∏™ÊÑèÊÄùÁöÑÈóÆÈ¢òÔºåSolanaÊó¢Ê≤°ÊúâmempoolÔºåÂá∫ÂùóÈÄüÂ∫¶ÂèàÂø´Ôºå‰∏çÂ∫îËØ•Ê≤°ÊúâMEVÂêóÔºüÂÆûÈôÖ‰∏äSolana‰πüÊúâMEVÔºåÂú®Ê≠§ÂÖà‰∏çÂÅöËÆ®ËÆ∫Ôºå‰ªÖËÆ®ËÆ∫‰ª•Â§™Âùä‰∏äÁöÑMEV„ÄÇ

ÈÇ£‰πàË∞ÅÊòØMEVÁöÑÂèóÁõäËÄÖÂë¢Ôºü

È¶ñÂÖàÁüøÂ∑•/È™åËØÅËÄÖË∫∫Ëµ¢Ôºå‰π∞ÂÆ∂‰πãÈó¥ÁöÑÁ´û‰∫â‰ΩøÂçñÂÆ∂ÁöÑÊî∂ÂÖ•ÊúÄÂ§ßÂåñÔºåÂå∫ÂùóÁ©∫Èó¥Â∏ÇÂú∫‰πü‰∏ç‰æãÂ§ñÔºõÂÖ∂Ê¨°MEVÊîªÂáªÁöÑÂèëËµ∑ËÄÖÂèóÁõäÔºåËøôÂæàÊòæÁÑ∂„ÄÇÈÇ£‰πàÁüøÂ∑•/È™åËØÅËÄÖÂèØ‰ª•Ëá™Â∑±‰∏ãÂú∫ÂÅöMEVÂêóÔºüÁ≠îÊ°àÂΩìÁÑ∂ÊòØÂèØ‰ª•ÁöÑ„ÄÇÊúÄ‰ºòÁöÑÊÉÖÂÜµÊòØÁüøÂ∑•/È™åËØÅËÄÖÂá∫ÂùóÊó∂ÊÅ∞Â•ΩËá™Â∑±ÂèàÂèëËµ∑‰∫ÜMEV‰∫§Êòì„ÄÇÁÑ∂ËÄåÂÆûÈôÖ‰∏äËøôÁßçÂá†ÁéáÂÆûÂú®Â§ü‰ΩéÔºåMEVÁöÑÂá∫Áé∞‰πüÊúâ‰∫õÁúãËøêÊ∞îÔºåËøêÊ∞îÂ•ΩÁöÑÈ™åËØÅËÄÖÂá∫ÁöÑÂùóÂèØËÉΩÊ≠£Â•ΩÂåÖÂê´Â§ßÈáèMEVÔºåËøêÊ∞îÂ∑Æ‰∫õÁöÑÂèØËÉΩÂÆåÂÖ®Ê≤°Êúâ„ÄÇÊ†πÊçÆ[Post-Merge MEV: Modelling Validator Returns](https://pintail.xyz/posts/post-merge-mev/)ÊñáÁ´†‰∏≠ËÆ°ÁÆóÁªìÊûúÔºåÊúâ‰∫õÈ™åËØÅËÄÖÂú®‰∏ÄÂπ¥‰∏≠Âá†‰πéÊ≤°ÊúâÊî∂Âà∞ MEVÔºåËÄåÊúâ‰∫õÈ™åËØÅËÄÖÁöÑÂπ¥ÂõûÊä•ÁéáÂàôËøúËøúË∂ÖËøá 100%„ÄÇÂπ≥ÂùáÊù•ËØ¥ÔºåMEV‰ºö‰∏∫È™åËØÅËÄÖÂπ≥ÂùáÂ§öÂ∏¶Êù•1.5% - 3%ÁöÑÂπ¥ÂõûÊä•„ÄÇÁÆó‰∏äÂå∫ÂùóÂ•ñÂä±ÔºåÈ™åËØÅËÄÖ‰∏≠‰ΩçÊï∞Âπ¥ÂõûÊä•ÁéáÂ§ßËá¥Âú®6.1%Âà∞7.6%ÔºàÂü∫‰∫é MEV ‚ÄúÊ∑°Â≠£‚ÄùÂíå‚ÄúÊó∫Â≠£‚ÄùÁöÑÊï∞ÊçÆÈõÜÔºâ„ÄÇ


## MEVÁöÑÊèêÂèñËøáÁ®ã
Âú® MEV ÊèêÂèñËøáÁ®ã‰∏≠ÔºåÁßëÂ≠¶ÂÆ∂‰ºöËÆ°ÁÆóÂà©Ê∂¶ÂíåÂ•óÂà©Ë∑ØÂæÑÔºåÂπ∂ÊääÊâßË°åÈÄªËæëÈÉΩÂÜôÊàêÂêàÁ∫¶‰ª£Á†ÅÔºå‰ΩøÁî®Êú∫Âô®‰∫∫Êù•ÂÆåÊàêË∞ÉÁî®„ÄÇËøôÊó∂Â¶ÇÊûúÊ≤°Êúâ‰∫∫ÂèëÁé∞Âπ∂ÊâßË°åÂêå‰∏ÄÂ•óÂà©Ë∑ØÂæÑÔºåÈÇ£‰πàÂè™ÈúÄË¶ÅÂêëÁüøÂ∑•Áº¥Á∫≥Ê≠£Â∏∏ÁöÑ GAS Ë¥πÁî®ÔºõÂ¶ÇÊûúÊúâÂà´‰∫∫ÂèëÁé∞Âπ∂ÊâßË°åÂêå‰∏ÄÂ•óÂà©Ë∑ØÂæÑÔºåÈÇ£‰πàÂ∞±ÂøÖÈ°ªÊîØ‰ªòÊØîÂà´‰∫∫Êõ¥È´òÁöÑ GAS ‰ª•Á°Æ‰øùËá™Â∑±ÁöÑ‰∫§Êòì‰ºòÂÖàÂÆåÊàê„ÄÇ

Áî±‰∫éÂå∫ÂùóÈìæ‰∏äÁöÑ‰∫§ÊòìÈÉΩÊòØÂÖ¨ÂºÄÁöÑÔºåÂà©Ê∂¶Á®çÂ§ßÁöÑÂ•óÂà©Ë∑ØÂæÑÈÉΩËÉΩË¢´Á≠õÈÄâÂπ∂Á†îÁ©∂Âá∫Êù•Ôºå‰ªéËÄåÂØºËá¥ÊøÄÁÉàÁöÑ GAS Á´û‰∫â„ÄÇËÄåÂå∫ÂùóÈìæ‰∏äÁöÑ GAS Á´û‰ª∑ÈÉΩÊòØÂÖ¨ÂºÄÁöÑÔºåÂõ†Ê≠§ÁªôÁüøÂ∑•ÁöÑ GAS ÂæÄÂæÄËÉΩÂú®‰∏Ä‰∏™ÂùóÁöÑÊó∂Èó¥ÂÜÖÁøª‰∏äÂ•ΩÂá†ÂÄç„ÄÇÊúÄÁªàÂ¶ÇÊûúÊ≤°Êúâ‰∫∫ÈÄÄÂá∫ÔºåÂæÄÂæÄÈúÄË¶ÅÂ∞ÜÂÖ®ÈÉ®ÁöÑÂà©Ê∂¶ÈÉΩÁªôÁüøÂ∑•ÔºåÁõ¥Âà∞Êúâ‰∏ÄÊñπÁªìÊùüÂÜÖËÄó„ÄÇ

![mev_supchain.jpg](img/mev_supchain.jpg)


## MEVÁöÑÂàÜÁ±ª
MEV Êú∫Âô®‰∫∫Ê†πÊçÆÂÆÉ‰ª¨ÂàõÂª∫ËÄÖÁöÑÊó®ÊÑèËøõË°åÁùÄÈìæ‰∏äÊ¥ªÂä®, Â∞Ü‰∫§ÊòìÂåÖË£ÖÂ•ΩÂêéÈÄÅÁªô‰∏çÁü•ÊÉÖÁöÑÁüøÂ∑•Âá∫Âùó„ÄÇ‰ªéÂ•ΩÁöÑËßíÂ∫¶Êù•Áúã, ÂÆÉ‰ª¨ÊòØ‰øùËØÅÂ∏ÇÂú∫Á®≥ÂÆöÂíå DApp Ê¥ªË∑ÉÂ∫¶ÁöÑÈáçË¶ÅËßíËâ≤; ‰ªé‰∏çÂ•ΩÁöÑËßíÂ∫¶Êù•Áúã, ÂÆÉ‰ª¨‰ª•Ëá™Â∑±Â§©ÁîüÁöÑ‰ºòÂäø ( ÂèØ‰ª•ÁõëËßÜÊï¥‰∏™Mempool), ÂØπÊôÆÈÄöÁî®Êà∑ËøõË°åÁùÄ‰∏çÂπ≥Á≠âÁöÑÂâ•Ââä„ÄÇ

ËÄÉËôëÊú¨Êñá‰∏ªË¶Å‰ªãÁªç‰ΩøÁî®DuneËøõË°åMEVÂàÜÊûêÔºåËøôÈáåÂü∫‰∫éDuneÁöÑÁõ∏ÂÖ≥ÂÜÖÂÆπÂØπMEVËøõË°åÁÆÄÂçïÁöÑÂàÜÁ±ªÔºö

### 1. Â•óÂà©
Â•óÂà©ÊòØ MEV ÊúÄÂ∏∏ËßÅÁöÑÂΩ¢Âºè„ÄÇÂΩìÂêå‰∏ÄËµÑ‰∫ßÂú®‰∏çÂêå‰∫§ÊòìÊâÄÁöÑ‰ª∑Ê†º‰∏çÂêåÊó∂ÔºåÂ∞±Â≠òÂú®Â•óÂà©Êú∫‰ºö„ÄÇ‰∏éÂú®‰º†ÁªüÈáëËûçÂ∏ÇÂú∫ÂØªÊâæÂ•óÂà©Êú∫‰ºöÁöÑÈ´òÈ¢ë‰∫§ÊòìÂëòÁ±ª‰ººÔºåÊêúÂØªËÄÖÔºàSearcherÔºåÂç≥ÊåñÊéòMEVÁöÑ‰∫∫ÔºâÈÉ®ÁΩ≤Êú∫Âô®‰∫∫Êù•ÂèëÁé∞Âéª‰∏≠ÂøÉÂåñ‰∫§ÊòìÊâÄ(DEX) ‰∏äÁöÑ‰ªª‰ΩïÊΩúÂú®Â•óÂà©Êú∫‰ºö„ÄÇAMMÊú∫Âà∂Â§©ÁÑ∂Âú∞Ê¨¢ËøéÂ•óÂà©‰∫§ÊòìÔºåÂõ†‰∏∫Êàê‰∫§‰ª∑‰∏çÂÜçÁî±ÊåÇÂçïÊñπÂÜ≥ÂÆöÔºåÁî±Ê±†ÂÜÖ‰∫§ÊòìÂÜ≥ÂÆöÔºåÈÇ£‰πàÂ•óÂà©Ë°å‰∏∫Â∞±Á≠âÂêå‰∫éÊâãÂä®Â∞Ü‰∏Ä‰∏™DEXÁöÑ‰∫§ÊòìÂØπ‰∏éÂÖ∂‰ªñDEX/CEX‰∫§ÊòìÂØπ‰ª∑Ê†ºËøõË°åÂêåÊ≠•ÔºåÁ°Æ‰øùÂ∏ÇÂú∫ÂÖ¨Âπ≥Á®≥ÂÆöÔºåÂêåÊó∂‰∏∫ÂçèËÆÆË¥°ÁåÆ‰∫§ÊòìÈáè„ÄÅÊ¥ªË∑ÉÂ∫¶ÔºåÊâÄ‰ª•ËøôÁ±ªMEVË¢´ËÆ§‰∏∫ÊòØ‚ÄúÂ•Ω‚ÄúÁöÑMEV„ÄÇÊ≥®ÊÑèÔºåÂè™ÊúâÂèëÁé∞Âà´‰∫∫Â•óÂà©Âπ∂ÈÄöËøáÊèêÈ´ògasÊèíÈòüÊõøÊç¢ËØ•Á¨î‰∫§ÊòìÊó∂ÔºåÂ•óÂà©ÊâçË¢´ËßÜ‰∏∫MEV„ÄÇ

### 2.Ê∏ÖÁÆó
DeFiÂÄüË¥∑Âπ≥Âè∞ÁõÆÂâçÈááÁî®Ë∂ÖÈ¢ùÊäµÊäºÂÄüË¥∑ÁöÑÊ®°Âºè„ÄÇËá™ÁÑ∂Âú∞ÔºåÁî®‰ΩúÊäµÊäºÂìÅÁöÑËµÑ‰∫ß‰ª∑Ê†º‰ºöÈöèÊó∂Èó¥Ê≥¢Âä®ÔºåÂ¶ÇÊûúËµÑ‰∫ßË∑åÁ†¥ÁâπÂÆö‰ª∑Ê†ºÔºåÂàôÊäµÊäºÂìÅÂ∞ÜË¢´Ê∏ÖÁÆó„ÄÇÈÄöÂ∏∏ÔºåÊäµÊäºÂìÅ‰ºöË¢´ÊâìÊäòÂá∫ÂîÆÔºåË¥≠‰π∞Ëµ∞ËøôÈÉ®ÂàÜÊäµÊäºÂìÅÁöÑ‰∫∫Áß∞‰∏∫Ê∏ÖÁÆó‰∫∫ÔºåÊ∏ÖÁÆóÂÆåÊàêÂêéËøò‰ºöÂæóÂà∞ÂÄüË¥∑Âπ≥Âè∞ÁöÑÂ•ñÂä±„ÄÇÂè™Ë¶ÅÊâæÂà∞Ê∏ÖÁÆóÊú∫‰ºöÔºåÂ∞±ÂèØ‰ª•Âá∫Áé∞ÊõøÊç¢Ê∏ÖÁÆó‰∫§ÊòìÁöÑÊÉÖÂÜµÔºåÂ≠òÂú® MEV Êú∫‰ºö„ÄÇÊêúÂØªËÄÖÊ≥®ÊÑèÂà∞‰º†ÂÖ•‰∫§ÊòìÊ±†‰∏≠ÁöÑÊ∏ÖÁÆó‰∫§ÊòìÔºåÁÑ∂ÂêéÂàõÂª∫‰∏éÂàùÂßãÊ∏ÖÁÆó‰∫§ÊòìÁõ∏ÂêåÁöÑ‰∫§ÊòìÔºåÊèíÂÖ•‰ªñ‰ª¨Ëá™Â∑±ÁöÑ‰∫§ÊòìÔºå‰∫éÊòØÊêúÂØªËÄÖÊàê‰∏∫Ê∏ÖÁÆóÂ§¥ÂØ∏Âπ∂Êî∂ÂèñËµèÈáëÁöÑ‰∫∫„ÄÇ

ËøôÁ±ªMEVÂä†ÈÄü‰∫ÜDeFiÁöÑÊµÅÂä®ÊÄßÔºå‰∏∫ÂÄüË¥∑Âπ≥Âè∞ÁöÑÊ≠£Â∏∏ËøêË°åÊèê‰æõ‰øùÈöúÔºå‰πüË¢´ËÆ§‰∏∫ÊòØ‚ÄúÂ•Ω‚ÄùÁöÑMEV„ÄÇ

### 3. Frontrunning„ÄÅBackrunning Âíå Sandwich(ing)
Êä¢Ë∑ëÊòØMEVÊú∫Âô®‰∫∫ÊîØ‰ªòÁ®çÈ´òÁöÑgas feeÊù•Êä¢ÂÖàÂú®MempoolÁöÑÊüê‰∫§ÊòìÂâçÊâßË°å‰∫§Êòì, ÊØîÂ¶Ç‰ª•Êõ¥‰ΩéÁöÑ‰ª∑Ê†º Swap ‰ª£Â∏Å„ÄÇÂõûË∑ëÊòØÊú∫Âô®‰∫∫Âú®‰∏ÄÁ¨î‰∫§ÊòìÈÄ†Êàê‰ª∑Ê†ºÂ§ßÂπÖÈîô‰Ωç‰πãÂêéÂ∞ùËØï‰∏çÂêåÁöÑÂ•óÂà©, Ê∏ÖÁÆó, Êàñ‰∫§Êòì„ÄÇ

![fr.jpg](img/fr.jpg)

‰∏âÊòéÊ≤ªÊîªÂáªÊòØÂâç‰∏§ÁßçÊîªÂáªÁöÑÁªìÂêà, ÂØπ‰∫§ÊòìËøõË°åÂâçÂêéÂ§πÂáªÔºåÈÄöÂ∏∏Ë¢´Áß∞‰∏∫Â§πÂ≠ê„ÄÇ‰æãÂ¶Ç MEV Êú∫Âô®‰∫∫Âú®‰∫§ÊòìÂâçÊîæ‰∏Ä‰∏™‰π∞Âçï, Âú®‰∫§ÊòìÂêéÊîæ‰∏Ä‰∏™ÂçñÂçï, ËÆ©Áî®Êà∑ÁöÑ‰∫§ÊòìÂú®Êõ¥Â∑ÆÁöÑ‰ª∑Ê†ºÊâßË°åÔºåÂè™Ë¶Å‰∫§ÊòìÊªëÁÇπËÆæÁΩÆÂæó‰∏çÂêàÁêÜÔºåÂ∞±ÂæàÂÆπÊòìÈÅ≠ÂèóÂà∞‰∏âÊòéÊ≤ªÊîªÂáªÔºåËøôÁ±ªMEVÊòæÁÑ∂ÊòØ‚ÄúÂùè‚ÄùÁöÑ„ÄÇ

![swa.png](img/swa.png)

### 4. Just-in-Time liquidity attack
JITÊµÅÂä®ÊÄßÊòØ‰∏ÄÁßçÁâπÊÆäÂΩ¢ÂºèÁöÑÊµÅÂä®ÊÄßÊèê‰æõ„ÄÇÂú®DEX‰∏≠ÊµÅÂä®ÊÄßÊèê‰æõËÄÖ‰ºöÂàÜÂæó‰∫§ÊòìÊâãÁª≠Ë¥πÔºåJITÊåáÁöÑÊòØÂú®‰∏ÄÁ¨îËæÉÂ§ßÁöÑSwapÂèëÁîüÂâçÊ∑ªÂä†ÊµÅÂä®ÊÄß‰ª•ÂæóÂà∞ËØ•Á¨î‰∫§ÊòìÊâãÁª≠Ë¥πÁöÑÂàÜÊàêÔºåÂú®‰∫§ÊòìÁªìÊùüÂêéÁ´ãÂç≥ÈÄÄÂá∫ÊµÅÂä®ÊÄß„ÄÇËøôÂê¨Ëµ∑Êù•‰ºöÊúâÁÇπÂ•áÊÄ™Ôºå‰∏ÄÁõ¥Êèê‰æõÊµÅÂä®ÊÄß‰∏çÊòØ‰∏ÄÁõ¥ËÉΩÊî∂Âà∞ÊâãÁª≠Ë¥πÂêóÔºü‰∏™‰∫∫ËßÇÁÇπÊòØÂÅöLP‰ºöÂ∏¶Êù•Êó†Â∏∏ÊçüÂ§±ÔºåËÄåÁû¨Êó∂ÁöÑÊµÅÂä®ÊÄßÊèê‰æõÊâÄÂ∏¶Êù•ÁöÑÊó†Â∏∏ÊçüÂ§±Âá†‰πéÂèØ‰ª•ÂøΩÁï•‰∏çËÆ°„ÄÇJITÊîªÂáªÁ±ª‰ºº‰∫é‰∏âÊòéÊ≤ªÊîªÂáªÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÉΩÊ∂âÂèäÂà∞ÂèóÂÆ≥ËÄÖ‰∫§ÊòìÁöÑÂâçÁΩÆÂíåÂêéÁΩÆÔºå‰ΩÜÂú®JITÁöÑÊÉÖÂÜµ‰∏ãÔºåÊîªÂáªËÄÖÂ¢ûÂä†ÂíåÂà†Èô§ÊµÅÂä®ÊÄßÔºåËÄå‰∏çÊòØË¥≠‰π∞ÂíåÂá∫ÂîÆ„ÄÇËøôÁ±ªMEVÂ¢ûÂä†‰∫ÜDEXÊµÅÂä®ÊÄßÔºå‰πüÊú™ÂØπ‰∫§ÊòìËÄÖ‰∫ßÁîü‰º§ÂÆ≥ÔºåÊâÄ‰ª•‰πüÊòØ‚ÄúÂ•Ω‚ÄùÁöÑMEV„ÄÇ

![JIT.png](img/JIT.png)

JITÊµÅÂä®ÊÄßÂÆûÈôÖ‰∏äÂú®DEX‰∫§Êòì‰∏≠Âç†ÊØîÈùûÂ∏∏Â∞ëÔºåËôΩÁÑ∂Âê¨Ëµ∑Êù•ÂæàÂéâÂÆ≥Ôºå‰ΩÜÊòØÊ†πÊçÆ[Just-in-time Liquidity on the Uniswap Protocol](https://uniswap.org/blog/jit-liquidity)Êä•ÂëäÔºåÂú®Uniswap‰∏≠ÔºåJITÊµÅÂä®ÊÄßÂç†ÊØîÂÆûÈôÖ‰∏ä‰∏ÄÁõ¥Â∞è‰∫é1%ÔºåÊâÄ‰ª•ÁÆóÊòØ‰∏ÄÁßçÂΩ±Âìç‰∏çÂ§ßÁöÑMEV„ÄÇ

![JITv.png](img/JITv.png)


## Áî®DuneÂÅöMEVÁöÑÂàÜÊûê

Áî®DuneÂÅöMEVÂàÜÊûêËøôÈáåÂàÜ‰∫´‰∏§ÁßçÊÄùË∑Ø„ÄÇÁõ∏ÂÖ≥Êü•ËØ¢ËØ∑ÂèÇËÄÉÊï∞ÊçÆÁúãÊùø[MEV Data Analytics Tutorial](https://dune.com/sixdegree/mev-data-analytics-tutorial)„ÄÇ

### 1. Âà©Áî®Êù•Ëá™FlashbotsÁöÑ`Á§æÂå∫Ë¥°ÁåÆË°®`
 
Â¶Ç‰∏ãÂõæÊâÄÁ§∫ÔºåDuneÁöÑÂõõÁ±ªÊï∞ÊçÆË°®‰∏≠ÔºåÁ§æÂå∫Ë¥°ÁåÆË°®ÊòØÁî±Â§ñÈÉ®ÁªÑÁªáÊèê‰æõÁöÑÊï∞ÊçÆÊ∫êÔºåÂÖ∂‰∏≠ÂåÖÊã¨FlashbotsÊèê‰æõÁöÑÊï∞ÊçÆ„ÄÇ

![dune_com.jpg](img/dune_com.jpg)

![dune_fb.jpg](img/dune_fb.jpg)

[Flashbots](https://www.flashbots.net/)ÊòØ‰∏Ä‰∏™MEVÁ†îÁ©∂ÂíåÂºÄÂèëÁªÑÁªáÔºåÂÆÉÁöÑÊàêÁ´ãÊòØ‰∏∫‰∫ÜÂáèËΩªMEVÂØπÂå∫ÂùóÈìæÈÄ†ÊàêÁöÑË¥üÂ§ñÈÉ®ÊÄßÔºåÁõÆÂâçË∂ÖËøáÁôæÂàÜ‰πã‰πùÂçÅÁöÑ‰ª•Â§™ÂùäÈ™åËØÅËÄÖËäÇÁÇπÂú®ËøêË°åFlashbotsÁ®ãÂ∫è„ÄÇÂÖ≥‰∫éFlashbotsÔºåÊÑüÂÖ¥Ë∂£ÁöÑÊúãÂèãÂèØ‰ª•Ëá™Ë°åÊü•Áúã‰ªñ‰ª¨ÁöÑ[Á†îÁ©∂ÂíåÊñáÊ°£](https://boost.flashbots.net/)ÔºåËøôÈáåÂè™ÈúÄË¶ÅÁü•ÈÅì‰ªñ‰ª¨ÊòØ‰∏Ä‰∏™mevÁ†îÁ©∂ÁªÑÁªáÔºåÊèê‰æõmevÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆ‰æõÁî®Êà∑Âú®Dune‰∏äÂÅöÊü•ËØ¢ÂíåÂàÜÊûêÂç≥ÂèØ„ÄÇ

‰πãÂâçÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥ÔºåflashbotsÁöÑÁ§æÂå∫Ë°®ÈÉΩÂÅúÊõ¥Âú®2022.9.15ÔºåÂú®ÂÜôËøôÁØáÊñáÁ´†Êó∂ÊàëÂèàÊ£ÄÊü•‰∫Ü‰∏Ä‰∏ãÔºåÂèëÁé∞‰ªé2023.01.09ÂºÄÂßãËØ•Ë°®Â±ÖÁÑ∂ÂèàÂºÄÂßãÊõ¥Êñ∞‰∫ÜÔºåÈÇ£‰ºöÊñπ‰æøÊàë‰ª¨ÂÅö‰∏Ä‰∫õMEVÁöÑÊü•ËØ¢ÔºåÂÖ∑‰ΩìÊØè‰∏™Ë°®ÂåÖÂê´ÁöÑÂÜÖÂÆπÔºåÂêÑÂàóÊï∞ÊçÆÂØπÂ∫îÁöÑÂê´‰πâÔºåÈÉΩÂèØ‰ª•ÈÄöËøáDuneÁöÑ[Flashbots ÊñáÊ°£](https://dune.com/docs/reference/tables/community/flashbots/)Êü•ËØ¢„ÄÇ

‰ª•**flashbots.mev\_summary**Ë°®‰∏∫‰æãÔºåÊü•ËØ¢ÁüøÂ∑•Êî∂ÁõäÔºö

| **ÂàóÂêçÁß∞**                      | **Á±ªÂûã**  | **ÊèèËø∞**                                        |
| ------------------------------------ | --------- | ------------------------------------------------------ |
| block\_timestamp                     | timestamp | Âå∫ÂùóÊó∂Èó¥Êà≥                                        |
| block\_number                        | bigint    | Âå∫ÂùóÂè∑                                           |
| base\_fee\_per\_gas                  | bigint    | Âçï‰ΩçgasË¥πÁî®                                       |
| coinbase\_transfer                   | bigint    | Áõ¥Êé•ÁªôÂà∞ÁüøÂ∑•ÁöÑÁüøÂ∑•Ë¥π                     |
| error                                | string    | ÈîôËØØ                                       |
| gas\_price                           | bigint    | gasË¥π                                       |
| gas\_price\_with\_coinbase\_transfer | bigint    | ÊÄªÊ∂àËÄóÁöÑgas+Áõ¥Êé•ÁªôÂà∞ÁüøÂ∑•ÁöÑÁüøÂ∑•Ë¥π |
| gas\_used                            | bigint    | gasÊ∂àËÄóÈáè                                     |
| gross\_profit\_usd                   |  double    | ‰ªé‰∫§Êòì‰∏≠Ëé∑ÂèñÁöÑÊÄªÊî∂ÁõäÔºàÁæéÈáëÔºâ               |
| miner\_address                       | string    | ÁüøÂ∑•Âú∞ÂùÄ                                   |
| miner\_payment\_usd                  |  double    | ÁüøÂ∑•Êî∂ÁõäÔºàÁæéÈáëÔºâ                   |
| protocol                             | string    | ‰∏ªË¶Å‰∫§‰∫íÁöÑÂçèËÆÆ                               |
| protocols                            | string    | ‰∫§Êòì‰∏≠Ê∂âÂèäÂà∞ÁöÑÂçèËÆÆ          |
| transaction\_hash                    | string    | ‰∫§ÊòìÂìàÂ∏å                                |
| type                                 | string    | MEVÁ±ªÂûãÔºàÊØîÂ¶ÇÂ•óÂà©Ôºâ                       |
| timestamp                            | timestamp | Êñá‰ª∂ÊúÄÂêéÊõ¥Êñ∞ÁöÑÊó∂Èó¥Êà≥             |


ËøôÈáåÊàë‰ª¨‰ª•Êó•‰∏∫Âçï‰Ωç‰ΩúÁªüËÆ°ÔºåÂ∞ÜÊîØ‰ªòÁªôÁüøÂ∑•ÁöÑË¥πÁî®Ê±ÇÂíåÔºåÂπ∂ÊåâMEVÁ±ªÂûãÂàÜÁ±ªÔºåÂç≥ÊØèÊó•ÂêÑÁ±ªMEVÊîØ‰ªòÁªôÁüøÂ∑•ÁöÑÁüøÂ∑•Ë¥πÁªüËÆ°„ÄÇ

```sql
select date_trunc('day', block_timestamp) as block_date,
    type,
    sum(miner_payment_usd) as miner_revenue_usd
from flashbots.mev_summary
where error is null
group by 1, 2
having sum(miner_payment_usd) <= 100000000 -- ÊéíÈô§ÂºÇÂ∏∏ÂÄº
order by 1, 2
```

ÁîüÊàêLine ChartÔºåÂèØ‰ª•ÂèëÁé∞Âú®2021Âπ¥MEVÈùûÂ∏∏Ê¥ªË∑ÉÔºå2022Âπ¥Âõ†‰∏∫Â∏ÇÂú∫Ë∂ã‰∫éÁÜäÂ∏ÇÔºåMEVÊ¥ªË∑ÉÂ∫¶ÊúâÊòéÊòæÁöÑ‰∏ãÈôç„ÄÇÂêåÊó∂ÔºåÂ•óÂà©ÁöÑÊú∫‰ºöÂíåÁ´û‰∫âÔºåÈÉΩÊØîÊ∏ÖÁÆóÁöÑÊøÄÁÉàÂæóÂ§öÔºåÊîØ‰ªòÁªôÁüøÂ∑•ÁöÑË¥πÁî®Ëá™ÁÑ∂‰πüÂ§ö„ÄÇÂè¶Â§ñ‰∏Ä‰∏™ÁªÜËäÇÔºåÊàë‰ª¨ÂèëÁé∞FlashbotsÁöÑÊï∞ÊçÆ‰∏≠ÊúâÂ∞èÈÉ®ÂàÜÊòéÊòæÁöÑÂºÇÂ∏∏ÂÄºÔºåÊâÄ‰ª•Êü•ËØ¢‰∏≠Êàë‰ª¨ÂÅö‰∫ÜÊéíÈô§ËøáÊª§„ÄÇ

![mevsumchat.png](img/mevsumchat.png)

ÂèÇËÄÉqueryÔºö[https://dune.com/queries/1883628](https://dune.com/queries/1883628)


Êé•‰∏ãÊù•ÁöÑ‰æãÂ≠êÊü•ËØ¢ÔºåÂì™‰∏™È°πÁõÆ‰∏äÂ•óÂà©ÊâÄ‰∫ßÁîüÁöÑÂà©Ê∂¶ÊúÄÂ§öÔºåÂç≥Áî®ÊØõÂà©gross_profitÂáèÂéªÊîØ‰ªòÁªôÁüøÂ∑•ÁöÑË¥πÁî®Âç≥ÂèØ„ÄÇ

```sql
select protocols,
    sum(gross_profit_usd - miner_payment_usd) as mev_pure_profit_usd
from flashbots.mev_summary
where error is null
    and type = 'arbitrage'
    and miner_payment_usd <= 1e9 -- exclude outlier
    and abs(gross_profit_usd) <= 1e9 -- exclude outlier
group by 1
order by 2 desc
```

‰∏∫‰ª•‰∏äÊü•ËØ¢ÁªìÊûúÂàÜÂà´ÁîüÊàê‰∏Ä‰∏™Table Á±ªÂûãÁöÑÂèØËßÜÂåñÁªìÊûúÈõÜÂíåÈ•ºÂõæÂõæË°®ÔºåÂ∞±ÂèØ‰ª•Ëé∑Âæó‰ª•‰∏ãÁªìÊûúÔºö

![arb.png](img/arb.png)

ÂèØ‰ª•ÂèëÁé∞ÔºåÁõÆÂâçFlashbots Êî∂ÂΩïÁöÑÂ•óÂà©‰∫§Êòì‰∏ªË¶ÅÊ∂âÂèäUniswap V2ÔºåUniswap V3ÔºåBalancer V1ÔºåCurveÂíåBancor„ÄÇÂÖ∂‰∏≠ÁªùÂ§ßÈÉ®ÂàÜÁöÑÂ•óÂà©Âà©Ê∂¶Êù•Ëá™‰∫éUniswapÂçèËÆÆ„ÄÇ

ÂèÇËÄÉqueryÔºö[https://dune.com/queries/1883757](https://dune.com/queries/1883757)

ËÄÉËôëÂà∞`protocols`ÊòØÁî±Â§ö‰∏™‰∏çÂêåÂçèËÆÆÁªÑÂêàÁöÑ‰∏Ä‰∏™ÈõÜÂêàÔºåÊàë‰ª¨ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•‰ºòÂåñ‰∏äÈù¢ÁöÑÊü•ËØ¢ÔºåÂØπÊï∞ÊçÆËøõË°åÊãÜÂàÜÔºåÂ¶ÇÊûúÊüê‰∏™Â•óÂà©‰∫§ÊòìÊ∂âÂèäÂ§ö‰∏™ÂçèËÆÆÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÂà©Ê∂¶ÊàñÈáëÈ¢ùÂπ≥ÂùáÂàÜÈÖç„ÄÇËøôÊ†∑ËÉΩÊõ¥Â•ΩÁöÑÁúãÂá∫ÂÖ∑‰ΩìÂì™‰∏Ä‰∏™ÂçèËÆÆ‰∫ßÁîü‰∫ÜÊúÄÂ§öÁöÑÂ•óÂà©Âà©Ê∂¶„ÄÇFork ‰∏äÈù¢ÁöÑÊü•ËØ¢Âπ∂‰øÆÊîπÂ¶Ç‰∏ãÔºö

```sql
with protocols_profit as (
    select protocols,
        sum(gross_profit_usd - miner_payment_usd) as mev_pure_profit_usd
    from flashbots.mev_summary
    where error is null
        and type = 'arbitrage'
        and miner_payment_usd <= 1e9 -- exclude outlier
        and abs(gross_profit_usd) <= 1e9 -- exclude outlier
    group by 1
),

protocols_profit_array as (
    select protocols,
        mev_pure_profit_usd,
        regexp_extract_all(protocols, '"([0-9a-zA-Z_]+)"', 1) as protocols_array
    from protocols_profit
),

single_protocol_profit as (
    select p.protocol,
        mev_pure_profit_usd / cardinality(protocols_array) as mev_pure_profit_usd,
        protocols_array,
        cardinality(protocols_array) as array_size,
        mev_pure_profit_usd as origin_amount
    from protocols_profit_array
    cross join unnest(protocols_array) as p(protocol)
)

select protocol,
    sum(mev_pure_profit_usd) as mev_pure_profit_usd
from single_protocol_profit
group by 1
order by 2 desc
```

Âú®Ëøô‰∏™Êü•ËØ¢‰∏≠ÔºåÂõ†‰∏∫`protocols`Â≠óÊÆµÊòØÂ≠óÁ¨¶‰∏≤Á±ªÂûãÔºåÊàë‰ª¨‰ΩøÁî®`regexp_extract_all()`Êù•Â∞ÜÂÖ∂ÊãÜÂàÜÂπ∂ËΩ¨Êç¢‰∏∫Êï∞ÁªÑÔºåÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ CTE `protocols_profit_array` ‰Ωú‰∏∫ËøáÊ∏°„ÄÇÂÖ∂‰∏≠ÔºåÊ≠£ÂàôË°®ËææÂºè`"([0-9a-zA-Z_]+)"`ÂåπÈÖçÂåÖÂê´Âú®ÂèåÂºïÂè∑‰∏≠ÁöÑÂ≠óÊØçÊï∞Â≠óÊàñ‰∏ãÂàíÁ∫øÁöÑ‰ªªÊÑèÁªÑÂêà„ÄÇÂèØ‰ª•ÂèÇËÄÉ[Trino Regular expression functions#](https://trino.io/docs/current/functions/regexp.html)‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇ

ÁÑ∂ÂêéÊàë‰ª¨Âú®`single_protocol_profit` CTE‰∏≠ÔºåÊ†πÊçÆÊï∞ÁªÑÁöÑÂü∫Êï∞ÔºàÂ§ßÂ∞èÔºâÂ∞ÜÊî∂ÁõäÈáëÈ¢ùËøõË°åÂπ≥ÂùáÂàÜÈÖç„ÄÇ‰ΩøÁî®`unnest(protocols_array) as p(protocol)`Â∞ÜÊï∞ÁªÑÊãÜÂàÜÂºÄÂπ∂‰∏∫ÂÖ∂ÂÆö‰πâ‰∏∫‰∏Ä‰∏™Ë°®Âà´ÂêçÂíåÂ≠óÊÆµÂà´ÂêçÔºàÂàÜÂà´‰∏∫`p`Âíå`protocol`„ÄÇÁªìÂêà‰ΩøÁî®`cross join`ÔºåÂ∞±ÂèØ‰ª•Âú®SELECTÂ≠êÂè•‰∏≠ËæìÂá∫ÊãÜÂàÜÂºÄÁöÑ`protocol`ÂÄº„ÄÇ

ÊúÄÂêéÊàë‰ª¨ÈíàÂØπÊãÜÂàÜÂºÄÁöÑÂçèËÆÆËøõË°åÊ±áÊÄª„ÄÇË∞ÉÊï¥ÂèØËßÜÂåñÂõæË°®ÁöÑËæìÂá∫Â≠óÊÆµÔºåÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫Â¶Ç‰∏ãÔºö

![arb_protocol.png](img/arb_protocol.png)

Áé∞Âú®Êàë‰ª¨ÂèØ‰ª•ÂæàÊ∏ÖÊô∞ÁöÑÁúãÂà∞ÔºåÊù•Ëá™Uniswap V2ÁöÑÂ•óÂà©Êî∂ÁõäÈ´òËææ176MÔºåÂç†ÊØîÁ∫¶Êé•Ëøë70%„ÄÇ

ÂèÇËÄÉqueryÔºö[https://dune.com/queries/1883791](https://dune.com/queries/1883791)

### 2. Â∞ÜSpellbookÁöÑLabelsË°®‰∏éDeFiÁöÑSpellbookË°®ËÅîÂêàÂª∫Á´ãÊü•ËØ¢
‰ª•Uniswap‰∏∫‰æãËØ¥ÊòéÔºö

Â¶ÇÊûú‰∏ç‰æùËµñ‰∫éflashbotsÁ§æÂå∫Ë°®ÔºåÂ∞§ÂÖ∂ÊòØÂÆÉÁöÑÁª¥Êä§ÂèØËÉΩ‰ºöÂá∫Áé∞‰∏≠Êñ≠ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ËøòÂèØ‰ª•‰ΩøÁî®Spellbook‰∏≠ÁöÑ `labels.arbitrage_traders` Ë°®„ÄÇ

```sql
select address
from labels.arbitrage_traders
where blockchain = 'ethereum'
```

Êé•ÁùÄÂ∞Üuniswap_v3_ethereum.tradesË°®‰∏éÂ•óÂà©‰∫§ÊòìËÄÖË°®ËÅîÂêàÔºåÁ≠õÈÄâÂÖ∂‰∏≠ÁöÑÂêÉÂçïËÄÖÔºàtakerÔºâÔºåÂç≥‰∫§ÊòìËÄÖÔºå‰∏∫Â•óÂà©‰∫§ÊòìËÄÖÁöÑ‰∫§Êòì„ÄÇÊé•‰∏ãÊù•Â∞±ÂèØ‰ª•ÁªüËÆ°‰∫§ÊòìÁ¨îÊï∞ÔºåÊÄªÁöÑ‰∫§ÊòìÈáëÈ¢ùÔºåÂπ≥Âùá‰∫§ÊòìÈáëÈ¢ùÔºåÁªüËÆ°Áã¨Á´ãÁöÑ‰∫§ÊòìÊú∫Âô®‰∫∫‰∏™Êï∞Á≠âMEVÂ•óÂà©‰ø°ÊÅØ„ÄÇÁ±ª‰ººÁöÑÔºåÊàë‰ª¨‰πüÂèØ‰ª•Êü•ËØ¢‰∏âÊòéÊ≤ªÊîªÂáªÁöÑÁõ∏ÂÖ≥Êï∞ÊçÆ„ÄÇ

```sql
with arbitrage_traders as (
    select address
    from labels.arbitrage_traders
    where blockchain = 'ethereum'
)

select block_date,
    count(*) as arbitrage_transaction_count, 
    sum(amount_usd) as arbitrage_amount,
    avg(amount_usd) as arbitrage_average_amount,
    count(distinct u.taker) as arbitrage_bots_count
from uniswap_v3_ethereum.trades u
inner join arbitrage_traders a on u.taker = a.address
where u.block_date > now() - interval '6' month
group by 1
order by 1
 ```
 
ÂÖ∑‰ΩìÂÜÖÂÆπÂèØ‰ª•ÂèÇËÄÉqueryÔºö[https://dune.com/queries/1883865](https://dune.com/queries/1883865)

Áî±Ê≠§Êàë‰ª¨ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Âú∞ÔºåÊü•ËØ¢MEVÊú∫Âô®‰∫∫ÁöÑ‰∫§ÊòìÊï∞„ÄÅ‰∫§ÊòìÈáëÈ¢ùÂíåÊôÆÈÄöÁî®Êà∑ÁöÑËøõË°åÂØπÊØîÔºõUniswap‰∏≠ÊØè‰∏™‰∫§ÊòìÂØπÁöÑMEV‰∫§ÊòìÊï∞Âç†ÊØî„ÄÅ‰∫§ÊòìÈáèÂç†ÊØîÔºö

Âå∫ÂàÜÊòØÂê¶ÊòØMEVÊú∫Âô®‰∫∫ÔºåÊàë‰ª¨‰æùÊóßÈÄöËøáÊ†áÁ≠æË°®Êù•Âà§Êñ≠ÔºåÂè™ÈúÄË¶ÅÂà§Êñ≠`taker`ÊòØÂê¶Âú®`arbitrage_traders`‰∏≠ÔºåÂ∞±ÂèØ‰ª•Âå∫ÂàÜÂÖ∂ÊòØÂê¶‰∏∫Â•óÂà©Êú∫Âô®‰∫∫„ÄÇ

```sql
with arbitrage_traders as (
    select address
    from labels.arbitrage_traders
    where blockchain = 'ethereum'
),

trade_details as (
    select block_date,
        taker,
        amount_usd,
        tx_hash,
        (case when a.address is null then 'MEV Bot' else 'Trader' end) as trader_type
    from uniswap_v3_ethereum.trades u
    left join arbitrage_traders a on u.taker = a.address
    where u.block_date > now() - interval '6' month
)

select block_date,
    trader_type,
    count(*) as arbitrage_transaction_count, 
    sum(amount_usd) as arbitrage_amount
from trade_details
group by 1, 2
order by 1, 2
```

‰∏∫‰ª•‰∏äÊü•ËØ¢ÁªìÊûúÂàÜÂà´ÁîüÊàê‰∏§‰∏™Area ChartÂõæË°®ÔºåÂØπÊØîMEV Bots ÂíåÊôÆÈÄöTrader ÁöÑ‰∫§ÊòìÊ¨°Êï∞Âíå‰∫§ÊòìÈáëÈ¢ùÂç†ÊØîÔºåÂ∞±ÂèØ‰ª•Ëé∑Âæó‰ª•‰∏ãÁªìÊûúÔºö

![uniswap_bot.png](img/uniswap_bot.png)

ÂÖ∑‰ΩìÂÜÖÂÆπÂèØ‰ª•ÂèÇËÄÉqueryÔºö[https://dune.com/queries/1883887](https://dune.com/queries/1883887)


Êàë‰ª¨ËøòÂèØ‰ª•Êåâ‰∫§ÊòìÂØπÔºåÂØπbotÂíåÊôÆÈÄöÁî®Êà∑‰∫§ÊòìËøõË°åÂàÜÂà´ÁªüËÆ°‰∫§ÊòìÊï∞„ÄÅ‰∫§ÊòìÈáëÈ¢ùÁ≠â„ÄÇÂè™ÈúÄÁªìÂêàÈ≠îÊ≥ïË°®ÈáåÈù¢ÁöÑ`token_pair`ËøõË°åÂàÜÁ±ªÁªüËÆ°Âç≥ÂèØÔºåËøôÈáå‰∏çÂÜç‰∏æ‰æã„ÄÇ

## ÊÄªÁªì

‰ª•‰∏ä‰ªãÁªç‰∫Ü‰ª•Â§™ÂùäMEVÁöÑÂéüÁêÜÔºåÂàÜÁ±ªÔºå‰ª•Âèä‰ª•Uniswap‰∏∫‰æãÂ¶Ç‰ΩïÁî®DuneÂÅöMEVÊü•ËØ¢ÁöÑ‰∏§ÁßçÊñπÊ≥ï„ÄÇ[AndrewHong](https://twitter.com/andrewhong5297)Âú®DuneÁöÑ[ÂçÅ‰∫åÂ§©ËØæÁ®ã](https://www.youtube.com/watch?v=SMnzCw-NeFE)‰∏≠‰πüÊúâ‰∏ÄËÆ≤ÂÖ≥‰∫éMEVÁöÑÔºåÊÑüÂÖ¥Ë∂£ÁöÑÊúãÂèãÂèØ‰ª•ÁúãÁúãDuniversityÊ†°ÈïøÁöÑËÆ≤Ëß£ÔºåÂÖ∂‰∏≠ÊèêÂà∞DuneÁöÑÊ†áÁ≠æË°®Ê∫ê‰∫éEtherscanÔºåÂÖ∂[Ë¶ÜÁõñÁéá](https://dune.com/queries/1764004)‰πü‰∏ç‰∏ÄÂÆöË∂≥Â§üÔºåÊâÄ‰ª•Êú¨Êñá‰ªãÁªçÁöÑ‰∏§ÁßçÊñπÊ≥ïÔºåÊúÄÂêéÁöÑÊü•ËØ¢ÁªìÊûúÂèØËÉΩ‰ºöÁï•ÊúâÂá∫ÂÖ•„ÄÇMEVÊòØ‰∏™Â§çÊùÇÁöÑËØæÈ¢òÔºåËøôÈáåÂè™ÊòØÊäõÁ†ñÂºïÁéâÔºåÊõ¥Â§öÁöÑÊñπÊ≥ïÈúÄË¶ÅÂ§ßÂÆ∂Ëá™Â∑±Êé¢Á¥¢„ÄÇ


## ÂèÇËÄÉ
1. Understanding the Full Picture of MEV https://huobi-ventures.medium.com/understanding-the-full-picture-of-mev-4151160b7583
2. Foresight VenturesÔºöÊèèÁªòÔºåÂàÜÁ±ªÔºåÊîØÈÖç MEV https://foresightnews.pro/article/detail/10011
3. Flashboy 2.0 https://arxiv.org/pdf/1904.05234.pdf
4. Post-Merge MEV: Modelling Validator Returns https://pintail.xyz/posts/post-merge-mev/
5. https://dune.com/amdonatusprince/mev-sandwich-attacks-and-jit
6. https://dune.com/alexth/uniswap-v3-mev-activity
7. Just-in-time Liquidity on the Uniswap Protocol https://uniswap.org/blog/jit-liquidity
8. https://github.com/33357/smartcontract-apps/blob/main/Robot/MEV_Who_are_you_working_for.md
9. https://dune.com/sixdegree/mev-data-analytics-tutorial


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch19/ch18-uniswap-multichain-analysis.md">
# Uniswap Â§öÈìæÊï∞ÊçÆÂØπÊØîÂàÜÊûê

Uniswap ÊòØDeFiÈ¢ÜÂüüÈ¢ÜÂÖàÁöÑDEX‰πã‰∏Ä„ÄÇUniswap Êô∫ËÉΩÂêàÁ∫¶‰∫é2018Âπ¥ÁéáÂÖàÈÉ®ÁΩ≤Âú®EthereumÂå∫ÂùóÈìæÔºå2021Âπ¥ÂèàÂÖàÂêéÈÉ®ÁΩ≤Âà∞ArbitrumÔºåOptimismÂíåPolygonÔºå2022Âπ¥Êâ©Â±ïÂà∞CeloÈìæ„ÄÇËøëÊúüÂèàÊúâÊñ∞ÁöÑÊèêÊ°àÊèêËÆÆÂ∞ÜÂÖ∂ÈÉ®ÁΩ≤Âà∞BNBÈìæÔºåÂèëÂ±ïÂäøÂ§¥‰∏çÂáè„ÄÇÊú¨ÊñáÊàë‰ª¨Â∞Ü‰∏ÄËµ∑Êù•Êé¢ËÆ®Â¶Ç‰ΩïÂØπÊØîÂàÜÊûê2022Âπ¥Â∫¶UniswapÂú®Â§öÈìæ‰∏äÁöÑÊï∞ÊçÆË°®Áé∞„ÄÇÁî±‰∫éDuneÁõÆÂâçÂ∞öÊú™ÊîØÊåÅCeloÈìæÔºåÊâÄ‰ª•Âπ∂Êú™ÂåÖÂê´Âú®ÂÜÖ„ÄÇ

Êú¨ÊïôÁ®ãÁöÑÊï∞ÊçÆÁúãÊùøÔºö[Uniswap V3 Performance In 2022 Multichains](https://dune.com/sixdegree/uniswap-v3-performance-in-2022-multi-chains)

Êú¨ÊïôÁ®ã‰∏≠ÂÖ®ÈÉ®QueryÈÉΩ‰ΩøÁî®Dune SQLÂºïÊìéÂÆåÊàê„ÄÇ

ÂæàÂ∑ßÔºåÂú®ÁºñÂÜôÂÆåÂñÑËøôÁØáÊïôÁ®ãÊúüÈó¥Ôºå2023Âπ¥1Êúà25Êó•Uniswap FoundationÊé®Âá∫‰∫ÜÊñ∞‰∏ÄÊúüÁöÑBountyÊ¥ªÂä®ÔºåÂÖ∂‰∏ªÈ¢òÊ≠£Â•ΩÊòØÂàÜÊûêUniswapÂú®Â§öÈìæÁöÑË°®Áé∞„ÄÇÂ∏åÊúõÊú¨ÊñáÂèØ‰ª•ÊäõÁ†ñÂºïÁéâÔºåÁªôÂ§ßÂÆ∂Êèê‰æõ‰∏Ä‰∫õÂèÇËÄÉÊÄùË∑ØÔºåÂ§ßÂÆ∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÊÄùË∑ØÔºåÁºñÂÜôÂá∫Êõ¥Â•ΩÁöÑÊü•ËØ¢ÂéªÂèÇÂä†Ëøô‰∏™BountyÊ¥ªÂä®„ÄÇÈ¢ÑÁ•ùÊÇ®Ëé∑Âæó‰∏∞ÂéöÁöÑÂ•ñÈáë„ÄÇUnigrantsÊ¥ªÂä®ÈìæÊé•Ôºö[Bounty # 21 - Uniswap Multichain](https://unigrants.notion.site/Bounty-21-Uniswap-Multichain-b1edc714fe1949779530e920701fd617)

## Â§öÈìæÊï∞ÊçÆÂàÜÊûêÁöÑ‰∏ªË¶ÅÂÜÖÂÆπ

Ê≠£Â¶Ç‚ÄúBounty # 21 - Uniswap Multichain‚ÄùÊ¥ªÂä®ÁöÑÊèèËø∞ÊâÄËØ¥ÔºåÈíàÂØπUniswapËøôÁ±ªDeFiÂ∫îÁî®ÔºåÊàë‰ª¨ÊúÄÂ∏∏ËßÅÈúÄË¶ÅÂàÜÊûêÁöÑÊåáÊ†áÂåÖÊã¨‰∫§ÊòìÈáè„ÄÅ‰∫§ÊòìÈáëÈ¢ù„ÄÅÁî®Êà∑„ÄÅTVLÔºàÊÄªÈîÅ‰ªì‰ª∑ÂÄºÔºâÁ≠â„ÄÇUniswap ÈÉ®ÁΩ≤Â§ßÈáè‰∏çÂêåToken‰∫§ÊòìÂØπÁöÑÊµÅÂä®ËµÑÈáëÊ±†ÔºàPoolÔºâÊô∫ËÉΩÂêàÁ∫¶ÔºåÊµÅÂä®ÊÄßÊèê‰æõËÄÖÔºàLiquidity ProviderÔºåLPÔºâÂ∞ÜÂÖ∂ËµÑÈáëÊ≥®ÂÖ•ÊµÅÂä®ÊÄßÊ±†‰ª•Ëé∑Âèñ‰∫§ÊòìÊâãÁª≠Ë¥πÊî∂ÁõäÔºåÂÖ∂‰ªñÁî®Êà∑Âú®Áõ∏Â∫îÁöÑÊµÅÂä®ÊÄßËµÑÈáëÊ±†ÂÖëÊç¢Ëá™Â∑±ÈúÄË¶ÅÁöÑToken„ÄÇÊâÄ‰ª•ÔºåÊõ¥Ê∑±ÂÖ•ÁöÑÂàÜÊûêËøòÂèØ‰ª•ÂåÖÊã¨ÊµÅÂä®ÊÄßÊ±†ÔºàPoolÔºâÁõ∏ÂÖ≥„ÄÅÊµÅÂä®ÊÄßÊèê‰æõËÄÖÔºàLPÔºâÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπ„ÄÇ

Êú¨ÊïôÁ®ã‰∏≠Êàë‰ª¨Â∞Ü‰∏ªË¶ÅËÆ®ËÆ∫Â¶Ç‰∏ãÂÜÖÂÆπÔºö
- ÊÄª‰∫§ÊòìÊ¶ÇÂÜµÔºà‰∫§ÊòìÊï∞Èáè„ÄÅ‰∫§ÊòìÈáëÈ¢ù„ÄÅÁî®Êà∑Êï∞Èáè„ÄÅTVLÔºâ
- ÊØèÊó•‰∫§ÊòìÊï∞ÊçÆÂØπÊØî
- ÊØèÊó•Êñ∞Â¢ûÁî®Êà∑ÂØπÊØî
- Âπ¥Â∫¶Êñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†Êï∞ÈáèÂØπÊØî
- ÊØèÊó•Êñ∞Â¢ûÊµÅÂä®ËµÑÈáëÊ±†ÂØπÊØî
- TVLÂØπÊØî
- ÊØèÊó•TVL
- TVLÊúÄÈ´òÁöÑÊµÅÂä®ËµÑÈáëÊ±†

DuneÁ§æÂå∫Áî®Êà∑‰∏∫UniswapÂàõÂª∫‰∫ÜÁõ∏ÂΩìÂÆåÂñÑÁöÑ‰∫§ÊòìÊï∞ÊçÆÈ≠îÊ≥ïË°®`uniswap.trades`ÔºåÂÖ∂‰∏≠ËÅöÂêà‰∫ÜÊù•Ëá™ÂâçÈù¢ÊèêÂèäÁöÑÂõõ‰∏™Âå∫ÂùóÈìæÁöÑUniswapÁõ∏ÂÖ≥Êô∫ËÉΩÂêàÁ∫¶ÁöÑ‰∫§ÊòìÊï∞ÊçÆ„ÄÇÊàë‰ª¨ÁöÑÂ§ßÂ§öÊï∞Êü•ËØ¢ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®Ëøô‰∏™Ë°®Êù•ÂÆûÁé∞„ÄÇÂØπ‰∫éÊµÅÂä®ËµÑÈáëÊ±†Áõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÔºåÁõÆÂâçËøòÊ≤°ÊúâÁõ∏ÂÖ≥ÁöÑÈ≠îÊ≥ïË°®ÔºåÊâÄ‰ª•Êàë‰ª¨ÈúÄË¶ÅËá™Â∑±ÂÜôÊü•ËØ¢Êù•ËÅöÂêàÊù•Ëá™‰∏çÂêåÂå∫ÂùóÈìæÁöÑÊï∞ÊçÆÔºå‰ª•ËøõË°åÂØπÊØîÂàÜÊûê„ÄÇ

Âè¶Â§ñÈúÄË¶ÅËØ¥ÊòéÔºåÊàë‰ª¨Âú®Ëøô‰∏™ÊïôÁ®ã‰∏≠Ôºå‰∏ªË¶ÅÂÖ≥Ê≥®2022Âπ¥Â∫¶ÁöÑÊï∞ÊçÆÔºåÊâÄ‰ª•Âú®Áõ∏ÂÖ≥Êü•ËØ¢‰∏≠ÊúâÊó•ÊúüËøáÊª§Êù°‰ª∂„ÄÇÂ¶ÇÊûúË¶ÅÂàÜÊûêÂÖ®ÈÉ®ÂéÜÂè≤Êï∞ÊçÆÔºåÂè™ÈúÄÁßªÈô§Ëøô‰∫õÊù°‰ª∂Âç≥ÂèØ„ÄÇ

## ÊÄª‰∫§ÊòìÊ¶ÇÂÜµ

ÂèØ‰ª•Áõ¥Êé•ÈíàÂØπË°®`uniswap.trades`ÁºñÂÜô‰∏Ä‰∏™Êü•ËØ¢Êù•Ê±áÊÄª‰∫§ÊòìÊÄªÈáëÈ¢ù„ÄÅ‰∫§ÊòìÊ¨°Êï∞ÂíåÁã¨Á´ãÁî®Êà∑Âú∞ÂùÄÊï∞Èáè„ÄÇ

```sql
select blockchain,
    sum(amount_usd) as trade_amount,
    count(*) as transaction_count,
    count(distinct taker) as user_count
from uniswap.trades
where block_time >= date('2022-01-01')
    and block_time < date('2023-01-01')
group by 1
```

ËÄÉËôëÂà∞ÁªìÊûúÊï∞ÊçÆÁöÑÊï∞Â≠óÈÉΩÊØîËæÉÂ§ßÔºåÊàë‰ª¨ÂèØ‰ª•Â∞Ü‰∏äËø∞Êü•ËØ¢ÊîæÂÖ•‰∏Ä‰∏™CTE‰∏≠Ôºå‰ªéCTEËæìÂá∫ÁöÑÊó∂ÂÄôÔºåÂèØ‰ª•Â∞ÜÊï∞Â≠óÊç¢ÁÆóÊàêMillionÔºàÁôæ‰∏áÔºâÊàñBillionÔºàÂçÅ‰∫øÔºâÂçï‰ΩçÔºåÂêåÊó∂ÂèØ‰ª•ÂæàÊñπ‰æøÂú∞Â∞ÜÂ§ö‰∏™ÈìæÁöÑÊï∞ÊçÆÊ±áÊÄªÂà∞‰∏ÄËµ∑„ÄÇ

‰∏∫Ëøô‰∏™Êü•ËØ¢Ê∑ªÂä†3‰∏™CounterÁ±ªÂûãÁöÑÂõæË°®ÔºåÂàÜÂà´Â±ïÁ§∫ÊÄªÁöÑ‰∫§ÊòìÈáëÈ¢ùÔºå‰∫§ÊòìÊ¨°Êï∞ÂíåÁî®Êà∑Êï∞Èáè„ÄÇÂÜçÂàÜÂà´Ê∑ªÂä†3‰∏™Pie ChartÁ±ªÂûãÁöÑÂõæË°®ÔºåÂàÜÂà´Â±ïÁ§∫ÂêÑÈìæÁöÑ‰∫§ÊòìÈáëÈ¢ùÂç†ÊØîÔºå‰∫§ÊòìÊï∞ÈáèÂç†ÊØîÂíåÁî®Êà∑Êï∞ÈáèÂç†ÊØî„ÄÇÂè¶Â§ñÂÜçÊ∑ªÂä†‰∏Ä‰∏™TableÁ±ªÂûãÁöÑÂõæË°®ÔºåÂ±ïÁ§∫ËØ¶ÁªÜÊï∞Â≠ó„ÄÇÂ∞ÜÊâÄÊúâÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ã„ÄÇ

![image_01.png](img/image_01.png)

Êü•ËØ¢ÈìæÊé•Ôºö[https://dune.com/queries/1859214](https://dune.com/queries/1859214)

## ÊØèÊó•‰∫§ÊòìÊï∞ÊçÆÂØπÊØîÂàÜÊûê

ÂêåÊ†∑‰ΩøÁî®`uniswap.trades`È≠îÊ≥ïË°®ÔºåÂèØ‰ª•ÁºñÂÜôÊåâÊó•ÊúüÁªüËÆ°ÁöÑ‰∫§ÊòìÊï∞ÊçÆÊü•ËØ¢„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
with transaction_summary as (
    select date_trunc('day', block_time) as block_date,
        blockchain,
        sum(amount_usd) as trade_amount,
        count(*) as transaction_count,
        count(distinct taker) as user_count
    from uniswap.trades
    where block_time >= date('2022-01-01')
        and block_time < date('2023-01-01')
    group by 1, 2
)

select block_date,
    blockchain,
    trade_amount,
    transaction_count,
    user_count,
    sum(trade_amount) over (partition by blockchain order by block_date) as accumulate_trade_amount,
    sum(transaction_count) over (partition by blockchain order by block_date) as accumulate_transaction_count,
    sum(user_count) over (partition by blockchain order by block_date) as accumulate_user_count
from transaction_summary
order by 1, 2
```

ËøôÈáåÊàë‰ª¨Â∞Ü2022Âπ¥Â∫¶ÁöÑÊâÄÊúâ‰∫§ÊòìÊï∞ÊçÆÊåâÊó•ÊúüÂíåÂå∫ÂùóÈìæ‰∏§‰∏™Áª¥Â∫¶ËøõË°åÂàÜÁ±ªÊ±áÊÄªÔºåÂêåÊó∂ËæìÂá∫ÊåâÊó•ÊúüÁ¥ØÂä†ÁöÑÊï∞ÊçÆ„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåÁõ∏ÂêåÁöÑÁî®Êà∑‰ºöÂú®‰∏çÂêåÁöÑÊó•ÊúüËøõË°å‰∫§ÊòìÔºåÊâÄ‰ª•ËøôÈáåÊ±áÊÄªÁöÑÁ¥ØËÆ°Áî®Êà∑Êï∞ÈáèÂπ∂‰∏çÊòØÂáÜÁ°ÆÁöÑ‚ÄúÁ¥ØËÆ°Áã¨Á´ãÁî®Êà∑Êï∞Èáè‚ÄùÔºåÂú®ÂêéÈù¢ÁöÑÊü•ËØ¢‰∏≠Êàë‰ª¨‰ºöÂçïÁã¨ËØ¥ÊòéÁªüËÆ°Áã¨Á´ãÁî®Êà∑Êï∞ÈáèÁöÑÊñπÊ≥ï„ÄÇ

Âõ†‰∏∫Êàë‰ª¨ÁöÑÁõÆÁöÑÊòØÂØπÊØîÂàÜÊûêÂú®‰∏çÂêåÈìæ‰∏äÁöÑÊï∞ÊçÆË°®Áé∞ÔºåÊàë‰ª¨ÂèØ‰ª•ÂêåÊó∂ÂÖ≥Ê≥®ÂÖ∑‰ΩìÁöÑÊï∞ÂÄºÂíåËøô‰∫õÊï∞ÂÄºÁöÑÂç†ÊØî„ÄÇÂç†ÊØîÂàÜÊûêÂèØ‰ª•Êõ¥Áõ¥ËßÇÂú∞ËßÇÂØü‰∏çÂêåÈìæÈöèÁùÄÊó∂Èó¥Êé®ÁßªÁöÑË°®Áé∞Ëµ∞Âäø„ÄÇÁªìÂêàÊï∞ÊçÆÁöÑÁâπÊÄßÔºåÊàë‰ª¨ÂàÜÂà´‰ΩøÁî®Line ChartÁîüÊàêÊØèÊó•‰∫§ÊòìÈáëÈ¢ùÂõæË°®Ôºå‰ΩøÁî®Bar ChartÁîüÊàêÊØèÊó•‰∫§ÊòìÊï∞ÈáèÂõæË°®ÂíåÊØèÊó•‰∫§ÊòìÁî®Êà∑Êï∞ÈáèÂõæË°®Ôºå‰ΩøÁî®Èù¢ÁßØÂõæÁîüÊàêÊØèÊó•Á¥ØÂä†ÁöÑ‰∫§ÊòìÈáëÈ¢ù„ÄÅ‰∫§ÊòìÊï∞ÈáèÂíå‰∫§ÊòìÁî®Êà∑Êï∞ÂõæË°®ÔºåÂêåÊó∂‰ΩøÁî®Èù¢ÁßØÂõæÊù•Â±ïÁ§∫ÊØèÊó•ÂêÑÈ°π‰∫§ÊòìÊï∞ÊçÆÁöÑÁôæÂàÜÊØî„ÄÇÂ∞ÜÁõ∏ÂÖ≥ÂõæË°®Ê∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_02.png](img/image_02.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1928680](https://dune.com/queries/1928680)


## ÊØèÊó•Êñ∞Áî®Êà∑ÂØπÊØîÂàÜÊûê

Ë¶ÅÂØπÊØîÂàÜÊûêÊØèÊó•ÁöÑÊñ∞Â¢ûÁî®Êà∑ÔºåÊàë‰ª¨ÈúÄË¶ÅÈ¶ñÂÖàÁªüËÆ°Âá∫ÊØè‰∏™Áî®Êà∑Âú∞ÂùÄÁöÑÂàùÊ¨°‰∫§ÊòìÊó•ÊúüÔºåÂÜçÊåâÁÖßÂàùÊ¨°‰∫§ÊòìÊó•ÊúüÊù•Ê±áÊÄªÁªüËÆ°ÊØèÊó•ÁöÑÊñ∞Â¢ûÁî®Êà∑Êï∞Èáè„ÄÇÂú®‰∏ãÈù¢ÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨Áî®CTE `user_initial_trade`Êù•ÁªüËÆ°ÊØè‰∏™Áî®Êà∑Âú∞ÂùÄÔºàÂç≥`taker`ÔºâÁöÑÂàùÊ¨°‰∫§ÊòìÊó•ÊúüÔºàÊ≥®ÊÑèËøôÈáå‰∏çË¶ÅÂä†Êó•ÊúüËøáÊª§Êù°‰ª∂ÔºâÔºåÁÑ∂ÂêéÂú®CTE `new_users_summary`‰∏≠ÁªüËÆ°2022Âπ¥Â∫¶ÊØèÂ§©ÁöÑÊñ∞Â¢ûÁî®Êà∑Êï∞Èáè„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨Â∞ÜÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞ÊçÆÁªüËÆ°Âà∞CTE `active_users_summary`‰∏≠„ÄÇÂú®ÊúÄÂêéËæìÂá∫Êü•ËØ¢ÁªìÊûúÁöÑQuery‰∏≠ÔºåÊàë‰ª¨Áî®ÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞ÂáèÂéªÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞Êù•ÂæóÂà∞ÊØèÊó•ÁïôÂ≠òÁöÑÁî®Êà∑Êï∞ÈáèÔºåËøôÊ†∑Êàë‰ª¨ÂèØ‰ª•ÁîüÊàêÂØπÊØîÊñ∞Â¢ûÁî®Êà∑ÂíåÁïôÂ≠òÁî®Êà∑Âç†ÊØîÁöÑÂèØËßÜÂåñÂõæË°®„ÄÇ

```sql
with user_initial_trade as (
    select blockchain,
        taker,
        min(block_time) as block_time
    from uniswap.trades
    group by 1, 2
),

new_users_summary as (
    select date_trunc('day', block_time) as block_date,
        blockchain,
        count(*) as new_user_count
    from user_initial_trade
    where block_time >= date('2022-01-01')
        and block_time < date('2023-01-01')
    group by 1, 2
),

active_users_summary as (
    select date_trunc('day', block_time) as block_date,
        blockchain,
        count(distinct taker) as active_user_count
    from uniswap.trades
    where block_time >= date('2022-01-01')
        and block_time < date('2023-01-01')
    group by 1, 2
)

select a.block_date,
    a.blockchain,
    a.active_user_count,
    n.new_user_count,
    coalesce(a.active_user_count, 0) - coalesce(n.new_user_count, 0) as retain_user_count,
    sum(new_user_count) over (partition by n.blockchain order by n.block_date) as accumulate_new_user_count
from active_users_summary a
inner join new_users_summary n on a.block_date = n.block_date and a.blockchain = n.blockchain
order by 1, 2
```

‰∏∫Ëøô‰∏™Êü•ËØ¢ÁªìÊûúÁîüÊàê‰∏çÂêåÁöÑÂèØËßÜÂåñÂõæË°®ÔºåÂàÜÂà´Â±ïÁ§∫ÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞ÈáèÂíåÂç†ÊØî„ÄÅÊØèÊó•ÁïôÂ≠òÁî®Êà∑Êï∞ÈáèÂíåÂç†ÊØî„ÄÅÊØèÊó•Á¥ØËÆ°Êñ∞Â¢ûÁî®Êà∑Êï∞ÈáèÂ∑≤ÂèäÂêÑÈìæÂú®2022Âπ¥Â∫¶Êñ∞Â¢ûÁî®Êà∑Êï∞ÈáèÁöÑÂç†ÊØî„ÄÇÂ∞ÜÁõ∏ÂÖ≥ÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_03.png](img/image_03.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1928825](https://dune.com/queries/1928825)


‰∏äÈù¢ÊèêÂà∞Êàë‰ª¨ÊÉ≥Ë¶ÅÂØπÊØîÊØèÊó•Êñ∞Â¢ûÁî®Êà∑ÂíåÊØèÊó•ÁïôÂ≠òÁî®Êà∑Êï∞ÈáèÂèäÂÖ∂Âç†ÊØîÊÉÖÂÜµ„ÄÇÁî±‰∫éÊàë‰ª¨ÁöÑÊü•ËØ¢ÁªìÊûúÂ∑≤ÁªèÊåâÁÖßÂå∫ÂùóÈìæËøõË°å‰∫ÜÂàÜÁªÑÔºåËøôÁßçÊÉÖÂÜµ‰∏ãÁõ∏ÂÖ≥ÂèØËßÜÂåñÂõæË°®‰∏ÄÊ¨°Âè™ËÉΩÂ±ïÁ§∫‰∏ÄÈ°πÊï∞ÊçÆÔºåÊó†Ê≥ïÂú®Âêå‰∏Ä‰∏™ÂõæË°®‰∏≠ÊòæÁ§∫ÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞ÈáèÂíåÊØèÊó•ÁïôÂ≠òÁî®Êà∑Êï∞ÈáèËøô‰∏§‰∏™Êï∞ÊçÆÊåáÊ†á„ÄÇËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Dune SQLÂºïÊìéÁöÑQuery of Query ÂäüËÉΩÔºåÁºñÂÜô‰∏Ä‰∏™Êñ∞ÁöÑÊü•ËØ¢Ôºå‰ΩøÁî®‰∏äËø∞Êü•ËØ¢ÁªìÊûú‰Ωú‰∏∫Êï∞ÊçÆÊ∫êÔºåÁ≠õÈÄâÂá∫ÂÖ∑‰ΩìÁöÑ‰∏Ä‰∏™Âå∫ÂùóÈìæÁöÑÁªüËÆ°ÁªìÊûú„ÄÇÂõ†‰∏∫‰∏çÂú®ÈúÄË¶ÅÊåâÂå∫ÂùóÈìæËøõË°åÂàÜÁªÑÔºåÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•Âú®‰∏Ä‰∏™ÂõæË°®‰∏≠ËæìÂá∫Â§öÈ°πÊåáÊ†á„ÄÇ

```sql
select block_date,
    active_user_count,
    new_user_count,
    retain_user_count
from query_1928825 -- This points to all returned data from query https://dune.com/queries/1928825
where blockchain = '{{blockchain}}'
order by block_date
```

ËøôÈáåÊàë‰ª¨Â∞ÜË¶ÅÁ≠õÈÄâÁöÑÂå∫ÂùóÈìæÂÆö‰πâ‰∏∫‰∏Ä‰∏™ÂèÇÊï∞ÔºåÂèÇÊï∞Á±ªÂûã‰∏∫ListÔºåÂ∞ÜÊîØÊåÅÁöÑ4‰∏™Âå∫ÂùóÈìæÁöÑÂêçÁß∞ÔºàÂ∞èÂÜôÊ†ºÂºèÔºâÂä†ÂÖ•ÈÄâÈ°πÂàóË°®„ÄÇ‰∏∫Êü•ËØ¢ÁªìÊûúÁîüÊàê‰∏§‰∏™ÂõæË°®ÔºåÂàÜÂà´ËæìÂá∫ÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞ÈáèÂèäÂÖ∂Âç†ÊØî„ÄÇÂ∞ÜÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_04.png](img/image_04.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1929142](https://dune.com/queries/1929142)

## Âπ¥Â∫¶Êñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÂØπÊØîÂàÜÊûê

Dune ÁõÆÂâçÁöÑÈ≠îÊ≥ïË°®‰∏≠Âπ∂Êú™Êèê‰æõÊµÅÂä®ËµÑÈáëÊ±†ÁöÑÊï∞ÊçÆÔºåÊàë‰ª¨ÂèØ‰ª•Ëá™Ë°åÁºñÂÜôÊü•ËØ¢Êù•Ê±áÊÄª„ÄÇÊ¨¢ËøéÂ§ßÂÆ∂ÂéªDuneÂú®Github‰∏äÁöÑSpellbook Â∫ìÊèê‰∫§PRÊù•ÁîüÊàêÂØπÂ∫îÁöÑÈ≠îÊ≥ïË°®„ÄÇ‰ΩøÁî®`PoolCreated`‰∫ã‰ª∂Ëß£ÊûêÊï∞ÊçÆË°®ÔºåÊàë‰ª¨Â∞ÜÊù•Ëá™4‰∏™Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÊ±áÊÄªÂà∞‰∏ÄËµ∑„ÄÇÁî±‰∫éUniswap V2Âè™Âú®EthereumÈìæ‰∏äÈÉ®ÁΩ≤ÔºåÊâÄ‰ª•ËøôÈáåÊàë‰ª¨Ê≤°ÊúâÂ∞ÜÂÖ∂Á∫≥ÂÖ•ÁªüËÆ°ËåÉÂõ¥„ÄÇ

```sql
with pool_created_detail as (
    select 'ethereum' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_ethereum.Factory_evt_PoolCreated

    union all
    
    select 'arbitrum' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_arbitrum.UniswapV3Factory_evt_PoolCreated

    union all
    
    select 'optimism' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_optimism.Factory_evt_PoolCreated

    union all
    
    select 'polygon' as blockchain,
        evt_block_time,
        evt_tx_hash,
        pool,
        token0,
        token1
    from uniswap_v3_polygon.factory_polygon_evt_PoolCreated
)

select blockchain,
    count(distinct pool) as pool_count
from pool_created_detail
where evt_block_time >= date('2022-01-01')
    and evt_block_time < date('2023-01-01')
group by 1
```

ÂèØ‰ª•‰∏∫Ëøô‰∏™Êü•ËØ¢ÁªìÊûúÁîüÊàê‰∏Ä‰∏™Pie ChartÊù•ÂØπÊØîÂêÑÈìæÂú®2022Âπ¥Â∫¶Êñ∞Âª∫ËµÑÈáëÊ±†ÁöÑÊï∞ÈáèÂèäÂÖ∂Âç†ÊØîÔºåÂêåÊó∂ÂèØ‰ª•ÁîüÊàê‰∏Ä‰∏™Table Á±ªÂûãÂõæË°®ËæìÂá∫ËØ¶ÁªÜÊï∞ÊçÆ„ÄÇÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÂêéÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_05.png](img/image_05.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1929177](https://dune.com/queries/1929177)


## ÊØèÊó•Êñ∞Â¢ûÊµÅÂä®ËµÑÈáëÊ±†ÂØπÊØî

Áõ∏Â∫îÂú∞ÔºåÈÄöËøáÂ¢ûÂä†‰∏Ä‰∏™Êó•ÊúüÁ∫¨Â∫¶Âà∞Êü•ËØ¢Âà∞ÂàÜÁªÑÊù°‰ª∂‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•ÁªüËÆ°Âá∫ÂêÑÈìæ‰∏äÊØèÊó•Êñ∞Â¢ûÁöÑÊµÅÂä®ËµÑÈáëÊ±†ÁöÑÊï∞ÊçÆ„ÄÇ

```sql
with pool_created_detail as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

daily_pool_summary as (
    select date_trunc('day', evt_block_time) as block_date,
        blockchain,
        count(distinct pool) as pool_count
    from pool_created_detail
    group by 1, 2
)

select block_date,
    blockchain,
    pool_count,
    sum(pool_count) over (partition by blockchain order by block_date) as accumulate_pool_count
from daily_pool_summary
where block_date >= date('2022-01-01')
    and block_date < date('2023-01-01')
order by block_date
```

Êàë‰ª¨ÂèØ‰ª•ÂàÜÂà´ÁîüÊàêÊØèÊó•Êñ∞Â¢ûËµÑÈáëÊ±†ÁöÑBar ChartÂíåÊòæÁ§∫ÊØèÊó•Êï∞ÈáèÂç†ÊØîÁöÑArea ChartÔºåÂÜçÁîüÊàê‰∏Ä‰∏™ÊòæÁ§∫ÊåâÊó•Á¥ØÂä†ÁöÑÊñ∞Âª∫ËµÑÈáëÊ±†Êï∞ÈáèÁöÑÈù¢ÁßØÂõæ„ÄÇÂ∞ÜÁõ∏Â∫îÂèØËßÜÂåñÂõæË°®Âä†ÂÖ•Êï∞ÊçÆÁúãÊùøÁöÑÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÔºö

![image_06.png](img/image_06.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1929235](https://dune.com/queries/1929235)

## ÊÄªÈîÅ‰ªì‰ª∑ÂÄºÔºàTVLÔºâÂØπÊØîÂàÜÊûê

‰∏çÂêåÁöÑTokenÊúâ‰∏çÂêåÁöÑ‰ª∑Ê†ºÔºåÂØπÊØîÂàÜÊûêTVLÊó∂ÔºåÊàë‰ª¨ÈúÄË¶ÅÈÄöËøáÂÖ≥ËÅî`prices.usd`È≠îÊ≥ïË°®Â∞ÜËøô‰∫õTokenÁöÑÈîÅ‰ªìÈáëÈ¢ùÔºàÊï∞ÈáèÔºâÂÖ®ÈÉ®Êç¢ÁÆó‰∏∫USDÈáëÈ¢ùÔºåÁÑ∂ÂêéÊâçËÉΩËøõË°åÊ±áÊÄª„ÄÇÊØè‰∏Ä‰∏™‰∫§ÊòìÂØπÔºàPairÔºâÂ∞±ÊòØ‰∏Ä‰∏™Áã¨Á´ãÁöÑÊµÅÂä®ËµÑÈáëÊ±†ÔºàPoolÔºâÔºåÊúâÂÖ∂‰∏ìÂ±ûÁöÑÂêàÁ∫¶Âú∞ÂùÄ„ÄÇTVLÂ∞±ÊòØËøô‰∫õÂêàÁ∫¶Âú∞ÂùÄÂΩìÂâçÊåÅÊúâÁöÑÊâÄÊúâTokenÊåâUSDËÆ°‰ª∑ÁöÑÊÄªÈáëÈ¢ù„ÄÇË¶ÅËÆ°ÁÆóPool‰∏≠ÂΩìÂâçÊåÅÊúâÁöÑTokenÊï∞ÈáèÔºåÊàë‰ª¨ÂèØ‰ª•ÁªìÂêà`erc20`È≠îÊ≥ïË°®ÂàÜÁ±ª‰∏ãÁöÑ`evt_Transfer`Ë°®Êù•ÁªüËÆ°ÊØè‰∏™PoolÁöÑËΩ¨ÂÖ•„ÄÅËΩ¨Âá∫Êï∞Èáè‰ªéËÄåÂæóÂà∞ÂΩìÂâç‰ΩôÈ¢ù„ÄÇÊØè‰∏™PoolÈÉΩÂåÖÂê´‰∏§Áßç‰∏çÂêåÁöÑTokenÔºåÊàë‰ª¨ËøòÈúÄË¶ÅÂàÜÂà´Ëé∑ÂæóËøô‰∫õTokenÁöÑÂ∞èÊï∞‰ΩçÊï∞ÂíåÂØπÂ∫îÁöÑ‰ª∑Ê†º‰ø°ÊÅØ„ÄÇÂÖàÁúãÊü•ËØ¢‰ª£Á†ÅÔºö

```sql
with pool_created_detail as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_transfer_detail as (
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_arbitrum.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'arbitrum'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_arbitrum.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'arbitrum'

    union all
    
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_ethereum.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'ethereum'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_ethereum.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'ethereum'

    union all
    
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_optimism.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'optimism'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_optimism.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'optimism'

    union all
    
    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."to" as pool,
        cast(t.value as double) as amount_original
    from erc20_polygon.evt_Transfer t
    inner join pool_created_detail p on t."to" = p.pool
    where p.blockchain = 'polygon'

    union all

    select p.blockchain,
        t.contract_address,
        t.evt_block_time,
        t.evt_tx_hash,
        t."from" as pool,
        -1 * cast(t.value as double) as amount_original
    from erc20_polygon.evt_Transfer t
    inner join pool_created_detail p on t."from" = p.pool
    where p.blockchain = 'polygon'
),

token_list as (
    select distinct contract_address
    from token_transfer_detail
),

latest_token_price as (
    select contract_address, symbol, decimals, price, minute
    from (
        select row_number() over (partition by contract_address order by minute desc) as row_num, *
        from prices.usd
        where contract_address in ( 
                select contract_address from token_list 
            )
            and minute >= now() - interval '1' day
        order by minute desc
    ) p
    where row_num = 1
),

token_transfer_detail_amount as (
    select blockchain,
        d.contract_address,
        evt_block_time,
        evt_tx_hash,
        pool,
        amount_original,
        amount_original / pow(10, decimals) * price as amount_usd
    from token_transfer_detail d
    inner join latest_token_price p on d.contract_address = p.contract_address
)

select blockchain,
    sum(amount_usd) as tvl,
    (sum(sum(amount_usd)) over ()) / 1e9 as total_tvl
from token_transfer_detail_amount
where abs(amount_usd) < 1e9 -- Exclude some outlier values from Optimism chain
group by 1
```

‰∏äËø∞Êü•ËØ¢‰ª£Á†ÅËØ¥ÊòéÂ¶Ç‰∏ãÔºö

- CTE `pool_created_detail`ÂèñÂæóÂêÑÈìæÂàõÂª∫ÁöÑÊâÄÊúâÊµÅÂä®ËµÑÈáëÊ±†ÁöÑÊï∞ÊçÆ„ÄÇ
- CTE `token_transfer_detail` ÈÄöËøáÂÖ≥ËÅî `evt_Transfer`Ë°®Âíå`pool_created_detail`ÔºåÁ≠õÈÄâÂá∫ÊâÄÊúâUniswapÊµÅÂä®ËµÑÈáëÊ±†ÁöÑTokenËΩ¨ÂÖ•„ÄÅËΩ¨Âá∫Êï∞ÊçÆ„ÄÇ
- CTE `token_list` Á≠õÈÄâÂá∫ÊâÄÊúâ‰∫§ÊòìÂØπ‰∏≠Áî®Âà∞ÁöÑToken ÂàóË°®„ÄÇ
- CTE `latest_token_price` ËÆ°ÁÆóËøô‰∫õTokenÁöÑÂΩìÂâç‰ª∑Ê†º„ÄÇÂõ†‰∏∫`prices.usd`‰∏≠‰ª∑Ê†ºÊï∞ÊçÆÂèØËÉΩ‰ºöÊúâÊó∂Èó¥Âª∂ËøüÔºåÊàë‰ª¨ÂÖàÂèñÂá∫ÊúÄËøë1Â§©ÂÜÖÁöÑÊï∞ÊçÆÔºåÁÑ∂ÂêéÁªìÂêà`row_number() over (partition by contract_address order by minute desc)`ËÆ°ÁÆóË°åÂè∑Âπ∂Âè™ËøîÂõûË°åÂè∑Á≠â‰∫é1ÁöÑË°åÔºåËøô‰∫õÂ∞±ÊòØÂêÑ‰∏™TokenÁöÑÊúÄÊñ∞‰ª∑Ê†ºËÆ∞ÂΩï„ÄÇ
- CTE `token_transfer_detail_amount`‰∏≠Êàë‰ª¨Áî®`token_transfer_detail`ËΩ¨ÂÖ•ËΩ¨Âá∫ÊòéÁªÜÂÖ≥ËÅî`latest_token_price`ÊúÄÊñ∞‰ª∑Ê†ºÊï∞ÊçÆÂæóÂà∞ËΩ¨ÂÖ•ËΩ¨Âá∫TokenÁöÑUSDÈáëÈ¢ù„ÄÇ
- ÊúÄÂêéËæìÂá∫ÁªìÊûúÁöÑÊü•ËØ¢‰∏≠ÔºåÊàë‰ª¨Ê±áÊÄªÁöÑÊØè‰∏™Âå∫ÂùóÈìæÁöÑÂΩìÂâçTVLÂ∑≤ÁªèÊâÄÊúâÈìæÁöÑTVLÊÄªÂíå„ÄÇ

ÂàÜÂà´ÁîüÊàê‰∏Ä‰∏™Pie Chart Âíå‰∏Ä‰∏™Counter ÂõæË°®„ÄÇÊ∑ªÂä†Âà∞Êï∞ÊçÆÁúãÊùøÂêéÊòæÁ§∫Â¶Ç‰∏ãÔºö

![image_07.png](img/image_07.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1929279](https://dune.com/queries/1929279)

### ÊØèÊó•TVLÂØπÊØîÂàÜÊûê

ÂΩìÈúÄË¶ÅÂØπÊØîÂàÜÊûêÊØèÊó•TVLÈáëÈ¢ùÊó∂ÔºåÊàë‰ª¨ÈúÄË¶ÅÂÖàÂ¢ûÂä†‰∏Ä‰∏™Êó•ÊúüÂàÜÁªÑÁª¥Â∫¶„ÄÇ‰ΩÜÊòØÊ≠§Êó∂ÁªüËÆ°Âá∫ÁöÑÂÖ∂ÂÆûÊòØÊØèÊó•ÁöÑTVLÂèòÂåñÂÄºÔºåÂπ∂‰∏çÊòØÊØèÊó•‰ΩôÈ¢ù„ÄÇÊàë‰ª¨ËøòÈúÄË¶ÅÊåâÊó•ÊúüÂ∞Ü‰ΩôÈ¢ùËøõË°åÁ¥ØÂä†ÔºåÊâçËÉΩÂæóÂà∞Ê≠£Á°ÆÁöÑÊØèÊó•‰ΩôÈ¢ù„ÄÇ

```sql
with pool_created_detail as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_transfer_detail as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_list as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

latest_token_price as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_transfer_detail_amount as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

tvl_daily as (
    select date_trunc('day', evt_block_time) as block_date,
        blockchain,
        sum(amount_usd) as tvl_change
    from token_transfer_detail_amount
    where abs(amount_usd) < 1e9 -- Exclude some outlier values from Optimism chain
    group by 1, 2
)

select block_date,
    blockchain,
    tvl_change,
    sum(tvl_change) over (partition by blockchain order by block_date) as tvl
from tvl_daily
where block_date >= date('2022-01-01')
    and block_date < date('2023-01-01')
order by 1, 2
```

Êàë‰ª¨ÂèëÁé∞OptmismÈìæÂ≠òÂú®ÈÉ®ÂàÜÂºÇÂ∏∏Êï∞ÊçÆÔºåÊâÄ‰ª•‰∏äÈù¢ÁöÑÊü•ËØ¢‰∏≠Ê∑ªÂä†‰∫ÜÊù°‰ª∂`abs(amount_usd) < 1e9`Êù•ÊéíÈô§„ÄÇ‰∏∫Ëøô‰∏™Êü•ËØ¢ÁîüÊàê‰∏Ä‰∏™Area ChartÂõæË°®„ÄÇÂä†ÂÖ•Êï∞ÊçÆÁúãÊùøÔºåÊòæÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÔºö

![image_08.png](img/image_08.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1933439](https://dune.com/queries/1933439)


## TVLÊúÄÈ´òÁöÑÊµÅÂä®ËµÑÈáëÊ±†

Âè™ÈúÄÊåâÁÖßÊµÅÂä®ËµÑÈáëÊ±†ÁöÑÂêàÁ∫¶Âú∞ÂùÄËøõË°åÊ±áÊÄªÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÁªüËÆ°Âá∫ÊØè‰∏™ËµÑÈáëÊ±†ÂΩìÂâçÁöÑTVL„ÄÇÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥Êõ¥Áõ¥ËßÇÂú∞ÂØπÊØîÂÖ∑‰ΩìÁöÑ‰∫§ÊòìÂØπÔºà‰ΩøÁî®‰∫§ÊòìÂØπÁöÑToken SymbolÔºâÔºåÂèØ‰ª•ÂÖ≥ËÅî`tokens.erc20`È≠îÊ≥ïË°®Êù•ÁªÑÂêàÁîüÊàê‰∫§ÊòìÂØπÂêçÁß∞„ÄÇUniswapÊîØÊåÅÂêå‰∏Ä‰∏™‰∫§ÊòìÂØπÊúâÂ§ö‰∏™‰∏çÂêåÁöÑÊúçÂä°Ë¥πË¥πÁéáÔºà‰∏çÂêåÁöÑPool AddressÔºâÔºåÊâÄ‰ª•Êàë‰ª¨ÈúÄË¶ÅÊîπÊàêÊåâ‰∫§ÊòìÂØπÂêçÁß∞Ê±áÊÄª„ÄÇSQLÂ¶Ç‰∏ãÔºö

```sql
with pool_created_detail as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_transfer_detail as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_list as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

latest_token_price as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

token_transfer_detail_amount as (
    -- Ê≠§Â§ÑSQLÂêå‰∏ä
),

top_tvl_pools as (
    select pool,
        sum(amount_usd) as tvl
    from token_transfer_detail_amount
    where abs(amount_usd) < 1e9 -- Exclude some outlier values from Optimism chain
    group by 1
    order by 2 desc
    limit 200
)

select concat(tk0.symbol, '-', tk1.symbol) as pool_name,
    sum(t.tvl) as tvl
from top_tvl_pools t
inner join pool_created_detail p on t.pool = p.pool
inner join tokens.erc20 as tk0 on p.token0 = tk0.contract_address
inner join tokens.erc20 as tk1 on p.token1 = tk1.contract_address
group by 1
order by 2 desc
limit 100
```

Êàë‰ª¨ÂèØ‰ª•ÂàÜÂà´ÁîüÊàê‰∏Ä‰∏™Bar ChartÂõæË°®Âíå‰∏Ä‰∏™Table ÂõæË°®ÔºåËæìÂá∫TVLÈîÅ‰ªìÈáëÈ¢ùÊúÄÂ§öÁöÑÊµÅÂä®ËµÑÈáëÊ±†Êï∞ÊçÆ„ÄÇ

![image_09.png](img/image_09.png)

Êü•ËØ¢ÈìæÊé•Ôºö
- [https://dune.com/queries/1933442](https://dune.com/queries/1933442)

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch20/ch19-useful-metrics.md">
# ÂêÑÁ±ªÂ∏∏ËßÅÊåáÊ†áÂàÜÊûê

## ËÉåÊôØÁü•ËØÜ

Âú®ÂâçÈù¢ÁöÑÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨Â≠¶‰π†‰∫ÜËÆ∏Â§öÂÖ≥‰∫éÊï∞ÊçÆË°®ÂíåSQLÊü•ËØ¢ËØ≠Âè•ÁöÑÁü•ËØÜ„ÄÇÂáÜÁ°ÆËßÑËåÉÂú∞Ê£ÄÁ¥¢ÁªüËÆ°Âá∫ÊâÄÈúÄÊï∞ÊçÆÊòØ‰∏ÄÂêçÂêàÊ†ºÂàÜÊûêÂ∏àÁöÑÂøÖÂ§áÊäÄËÉΩ„ÄÇ‰∏éÊ≠§ÂêåÊó∂ÔºåÊ≠£Á°ÆÂú∞ËÆ§ËØÜÂíåËß£ËØªËøô‰∫õÊï∞ÊçÆÊåáÊ†á‰πüÂçÅÂàÜÂÖ≥ÈîÆ„ÄÇÂè™ÊúâÂØπÊï∞ÊçÆÊåáÊ†áÊúâË∂≥Â§üÊ∑±ÂàªÁöÑÁêÜËß£ÔºåÂÆÉÊâçËÉΩÂØπÊàë‰ª¨ÁöÑÂÜ≥Á≠ñÊèê‰æõÂº∫ÂäõÁöÑÊîØÊåÅ„ÄÇ

Âú®ÁúãÂÖ∑‰ΩìÁöÑÊåáÊ†á‰πãÂâçÔºåÊàë‰ª¨ÂÖàÊÄùËÄÉ‰∏Ä‰∏ãÔºåÊàë‰ª¨‰∏∫‰ªÄ‰πàÈúÄË¶ÅÊï∞ÊçÆÊåáÊ†áÂë¢ÔºüÁÆÄÂçïÂú∞ËØ¥ÔºåÊåáÊ†áÂ∞±ÊòØËÉΩÂ§üÂèçÊò†‰∏ÄÁßçÁé∞Ë±°ÁöÑÊï∞Â≠óÔºåÊØîÂ¶ÇÊüê‰∏™NFTÁöÑÂú∞Êùø‰ª∑ÔºåÊüêÂÆ∂DEXÁöÑÊó•Ê¥ªË∑É‰∫§ÊòìÊï∞„ÄÇÊåáÊ†áÂèØ‰ª•Áõ¥Êé•ÂèçÊò†Êàë‰ª¨Á†îÁ©∂ÂØπË±°ÁöÑÁä∂ÂÜµÔºå‰∏∫Áõ∏Â∫îÂÜ≥Á≠ñÊèê‰æõÊï∞ÊçÆÊîØÊíëÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøá‰πãÂâçÂ≠¶‰π†ÁöÑÊï∞ÊçÆË°®ÂíåSQLËØ≠Âè•Áü•ËØÜÔºåÊûÑÂª∫„ÄÅË∞ÉÁî®„ÄÅÂàÜÊûêËøô‰∫õÊåáÊ†áÔºåËææÂà∞‰∫ãÂçäÂäüÂÄçÁöÑÊïàÊûú„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÊåáÊ†áÔºåÊàë‰ª¨Ëé∑ÂèñÁöÑ‰ø°ÊÅØÂ∞±‰ºöÊòæÂæóÂæà‰π±ÔºåÊàë‰ª¨ËÉΩÂ§ü‰ªé‰∏≠Ëé∑ÂæóÁöÑÊ¥ûÂØüÂ∞±Â∞ë„ÄÇ

ÂÖ∑‰ΩìÂà∞Âå∫ÂùóÈìæÈ¢ÜÂüüÔºåËôΩÁÑ∂Êúâ‰∫õÊåáÊ†á‰∏éÈáëËûçÂ∏ÇÂú∫ÁöÑÊåáÊ†áÁ±ª‰ººÔºå‰ΩÜÂÆÉ‰πüÊúâÁõ∏ÂΩì‰∏ÄÈÉ®ÂàÜÁâπÊúâÁöÑÊåáÊ†áÔºåÊØîÂ¶ÇÊØîÁâπÂ∏ÅÂ∏ÇÂÄºÂç†ÊØîÔºàBitcoin DominanceÔºâÔºå‰∫§ÊòìÊâÄ‰∏ÉÊó•ÊµÅÂÖ•ÈáèÔºàAll Exchanges Inflow Mean-MA7ÔºâÁ≠â„ÄÇÂú®Êú¨ÊïôÁ®ã‰∏≠ÔºåÊàë‰ª¨ÂÖàÊù•Â≠¶‰π†‰ª•‰∏ãÂá†‰∏™Â∏∏ËßÅÊåáÊ†áÂíåÂÆÉ‰ª¨ÁöÑËÆ°ÁÆóÊñπÊ≥ïÔºö

- ÊÄªÈîÅ‰ªìÈáè Total Value Locked (TVL)
- ÊµÅÈÄöÊÄªÈáè Circulating Supply
- ÊÄªÂ∏ÇÂÄº Market Cap 
- Êó•/ÊúàÊ¥ªË∑ÉÁî®Êà∑ Daily / Monthly Active User (DAU / MAU)
- Êó•/ÊúàÊñ∞Áî®Êà∑Êï∞ Daily / Monthly New User


## ÊÄªÈîÅ‰ªìÈáèTotal Value Locked (TVL)
Êàë‰ª¨Êù•ÁúãÊàë‰ª¨‰ªäÂ§©Â≠¶‰π†ÁöÑÁ¨¨‰∏Ä‰∏™ÊåáÊ†á - ÊÄªÈîÅ‰ªìÈáèTotal Value Locked (TVL)„ÄÇ ÂÆÉÊèèËø∞‰∫Ü‰∏Ä‰∏™ÂçèËÆÆ‰∏≠ÈîÅÂÆöÁöÑÊâÄÊúâ‰ª£Â∏Å‰ª∑ÂÄºÁöÑÊÄªÂíåÔºåËØ•ÂçèËÆÆÂèØ‰ª•ÊòØDex,ÂÄüË¥∑Âπ≥Âè∞,‰πüÂèØ‰ª•ÊòØ‰æßÈìæÔºåL2‰∫åÂ±ÇÁΩëÁªúÁ≠âÁ≠â„ÄÇTVLÊèèËø∞‰∫ÜËØ•ÂçèËÆÆÁöÑÊµÅÂä®ÊÄßÔºåÂêåÊó∂‰πüÂèçÊò†‰∫ÜÂÖ∂ÂèóÊ¨¢ËøéÁ®ãÂ∫¶‰ª•ÂèäÁî®Êà∑ÁöÑ‰ø°ÂøÉ„ÄÇ

ÊØîÂ¶ÇÊàë‰ª¨Êù•Áúã‰∏Ä‰∏ãDEXÁöÑTVLÊéíË°åÔºö

![DEX TVL](img/image_01.png)

‰ª•Âèä‰∫åÂ±ÇÁΩëÁªúL2ÁöÑTVLÊéíË°åÔºö

![L2TVL](img/image_02.png)

ÊéíÂêçÈù†ÂâçÁöÑÂùáÊòØÁÉ≠Â∫¶ÊØîËæÉÈ´òÁöÑÂçèËÆÆ„ÄÇ

TVLÁöÑËÆ°ÁÆóÈÄªËæëÊØîËæÉÁÆÄÂçïÔºåÂç≥ÁªüËÆ°Âá∫ÂçèËÆÆ‰∏≠ÊâÄÊúâÁõ∏ÂÖ≥‰ª£Â∏ÅÁöÑÊï∞ÁõÆÔºåÂÜç‰πò‰ª•ÊØèÁßç‰ª£Â∏ÅÁöÑ‰ª∑Ê†ºÔºåÊúÄÂêéÊ±ÇÂíåÂæóÂá∫„ÄÇËøôÈáåÊàë‰ª¨‰ª•ArbitrumÈìæ‰∏äÁöÑ‰∏Ä‰∏™DEXÈ°πÁõÆAuragi‰∏∫‰æãËøõË°åËØ¥Êòé„ÄÇDEXÈ°πÁõÆÁöÑTVLÈÄöËøáÂÖ∂‰∏≠ÁöÑÊµÅÂä®ÊÄßÊ±†PoolÁöÑ‰ΩôÈ¢ùÊù•‰ΩìÁé∞„ÄÇ‰∏∫‰∫ÜËÆ°ÁÆóËøô‰∏™È°πÁõÆÊØè‰∏ÄÂ§©ÁöÑTVLÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÁªüËÆ°Âá∫ÂÆÉÊØè‰∏ÄÂ§©ÁöÑÊâÄÊúâPair‰∏≠Áõ∏ÂÖ≥‰ª£Â∏ÅÁöÑ‰ΩôÈ¢ùÊï∞ÈáèÔºå‰ª•Âèä‰ª£Â∏ÅÂú®ËØ•Êó∂Èó¥ÁÇπÁöÑ‰ª∑Ê†ºÔºåÁÑ∂ÂêéÁõ∏‰πòÂæóÂà∞‰ª•USDËÆ°ÁÆóÁöÑÈáëÈ¢ù„ÄÇ

‰∏∫‰∫ÜÂæóÂà∞ÊØè‰∏ÄÂ§©ÁöÑÂêÑ‰∏™PairÁöÑ‰ª£Â∏Å‰ΩôÈ¢ùÔºåÊàë‰ª¨Ë¶ÅÂÖàÊï¥ÁêÜÂá∫ÊâÄÊúâÁöÑ‰∫§ÊòìÊòéÁªÜËÆ∞ÂΩïÔºö

```sql
with token_pairs as (
    select 
        coalesce(k1.symbol, 'AGI') || '-' || coalesce(k2.symbol, 'AGI') as pair_name,
        p.pair,
        p.evt_block_time,
        p.token0,
        p.token1,
        p.stable
    from auragi_arbitrum.PairFactory_evt_PairCreated p
    left join tokens.erc20 k1 on p.token0 = k1.contract_address and k1.blockchain = 'arbitrum'
    left join tokens.erc20 k2 on p.token1 = k1.contract_address and k2.blockchain = 'arbitrum'
),

token_transfer_detail as (
    select date_trunc('minute', evt_block_time) as block_date,
        evt_tx_hash as tx_hash,
        contract_address,
        "to" as user_address,
        cast(value as decimal(38, 0)) as amount_raw
    from erc20_arbitrum.evt_Transfer
    where "to" in (select pair from token_pairs)
        and evt_block_time >= date('2023-04-04')

    union all
    
    select date_trunc('minute', evt_block_time) as block_date,
        evt_tx_hash as tx_hash,
        contract_address,
        "from" as user_address,
        -1 * cast(value as decimal(38, 0)) as amount_raw
    from erc20_arbitrum.evt_Transfer
    where "from" in (select pair from token_pairs)
        and evt_block_time >= date('2023-04-04')
),

token_price as (
    select date_trunc('minute', minute) as block_date,
        contract_address,
        decimals,
        symbol,
        avg(price) as price
    from prices.usd
    where blockchain = 'arbitrum'
        and contract_address in (select distinct contract_address from token_transfer_detail)
        and minute >= date('2023-04-04')
    group by 1, 2, 3, 4
    
    union all
    
    -- AGI price from swap trade
    select date_trunc('minute', block_time) as block_date,
        0xFF191514A9baba76BfD19e3943a4d37E8ec9a111 as contract_address,
        18 as decimals,
        'AGI' as symbol,
        avg(case when token_in_address = 0xFF191514A9baba76BfD19e3943a4d37E8ec9a111 then token_in_price else token_out_price end) as price
    from query_2337808
    group by 1, 2, 3, 4
)

select p.symbol,
    d.block_date,
    d.tx_hash,
    d.user_address,
    d.contract_address,
    d.amount_raw,
    (d.amount_raw / power(10, p.decimals) * p.price) as amount_usd
from token_transfer_detail d
inner join token_price p on d.contract_address = p.contract_address and d.block_date = p.block_date
```

‰∏äÈù¢ÁöÑÊü•ËØ¢ÈÄªËæëÂ¶Ç‰∏ãÔºö
- ÂÖàÂú®`token_pairs`‰∏≠ÂæóÂà∞Ëøô‰∏™È°πÁõÆÁöÑÊâÄÊúâ‰∫§ÊòìÂØπÔºàPairÔºâ„ÄÇ
- ÁªìÂêà`evt_Transfer`Ë°®ÔºåÊü•ËØ¢Âá∫ÊØè‰∏Ä‰∏™‰∫§ÊòìÂØπÁöÑËµÑÈáëËΩ¨ÂÖ•ËΩ¨Âá∫ËØ¶ÊÉÖ„ÄÇ
- Âú®`token_price`‰∏≠ËÆ°ÁÆóÂá∫Âì•Âì•TokenÁöÑÂΩìÂâç‰ª∑Ê†º„ÄÇÂõ†‰∏∫Ëøô‰∏™ÊòØ‰∏Ä‰∏™ÊØîËæÉÊñ∞ÁöÑTokenÔºåDuneÂèØËÉΩÊ≤°ÊúâÂÆÉÁöÑ‰ª∑Ê†ºÊï∞ÊçÆÔºåÊâÄ‰ª•Êàë‰ª¨‰ΩøÁî®‰∫Ü‰∫§ÊòìÊï∞ÊçÆÊù•Êç¢ÁÆó‰ª∑Ê†º„ÄÇ‰∫§ÊòìÊï∞ÊçÆÁöÑËØ¶ÁªÜÂàóË°®Âú®Âè¶Â§ñ‰∏Ä‰∏™Êü•ËØ¢‰∏≠ÔºåËøôÈáå‰ΩøÁî®Query of QueryÁöÑÊñπÂºèÊù•ÂºïÁî®„ÄÇ
- ÊúÄÂêéÊàë‰ª¨Â∞Ü‰∫§ÊòìÊòéÁªÜÂíå‰ª∑Ê†º‰ø°ÊÅØÂÖ≥ËÅîÔºåËÆ°ÁÆóÂá∫ÊØè‰∏ÄÁ¨î‰∫§ÊòìÁöÑUSDÈáëÈ¢ù„ÄÇ

Âú®‰∏äÈù¢ÁöÑ‰∫§ÊòìËØ¶ÊÉÖÊü•ËØ¢ÁªìÊûúÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•Êù•ÁªüËÆ°ËÆ°ÁÆóÊØè‰∏ÄÂ§©ÁöÑTVL‰∫Ü„ÄÇ

È¶ñÂÖàÊàë‰ª¨Âú®`date_series`‰∏≠ÁîüÊàê‰∏Ä‰∏™Êó•ÊúüÊó∂Èó¥Â∫èÂàó„ÄÇËÄÉËôëÂà∞ËøôÊòØ‰∏Ä‰∏™ÊØîËæÉÊñ∞ÁöÑÈ°πÁõÆÔºåÊàë‰ª¨ÊåâÂ∞èÊó∂Á∫¨Â∫¶ËøõË°åÁªüËÆ°„ÄÇÂ¶ÇÊûúÈ°πÁõÆ‰∏äÁ∫øÊó∂Èó¥Â∑≤ÁªèË∂≥Â§ü‰πÖÔºåÂª∫ËÆÆÊåâÂ§©ËøõË°åÁªüËÆ°„ÄÇ

ÁÑ∂ÂêéÂú®`pool_balance_change`‰∏≠ÔºåÁªìÂêà‰∏äÈù¢ÁöÑ‰∫§ÊòìËØ¶ÊÉÖÊï∞ÊçÆÔºåÊàë‰ª¨Êï¥ÁêÜÂá∫ÁæéÂõΩTokenÊØè‰∏Ä‰∏™Â∞èÊó∂ÁöÑ‰ΩôÈ¢ùÂèòÂåñÈáëÈ¢ù„ÄÇ

Êé•‰∏ãÊù•Âú®`pool_balance_summary`‰∏≠ÔºåÊàë‰ª¨ÊåâÊó∂Èó¥ÊéíÂ∫èÊ±áÊÄªÂá∫ÊØè‰∏™TokenÁöÑÁ¥ØÁßØ‰ΩôÈ¢ù„ÄÇËøôÈáåÂêåÊó∂‰ΩøÁî®`lead()`ÂáΩÊï∞ËÆ°ÁÆóÂá∫ÊØè‰∏Ä‰∏™tokenÊØè‰∏Ä‰∏™Êó∂Èó¥ÊÆµÂ≠òÂú®ÂØπÂ∫îÂêéÁª≠‰∫§ÊòìËÆ∞ÂΩïÁöÑ‰∏ã‰∏Ä‰∏™Êó∂Èó¥ÁÇπ„ÄÇ

ÊúÄÂêéÔºåÊàë‰ª¨Â∞ÜÊó∂Èó¥Â∫èÂàóÂíåÊØè‰∏Ä‰∏™Â∞èÊó∂ÁöÑÁ¥ØÁßØ‰ΩôÈ¢ùËøõË°åÂÖ≥ËÅîÔºåË°•Ë∂≥Áº∫Â§±‰∫§ÊòìÊï∞ÊçÆÁöÑÊó∂Èó¥ÊÆµÁöÑÂÄº„ÄÇËØ∑Ê≥®ÊÑèËøôÈáåÁöÑÂÖ≥ËÅîÊù°‰ª∂Ôºö`inner join date_series d on p.block_date <= d.block_date and d.block_date < p.next_date`„ÄÇËøôÈáå‰ΩøÁî®‰∫Ü‰∏§‰∏™Êù°‰ª∂ÔºåÈôêÂÆöÁ¥ØËÆ°‰ΩôÈ¢ùÁöÑÊó•ÊúüÊó∂Èó¥ÂøÖÈ°ªÂ∞è‰∫éÁ≠â‰∫éÊó•ÊúüÂ∫èÂàóÁöÑÊó•ÊúüÊó∂Èó¥ÂÄºÔºåÂêåÊó∂Â∫èÂàóÁöÑÊó•ÊúüÊó∂Èó¥ÂÄºÂøÖÈ°ªÂ∞è‰∫é‰∏ã‰∏Ä‰∏™ÊúâËÆ∞ÂΩïÁöÑ‰ΩôÈ¢ùÁöÑÊó•ÊúüÊó∂Èó¥ÂÄº„ÄÇËøôÊòØ‰∏Ä‰∏™ÂæàÂ∏∏ËßÅÁöÑÂ§ÑÁêÜÊäÄÂ∑ß„ÄÇÂõ†‰∏∫Âπ∂‰∏çÊòØÊâÄÊúâÁöÑTokenÂú®ÊØè‰∏Ä‰∏™Êó∂Èó¥ÊÆµÈÉΩÊúâ‰∫§ÊòìÔºåÂ¶ÇÊûúÈÅáÂà∞Ê≤°ÊúâÂèëÁîü‰∫§ÊòìÁöÑÊó∂Èó¥ÊÆµÔºåÊàë‰ª¨ÈúÄË¶ÅÁî®Ââç‰∏Ä‰∏™Êó∂Èó¥ÊÆµÁöÑ‰ΩôÈ¢ùÊù•‰ª£Ë°®ÂÖ∂Âú®ÂΩìÂâçÊó∂Èó¥ÊÆµÁöÑ‰ΩôÈ¢ù„ÄÇËøô‰∏™Â∫îËØ•‰∏çÈöæÁêÜËß£ÔºåÂõ†‰∏∫‚ÄúÂΩìÂâçÊó∂Èó¥ÊÆµ‚ÄùÂÜÖÊ≤°ÊúâÂèëÁîüÊñ∞ÁöÑÂèòÂåñÔºåÊâÄ‰ª•‰ΩôÈ¢ùËá™ÁÑ∂Ë∑ü‰∏ä‰∏Ä‰∏™Êó∂Èó¥ÊÆµÁõ∏Âêå„ÄÇ

Êü•ËØ¢‰ª£Á†ÅÂ¶Ç‰∏ãÔºö

```sql
with date_series as (
    select block_date
    from unnest(sequence(timestamp '2023-04-01 00:00:00', localtimestamp, interval '1' hour)) as tbl(block_date)
),

pool_balance_change as (
    select symbol,
        date_trunc('hour', block_date) as block_date,
        sum(amount_usd) as amount
    from query_2339248
    group by 1, 2
),

pool_balance_summary as (
    select symbol,
        block_date,
        sum(amount) over (partition by symbol order by block_date) as balance_amount,
        lead(block_date, 1, current_date) over (partition by symbol order by block_date) as next_date
    from pool_balance_change
    order by 1, 2
)

select d.block_date,
    p.symbol,
    p.balance_amount
from pool_balance_summary p
inner join date_series d on p.block_date <= d.block_date and d.block_date < p.next_date
order by 1, 2
```

ËøôÊ†∑Êàë‰ª¨Â∞±ËÉΩÂ§üÊääTVLÁöÑÂèòÂåñÂëàÁé∞Âá∫Êù•Ôºö

![tvl](img/image_03.png)

‰ª•‰∏äÊü•ËØ¢ÁöÑÈìæÊé•Ôºö
- [https://dune.com/queries/2339317](https://dune.com/queries/2339317)
- [https://dune.com/queries/2339248](https://dune.com/queries/2339248)
- [https://dune.com/queries/2337808](https://dune.com/queries/2337808)

Âè¶Â§ñ‰∏Ä‰∏™ËÆ°ÁÆóTVlÁöÑ‰æãÂ≠êÔºö[https://dune.com/queries/1059644/1822157](https://dune.com/queries/1059644/1822157)

## ÊµÅÈÄöÊÄªÈáè Circulating Supply

ÊµÅÈÄöÊÄªÈáèÊòØÂΩìÂâçÂ∏ÇÂú∫‰∏≠‰ª•ÂèäÊåÅÂ∏ÅËÄÖÊéåÊè°ÁöÑÊµÅÈÄöÁöÑÂä†ÂØÜË¥ßÂ∏ÅÊï∞Èáè„ÄÇÂÆÉ‰∏éÊÄª‰æõÂ∫îÈáè(Total Supply)‰∏çÂêåÔºåÂÆÉ‰∏ç‰ºöÂ∞ÜÊó†Ê≥ï‰∫§ÊòìÊµÅÈÄöÁöÑÈÉ®ÂàÜÁ∫≥ÂÖ•ÁªüËÆ°ÔºåÊØîÂ¶ÇË¢´ÈîÅÂÆöËÄåÊó†Ê≥ï‰∫§ÊòìÁöÑË¥ßÂ∏ÅÊï∞Èáè„ÄÇÁî±‰∫éËøôÈÉ®ÂàÜÊó†Ê≥ïÊµÅÈÄöÁöÑÂä†ÂØÜË¥ßÂ∏ÅÈÄöÂ∏∏Âπ∂‰∏ç‰ºöÂΩ±ÂìçÂÖ∂‰ª∑Ê†ºÔºåÊâÄ‰ª•ÊµÅÈÄöÊÄªÈáè‰Ωú‰∏∫‰ª£Â∏ÅÊï∞ÈáèÁöÑÂ∫¶ÈáèËæÉÊÄª‰æõÂ∫îÈáèÊõ¥‰∏∫Â∏∏Áî®„ÄÇÂØπ‰∫é‰∏çÂêåÁöÑÂä†ÂØÜË¥ßÂ∏ÅÔºåÂÖ∂ËÆ°ÁÆóÊñπÂºèÊúâÊâÄ‰∏çÂêå„ÄÇÊØîÂ¶Ç‰∏Ä‰∫õÁ∫øÊÄßÈáäÊîæÁöÑ‰ª£Â∏ÅÔºå‰ªñÁöÑ‰æõÂ∫îÈáèÈöèÊó∂Èó¥Â¢ûÂä†„ÄÇÂèàÂ¶Ç‰∏Ä‰∫õÊúâÈÄöÁº©ÁáÉÁÉßÊú∫Âà∂ÁöÑ‰ª£Â∏ÅÔºåÊàë‰ª¨Âú®ËÆ°ÁÆóÊµÅÈÄöÊÄªÈáèÁöÑÊó∂ÂÄôÂ∞±Ë¶ÅÂáèÂéªËøô‰∏ÄÈÉ®ÂàÜ„ÄÇËøôÈáåÊàë‰ª¨‰ª•ÊØîÁâπÂ∏Å‰∏∫‰æãÔºåËÆ°ÁÆóÂÆÉÁöÑÂΩìÂâçÊµÅÈÄöÊÄªÈáè„ÄÇ
ÊØîÁâπÂ∏ÅÁöÑÊµÅÈÄöÊÄªÈáèËÆ°ÁÆóÈÄªËæëËæÉ‰∏∫ÁÆÄÂçïÔºå‰ªéËµ∑ÂßãÂë®ÊúüÊØè‰∏™Âå∫Âùó‰∫ßÂá∫50ÊûöÔºåÊØè210000‰∏™Âå∫ÂùóËøõÂÖ•‰∏Ä‰∏™ÂáèÂçäÂë®Êúü„ÄÇÂü∫‰∫éÊ≠§ÔºåÊàë‰ª¨ÂèØ‰ª•ËÆ°ÁÆóÂá∫ÂÆÉÂΩìÂâçÁöÑÊµÅÈÄöÊÄªÈáèÔºö

```sql
SELECT SUM(50/POWER(2, ROUND(height/210000))) as Supply                      
FROM bitcoin.blocks
```


## ÊÄªÂ∏ÇÂÄº Market Cap 

‰ªäÂ§©Â≠¶‰π†ÁöÑÁ¨¨‰∏â‰∏™ÊåáÊ†áÊòØÊÄªÂ∏ÇÂÄº(Market Cap)„ÄÇÁõ∏‰ø°Â§ßÂÆ∂ÂØπËøô‰∏™ÊåáÊ†áÂπ∂‰∏çÈôåÁîü„ÄÇÂú®ËÇ°Á•®Â∏ÇÂú∫ÔºåÊÄªÂ∏ÇÂÄºÊòØÊåáÂú®ÊüêÁâπÂÆöÊó∂Èó¥ÂÜÖÊÄªËÇ°Êú¨Êï∞‰πò‰ª•ÂΩìÊó∂ËÇ°‰ª∑ÂæóÂá∫ÁöÑËÇ°Á•®ÊÄª‰ª∑ÂÄº„ÄÇÁõ∏Â∫îÁöÑÂú®Âå∫ÂùóÈìæÈ¢ÜÂüüÔºåÂÆÉÊòØ‰∏ÄÁßçÂä†ÂØÜË¥ßÂ∏ÅÁöÑÊµÅÈÄöÊÄªÈáè(Circulating SupplyÔºâ‰πò‰ª•ËØ•Âä†ÂØÜË¥ßÂ∏ÅÁöÑ‰ª∑Ê†ºÂæóÂá∫ÁöÑËØ•Âä†ÂØÜË¥ßÂ∏ÅÊÄª‰ª∑ÂÄº„ÄÇÂõ†Ê≠§ËÆ°ÁÆóÊÄªÂ∏ÇÂÄºÁöÑÂÖ≥ÈîÆÊòØËÆ°ÁÆóÂá∫Êàë‰ª¨ÂàöÂàöÂ≠¶‰π†ÁöÑÊåáÊ†á-ÊµÅÈÄöÊÄªÈáè„ÄÇÂΩìÊàë‰ª¨ËÆ°ÁÆóÂá∫‰∫ÜÊµÅÈÄöÊÄªÈáèÔºåÂÜç‰πò‰ª•ËØ•Âä†ÂØÜË¥ßÂ∏ÅÁöÑÂΩìÂâç‰ª∑Ê†ºÔºåÂ∞±ËÉΩÂæóÂá∫ÂÖ∂ÊÄªÂ∏ÇÂÄº„ÄÇ
Êàë‰ª¨ÁªßÁª≠‰ª•ÊØîÁâπÂ∏Å‰∏∫‰æãÔºåÂú®ËÆ°ÁÆóÂá∫ÂÖ∂ÊµÅÈÄöÊÄªÈáèÁöÑÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÂÜç‰πò‰ª•ÂÆÉÂΩìÂâçÁöÑ‰ª∑Ê†ºÂç≥ÂèØËé∑ÂæóÂÆÉÁöÑÊÄªÂ∏ÇÂÄºÔºö

```sql
SELECT SUM(50/POWER(2, ROUND(height/210000))) as Supply, 
       SUM(50/POWER(2, ROUND(height/210000)) * p.price) /POWER(10, 9) AS "Market Cap"
FROM bitcoin.blocks
INNER JOIN (
    SELECT price FROM prices.usd_latest
    WHERE symbol='BTC'
        AND contract_address IS NULL
) p ON TRUE
```

Êàë‰ª¨ÊúÄÂºÄÂßãÊèêÂà∞ÁöÑÊØîÁâπÂ∏ÅÂ∏ÇÂÄºÂç†ÊØîÔºàBitcoin DominanceÔºâÔºåÂ∞±ÊòØ‰ª•Ê≠§‰∏∫ÂàÜÂ≠êÔºåÁÑ∂Âêé‰ª•ÊâÄÊúâÂä†ÂØÜË¥ßÂ∏ÅÂ∏ÇÂÄº‰πãÂíå‰∏∫ÂàÜÊØçËÆ°ÁÆóÂá∫Êù•ÁöÑ„ÄÇ


## Êó•/ÊúàÊ¥ªË∑ÉÁî®Êà∑ Daily/Monthly Active User

‰ªäÂ§©Â≠¶‰π†ÁöÑ‰∏ã‰∏Ä‰∏™ÊåáÊ†áÊòØÊó•/ÊúàÊ¥ªË∑ÉÁî®Êà∑ (Daily/Monthly Active User,DAU/MAU)„ÄÇÁõ∏ÂØπ‰∫éÁªùÂØπ‰∫§ÊòìÊï∞È¢ùÔºåÊ¥ªË∑ÉÁî®Êà∑ÁöÑÊï∞ÁõÆÊõ¥ËÉΩÂèçÂ∫î‰∏Ä‰∏™ÂçèËÆÆÂèóÊ¨¢ËøéÁ®ãÂ∫¶„ÄÇÁî±‰∫éÂ∞ëÊï∞Áî®Êà∑ÁöÑÂ§ßÈ¢ù‰∫§‰∫íÂ∞±ÂèØ‰ª•ÊãâÈ´ò‰∫§ÊòìÊï∞È¢ùÔºåÊ¥ªË∑ÉÁöÑÁî®Êà∑Êï∞ÂèØ‰ª•Êõ¥ÂÆ¢ËßÇÁöÑÊèèËø∞ËØ•ÂçèËÆÆÁöÑÁÉ≠Â∫¶„ÄÇÂÆÉÁöÑËÆ°ÁÆóÊñπÂºèÊØîËæÉÁÆÄÂçïÔºåÊàë‰ª¨Âè™Ë¶ÅÊâæÂá∫‰∏éÊüê‰∏™ÂêàÁ∫¶‰∫§ÊòìÁöÑÈí±ÂåÖÂú∞ÂùÄÔºåÂπ∂ÊåâÂ§©/ÊúàÁªüËÆ°È¢ëÊï∞Âç≥ÂèØÂæóÂá∫„ÄÇ
Êàë‰ª¨‰ª•ÊúÄËøëÊØîËæÉÁÉ≠Èó®ÁöÑLens‰∏∫‰æãÔºö

```sql
with daily_count as (
    select date_trunc('day', block_time) as block_date,
        count(*) as transaction_count,
        count(distinct "from") as user_count
    from polygon.transactions
    where "to" = 0xdb46d1dc155634fbc732f92e853b10b288ad5a1d   -- LensHub
        and block_time >= date('2022-05-16')  -- contract creation date
    group by 1
    order by 1
)

select block_date,
    transaction_count,
    user_count,
    sum(transaction_count) over (order by block_date) as accumulate_transaction_count,
    sum(user_count) over (order by block_date) as accumulate_user_count
from daily_count
order by block_date
```

Êàë‰ª¨‰ΩøÁî®distinctÂáΩÊï∞ËÆ©ÊØè‰ΩçÁî®Êà∑ÊØèÂ§©Âè™‰ºöË¢´ÁªüËÆ°‰∏ÄÊ¨°„ÄÇÂú®ÁªüËÆ°ÊØèÊó•Ê¥ªË∑É‰∫∫Êï∞ÁöÑÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨Ëøò‰ΩøÁî® `sum` `over`ÂáΩÊï∞ÔºåÁªüËÆ°Âá∫‰∫ÜÁ¥ØËÆ°Áî®Êà∑Êï∞„ÄÇÂ¶ÇÊûúË¶ÅÁªüËÆ°ÊúàÂ∫¶Ê¥ªË∑ÉÁî®Êà∑Êï∞ÔºàMAUÔºâÔºåÂè™ÈúÄË¶ÅÊîπÊàê‰ΩøÁî®`date_trunc('month', block_time)` Êù•Ëé∑ÂèñÊØèÊúàÁ¨¨‰∏ÄÂ§©ÁöÑÊó•ÊúüÂπ∂ËøõË°åÊ±áÊÄªÁªüËÆ°Âç≥ÂèØ„ÄÇ

![user](img/image_04.png)

## Êó•/ÊúàÊñ∞Áî®Êà∑Êï∞ Daily / Monthly New User

Èô§‰∫ÜÂÖ≥Ê≥®Ê¥ªË∑ÉÁî®Êà∑Êï∞ÊçÆÂ§ñÔºåÊØèÊó•/ÊØèÊúàÊñ∞Â¢ûÁî®Êà∑Êï∞Èáè‰πüÊòØÈùûÂ∏∏Â∏∏ËßÅÁöÑ‰∏Ä‰∏™ÂàÜÊûêÊåáÊ†á„ÄÇÈÄöÂ∏∏Ôºå‰∏∫‰∫ÜÂæóÂà∞ÂáÜÁ°ÆÁöÑÊñ∞Â¢ûÁî®Êà∑Êï∞ÊçÆÔºåÊàë‰ª¨ÈúÄË¶ÅÂÖàËÆ°ÁÆóÂá∫ÊØè‰∏™Áî®Êà∑Âú∞ÂùÄÁ¨¨‰∏ÄÊ¨°‰∫§ÊòìÁöÑÊó•ÊúüÊó∂Èó¥ÔºåÊàñËÄÖÊî∂Âà∞/ÂèëÂá∫Á¨¨‰∏ÄÁ¨îËΩ¨Ë¥¶ËÆ∞ÂΩïÁöÑÊó•ÊúüÊó∂Èó¥ÔºåÁÑ∂ÂêéÂÜçÊåâÂ§©ÊàñËÄÖÊúàËøõË°åÁªüËÆ°ÂæóÂà∞Êñ∞Â¢ûÁî®Êà∑Êï∞Èáè„ÄÇËøôÈáåÊàë‰ª¨‰ª•ÁªüËÆ°OptimismÈìæ‰∏äÊØèÊó•Êñ∞Â¢ûÁî®Êà∑Êï∞ÈáèÁöÑÊü•ËØ¢‰∏∫‰æã„ÄÇ

```sql
with optimism_new_users as (
    SELECT "from" as address,
        min(block_time) as start_time
    FROM optimism.transactions
    GROUP BY 1
)

SELECT date_trunc('day', start_time) as block_date,
    count(n.address) as new_users_count
FROM optimism_new_users n
WHERE start_time >= date('2022-10-01')
GROUP BY 1
```

![new users](img/image_05.png)

ËøôÈáåÊúâ‰∏Ä‰∏™ÁªìÂêà‰∫ÜÊñ∞Áî®Êà∑Êï∞ÈáèÂíåÂÖ∑‰ΩìNFTÈ°πÁõÆÁî®Êà∑Êï∞ÊçÆÁªüËÆ°ÁöÑ[ÂÆûÈôÖÊ°à‰æã](https://dune.com/queries/1334302)„ÄÇ


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch21/ch20-network-analysis.md">
# Âå∫ÂùóÈìæÁΩëÁªúÂàÜÊûê

## ÂÜôÂú®ÂâçËæπ

ÊâÄÊúâÁöÑÂÖ¨ÈìæÊú¨Ë∫´Â∞±ÊòØ‰∏Ä‰∏™Â§ßÁöÑÁΩëÁªúÔºåÂàÜÊûêÈìæ‰∏äÊï∞ÊçÆÂ§ßÊ¶ÇÁéáÊòØÈÄÉ‰∏çÊéâÂÖ≥‰∫éÁΩëÁªúÁöÑÂàÜÊûê„ÄÇÂ∏∏Áî®ÁöÑÊï∞ÊçÆÂπ≥Âè∞ÊØîÂ¶ÇDuneÁé∞ÊúâÁöÑÂèØËßÜÂåñÂäüËÉΩÂÖ∂ÂÆûÁõÆÂâçÂæàÈöæÊØîËæÉÂ•ΩÂú∞ÂàªÁîªÂÖ¨Èìæ‰∏äÂêÑ‰∏™ËäÇÁÇπ‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇËøôÈáåÊàë‰ª¨‰ª•‰πãÂâç‰º†ÁöÑÊ≤∏Ê≤∏Êâ¨Êâ¨ÁöÑFTX"ÈªëÂÆ¢"Âú∞ÂùÄ(0x59ABf3837Fa962d6853b4Cc0a19513AA031fd32b)‰∏∫‰æãÂÅö‰∏Ä‰∫õÁΩëÁªúÂàÜÊûê(ÂÖ∑‰ΩìÊòØÈªëÂÆ¢ËøòÊòØÂ∑¥ÊãøÈ©¨ÊîøÂ∫úËøôÈáåÂ∞±‰∏çÁªÜÁ©∂‰∫Ü)ÔºåÂéªÁúã‰∏ãËøô‰∏™Âú∞ÂùÄ‰∏ãÁöÑETHÈÉΩÂéª‰∫ÜÂì™Èáå(ËøôÈáåÊàë‰ª¨Áúã‰ªéËøô‰∏™Âú∞ÂùÄÂæÄÂ§ñÁöÑ2Â±ÇÂÖ≥Á≥ª)

Êï¥‰∏™ËøáÁ®ã‰∏≠Áî®Âà∞ÁöÑ‰∏úË•ø

- DuneÔºöËé∑ÂèñÁΩëÁªúÈó¥ÂêÑ‰∏™Âú∞ÂùÄÈó¥ÁöÑÂéüÂßãÊï∞ÊçÆÔºåÂπ∂ÂØπ‰ªñ‰ª¨ÂÅöÂàùÊ≠•ÁöÑÂ§ÑÁêÜ
- Python
  - NetworkxÔºöÊòØÁî®pythonËØ≠Ë®ÄÁºñÂÜôÁöÑËΩØ‰ª∂ÂåÖÔºå‰æø‰∫éÁî®Êà∑ÂØπÂ§çÊùÇÁΩëÁªúËøõË°åÂàõÂª∫„ÄÅÊìç‰ΩúÂíåÂ≠¶‰π†„ÄÇÂà©Áî®networkxÂèØ‰ª•‰ª•Ê†áÂáÜÂåñÂíåÈùûÊ†áÂáÜÂåñÁöÑÊï∞ÊçÆÊ†ºÂºèÂ≠òÂÇ®ÁΩëÁªú„ÄÅÁîüÊàêÂ§öÁßçÈöèÊú∫ÁΩëÁªúÂíåÁªèÂÖ∏ÁΩëÁªú„ÄÅÂàÜÊûêÁΩëÁªúÁªìÊûÑ„ÄÅÂª∫Á´ãÁΩëÁªúÊ®°Âûã„ÄÅËÆæËÆ°Êñ∞ÁöÑÁΩëÁªúÁÆóÊ≥ï„ÄÅËøõË°åÁΩëÁªúÁªòÂà∂Á≠â„ÄÇ
    - Êõ¥Â§ö‰ø°ÊÅØÂèØ‰ª•ËÆøÈóÆÔºöhttps://networkx.org/
  - PlotlyÔºöÂÅöÂèØËßÜÂåñÂæàÂ•ΩÁî®ÁöÑÂåÖÔºåÂèØ‰ª•ÁîüÊàêÂèØ‰∫§‰∫íÁöÑHTMLÊñá‰ª∂„ÄÇÂè¶Â§ñËøòÊúâ‰∏Ä‰∏™‰∏é‰πãÈÖçÂêàÁöÑÂâçÁ´ØÊ°ÜÊû∂DASHÔºåÂØπÂ∑•Á®ãËÉΩÂäõÊ≤°ÊúâÈÇ£‰πàÂá∫‰ºóÁöÑÊï∞ÊçÆÂàÜÊûêÂ∏àÈùûÂ∏∏ÂèãÂ•Ω„ÄÇ
    - Êõ¥Â§ö‰ø°ÊÅØÂèØ‰ª•ËÆøÈóÆÔºöhttps://plotly.com/
  - PandasÔºöÊúÄÂ∏∏ËßÅÁöÑÂ§ÑÁêÜÊï∞ÊçÆÁöÑpythonÂåÖÔºåÊèê‰æõ‰∫ÜÂ§ßÈáèËÉΩ‰ΩøÊàë‰ª¨Âø´ÈÄü‰æøÊç∑Âú∞Â§ÑÁêÜÊï∞ÊçÆÁöÑÂáΩÊï∞ÂíåÊñπÊ≥ï„ÄÇ
    - Êõ¥Â§ö‰ø°ÊÅØÂèØ‰ª•ËÆøÈóÆÔºöhttps://pandas.pydata.org/
- Etherscan APIÔºöETH BalanceÂú®dune‰∏äÁÆóËµ∑Êù•Â§™È∫ªÁÉ¶‰∫ÜÔºåÊØèÊ¨°ÈÉΩË¶ÅÊãâÂÖ®ÈáèÊï∞ÊçÆÂéªÁÆóÔºåÊàë‰ª¨Áõ¥Êé•‰ªéEtherscan APIÂèñBalance

## Ê¶ÇËø∞

Â¶ÇÊûúÊàë‰ª¨ÁÆÄÂçïÂú∞ÊèèËø∞Ëøô‰∏™ËøáÁ®ãÔºåÂ§ßÊ¶Ç‰ºöÂàÜÊàê‰ª•‰∏ãÂá†Ê≠•

- ÈÄöËøáDuneËé∑ÂèñÂéüÂßãÊï∞ÊçÆ
- ÈÄöËøáNetworkxÂ§ÑÁêÜNode‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂπ∂Â§ÑÁêÜÁîªÁΩëÁªúÂõæÊó∂ÈúÄË¶ÅÁöÑÂêÑÁßçÂ±ûÊÄßÊï∞ÊçÆ(pos,label,color,SizeÁ≠âÁ≠â)
- ÈÄöËøáPlotlyÁîªÂá∫ÁΩëÁªúÂõæ

## ËØ¶ÁªÜËøáÁ®ã

#### ‰∏Ä„ÄÅÈÄöËøáDuneËé∑ÂèñÂéüÂßãÊï∞ÊçÆ(SQLÈÉ®ÂàÜ)

SQLÊØîËæÉÂ§çÊùÇÔºåÂ∞±‰∏çÂ±ïÂºÄËØ¥‰∫ÜÔºåÂ§ßÂÆ∂ÊÑüÂÖ¥Ë∂£ÂéªURLÈáåËá™Â∑±Á†îÁ©∂

- ÈÄöËøáSQLËé∑ÂæóÂåÖÂê´ÊâÄÊúâÁõ∏ÂÖ≥Âú∞ÂùÄ‰πãÈó¥ÂÖ≥Á≥ªÊï∞ÊçÆÔºöhttps://dune.com/queries/1753177

  - from:ËΩ¨Ë¥¶ÁöÑÂèëËµ∑Êñπ
  - to:ËΩ¨Ë¥¶ÁöÑÊî∂Ê¨æÊñπ
  - transfer_eth_balanceÔºöÂèåÊñπËΩ¨Ë¥¶ETHÁöÑÊÄªÈáè
  - transfer_eth_countÔºöÂèåÊñπËΩ¨Ë¥¶ETHÁöÑÊÄªÊ¨°Êï∞

  ![image-20221214165849494.png](img/image-20221214165849494.png)

- ÈÄöËøáSQLËé∑ÂæóÂåÖÂê´ÊâÄÊúâÂú∞ÂùÄÁöÑÂàóË°®‰ª•ÂèäÁõ∏ÂÖ≥Ê†áÁ≠æÔºöhttps://dune.com/queries/2430347

  - address:Êú¨Ê¨°ÁΩëÁªúÂàÜÊûê‰∏≠Ê∂âÂèäÁöÑÊâÄÊúâÂú∞ÂùÄ
  - level_type:Êú¨Ê¨°ÁΩëÁªúÂàÜÊûê‰∏≠Ê∂âÂèäÁöÑÊâÄÊúâÂú∞ÂùÄÁöÑÂú®ÁΩëÁªú‰∏≠ÁöÑÂ±ÇÁ∫ß(Core,Layer One,Layer Two)
  - account_typeÔºöÊòØEOAÊôÆÈÄöÂú∞ÂùÄËøòÊòØ‰∫§ÊòìÊâÄÊàñËÄÖÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂêàÁ∫¶
  - labelÔºöËøô‰∏™Âú∞ÂùÄÁöÑÊúâÁî®ÁöÑ‰ø°ÊÅØËÅöÂêàÊàê‰∏Ä‰∏™Ê†áÁ≠æÂ≠óÊÆµÔºåÁî®‰∫éÂêéÁª≠Âú®python‰∏≠ÂÅöÂèØËßÜÂåñ

  ![image-20221214170041781.png](img/image-20221214170041781.png)

#### ‰∫å„ÄÅÁî®pandasËØªÂèñÊú¨Âú∞Êñá‰ª∂Âà∞DataframeÂπ∂ÈÄöËøáEtherscan APIË°•ÂÖÖBalnaceÂàó

- Â∞ÜduneÁöÑÊï∞ÊçÆ‰∏ãËΩΩÂà∞Êú¨Âú∞(ÂèØ‰ª•ÈÄöËøáDuneÁöÑAPIÊàñËÄÖÈÄöËøáÁõ¥Êé•Â§çÂà∂Á≤òË¥¥)ÈÄöËøápandas‰ªéÊú¨Âú∞ËØªÂèñÂú®dune‰∏≠Ëé∑ÂæóÁöÑÊï∞ÊçÆ

```python
## Ë∑ØÂæÑÊîπÊàêËá™Â∑±Êú¨Âú∞ÁöÑÊñá‰ª∂Ë∑ØÂæÑ
df_target_label  = pd.read_csv(u'YOUE FILE PATH/graph_raw_label.csv')
df_target_relation  = pd.read_csv(u'YOUE FILE PATH/graph_relation.csv')
##ÂèñÊâÄÊúâaddresss listÁî®‰∫éËØ∑Ê±ÇAPI
address_list=list(df_target_label.address.values)
balance_list=[]
print(address_list)
```
- ÈÄöËøáEtherscan APIËé∑ÂæóÊâÄÊúâÂú∞ÂùÄÁöÑBalanceÊï∞ÊçÆÂπ∂ÂÜôÂÖ•DataFrame
```python
while len(address_list)>0:
    for address in address_list:

        api_key = "api_key"
        try:
            response = requests.get(
                "https://api.etherscan.io/api?module=account&action=balance&address=" + address + "&tag=latest&apikey=" + api_key
            )


            # Parse the JSON-formatted response
            response_json = json.loads(response.text)

            # Get the balance information from the response
            eth_balance = response_json["result"]
            eth_balance= int(eth_balance)/(1E18)
            balance_list.append((address,eth_balance))
            address_list.remove(address)
            time.sleep(1)
            print(eth_balance)
        except:
            print('Error')
            print('List Length:'+str(len(address_list)))


df_balance = pd.DataFrame(balance_list, columns=['address', 'Balance'])
df_target_label=df_target_label.merge(df_balance,left_on=['address'],right_on=['address'],how='left')
print('end')
```

- Â∞Ülist‰∏≠ÁöÑBalanceÊîæÂÖ•Dataframe‰∏≠Âπ∂ÂÆö‰∏Ä‰∏™ÂàóBalance_level(Ê†πÊçÆBalanceÂ§ßÂ∞èÊâìÊ†áÁ≠æ)ÂêéÁª≠ÊéßÂà∂ÁΩëÁªúÂõæ‰∏≠NodeÁöÑÂ§ßÂ∞è
```python
##ÂÆö‰∏Ä‰∏™‰∏Ä‰∏™ÂáΩÊï∞Ê†πÊçÆÂÄºÁöÑÂ§ßÂ∞èÂéªËøîÂõû‰∏çÂêåÁöÑÊ†áÁ≠æÔºåÁ±ª‰ºº‰∫éSQLÈáåÁöÑcase when

def get_balance_level(x):
    if x ==0 :
        output = 'Small'
    elif x > 0 and x<1000:
            output = 'Medium'
    elif x > 1000 and x<10000:
            output = 'Large'
    else:
        output = 'Huge'
    return output


df_target_label['Balance_level'] = df_target_label['Balance'].round(2).apply(lambda x: get_balance_level(x))

df_target_label['Balance'] = df_target_label['Balance'].round(2).astype('string')
df_target_label['label'] =df_target_label['label']+' | '+ df_target_label['Balance'] +' ETH' 
```
#### ‰∏â„ÄÅÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞ÈÄöËøáNetwork XÂ§ÑÁêÜËäÇÁÇπÂÖ≥Á≥ªÂπ∂‰ΩøÁî®PlotlyÁîªÂõæ

```python
def drew_graph(df_target_relation,df_target_label):
    def add_node_base_data(df_target_relation):
        df_target_relation = df_target_relation
        node_list = list(set(df_target_relation['from_address'].to_list()+df_target_relation['to_address'].to_list()))
        edges = list(set(df_target_relation.apply(lambda x: (x.from_address, x.to_address), axis=1).to_list()))
        G.add_nodes_from(node_list)
        G.add_edges_from(edges)
        return node_list,edges

    def add_node_attributes(df_target_label,df_key_list,df_vlaue_list,color_list):
        for node, (n,p) in zip(G.nodes(), pos.items()):
                G.nodes[node]['pos'] = p
                G.nodes[node]['color'] = '#614433'
                for id,label,layer_type,Balance_level in list(set(df_target_label.apply(lambda x: (x.address, x.label, x.level_type,x.Balance_level), axis=1).to_list())):
                        if node==id:
                            G.nodes[node]['label']=label
                            if Balance_level=='Large':
                                G.nodes[node]['size']=40
                            elif Balance_level=='Medium':
                                G.nodes[node]['size']=20
                            elif Balance_level=='Small':
                                G.nodes[node]['size']=10
                            elif Balance_level=='Huge':
                                G.nodes[node]['size']=80

                for x,y,z in zip(df_key_list,df_vlaue_list,color_list):
                    target_list = df_target_label[df_target_label[x]==y]['address'].values.tolist()
                    if len(target_list)>0:
                        for id in target_list:
                            if id==node and G.nodes[node]['color']=='#614433':
                                G.nodes[node]['color'] = z

     ###############ÁîªÂá∫ÊâÄÊúâÁöÑËæπ 
    def get_edge_trace(G):
        xtext=[]
        ytext=[]
        edge_x = []
        edge_y = []
        for edge in G.edges():
            x0, y0 = G.nodes[edge[0]]['pos']
            x1, y1 = G.nodes[edge[1]]['pos']
            xtext.append((x0+x1)/2)
            ytext.append((y0+y1)/2)

            edge_x.append(x0)
            edge_x.append(x1)
            edge_x.append(None)
            edge_y.append(y0)
            edge_y.append(y1)
            edge_y.append(None)

            xtext.append((x0+x1)/2)
            ytext.append((y0+y1)/2)


        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#333'),
            hoverinfo='none',
            mode='lines')
        
        eweights_trace = go.Scatter(x=xtext,y= ytext, mode='text',
                              marker_size=0.5,
                              text=[0.45, 0.7, 0.34],
                              textposition='top center',
                              hovertemplate='weight: %{text}<extra></extra>')
        return edge_trace, eweights_trace
    
    def get_node_trace(G):
        node_x = []
        node_y = []
        for node in G.nodes():
            x, y = G.nodes[node]['pos']
            node_x.append(x)
            node_y.append(y)

        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers',
            hoverinfo='text',
            marker=dict(
                color=[],
                colorscale = px.colors.qualitative.Plotly,
                size=10,
                line_width=0))
        return node_trace

    ###############ÂÆö‰πâGraph
    G = nx.Graph()
    
    ###############ÁªôGraphÊ∑ªÂä†Node‰ª•ÂèäEdge
    node_list = add_node_base_data(df_target_relation)[0]
    edges = add_node_base_data(df_target_relation)[1]
#     eweights_trace = add_node_base_data(df_target_relation)[1]

    ###############ÈÄâÊã©layoutÂπ∂ÂæóÂà∞Áõ∏ÂÖ≥nodeÁöÑpos
    pos = nx.fruchterman_reingold_layout(G)
    
    df_key_list = [   'level_type'  ,'account_type' ,  'account_type' , 'account_type' ]
    df_vlaue_list = [  'Core' , 'EOA' ,           'Cex Address'   , 'Contract Address']
    color_list = [    '#109947' ,'#0031DE'      , '#F7F022'     , '#E831D6' ]
    
    ###############ÁªônodeÊ∑ªÂä†label,Size,colorÂ±ûÊÄß
    add_node_attributes(df_target_label,df_key_list,df_vlaue_list,color_list)
    
    edge_trace, eweights_trace = get_edge_trace(G)
    node_trace = get_node_trace(G)
    
    ###############ÂÆö‰πâcolorÁöÑËßÑÂàô
   


    ###############Â∞Ünode_textÔºånode_sizeÔºånode_colorÂÜôÂÖ•list
    node_text = []
    node_size = []
    node_color = []
    for node in G.nodes():
        x = G.nodes[node]['label']
        y = G.nodes[node]['size']
        z = G.nodes[node]['color']
        node_text.append(x)
        node_size.append(y)
        node_color.append(z)

    
   

     # ‰æùÊçÆËÆæÁΩÆlabelÔºåsizeÔºåcolor
    node_trace.marker.color = node_color
    node_trace.marker.size =node_size
    node_trace.text = node_text
    
    fig_target_id=go.Figure()
    fig_target_id.add_trace(edge_trace)
    fig_target_id.add_trace(node_trace)

    fig_target_id.update_layout(
        
                                    height=1000,
                                    width=1000,
                                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                    showlegend=False,
                                    hovermode='closest',
                                )
    
    return fig_target_id


```


#### Âõõ„ÄÅË∞ÉÁî®ÂáΩÊï∞drew_graphÔºå‰º†ÂÖ•2‰∏™DataframeÁîªÂõæ„ÄÇÂπ∂ÂØºÂá∫HTMLÊñá‰ª∂

```python
fig =drew_graph(df_target_relation,df_target_label)
fig.show()
fig.write_html(u'YOUR FILE PATH/FTX_Accounts_Drainer.html')
print('end')
```



#### ‰∫î„ÄÅÊïàÊûúÂõæ

ÂèØ‰ª•ËÆøÈóÆURLÊü•ÁúãÂèØ‰∫§‰∫íÁöÑÁâàÊú¨:https://pro0xbi.github.io/FTX_Accounts_Drainer.html

- NodeÈ¢úËâ≤

  - ÁªøËâ≤ÊòØFTX"ÈªëÂÆ¢"Âú∞ÂùÄ
  - ËìùËâ≤ÊâÄÊúâ‰∏é‰πãÂèëÁîüËøáÂ§ßÈ¢ùËΩ¨Ë¥¶(>100ETH)ÊòØÊôÆÈÄöÁöÑEOAË¥¶Êà∑
  - ÈªÑËâ≤ÊòØExchangeÂú∞ÂùÄ(FTX)
  - Á∫¢Ëâ≤ÊòØÊô∫ËÉΩÂêàÁ∫¶

- NodeÂ§ßÂ∞è

  - NodeË∂äÂ§ßË°®ÊòéÂØπÂ∫îÂú∞ÂùÄÁöÑ‰ΩôÈ¢ùË∂äÂ§ßÔºåÂÖ∂‰∏≠ÊúÄÂ§ßÁöÑNodeË°®Á§∫ÂΩìÂâçÂú∞ÂùÄÈÇ£Balance‰ΩôÈ¢ùÂ§ß‰∫é10000ETH

  ÂèØ‰ª•ÁúãÂá∫‰∏éFTX"ÈªëÂÆ¢"Âú∞ÂùÄÊúâÂÖ≥ÁöÑÊâÄÊúâÂú∞ÂùÄ‰∏≠ÁõÆÂâçËá≥Â∞ëËøòÊúâ12‰∏™Âú∞ÂùÄÊúâË∂ÖËøá10000‰∏™ETHÔºå‰πüÂ∞±ÊòØËØ¥Ëá≥Â∞ëÊúâ12‰∏áETHËøòÊ≤°ÊúâË¢´"ÈªëÂÆ¢"ÊäõÂîÆ

  ![image-20221214201810132.png](img/image-20221214201810132.png)
</file>

<file path="zh/ch22/ch21-btc-analysis.md">
# Â¶Ç‰ΩïËÆæËÆ°‰∏Ä‰∏™Dshboard-‰ª•BTCÊåáÊ†áCDD(Coin Day Destroyed)‰∏∫‰æã
## ‰∏Ä„ÄÅBTC CDDÊåáÊ†á‰ªãÁªç

### 1.ÊåáÊ†áËØ¥Êòé

CDD ÊòØ Coin Day Destroyed ÁöÑÁÆÄÁß∞ÔºåÂú®ÊüêÁßçÁ®ãÂ∫¶‰∏äÊàë‰ª¨ÂèØ‰ª•ËÆ§‰∏∫ÂÆÉÊòØÂØπÈìæ‰∏ä‰∫§ÊòìÈáèÊåáÊ†á(Transaction Volumn)ÂÅö‰∫Ü‰∏Ä‰∫õÊîπËøõ„ÄÇÂÖ∑‰ΩìÁöÑÊîπËøõÂ∞±ÊÄùË∑ØÂ∞±ÊòØÂú®ËØÑ‰º∞Èìæ‰∏äÊ¥ªÂä®(Transfer)ÁöÑÊó∂ÂÄôÂºïÂÖ•Êó∂Èó¥ÁâπÂæÅÔºöÂú®Èìæ‰∏äÂ§Ñ‰∫éÈïøÊó∂Èó¥HODLÁä∂ÊÄÅ(Ê≤°ÊúâË¢´ËΩ¨ÁßªÂà∞ÂÖ∂‰ªñÈí±ÂåÖ)ÁöÑTokenÂèëÁîüÁßªÂä®ÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨ÁªôËøôÊ¨°ÁöÑËΩ¨Ë¥¶Ëµã‰∫àÊõ¥Â§ßÁöÑÊùÉÈáç„ÄÇ

ËøôÈáåÊàë‰ª¨ÂºïÂÖ•‰∏Ä‰∏™Êñ∞ÁöÑÊ¶ÇÂøµÂè´Â∏ÅÂ§©(Coin Day)Ôºå`Â∏ÅÂ§©(Coin Day)  = TokenÊï∞Èáè * ËØ•Token‰øùÊåÅHODLÁä∂ÊÄÅÁöÑÂ§©Êï∞`„ÄÇ

Èìæ‰∏äÁöÑÊâÄÊúâBTCÊØèÂ§©ÈÉΩÂú®Á¥ØÁßØÂ∏ÅÂ§©(Coin Day)ÔºåÂ¶ÇÊûúÂÖ∂‰∏≠Êüê‰∏ÄÈÉ®ÂàÜBTCÂèëÁîü‰∫ÜÁßªÂä®(‰ªéÈí±ÂåÖAËΩ¨ÁßªÂà∞Èí±ÂåÖB)ÔºåÈÇ£‰πàËøôÈÉ®ÂàÜÁ¥ØÁßØÂ∏ÅÂ§©Â∞±‰ºöË¢´Ê∂àËÄóÔºåËøôÂ∞±ÊòØÊâÄË∞ìÁöÑ Coin Day Destroyed „ÄÇ      

![historical_trend.png](img//historical_trend.png)    


### 2.Â∫ïÂ±ÇÈÄªËæë

Êàë‰ª¨ËÆæËÆ°ÊâÄÊúâÊåáÊ†áÈÉΩÊòØ‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÂàªÁîªÊèèËø∞Âá∫Êàë‰ª¨ÊÉ≥Ë¶ÅÂèçÂ∫îÁöÑÁä∂ÂÜµÔºåÂØπ‰∫éËøô‰∏™ÊåáÊ†áÊù•ËÆ≤ÔºåÂÆÉÊúÄÁªàÊòØÂ∏åÊúõÂèçÂ∫îÈïøÊúüÊåÅÊúâËÄÖÁöÑ‰∏Ä‰∫õË°å‰∏∫„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãËøôÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™Smart MoneyÁ±ªÂûãÁöÑÊåáÊ†áÔºåÂ§ßÂÆ∂ÂÄæÂêë‰∫éËÆ§‰∏∫ÈïøÊúüÊåÅÊúâËÄÖÊòØBTCÊó©ÊúüÁöÑÂèÇ‰∏éËÄÖÔºåËøõËÄå‰ªñ‰ª¨ÂØπBTC‰ª•ÂèäÂ∏ÇÂú∫ÁöÑÁêÜËß£ÊòØÊõ¥ËÅ™Êòé‰ª•ÂèäÊúâÁªèÈ™åÁöÑÔºåÂ¶ÇÊûú‰ªñ‰ª¨ÁöÑToken(ÈïøÊúüÂ§Ñ‰∫éHODLÁä∂ÊÄÅ)ÂèëÁîü‰∫ÜËΩ¨ÁßªÔºåÈÇ£‰πàÂæàÊúâÂèØËÉΩÊòØÂ∏ÇÂú∫ÂèëÁîü‰∫Ü‰∏Ä‰∫õÂèòÂåñ‰øÉ‰Ωø‰ªñ‰ª¨ÈááÂèñ‰∫Ü‰∏Ä‰∫õË°åÂä®(Âú®ÂæàÂ§öÊÉÖÂÜµ‰∏ãÊòØËΩ¨Âà∞‰∫§ÊòìÊâÄÊàñËÄÖÈÄöËøáOTCÂá∫ÂîÆÔºå‰ΩÜ‰πüÂ≠òÂú®ÂÖ∂‰ªñÁöÑÂú∫ÊôØÔºå‰∏çËÉΩ‰∏ÄÊ¶ÇËÄåËÆ∫)„ÄÇ

Â¶ÇÊûú‰Ω†ÁªèÂ∏∏Áî®GlassnodeÔºå‰Ω†‰ºöÂèëÁé∞Glassnode‰∏äÈùûÂ∏∏Â§öÁöÑÊåáÊ†áÈÉΩÊòØÂü∫‰∫é‰∏äËø∞ÈÄªËæëËÆæËÆ°ÁöÑÔºåËøô‰∏™ÂèØ‰ª•ÁÆóÊòØÁé∞ÊúâBTCÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÁöÑÊúÄÈáçË¶ÅÁöÑÂ∫ïÂ±ÇÈÄªËæë‰πã‰∏Ä„ÄÇ

### 3.UTXOÊú∫Âà∂

ËøôÈáåÈúÄË¶ÅÂºïÂÖ•ÂÖ≥‰∫éBTCÁöÑ‰∏Ä‰∏™Âü∫Êú¨Â∏∏ËØÜÔºöUTXOÊú∫Âà∂„ÄÇÁêÜËß£ÂÆÉÂêéÊâçËÉΩÊòéÁôΩÂ∫îËØ•Â¶Ç‰ΩïÂà©Áî®Dune‰∏äÁöÑÂÖ≥‰∫éBTCÁöÑÂá†Âº†Ë°®ÂÆåÊàê‰∏äËø∞ÁöÑËÆ°ÁÆó„ÄÇ

UTXOÊòØ Unspent Transaction OutputÁöÑÁÆÄÁß∞ÔºåÂç≥Êú™Ëä±Ë¥πÁöÑ‰∫§Êòì‰∫ßÂá∫„ÄÇBTCÁé∞ÊúâÁöÑËøêË°åÊú∫Âà∂‰∏≠ÂÖ∂ÂÆûÊ≤°ÊúâBalanceÁöÑÊ¶ÇÂøµÔºåÊØè‰∏™Èí±ÂåÖÁöÑBalanceÊòØÈÄöËøáÂ∞Ü‰∏éËØ•Èí±ÂåÖÊã•ÊúâÁöÑÊâÄÊúâUTXO‰∏≠ÂåÖÂê´ÁöÑBTCÊï∞ÈáèÊ±ÇÂíåÂæóÂà∞ÁöÑ„ÄÇ


ÊêúÁ¥¢Âà∞‰∏ÄÁØáÊñáÁ´†ÊÑüËßâËÆ≤Âú∞ÊØîËæÉÈÄö‰øóÊòìÊáÇÔºåËøôÈáåÊîæ‰∏Ä‰∏ãÈìæÊé•Ôºöhttps://www.liaoxuefeng.com/wiki/1207298049439968/1207298275932480

## ‰∫å„ÄÅ DuneÁõ∏ÂÖ≥Ë°®

Â¶ÇÊûú‰Ω†ËÉΩÂ§ßÊ¶ÇÁêÜËß£InputÔºåOutputÔºåUTXOËøôÂá†‰∏™Ê¶ÇÂøµÔºåÂ∞±ÂæàÂÆπÊòìËÉΩÁêÜËß£Dune‰∏äÊàë‰ª¨ÈúÄË¶ÅÁî®Âà∞ÁöÑ2‰∏™Ë°®„ÄÇËøôÈáåÂØπÈúÄË¶ÅÁî®Âà∞ÁöÑË°®‰ª•ÂèäÂ≠óÊÆµÂÅö‰∏Ä‰∏™ÁÆÄÂçïÁöÑËØ¥Êòé„ÄÇ

### 2.1 bitcoin.inputs 

- ËØ¥ÊòéÔºöÂåÖÂê´ÊâÄÊúâÁöÑInputÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÔºåÂç≥ÂØπ‰∫éÊØè‰∏™Âú∞ÂùÄÊù•ËØ¥‰ªñ‰ª¨ÁöÑÊØè‰∏ÄÁ¨îBTCÁöÑÊ∂àË¥π/ËΩ¨Âá∫
- ÈáçË¶ÅÂ≠óÊÆµ
  - `address`ÔºöÈí±ÂåÖÂú∞ÂùÄ
  - `block_time`ÔºöËøôÊ¨°ËΩ¨Âá∫TransactionÂèëÁîüÁöÑÊó∂Èó¥
  - `tx_id`ÔºöËøôÊ¨°ËΩ¨Âá∫TransactionÁöÑtx id
  - `value`ÔºöËøôÊ¨°ËΩ¨Âá∫TransactionÂåÖÂê´ÁöÑBTCÈáëÈ¢ù
  - `spent_tx_id`ÔºöËøôÊ¨°‰∫ßÁîüInput(Ëä±Ë¥π)ÊòØÊ∫ê‰∫éÈÇ£‰∏™Output(ÊàëËøôÊ¨°Ëä±ÁöÑÊòØ‰πãÂâçÊî∂Âà∞Âì™Á¨îÈí±)
    
![input_info.png](img//input_info.png)       

### 2.2 bitcoin.outputs 

- ËØ¥ÊòéÔºöÂåÖÂê´ÊâÄÊúâÁöÑOutputÁõ∏ÂÖ≥ÁöÑÊï∞ÊçÆÔºåÂç≥ÂØπ‰∫éÊØè‰∏™Âú∞ÂùÄÊù•ËØ¥‰ªñ‰ª¨ÁöÑÊØè‰∏ÄÁ¨îBTCÁöÑËΩ¨ÂÖ•ËÆ∞ÂΩï
- ÈáçË¶ÅÂ≠óÊÆµ
  - `address`ÔºöÈí±ÂåÖÂú∞ÂùÄ
  - `block_time`ÔºöËøôÊ¨°ËΩ¨Âá∫TransactionÂèëÁîüÁöÑÊó∂Èó¥
  - `tx_id`ÔºöËøôÊ¨°ËΩ¨Âá∫TransactionÁöÑtx id
  - `value`ÔºöËøôÊ¨°ËΩ¨Âá∫TransactionÂåÖÂê´ÁöÑBTCÈáëÈ¢ù
  
![output_info.png](img//output_info.png)    

## ‰∏â„ÄÅDashboardËÆæËÆ°‰ª•ÂèäÂÆûÁé∞

### 1. Â¶Ç‰ΩïËÆæËÆ°‰∏Ä‰∏™Dashboard
#### 1.1 Êï¥‰ΩìÊÄùË∑Ø

Â¶Ç‰ΩïËÆæËÆ°‰∏Ä‰∏™DashbaordÂèñÂÜ≥‰∫éÊàë‰ª¨‰ΩøÁî®DashboardÁöÑÊúÄÁªàÁõÆÁöÑ„ÄÇDashbaordÊàñËÄÖÊï∞ÊçÆÁöÑÊúÄÁªàÁõÆÁöÑÊòØËæÖÂä©‰∫∫ÂéªÂÅöÂÜ≥Á≠ñ„ÄÇÂú®ÊàëÁúãÊù•Êï∞ÊçÆËÉΩÈÄöËøáÂõûÁ≠î‰ª•‰∏ã‰∏§‰∏™ÈóÆÈ¢òÊù•ËæÖÂä©ÂÜ≥Á≠ñÔºåËÉΩÊúâÊïàÂõûÁ≠îËøô‰∏§‰∏™ÈóÆÈ¢òÊâçÁÆóÊòØ‰∏Ä‰∏™ÂêàÊ†ºÁöÑDashboard„ÄÇ

`[a].`XXX ÊòØ‰ªÄ‰πàÔºü ÂÆÉÊúâ‰ªÄ‰πàÁâπÂæÅÔºü

ÈÄöËøá‰∏ÄÁ≥ªÂàóÊåáÊ†áÂèçÊò†Êüê‰∏™‰∫ãÁâ©ÁöÑÂü∫Êú¨ÁâπÂæÅ‰ª•ÂèäÁé∞Áä∂ÔºàÊØîÂ¶Ç‰ª•Â§™ÂùäÊØèÂ§©ÁöÑÁî®Êà∑ÈáèÔºåtxÊï∞ÈáèÔºåÊñ∞Â¢ûÂêàÁ∫¶Êï∞Èáè....Ôºâ„ÄÇ

`[b].`ÂèçÂ∫îXXXÁâπÂæÅÁöÑ‰∏Ä‰∫õÈáçË¶ÅÊåáÊ†áÂèëÁîü‰∫ÜÂèòÂåñÔºåÂéüÂõ†ÊòØ‰ªÄ‰πàÔºü

ÂΩì`[a]`‰∏≠ÁöÑÊåáÊ†áÂèëÁîüÂèòÂåñÊó∂Êàë‰ª¨ÂéªÂàÜÊûêÂèòÂåñÁöÑÂéüÂõ†ÊàñËÄÖËØ¥Â∞±ÊòØÂéªÂØªÊâæÊï∞ÊçÆÊ≥¢Âä®ÁöÑÂéüÂõ†„ÄÇ

#### 1.2 Ê≥¢Âä®ÂàÜÊûê

`[a]`ÊØîËæÉÂ•ΩÁêÜËß£ÔºåÂ∞±‰∏çÂ±ïÂºÄËØ¥‰∫ÜÔºåÊåáÊ†á‰ΩìÁ≥ªËÆæËÆ°ÁöÑÂ•ΩÂùèÂèñÂÜ≥‰∫é‰Ω†ÂØπËøô‰∏™‰∫ãÁâ©Êú¨Ë∫´ÁöÑÁêÜËß£Á®ãÂ∫¶ÔºåÊØè‰∏™Ë°å‰∏öÊàñËÄÖÊØè‰∏™Ë°å‰∏ö‰∏ãÊØè‰∏™ÁªÜÂàÜÈ¢ÜÂüüÂÖ∂ÂÆûÈÉΩ‰∏ç‰∏ÄÊ†∑„ÄÇ

Êàë‰ª¨ÂèØ‰ª•ËØ¥ËØ¥ÂàÜÊûêÊ≥¢Âä®ÔºåÂú®ÊàëÁúãÊù•ÂàÜÊûêÊ≥¢Âä®Â∞±ÊòØÂéªÂÅöÊãÜËß£„ÄÇÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÂèØ‰ª•‰ªé‰∏§‰∏™ËßíÂ∫¶ÂéªÊãÜËß£‰∏Ä‰∏™ÊåáÊ†áÁöÑÊ≥¢Âä®ÔºåËøôÈáå‰ª•Â§™ÂùäÊØèÂ§©ÈîÄÊØÅÊï∞ÈáèÁöÑ‰∏∫‰æãÔºåÂÅáËÆæÊüê‰∏ÄÂ§©‰ª•Â§™ÂùäÈîÄÊØÅÈáè+30%ÔºåÊàë‰ª¨Â∫îËØ•ÊÄé‰πàÂàÜÊûêÔºü

**1.‰∫ãÁâ©ÂΩ¢ÊàêÁöÑËøáÁ®ã**

`‰ªäÊó•ETHÁáÉÁÉß = ‰ªäÊó•gas feeÊ∂àËÄóÊÄªÈáè * ÁáÉÁÉßÊØî‰æã`

- `‰ªäÊó•gas feeÊ∂àËÄóÊÄªÈáè = ‰ªäÊó•Âçï‰∏™txÂπ≥ÂùáÊ∂àËÄógas fee * ‰ªäÊó• txÊï∞`
  - `‰ªäÊó•txÊï∞ = ‰ªäÊó•‰ª•Â§™ÂùäÊ¥ªË∑ÉÁî®Êà∑ * ‰ªäÊó•‰ª•Â§™ÂùäÊ¥ªË∑ÉÁî®Êà∑Âπ≥ÂùáÂèëÂá∫txÊï∞`
    - `‰ªäÊó•‰ª•Â§™ÂùäÊ¥ªË∑ÉÁî®Êà∑ = ‰ª•Â§™ÂùäÊÄªÁî®Êà∑Êï∞ * ‰ªäÊó•Ê¥ªË∑ÉÊØî‰æã`
- `ÁáÉÁÉßÊØî‰æãÔºöÂèñÂÜ≥‰∫éEIP1559 ÊàñËÄÖÊòØÂê¶ÊúâÊñ∞ÁöÑÊèêÊ°à`    

![funnel_info.png](img//funnel_info.png)    


**2.‰∫ãÁâ©Êú¨Ë∫´ÁöÑÁâπÂæÅ**

- Êó∂Èó¥ÔºöÂå∫ÂàÜÂ∞èÊó∂Êù•ÁúãÊòØ24Â∞èÊó∂‰∏≠Âì™‰∏™Â∞èÊó∂gas feeÊ∂àËÄó‰∏äÊ∂®ËøòÊòØÊâÄÊúâÂ∞èÊó∂ÊôÆÈÅç‰∏äÊ∂®
- Á©∫Èó¥ÔºöÂ¶ÇÊûúËÉΩÊãøÂà∞ÊØè‰∏™ÂèëËµ∑‰∫§ÊòìÁöÑÈí±ÂåÖÁöÑipÂéªÁúãÂê¶ÊòØÊòØÂê¶Êüê‰∏™ÂõΩÂÆ∂ÁöÑgas feeÊ∂àËÄóÂ§ßÂπÖÂ∫¶‰∏äÊ∂®ÔºàÂÆûÈôÖÂÅö‰∏çÂà∞Ôºâ
- ÂÖ∂‰ªñÁâπÂæÅÔºöÊòØEOAÂú∞ÂùÄÁöÑgas feeÊ∂àËÄó‰∏äÊ∂®ËøòÊòØÂêàÁ∫¶Âú∞ÂùÄÁöÑgas feeÊ∂àËÄó‰∏äÊ∂®
  - Â¶ÇÊûúÊòØEOAÂú∞ÂùÄÔºåÊòØBOTÈÄ†ÊàêÁöÑÔºåËøòÊòØÊôÆÈÄöEOAÂú∞ÂùÄÔºõÂ¶ÇÊûúÊòØÊôÆÈÄöEOAÂú∞ÂùÄÔºåÊòØÈ≤∏È±ºÈÄ†ÊàêÁöÑËøòÊòØÊôÆÈÄöÈí±ÂåÖÈÄ†ÊàêÁöÑ
  - Â¶ÇÊûúÊòØÂêàÁ∫¶Âú∞ÂùÄÔºåÊòØÂì™‰∏™Á±ªÂûãÁöÑÈ°πÁõÆ(Defi Gamefi...ÁöÑÂêàÁ∫¶gas feeÊ∂àËÄó‰∏äÊ∂®ÔºåÂ¶ÇÊûúÊòØGamefiÈ°πÁõÆÔºåÂÖ∑‰ΩìÊòØÂì™‰∏™ÂêàÁ∫¶ÈÄ†ÊàêÁöÑ

‰∏äËø∞ÊòØ‰∏§Â§ßÁ±ªÊãÜËß£ÊÄùË∑ØÔºåÈÄöËøáÂ∞Ü‰∏ªÊåáÊ†á‰∏ÄÂ±Ç‰∏ÄÂ±ÇÊãÜËß£ÊàêÂ≠êÊåáÊ†áÔºåÂ∞±ÂèØ‰ª•ÊØîËæÉÂ•ΩÂú∞ËßÇÂØüÊòØÈÇ£‰∫õÂ≠êÊåáÊ†áÁöÑÊ≥¢Âä®ÈÄ†Êàê‰∫Ü‰∏ªÊåáÊ†áÁöÑÊ≥¢Âä®ÔºåËøõËÄåÊé®ÊµãÊúÄÊ∫êÂ§¥ÁöÑÂéüÂõ†„ÄÇ

### 2. Bitcoin - Coin Day Destroyed Matrix ÁöÑËÆæËÆ°

ÂõûÂà∞ËøôÊ¨°ÁöÑ‰∏ªÈ¢òÔºåÊàë‰ª¨ÂºÄÂßãËÆæËÆ° Bitcoin - Coin Day Destroyed Ëøô‰∏™Dashboard„ÄÇ

#### 2.1 Êï¥‰ΩìÁä∂ÂÜµ

È¶ñÂÖàÊòØÈúÄË¶Å‰∏ÄÂº†ÂõæÂèçÊò†Êï¥‰ΩìÁöÑÁä∂ÂÜµÔºåÂõ†‰∏∫Âè™ÊúâCDDËøô‰∏Ä‰∏™ÊåáÊ†áÊØîËæÉÁÆÄÂçïÔºåÊàëÂ∞±Âè™Êîæ‰∫Ü‰∏ÄÂº†ÂéÜÂè≤Ë∂ãÂäøÂõæ„ÄÇ    

![historical_trend.png](img//historical_trend.png)    

‰ΩÜÊòØËøô‰∏™ÂõæÁöÑÊó∂Èó¥Âë®ÊúüËøáÈïøÔºåÊàë‰ª¨ÂæàÈöæÈÄöËøáËøôÂº†ÂõæÊØîËæÉÊòéÊòæÂú∞ÁúãÂá∫ËøëÊúüCDDÁöÑÂèòÂåñÔºåÂõ†Ê≠§ÊàëÂèàÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™ËøëÊúüÁöÑË∂ãÂäø„ÄÇ

![recent_trend.png](img//recent_trend.png)     

PSÔºöËøôÈáåËøòÊòØÂèØ‰ª•ÁúãÂà∞ËøôËΩÆ‰∏ãË∑åÈí±ÂèàÊòéÊòæÁöÑCDDÂºÇÂä®ÁöÑ„ÄÇ

#### 2.2 Ê≥¢Âä®ÂàÜÊûê

ËøôÈáåÊàëÂè™ÂÅö‰∫Ü3‰∏™Á∫¨Â∫¶ÁöÑÊãÜËß£Ôºö

- ÊåâÁÖßÊó∂Èó¥(Â∞èÊó∂)ÊãÜËß£ÔºåËøôÊ†∑ÊàëÂ∞±ÊåáÊ†áÂºÇÂä®ÂèëÁîüÂú®Â§ßÊ¶Ç‰ªÄ‰πàÊó∂Èó¥„ÄêÁªüËÆ°ÊúÄÊñ∞‰∏ÄÂ§©ÁöÑÊï∞ÊçÆ„Äë    

![hour.png](img//hour.png)    

- ÊåâÁÖßÂèëËµ∑TransactionÁöÑÈí±ÂåÖÂú∞ÂùÄÊãÜËß£ÔºåËøôÊ†∑ÊàëÂ∞±Áü•ÈÅìÊåáÊ†áÂºÇÂä®ÊòØÁî±‰ªÄ‰πàÂºïËµ∑ÁöÑÔºöÊòØ‰∏Ä‰∏™Èí±ÂåÖËøòÊòØÂæàÂ§öÈí±ÂåÖÂºïËµ∑ÁöÑÔºåÊòØ‰∏ÄÂ∞èÈÉ®ÂàÜ`ËÄÅÂ∏Å`ÔºåËøòÊòØÂ§ßÈáè`Êñ∞Â∏Å`„ÄÇ„ÄêÁªüËÆ°ÊúÄÊñ∞‰∏ÄÂ§©ÁöÑÊï∞ÊçÆ„Äë     

![wallet.png](img//wallet.png)    

- ÊåâÁÖßTransaction_IDËøô‰∏™ÈùûÂ∏∏ÁªÜÁöÑÁ≤íÂ∫¶ÂéªÊãÜËß£ÔºåËøôÊ†∑ÊàëÂ∞±Áü•ÈÅìÂºÇÂä®ÂÖ∑‰ΩìÊòØÁî±Âì™‰∫õTransactionÂ∏¶Êù•ÁöÑÔºå‰πüÂèØ‰ª•ÂéªÂå∫ÂùóÈìæÊµèËßàÂô®‰∏≠ÂéªÊ†∏ÂÆû„ÄÇ„ÄêÁªüËÆ°ÊúÄÊñ∞‰∏ÄÂ§©ÁöÑÊï∞ÊçÆ„Äë    

![transaction.png](img//transaction.png)    

- Èô§Ê≠§‰πãÂ§ñÔºå‰∏∫‰∫ÜÊñπ‰æøÊåâÁÖßÈí±ÂåÖÂú∞ÂùÄÂéªÂàÜÊûêÂéÜÂè≤‰∏ä‰ªªÊÑè‰∏ÄÂ§©ÁöÑÊ≥¢Âä®ÂéüÂõ†ÔºåÊàëÊñ∞Â¢û‰∫Ü‰∏Ä‰∏™Â∑•ÂÖ∑Ê®°ÂùóÔºåÂèØ‰ª•ÈÄöËøáËæìÂÖ•Êó•ÊúüÊù•Êü•ÊâæÂéÜÂè≤‰∏ä‰ªªÊÑè‰∏ÄÂ§©CDDÊåâÁÖßÈí±ÂåÖÁöÑÂàÜÂ∏É    

![tool.png](img//tool.png)    

### 3. ÂÆåÊàê

Â∞±ËøôÊ†∑‰∏Ä‰∏™Áî®‰∫éÂÖ≥Ê≥®CDDÁöÑDashboardÂ∞±ÂÆåÊàê‰∫Ü.ÊúÄÁªàÁöÑÊïàÊûúÂ∞±ÊòØ‰Ω†ÂèØ‰ª•ÊØîËæÉÊñπ‰æøÂú∞ÁúãÂà∞ËØ•ÊåáÊ†áÁöÑÂéÜÂè≤Ë∂ãÂäø‰ª•ÂèäËøëÊúüÂèòÂåñ„ÄÇÂ¶ÇÊûúÊüêÂ§©ÂèëÁîüÂºÇÂä®ÔºåÂèØ‰ª•Âø´ÈÄüÂú∞ÂÆö‰ΩçÂà∞ÂºÇÂä®ÂèëÁîüÁöÑÊó∂Èó¥‰ª•ÂèäÂÖ≥ËÅîÈí±ÂåÖÔºåÂÖ∑‰ΩìÁöÑtransaction_idËæÖÂä©Ëøõ‰∏ÄÊ≠•ÂàÜÊûê„ÄÇ  

![overview.png](img//overview.png)    

ËØ¶ÁªÜDashboardËßÅÔºöhttps://dune.com/sixdegree/bitcoin-coin-day-destroyed-matrix  


Ë°•ÂÖÖ‰∏Ä‰∫õÊõ¥Â§öÁöÑÊãÜËß£ÊÄùË∑ØÔºö
- Â∞ùËØïÊåâÁÖßTransactionÁöÑÁõÆÊ†áÂú∞ÂùÄÂéªÊãÜËß£ÔºåÂàÜÊàêËΩ¨ÂÖ•‰∫§ÊòìÊâÄÁöÑTxÁöÑCDD‰ª•ÂèäÊôÆÈÄöÁöÑtxÁöÑCDD„ÄÇËøôÊ†∑‰Ω†Â∞±Áü•ÈÅìCDD‰∏≠ÊúâÂ§öÂ§ßÊØî‰æãÊòØÊúâÊòéÁ°ÆÂá∫ÂîÆÊÑèÂêëÁöÑ
- Â∞ùËØïÊåâÁÖßÈí±ÂåÖÁöÑÁ±ªÂûãÂéªÂÅöÊãÜËß£ÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ùËØïËÆ°ÁÆóÊØè‰∏™Èí±ÂåÖÂá∫Áé∞Â§ßÈ¢ùCDDÂºÇÂä®Âêé‰ª∑Ê†º‰∏ãË∑å‰∫ÜÁöÑÊ¶ÇÁéáÔºåÁÑ∂ÂêéÂÆö‰πâÂá∫‰∏Ä‰∫õSmart MoneyÔºåËøôÊ†∑Â∞±ÊääCDDÊãÜËß£Êàê‰∫ÜSmart Money CDD & Normal CDD

ÊÑüÂÖ¥Ë∂£ÂèØ‰ª•Ëá™Â∑±fork DashboardÔºåÂéªÂ∞ùËØïÂéªÂÆûÁé∞„ÄÇ


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch23/ch22-how-to-build-spellbook.md">
# Â¶Ç‰ΩïÊûÑÂª∫È≠îÊ≥ïË°®ÔºàSpellÔºâ

È≠îÊ≥ï‰π¶ÔºàSpellbookÔºâÊòØ‰∏Ä‰∏™Áî± Dune Á§æÂå∫ÂÖ±ÂêåÂª∫ËÆæÁöÑÊï∞ÊçÆËΩ¨Êç¢Â±Ç„ÄÇÈ≠îÊ≥ïË°®ÔºàSpellÔºâÊòØDuneÂõ¢ÈòüÂíåÁ§æÂå∫Áî®Êà∑ÂÖ±ÂêåÂèÇ‰∏éÊûÑÂª∫ËÄåÊàêÁöÑÈ´òÁ∫ßÊäΩË±°ËßÜÂõæÊàñË°®Ê†º„ÄÇ

ÈÄöËøáÊûÑÂª∫È≠îÊ≥ïË°®ÔºåÊâÄÊúâDuneÁ§æÂå∫Áî®Êà∑ÈÉΩÂèØ‰ª•Êõ¥‰æøÊç∑Âú∞ÂÆåÊàêÊï∞ÊçÆÂàÜÊûê„ÄÇÊûÑÂª∫È≠îÊ≥ïÊúâËØ∏Â§öÂ•ΩÂ§Ñ„ÄÇÊÉ≥Ë±°‰ª•‰∏ãÊÉÖÂΩ¢Ôºö
- ‰Ω†ÊúâÂ§ö‰∏™Êü•ËØ¢ÂåÖÂê´Áõ∏ÂêåÁöÑÂ≠êÊü•ËØ¢ÊàñËÄÖCTE
- ‰Ω†ÁöÑÂ§ö‰∏™Êü•ËØ¢‰∏≠ÈáçÂ§ç‰ΩøÁî®‰∫ÜÈùûÂ∏∏ÈïøÁöÑÈùôÊÄÅÊï∞ÊçÆÂàóË°®
- ‰Ω†ÁöÑÊüê‰∏™Êü•ËØ¢Ë¢´Â§öÊ¨°ÂàÜÂèâÔºàForkÔºâÊàñËÄÖÂ§çÂà∂‰ΩøÁî®
- ‰Ω†ÁöÑÊü•ËØ¢‰∏≠ÂåÖÂê´ÂçÅÂàÜÂ§çÊùÇÁöÑËøêÁÆóÈÄªËæëÔºåËøô‰∏™Êü•ËØ¢ÂèØ‰ª•Âú®ÂÖ∂‰ªñÂú∞ÊñπÈáçÁî®

Âú®‰ª•‰∏äËøô‰∫õÊÉÖÂΩ¢‰πã‰∏ÄÊª°Ë∂≥Êó∂ÔºåÊàë‰ª¨ÈÉΩÂèØ‰ª•ÈÄöËøáÊûÑÂª∫È≠îÊ≥ïË°®ÁöÑÊñπÂºèÔºåÂ∞ÜËøô‰∏™Êü•ËØ¢ËΩ¨Âåñ‰∏∫‰∏Ä‰∏™È≠îÊ≥ïË°®„ÄÇËøôÊ†∑ÂèØ‰ª•ÁÆÄÂåñÊü•ËØ¢SQLÈÄªËæëÔºåÊèêÈ´ò‰∏ÄËá¥ÊÄßÂíåÂèØÁª¥Êä§ÊÄßÔºåÊèêÂçáÊï∞ÊçÆÊåáÊ†áÁöÑÊ∏ÖÊô∞Â∫¶„ÄÇ

DuneÂºÄÊ∫êÁöÑÈ≠îÊ≥ï‰π¶È°πÁõÆÂèØËá™Âä®ÊûÑÂª∫Âπ∂Áª¥Êä§Ëøô‰∫õÈ≠îÊ≥ïË°®„ÄÇÁ§æÂå∫‰∏≠ÁöÑ‰ªª‰Ωï‰∫∫ÈÉΩÂèØ‰ª•Ë¥°ÁåÆÈ≠îÊ≥ï‰π¶È°πÁõÆ‰∏≠ÁöÑÈ≠îÊ≥ïË°®„ÄÇÊú¨ÁØáÊïôÁ®ãÊàë‰ª¨Â∞ùËØïÁºñÂÜô‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈ≠îÊ≥ïË°®ÔºåÂ∏åÊúõËÉΩÂ∏ÆÂä©Â§ßÂÆ∂ËΩªÊùæËøàÂá∫Á¨¨‰∏ÄÊ≠•„ÄÇ

## ÊûÑÂª∫È≠îÊ≥ïË°®ÁöÑÂü∫Êú¨Ê≠•È™§

Áî®ÊúÄÁÆÄÂçïÁöÑËØ¥Ê≥ïÔºåÈ≠îÊ≥ïË°®ÂÖ∂ÂÆûËÉåÂêéÂ∞±ÊòØ‰∏Ä‰∏™SELECTÊü•ËØ¢ËØ≠Âè•„ÄÇ‰ΩÜÊòØÂÖ∑‰ΩìÊûÑÂª∫È≠îÊ≥ïË°®ÁöÑËøáÁ®ã‰ºöÊ∂âÂèäÂ§ö‰∏™ÊñπÈù¢ÔºåÂ§ö‰∏™Ê≠•È™§ÔºåÂøÖÈ°ªÊåâÁÖßÊñáÊ°£ÊåáÂºïÈÄêÊ≠•Êìç‰ΩúÊâçËÉΩÈ°∫Âà©ÂÆåÊàêÈ≠îÊ≥ïË°®ÊûÑÂª∫„ÄÇ

ÊûÑÂª∫È≠îÊ≥ïË°®ÁöÑÂü∫Êú¨Ê≠•È™§ÂåÖÊã¨Ôºö
- **Á°ÆÂÆöÊï∞ÊçÆÂØπË±°**ÔºöÊ†πÊçÆÂâçËø∞‰∏æ‰æãÁöÑÊÉÖÂΩ¢ÔºåÁªìÂêàËá™Â∑±ÊàñËÄÖÂÖ∂‰ªñÁ§æÂå∫Áî®Êà∑Âú®ÁºñÂÜôÊü•ËØ¢Êó∂ÈÅáÂà∞ÁöÑÂÖ∑‰ΩìÈóÆÈ¢òÂíåÈúÄÊ±ÇÔºåÁ°ÆÂÆöË¶ÅÂ§ÑÁêÜÊûÑÂª∫ÁîüÊàêÈ≠îÊ≥ïË°®ÁöÑÊï∞ÊçÆÂØπË±°ÔºåÂêåÊó∂‰∏∫Ë¶ÅËæìÂá∫ÁöÑÈ≠îÊ≥ïË°®ÂÆö‰πâÊ®°ÂºèÔºàSchemaÔºâ„ÄÇ
- **ÈÖçÁΩÆÊï∞ÊçÆÊ∫ê**ÔºöÊï∞ÊçÆÊ∫êÊòØÊåáÊûÑÂª∫È≠îÊ≥ïË°®ÊâÄ‰æùËµñÁöÑÂéüÂßãÊï∞ÊçÆË°®ÂíåËß£ÊûêÊï∞ÊçÆË°®„ÄÇÂÆÉ‰ª¨ÂøÖÈ°ªË¢´ÂÆö‰πâÂà∞YAMLÊñá‰ª∂‰∏≠„ÄÇÊØè‰∏Ä‰∏™Êï∞ÊçÆÊ∫êÂú®È≠îÊ≥ïË°®‰∏≠Âè™ÈúÄÂÆö‰πâ‰∏ÄÊ¨°„ÄÇ
- **ÁºñÂÜôÊµãËØï**ÔºöÂºÄÂßãÁºñÂÜôÈ≠îÊ≥ïË°®‰πãÂâçÂÖàËÄÉËôëÂ•ΩÈúÄË¶ÅËæìÂá∫ÁöÑÊü•ËØ¢ÁªìÊûúÔºåÈíàÂØπËØ•ÁªìÊûúÁºñÂÜôÁõ∏Â∫îÁöÑÊµãËØï„ÄÇÂΩìÁÑ∂Â¶ÇÊûúÊàë‰ª¨ÁöÑÈ≠îÊ≥ïË°®Âè™ÊòØ‰∏Ä‰∏™ËÅöÂêàÊï∞ÊçÆÁöÑËßÜÂõæÔºåÊµãËØï‰πüÂèØ‰ª•ÊîæÂà∞ÁºñÂÜôÂ•ΩÈ≠îÊ≥ïË°®ÂêéÈù¢Êù•Ê∑ªÂä†„ÄÇ
- **ÁºñÂÜôÈ≠îÊ≥ïË°®**Ôºö‰∏∫ÊØè‰∏Ä‰∏™Ë¶ÅÊûÑÂª∫ÁöÑÈ≠îÊ≥ïË°®Âú®ÂÖ∂Áã¨ÊúâÁöÑ`.sql`Êñá‰ª∂‰∏≠ÈÄöËøáÁºñÂÜôÂåÖÂê´‰∏ÄÂÆöÁâπÊÆäÊ†ºÂºèÔºàJINJAÊ®°ÁâàÔºâÁöÑ`SELECT`Êü•ËØ¢Êù•ÊûÑÂª∫È≠îÊ≥ïË°®„ÄÇÂØπÈ≠îÊ≥ïË°®ËøõË°åÁºñËØëÂíåÊµãËØï„ÄÇ
- **Êèê‰∫§PR**ÔºöÁºñÂÜôÂ•ΩÈ≠îÊ≥ïË°®ÔºåÊú¨Âú∞ÁºñËØëÊàêÂäüÔºåÊâãÂä®ÊµãËØïÈÄöËøáÂêéÔºåÂú®githubÂàõÂª∫Êñ∞ÁöÑPRÔºàPull RequestÔºâÔºåÁ≠âÂæÖDuneÂõ¢ÈòüÁöÑÊäÄÊúØ‰∫∫ÂëòreviewÂíåÂêàÂπ∂„ÄÇÊàêÂäüÂêàÂπ∂ÂêéÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•Âú®Êü•ËØ¢ÁºñËæëÂô®‰∏≠ÊâæÂà∞Êñ∞Âª∫ÁöÑÈ≠îÊ≥ïË°®‰∫Ü„ÄÇ

DuneÁöÑÂú®Á∫øÊñáÊ°£ÊúâÊõ¥ËØ¶ÁªÜÁöÑËØ¥ÊòéÔºö[È≠îÊ≥ï‰π¶ÂÖ•Èó®](https://dune.com/docs/zh/spellbook/getting-started/)

## ÊûÑÂª∫È≠îÊ≥ïË°®ÂâçÁöÑÂáÜÂ§áÂ∑•‰Ωú

ÂºÄÂßãÊûÑÂª∫È≠îÊ≥ïË°®‰πãÂâçÔºå‰Ω†ÈúÄË¶ÅÂÅö‰∏Ä‰∫õÂøÖÂ§áÁöÑÂáÜÂ§áÂ∑•‰ΩúÔºåÂåÖÊã¨ÁÜüÊÇâdbt Â∑•ÂÖ∑ÁöÑÂü∫Êú¨‰ΩøÁî®ÔºåÁÜüÊÇâgithub ÁöÑÂü∫Êú¨Êìç‰ΩúÔºàÂøÖÈ°ªÊúâgithubË¥¶Âè∑ÔºâÔºåÈÖçÁΩÆÊú¨Âú∞Â∑•‰ΩúÁéØÂ¢ÉÁ≠â„ÄÇËØ¶ÁªÜÁöÑÁéØÂ¢ÉÈÖçÁΩÆË¶ÅÊ±ÇÂíåËØ¥ÊòéÂú®ËøôÈáåÔºö

[üíª ÂáÜÂ§á‰∏Ä‰∫õÂÖàÂÜ≥Êù°‰ª∂Âπ∂‰∏îËÆæÁΩÆÂ•ΩÈ≠îÊ≥ï‰π¶ dbt](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/1-do-some-prerequisites%20and-set-up-Spellbook-dbt/)

ÂÖ≥‰∫éDBTÁöÑÊõ¥Â§öËØ¥Êòé‰ø°ÊÅØÔºö

[What is dbt?](https://docs.getdbt.com/docs/introduction)

ËøôÈáåÂÅáËÆæ‰Ω†Â∑≤ÁªèÊåâÁÖßÈìæÊé•ÈáåÈù¢ÁöÑËØ¥ÊòéÈÖçÁΩÆÂ•ΩÁõ∏ÂÖ≥ËΩØ‰ª∂„ÄÇ‰∏îÂ∑≤ÁªèÂú®github‰∏äÈÄöËøáÂàÜÂèâÔºàForkÔºâÂ∞ÜDuneÈ≠îÊ≥ï‰π¶Â≠òË¥ÆÂ∫ìÔºàhttps://github.com/duneanalytics/spellbookÔºâÂàÜÂèâÂà∞‰∫Ü‰Ω†Ëá™Â∑±ÁöÑgithubË¥¶Âè∑‰∏ã„ÄÇÊé•‰∏ãÊù•ÁöÑÈáçÁÇπÊ≠•È™§ÁÆÄË¶ÅËØ¥Êòé„ÄÇÊàëÊú¨Âú∞ÊòØMacÊìç‰ΩúÁ≥ªÁªüÔºåÊâÄ‰ª•ËøôÈáå‰ªÖ‰ª•MacÁéØÂ¢É‰∏∫‰æã„ÄÇÂ¶ÇÊûú‰Ω†Áî®ÁöÑÊòØWindowsÁéØÂ¢ÉÔºå‰ΩøÁî®ËøáÁ®ãÈÅáÂà∞‰ªª‰ΩïÈóÆÈ¢òÔºåËØ∑Âú®Áæ§ÈáåÊèêÈóÆ„ÄÇ

‰ΩøÁî®`git clone`ÂëΩ‰ª§Â∞ÜÂàÜÂèâÁöÑÂ≠òË¥ÆÂ∫ìÂÖãÈöÜÂà∞Êú¨Âú∞„ÄÇÂú®Êú¨Âú∞Êñ∞Âª∫‰∏Ä‰∏™Â∑•‰ΩúÁõÆÂΩï„ÄÇËøõÂÖ•ËØ•ÁõÆÂΩïÔºå‰ΩøÁî®‰∏ãÈù¢ÁöÑÂëΩ‰ª§ËøõË°åCloneÔºàÂú∞ÂùÄ‰ªégithub‰∏ä‰Ω†Ëá™Â∑±ÂàÜÂèâÁöÑÂ≠òË¥ÆÂ∫ìÈ°µÈù¢Â§çÂà∂ÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫ÔºâÔºö

```
git clone git@github.com:springzh/spellbook.git
```

![image_00.jpg](img/image_00.jpg)

ÂÖãÈöÜÂÆåÊàêÂêéÔºåÂ∑•‰ΩúÁõÆÂΩï‰∏≠‰ºöÁúãÂà∞‰∏Ä‰∏™Êñ∞ÁöÑ`spellbook`Â≠êÁõÆÂΩï„ÄÇËøõÂÖ•ËØ•Â≠êÁõÆÂΩï„ÄÇ

```
cd spellbook
```

Â¶ÇÊûú‰πãÂâçÊ≤°ÊúâËøêË°åËøá`pipenv install`Êù•ÂàõÂª∫Êú¨Âú∞ÁöÑpipenvÁéØÂ¢ÉÔºåÂàôÈúÄË¶ÅÊâßË°åÂÆâË£Ö„ÄÇ

```
pipenv install
```

Â¶ÇÊûú‰∏äÈù¢ÁöÑÂëΩ‰ª§ÊâßË°åÂá∫ÈîôÔºåÂèØ‰ª•Â∞ùËØïÔºö

```
sudo -H pip install -U pipenv
```

Â¶ÇÊûú‰∏äËø∞ÂëΩ‰ª§ËøîÂõûÈîôËØØÔºö

```
pipenv install returns warning LANG, warning Python 3.9 not found
```

ÈÇ£‰πàÂèØ‰ª•ÂÜçÊ¨°Â∞ùËØïÊåáÂÆöPython ÁâàÊú¨ÁöÑÊñπÂºèÊù•ÂÆâË£ÖÔºö

```
pipenv install --python 3.9.13
```

ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÂëΩ‰ª§Êù•Á°ÆËÆ§‰Ω†Êú¨Âú∞ÂÆâË£ÖÁöÑPythonÁâàÊú¨Ôºö

```
python3 ‚Äìversion
```

pipenvÁéØÂ¢ÉÂÆâË£ÖÂ•Ω‰πãÂêéÔºåÁé∞Âú®Â∞±ÂèØ‰ª•ÂêØÂä®ÂÆÉ‰∫Ü„ÄÇ

```
pipenv shell
```

Êé•‰∏ãÊù•ÔºåËøêË°å`dbt init`ÂëΩ‰ª§Êù•ÂàùÂßãÂåñdbt„ÄÇËØ•ÂëΩ‰ª§‰ª•‰∫§‰∫íÂºèÊñπÂºèÂºïÂØºÊàë‰ª¨ÂÆåÊàêdbtÁöÑÂàùÂßãÂåñÔºåÂâçÈù¢‚ÄúÂáÜÂ§á‰∏Ä‰∫õÂÖàÂÜ≥Êù°‰ª∂Âπ∂‰∏îËÆæÁΩÆÂ•ΩÈ≠îÊ≥ï‰π¶ dbt‚ÄùÈìæÊé•ÈáåÊúâËØ¶ÁªÜÁöÑËØ¥Êòé„ÄÇ

```
dbt init
```

ÂΩìÊàë‰ª¨ÁºñÂÜôÂ•ΩÈ≠îÊ≥ïË°®ÂêéÔºåÊàñËÄÖÂú®ÊØèÊ¨°Êàë‰ª¨ÂØπÈ≠îÊ≥ïË°®ÁöÑÁõ∏ÂÖ≥Êñá‰ª∂ËøõË°å‰∫Ü‰ªª‰Ωï‰øÆÊîπ‰πãÂêéÔºåÊàë‰ª¨‰ΩøÁî®`dbt compile`Êù•ÁºñËØëÊï¥‰∏™dbtÈ°πÁõÆÔºåÈáçÊñ∞ÁîüÊàêÈ≠îÊ≥ïË°®ÁöÑSQL„ÄÇ

‰∏∫ÈÅøÂÖçÊ∑∑Ê∑ÜÔºåÂÜçÊ¨°Âàó‰∏Ä‰∏ã‰∏ªË¶ÅÁöÑÊ≠•È™§Ôºö

**Á¨¨‰∏ÄÊ¨°ÂàùÂßãÂåñÂπ∂ËøêË°åÁöÑÊâßË°åÊ≠•È™§**Ôºö

```
# ÂÆâË£Öpipenv ÁéØÂ¢É
pipenv install

# ÂêØÂä® pipenv ÁéØÂ¢É
pipenv shell 

# ÂàùÂßãÂåñ dbt
dbt init 

# Ê∑ªÂä†„ÄÅ‰øÆÊîπÊñá‰ª∂

# ÁºñËØë dbt
dbt compile
```

**Â∑≤ÁªèÂÆåÊàêÂàùÂßãÂåñ‰πãÂêéÁöÑÂêéÁª≠Êó•Â∏∏ËøêË°åÁöÑÊâßË°åÊ≠•È™§**Ôºö

```
# ÂêØÂä® pipenv ÁéØÂ¢É
pipenv shell 

# Ê∑ªÂä†„ÄÅ‰øÆÊîπÊñá‰ª∂

# ÁºñËØë dbt
dbt compile
```

Âú®ÁºñÂÜô„ÄÅË∞ÉËØï‰∏Ä‰∏™Êñ∞ÁöÑÈ≠îÊ≥ïË°®ËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨ÂèØËÉΩÈúÄË¶ÅÂèçÂ§çË∞ÉÊï¥‰øÆÊîπÁõ∏ÂÖ≥ÁöÑÊñá‰ª∂ÔºåÂèØ‰ª•Â§öÊ¨°ÊâßË°ådbt compile„ÄÇÂ¶ÇÊûúÁºñËØëÂá∫ÈîôÔºåÊ†πÊçÆÈîôËØØ‰ø°ÊÅØËøõË°å‰øÆÊîπ„ÄÇÁºñËØëÊàêÂäüÔºåÂàôÂ§çÂà∂ÁîüÊàêÁöÑSQLËØ≠Âè•Âà∞Dune‰∏äËøõË°åÂÆûÈôÖÁöÑÊü•ËØ¢ÊµãËØïÔºåÁ°ÆËÆ§SQLÂ∑•‰ΩúÊ≠£Â∏∏‰∏îËæìÂá∫ÁªìÊûúÁ¨¶ÂêàÈ¢ÑÊúü„ÄÇ

## Êú¨ÊïôÁ®ãË¶ÅÊûÑÂª∫ÁöÑÈ≠îÊ≥ïË°®

Êú¨ÊïôÁ®ãÁöÑÁõÆÁöÑÊòØËÆ©Â§ßÂÆ∂ÂèØ‰ª•ÈÄöËøáÂæàÁÆÄÂçïÁöÑ‰æãÂ≠êÂø´ÈÄü‰∏äÊâãÊûÑÂª∫È≠îÊ≥ïË°®„ÄÇ‰πãÂâçÂú®BNBÈìæ‰∏äÁöÑSpace IDÂàöÊé®Âá∫ÂüüÂêçÊ≥®ÂÜåÊó∂ÔºåÊàëÊõæÁªèÂàõÂª∫‰∫Ü‰∏Ä‰∏™SpaceIDÊï∞ÊçÆÁúãÊùøÔºà[SpaceID - BNB Domain](https://dune.com/sixdegree/bnb-domain-spaceid)Ôºâ„ÄÇËÆ∞ÂæóÂΩìÊó∂Space IDÂè™ÊòØÂ∞èËåÉÂõ¥ÂºÄÊîæMintÊùÉÈôêÔºåÁî®Êà∑ÂØπÁõ∏ÂÖ≥ÁöÑMintËßÑÂàôÊèêÂá∫‰∫ÜÂæàÂ§öÂèçÈ¶àÂª∫ËÆÆ„ÄÇSpaceIDÈ°πÁõÆÊñπÈíàÂØπËøô‰∫õÂèçÈ¶àÂª∫ËÆÆ‰πü‰∏çÊñ≠ÂØπÂÖ∂Êô∫ËÉΩÂêàÁ∫¶ËøõË°å‰∫ÜÂÆåÂñÑÂçáÁ∫ßÔºåÁü≠Áü≠Âá†Â§©Êó∂Èó¥ÂÜÖÔºåÂüüÂêçÊ≥®ÂÜåÁöÑÂêàÁ∫¶ÂèëÂ∏É‰∫Ü5‰∏™‰∏ªË¶ÅÁâàÊú¨Ôºå‰ªé V3 Âà∞ V7„ÄÇËøôÂ∞±ÂØºËá¥‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºåÂΩìÊàë‰ª¨Ë¶ÅÊ±áÊÄªÂΩìÂâçÂ∑≤ÁªèË¢´Ê≥®ÂÜåÁöÑÊâÄÊúâSpaceIDÂüüÂêçÊï∞ÊçÆÊó∂ÔºåÂ∞±ÂøÖÈ°ªÂàÜÂà´‰ªéËøô‰∫õ‰∏çÂêåÁâàÊú¨Êô∫ËÉΩÂêàÁ∫¶ÁöÑ‰∫ã‰ª∂Êó•ÂøóË°®Êù•Êü•ËØ¢Êï∞ÊçÆÂπ∂Ëá™Ë°å‰ΩøÁî®‚ÄúUnion All‚ÄùÁöÑÊñπÂºèÂêàÂπ∂Âà∞‰∏ÄËµ∑„ÄÇÊâÄ‰ª•Â§ßÂÆ∂Â¶ÇÊûúÂéªÁúãÊàëËøô‰∏™Êï∞ÊçÆÁúãÊùøÁöÑÊü•ËØ¢Ê∫ê‰ª£Á†ÅÔºåÈáåÈù¢ÁöÑÊü•ËØ¢Âü∫Êú¨ÈÉΩÊúâ‰∏Ä‰∏™ÂæàÈïøÁöÑCTEÂÆö‰πâÊù•Ê±áÊÄªÂêàÂπ∂Êù•Ëá™‰∏çÂêåÁâàÊú¨ÂêàÁ∫¶ÁöÑÂüüÂêçÊ≥®ÂÜå‰∫ã‰ª∂„ÄÇ‰æãÂ¶ÇÔºö[https://dune.com/queries/1239514/2124307](https://dune.com/queries/1239514/2124307)„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÊõ¥Êñ∞ÔºåÊàë‰∏çÂæó‰∏çÂ§öÊ¨°ÂØπÁõ∏ÂÖ≥ÁöÑÊü•ËØ¢ÈÄê‰∏™ËøõË°å‰øÆÊîπÔºåÂ∞ÜÊñ∞ÁöÑÂêàÁ∫¶ÁâàÊú¨ÁöÑÊï∞ÊçÆÂåÖÊã¨ËøõÂéª„ÄÇÂÆûÈôÖ‰∏äÔºåÁõÆÂâçSpaceID Â∑≤ÁªèÊúâV8ÂíåV9ÁöÑÂüüÂêçÊ≥®ÂÜåÂêàÁ∫¶ÁâàÊú¨ÔºåËÄåÊàëËøô‰∏™ÁúãÊùøÂπ∂Êú™ÂåÖÊã¨ÂÆÉ‰ª¨ÁöÑÊï∞ÊçÆÔºåÂ∑≤ÁªèËøáÊó∂„ÄÇÂ¶ÇÊûúÊúâÂÖ∂‰ªñÁî®Êà∑Fork‰∫ÜÊàëÁöÑÊü•ËØ¢Âπ∂‰∏îÂÅö‰∫Ü‰∏Ä‰∫õË∞ÉÊï¥ÔºåÈÇ£‰πàÂæà‰∏çÂπ∏Ôºå‰ªñ‰ª¨ÁöÑÊü•ËØ¢‰πüËøáÊó∂‰∫Ü„ÄÇ

![image_01.jpg](img/image_01.jpg)

ÂØπ‰∫éËøôÁßçÊÉÖÂÜµÔºåÂ¶ÇÊûúÊàë‰ª¨Â∞ÜÂüüÂêçÊ≥®ÂÜå‰∫ã‰ª∂ÊûÑÂª∫‰∏∫‰∏Ä‰∏™È≠îÊ≥ïË°®ÔºàÂÆûÈôÖ‰∏äÊòØ‰∏Ä‰∏™ËßÜÂõæÔºâÔºåÈÇ£‰πàÊâÄÊúâÁöÑÊü•ËØ¢ÈÉΩÂèØ‰ª•Áõ¥Êé•Âü∫‰∫éËøô‰∏™È≠îÊ≥ïË°®Êù•ÁºñÂÜô„ÄÇÂΩìÊúâÊñ∞ÁöÑÊô∫ËÉΩÂêàÁ∫¶ÁâàÊú¨ÂèëÂ∏ÉÊó∂ÔºåÊàë‰ª¨Âè™ÈúÄË¶Å‰øÆÊîπÊõ¥Êñ∞È≠îÊ≥ïË°®ÁöÑÂÆö‰πâÔºåÈáçÊñ∞Êèê‰∫§PRÂéªreview„ÄÇÊèê‰∫§ÁöÑPRË¢´ÂÆ°Ê†∏ÈÄöËøáÂπ∂‰∏îÂêàÂπ∂‰πãÂêéÔºåÈ≠îÊ≥ïË°®ÁöÑÊï∞ÊçÆÂ∞±Ëá™Âä®Êõ¥Êñ∞‰∫Ü„ÄÇÊâÄÊúâ‰ΩøÁî®Ëøô‰∏™È≠îÊ≥ïË°®ÁöÑÊü•ËØ¢ÈÉΩ‰∏çÈúÄË¶Å‰ªª‰ΩïÊîπÂä®„ÄÇÂèç‰πãÔºåÂú®Ê≤°ÊúâÈ≠îÊ≥ïË°®ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàëÁöÑËøô‰∫õÊü•ËØ¢ÔºåÂåÖÊã¨ÂÖ∂‰ªñ‰∫∫ForkËøô‰∫õÊü•ËØ¢ÁîüÊàêÁöÑÊñ∞Êü•ËØ¢ÔºåÈÉΩÂøÖÈ°ªÈÄê‰∏™‰øÆÊîπ„ÄÇ‰ªéËøôÈáåÊàë‰ª¨ÂèØ‰ª•ÂÖÖÂàÜÁúãÂà∞ÊûÑÂª∫È≠îÊ≥ïË°®ÁöÑÂ•ΩÂ§Ñ„ÄÇ

ÊâÄ‰ª•ÔºåÊàë‰ª¨ËøôÈáåË¶ÅÂÅöÁöÑÂ∞±ÊòØÈíàÂØπ`bnb`Âå∫ÂùóÈìæ‰∏äÁöÑ`spaceid`È°πÁõÆÔºåÊûÑÂª∫‰∏Ä‰∏™ÂåÖÊã¨ÂÖ®ÈÉ®Space IDÂüüÂêçÊ≥®ÂÜå‰ø°ÊÅØÁöÑÈ≠îÊ≥ïË°®„ÄÇ

## ÂàõÂª∫ÁõÆÂΩïÁªìÊûÑÂíåÊñá‰ª∂

Á°ÆÂÆö‰∫ÜË¶ÅÂà∂‰Ωú‰ªÄ‰πàÈ≠îÊ≥ïË°®‰πãÂêéÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÁùÄÊâãÂºÄÂßãÂ∑•‰Ωú‰∫Ü„ÄÇ‰ΩøÁî®gitÊó∂ÔºåÊÄªÊòØÂú®Â∑•‰ΩúÂàÜÊîØ‰∏≠ËøõË°åÂºÄÂèëÊòØ‰∏Ä‰∏™Â•Ω‰π†ÊÉØÔºåÂª∫ËÆÆÂ§ßÂÆ∂ÈÉΩÈÅµÂæ™Ëøô‰∏™ÊñπÂºè„ÄÇÊàë‰ª¨Âú®Â∑≤ÁªèÂÖãÈöÜÂà∞Êú¨Âú∞ÁöÑspellbook Â≠òË¥ÆÂ∫ì‰∏≠Êñ∞Âª∫‰∏Ä‰∏™Â∑•‰ΩúÂàÜÊîØÔºö

```
git checkout -b add_bnb_spaceid
```

Áé∞Âú®Êàë‰ª¨Â∞±Ëá™Âä®ÂàáÊç¢Âà∞‰∫Ü`add_bnb_spaceid`Ëøô‰∏™Êñ∞Âª∫ÁöÑgit Â∑•‰ΩúÂàÜÊîØ‰∏ã„ÄÇÂèØ‰ª•ÂºÄÂßãÂàõÂª∫È≠îÊ≥ïË°®ÈúÄË¶ÅÁöÑÁõÆÂΩïÁªìÊûÑÂíåÊñá‰ª∂„ÄÇ

È°πÁõÆÁ±ªÂûãÁöÑÈ≠îÊ≥ïË°®ÔºåÈÉΩÊåâ‚ÄúÈ°πÁõÆÂêçÁß∞/Âå∫ÂùóÈìæÂêçÁß∞‚ÄùÁöÑÁªìÊûÑÂ≠òÂÇ®Âú® /spellbook/models ÁõÆÂΩï‰∏≠„ÄÇÂêçÁß∞ÂÖ®ÈÉ®‰ΩøÁî®Â∞èÂÜôÂ≠óÊØçÔºåÂçïËØç‰πãÈó¥Áî® `_` ÂàÜÈöî„ÄÇ‰æãÂ¶ÇÔºö`/spellbook/models/[project_name]/[blockchain_name]`„ÄÇÊàë‰ª¨Ë¶ÅÊûÑÂª∫È≠îÊ≥ïË°®ÁöÑÈ°πÁõÆÂêçÁß∞ÊòØ`spaceid`ÔºåÂå∫ÂùóÈìæÊòØ`bnb`ÔºåÊâÄ‰ª•Êàë‰ª¨Ëøô‰∏™È≠îÊ≥ïË°®ÁöÑÂÆåÊï¥ÁõÆÂΩïÁªìÊûÑÂ∞±ÊòØÔºö`/spellbook/models/spaceid/bnb/`„ÄÇ

ËØ∑ËøõÂÖ•`models`ÁõÆÂΩïÔºåÂú®ÂÖ∂‰∏ãÂàõÂª∫Â≠êÁõÆÂΩï`spaceid`ÔºåÂÜçËøõÂÖ•Ëøô‰∏™Êñ∞Âª∫ÁöÑÁõÆÂΩï‰∏≠ÂàõÂª∫`bnb`Â≠êÁõÆÂΩï„ÄÇ

È≠îÊ≥ïË°®Êñá‰ª∂ÂëΩÂêçÂ¶Ç‰∏ãÔºö
- ÂØπ‰∫éÊ®°ÂºèÊñá‰ª∂Ôºö[project_name]_[blockchain]_schema.yml
- ÂØπ‰∫é‰æùËµñÊ∫êÊñá‰ª∂Ôºö[project_name]_[blockchain]_sources.yml
- ÂØπ‰∫éÈ≠îÊ≥ïË°®ÁöÑSQLÊñá‰ª∂Ôºö[project_name]_[blockchain]_[spell_name].sql

ÂÖ∂‰∏≠Ôºå`spell_name`ÊòØÊàë‰ª¨ÊÉ≥ÂàõÂª∫ÁöÑÈ≠îÊ≥ïË°®ÁöÑÂêçÁß∞„ÄÇÊàë‰ª¨‰ΩøÁî®`registrations`‰Ωú‰∏∫ÂêçÁß∞„ÄÇ

ÊâÄ‰ª•Êàë‰ª¨ÈúÄË¶ÅÂú®`spaceid/bnb/`ÁõÆÂΩï‰∏≠ÂàÜÂà´ÂàõÂª∫‰ª•‰∏ã3‰∏™ÂØπÂ∫îÁöÑÊñá‰ª∂ÔºàÊñá‰ª∂ÂÜÖÂÆπÂÖà‰øùÊåÅ‰∏∫Á©∫ÔºåÁ®çÂêéÊàë‰ª¨ÈÄê‰∏™ËÆ≤Ëß£ÔºâÔºö
- spaceid_bnb_schema.yml
- spaceid_bnb_sources.yml
- spaceid_bnb_registrations.sql

Áé∞Âú®ÁöÑÁõÆÂΩïÂíåÊñá‰ª∂ÁªìÊûÑÂ¶Ç‰∏ãÔºö

![image_02.jpg](img/image_02.jpg)

ÂèÇËÄÉÊñáÊ°£Ôºö[üõ£Ô∏è ‰∏∫ SQL„ÄÅÊ®°ÂºèÂíåÊ∫êÊñá‰ª∂ËÆæÁΩÆÊñá‰ª∂ÁªìÊûÑ](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/3-set-up-your-file-structure-for-SQL-schema-and-source-files/)

## ÂÆö‰πâ‰æùËµñÊ∫êÊñá‰ª∂

Êàë‰ª¨ËøôÈáåÂè™ÈúÄË¶ÅÁî®Âà∞SpaceIDÈ°πÁõÆÂà∞ÁõÆÂâç‰∏∫Ê≠¢Â∑≤ÂèëÂ∏ÉÁöÑÂêàÁ∫¶`RegistrarController`ÁöÑ‰∏É‰∏™‰∏çÂêåÁâàÊú¨ÁöÑÂ∑≤Ëß£ÊûêË°®„ÄÇËøô‰∫õË°®‰Ωç‰∫é`spaceid_bnb` Ê®°Âºè‰πã‰∏ã„ÄÇÊàë‰ª¨ÁöÑ‰æùËµñÊ∫êÊñá‰ª∂`spaceid_bnb_sources.yml`ÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö

```yml
version: 2

sources:
  - name: spaceid_bnb
    description: "bnb decoded tables related to SpaceId contract"
    freshness: # default freshness
      warn_after: { count: 12, period: hour }
      error_after: { count: 24, period: hour }
    tables:
      - name: BNBRegistrarControllerV3_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV4_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV5_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV6_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV7_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV8_evt_NameRegistered
        loaded_at_field: evt_block_time
      - name: BNBRegistrarControllerV9_evt_NameRegistered
        loaded_at_field: evt_block_time
```

Âú®Êàë‰ª¨ÂÆö‰πâÁöÑ‰æùËµñÊ∫êÊñá‰ª∂‰∏≠Ôºö
1. `version` ÊÄªÊòØ‰∏∫`2`„ÄÇ
2. `name` ÊåáÂÆö‰æùËµñÊ∫êÊï∞ÊçÆË°®ÁöÑÊ®°ÂºèÔºàSchemaÂêçÁß∞Ôºâ„ÄÇÊàë‰ª¨ÂèØ‰ª•Âú®Dune‰∏äÊñ∞Âª∫Êü•ËØ¢ÔºåÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑË°®ÔºåÂ∞ÜË°®ÂêçÊ∑ªÂä†Âà∞Êü•ËØ¢ÁºñËæëÂô®‰∏≠Ôºå`.`Á¨¶Âè∑Â∑¶ËæπÁöÑÈÉ®ÂàÜÂ∞±ÊòØË°®ÁöÑÊ®°ÂºèÂêçÁß∞„ÄÇÊØîÂ¶Ç`spaceid_bnb.BNBRegistrarControllerV3_evt_NameRegistered` Ë°®ÁöÑÊ®°ÂºèÂêçÁß∞Â∞±ÊòØ`spaceid_bnb`„ÄÇ
3. `freshness` Ëøô‰∏™ËÆæÁΩÆÁî®‰∫éÁ°ÆËÆ§È≠îÊ≥ïË°®Êï∞ÊçÆÁöÑËá™Âä®Êõ¥Êñ∞ÔºåÂ¶ÇÊûúË∂ÖËøáÊåáÂÆöÊó∂Èó¥Êú™ÊàêÂäüÊõ¥Êñ∞ÔºåÂàô‰ºöÂú®‰ΩøÁî®È≠îÊ≥ïË°®Êó∂ÂèëÂá∫Ë≠¶ÂëäÊàñÊòæÁ§∫ÈîôËØØÔºàÊàëËá™Â∑±Â∞öÊú™ÈÅáÂà∞ËøáÊ≠§Á±ªÈîôËØØÔºåÊâÄ‰ª•‰πüÂèØËÉΩÈîôËØØÂè™ÂèëÈÄÅÁªôÁª¥Êä§È≠îÊ≥ïË°®Ê®°ÂùóÁöÑÂ∑•‰Ωú‰∫∫ÂëòÔºâ„ÄÇ‰øùÊåÅÁõ∏ÂêåÁöÑÈªòËÆ§ËÆæÁΩÆÂç≥ÂèØ„ÄÇËøôÈáåÁöÑËÆæÁΩÆÂØπÂêéÁª≠`tables`‰∏ãÁöÑÊâÄÊúâÊï∞ÊçÆÊù•Ê∫êË°®ÈÉΩÊúâÊïà„ÄÇÂΩìÁÑ∂‰πüÂèØ‰ª•ÂØπÂçï‰∏™Ë°®Ê∑ªÂä†Ê≠§È°πËÆæÁΩÆ„ÄÇ
4. `tables`ÈÉ®ÂàÜÈÄê‰∏™ÂàóÂá∫Êàë‰ª¨ÈúÄË¶ÅÁî®Âà∞ÁöÑÊï∞ÊçÆÊù•Ê∫êË°®„ÄÇËøô‰∫õË°®ÈúÄË¶ÅÈÉΩÂΩíÂ±û‰∫é‰∏äÈù¢Ê®°ÂºèÂêçÁß∞ÊåáÂÆöÁöÑÂêå‰∏Ä‰∏™Ê®°Âºè„ÄÇÂ¶ÇÊûúÊúâÂ±û‰∫é‰∏çÂêåÊ®°ÂºèÁöÑË°®ÔºåÊàë‰ª¨Â∞±ÈúÄË¶ÅÂú®Âêå‰∏Ä‰∏™Êñá‰ª∂‰∏≠ÂçïÁã¨ÂÜçÊ∑ªÂä†‰∏ÄÊÆµÁõ∏ÂêåÁöÑÁªìÊûÑÁöÑÂÆö‰πâ„ÄÇÂèØÂèÇËÄÉÂÖ∂‰ªñÂ∑≤ÊúâÁöÑÈ≠îÊ≥ïË°®ÁöÑÊ®°ÂºèÊñá‰ª∂ÂÆö‰πâ„ÄÇ
  - `name` ËÆæÁΩÆË°®ÁöÑÂêçÁß∞„ÄÇËøôÈáå‰∏çË¶ÅÂåÖÊã¨Ê®°ÂºèÂêçÁß∞„ÄÇ
  - `loaded_at_field` ÊåáÂÆöÁî®‰∫éÊ£ÄÊü•È™åËØÅÊúÄÂêéÂá†Ë°åÊï∞ÊçÆÁöÑÂä†ËΩΩÊó∂Èó¥ÔºåÈúÄË¶ÅÊåáÂÆö‰∏Ä‰∏™Êó∂Èó¥Êà≥Á±ªÂûãÂ≠óÊÆµ„ÄÇËøô‰∏™ÈÖçÂêà`freshness` ËÆæÁΩÆÁ°Æ‰øùÈ≠îÊ≥ïË°®Êï∞ÊçÆÁöÑÊ≠£Â∏∏Êõ¥Êñ∞„ÄÇ


ÂèÇËÄÉÊñáÊ°£Ôºö
- [üìô ËØÜÂà´ÂíåÂÆö‰πâ‰æùËµñÊ∫ê](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/4-identify-and-define-sources/)
- [Êï∞ÊçÆÊ∫ê](https://dune.com/docs/zh/spellbook/getting-started/data-sources/)

## ÂÆö‰πâÊ®°ÂºèÊñá‰ª∂

Ê®°ÂºèÊñá‰ª∂`spaceid_bnb_schema.yml`Êèê‰æõË¶ÅÂàõÂª∫ÁöÑÈ≠îÊ≥ïË°®ÁöÑÂêçÁß∞„ÄÅÂ≠óÊÆµ„ÄÅÊèèËø∞Á≠â‰ø°ÊÅØÔºåÂ∑≤ÁªèÁõ∏Â∫îÁöÑÈÖçÁΩÆ‰ø°ÊÅØ„ÄÇ

```yml
version: 2

models:
  - name: spaceid_bnb_registrations
    meta:
      blockchain: bnb
      project: spaceid
      contributors: [springzh]
    config:
      tags: ['bnb','spaceid','name','registrations']
    description: >
       SpaceID V3, V4, V5, V6, V7, V8 & V9 Name Registered on BNB
    columns:
      - &version
        name: version
        description: "Contract version"
      - &block_time
        name: block_time
        description: "UTC event block time"
      - &name
        name: name
        description: "Name of the space ID"
        tests:
          - unique
      - &label
        name: label
        description: "Label of the space ID"
      - &owner
        name: owner
        description:  "Owner of the space ID"
      - &cost
        name: cost
        description:  "Cost spent to register the space id"
      - &expires
        name: expires
        description:  "Name expires date and time in unix timestamp format"
      - &contract_address
        name: contract_address
        description:  "Contract address that called to register the space id"
      - &tx_hash
        name: tx_hash
        description:  "Transaction hash"
      - &block_number
        name: block_number
        description: "Block number in which the transaction was executed"
      - &evt_index
        name: evt_index
        description: "Event index"
```

SpaceIDÁöÑÂ§ö‰∏™ÁâàÊú¨ÁöÑ`NameRegistered`‰∫ã‰ª∂Ë°®ÁªìÊûÑÂÆåÂÖ®Áõ∏ÂêåÔºåÊâÄ‰ª•Êàë‰ª¨ÁöÑÂ∑•‰ΩúÊØîËæÉÁÆÄÂçïÔºå‰ΩøÁî®ÂÖ∂‰∏≠‰∏Ä‰∏™Ë°®ÁöÑÁªìÊûÑÂÅöÂèÇËÄÉÔºåÂ∞±ÂèØ‰ª•ÂÆö‰πâÂá∫Êàë‰ª¨ÁöÑÊ®°ÂºèÊñá‰ª∂„ÄÇ‰∏∫‰∫ÜÂå∫ÂàÜÂüüÂêçÊ≥®ÂÜåÁöÑÊù•Ê∫êÔºåÊàë‰ª¨Ê∑ªÂä†‰∏Ä‰∏™`version`Â≠óÊÆµÔºå‰øùÂ≠ò'v3'„ÄÅ'v4'ËøôÊ†∑ÁöÑÊô∫ËÉΩÂêàÁ∫¶ÁâàÊú¨‰ø°ÊÅØ„ÄÇ

Âõ†‰∏∫ÂüüÂêçÊòØÂîØ‰∏ÄÁöÑÔºåÊàë‰ª¨Áªô`name`Â≠óÊÆµÊ∑ªÂä†‰∫Ü‰∏Ä‰∏™ÂîØ‰∏ÄÊÄßÁöÑÊµãËØïÂÆö‰πâ„ÄÇÁºñËØëÊó∂‰ºöËá™Âä®ÁîüÊàê‰∏Ä‰∏™ÂØπÂ∫îÁöÑÊµãËØïSQLÔºåÁî®‰∫éÁ°Æ‰øùÈ≠îÊ≥ïË°®Êï∞ÊçÆ‰∏≠‰∏çÂ≠òÂú®ÈáçÂ§çÂÄº„ÄÇ

`&field_name`ÂÆö‰πâÂ≠óÊÆµÂêçÁß∞„ÄÇÂêå‰∏Ä‰∏™Â≠óÊÆµÂêçÁß∞Á¨¨‰∏ÄÊ¨°Âá∫Áé∞Êó∂ÔºåÈúÄË¶ÅÂ∏¶Êúâ‚Äú&‚ÄùÂâçÁºÄ„ÄÇÂêéÁª≠Âú®Âêå‰∏Ä‰∏™Êñá‰ª∂‰∏≠ÁöÑÂÖ∂‰ªñË°®ÁöÑÂ≠óÊÆµÂÆö‰πâÂèØ‰ª•‰ΩøÁî®`*field_name`Êù•ÂºïÁî®ÔºåËøôÊ†∑ÂèØ‰ª•ËÆ©‰ª£Á†ÅÊõ¥ÁÆÄÊ¥Å„ÄÇ

## ÁºñÂÜôÈ≠îÊ≥ïË°®ËßÜÂõæÁöÑSQLËØ≠Âè•

Êé•‰∏ãÊù•Êàë‰ª¨ËøõÂÖ•È≠îÊ≥ïË°®ÊúÄÂÖ≥ÈîÆÁöÑSQLÁºñÂÜôÈÉ®ÂàÜ„ÄÇÊâìÂºÄ`spaceid_bnb_registrations.sql`Êñá‰ª∂ÔºåËæìÂÖ•Â¶Ç‰∏ãÂÜÖÂÆπÔºàÂÅö‰∫ÜÈÉ®ÂàÜÁúÅÁï•ÔºâÔºö

```sql
{{config(alias='registrations',
        post_hook='{{ expose_spells(\'["bnb"]\',
                                    "project",
                                    "spaceid",
                                    \'["springzh"]\') }}')}}
SELECT 'v3' as version,
    evt_block_time as block_time,
    name,
    label,
    owner,
    cast(cost as double) as cost,
    cast(expires as bigint) as expires,
    contract_address,
    evt_tx_hash as tx_hash,
    evt_block_number as block_number,
    evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV3_evt_NameRegistered')}}

UNION ALL

SELECT 'v4' as version,
    evt_block_time as block_time,
    name,
    label,
    owner,
    cast(cost as double) as cost,
    cast(expires as bigint) as expires,
    contract_address,
    evt_tx_hash as tx_hash,
    evt_block_number as block_number,
    evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV4_evt_NameRegistered')}}

-- Ê≠§Â§ÑÁúÅÁï•‰∫Ü V5 - V8ÁöÑ‰ª£Á†ÅÈÉ®ÂàÜ

UNION ALL

-- There are some records in v9 table are duplicated with those in v5 table. So we join to exclude them
SELECT 'v9'                       as version,
       v9.evt_block_time          as block_time,
       v9.name,
       v9.label,
       v9.owner,
       cast(v9.cost as double)    as cost,
       cast(v9.expires as bigint) as expires,
       v9.contract_address,
       v9.evt_tx_hash             as tx_hash,
       v9.evt_block_number        as block_number,
       v9.evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV9_evt_NameRegistered')}} v9
LEFT JOIN {{source('spaceid_bnb', 'BNBRegistrarControllerV5_evt_NameRegistered')}} v5
    ON v9.name = v5.name
WHERE v5.name is null
```

ËØ¥ÊòéÂ¶Ç‰∏ãÔºö
- ÂºÄÂ§¥ÁöÑ`config`ÂØπÈ≠îÊ≥ïË°®ÂÅö‰∏Ä‰∫õÈÖçÁΩÆËØ¥ÊòéÔºåÈùûÂ∏∏ÂÖ≥ÈîÆ„ÄÇËØ∑ÊÄªÊòØ‰øùÊåÅÁõ∏ÂêåÁöÑÊ†ºÂºè„ÄÇ‰πüËØ∑Ê≥®ÊÑèÂçïÂºïÂè∑ÂèåÂºïÂè∑ÂµåÂ•óÊó∂ÁöÑËΩ¨‰πâÂ§ÑÁêÜ„ÄÇÂÖ∂‰∏≠Ôºå`alias`ÊåáÂÆöÈ≠îÊ≥ïË°®ÁöÑÂà´ÂêçÔºåËøô‰∏™Â∞±ÊòØÁî®Êà∑Âú®Êü•ËØ¢ÁºñËæëÂô®‰∏≠Áî®Âà∞ÁöÑÈ≠îÊ≥ïË°®ÂêçÁß∞„ÄÇÂª∫ËÆÆ‰ΩøÁî®Ë∑üÂú®schema‰∏≠ÂÆö‰πâÁöÑÂêçÁß∞„ÄÇ`post_hook` ÈÖçÁΩÆÈ≠îÊ≥ïË°®ÊûÑÂª∫ÂÆåÊàêÂèëÂ∏ÉÊó∂ÁöÑÈôÑÂä†Êìç‰Ωú„ÄÇ`expose_spells`ËÆæÁΩÆÂ∞ÜÈ≠îÊ≥ïË°®Â±ïÁ§∫Âà∞Êü•ËØ¢ÁºñËæëÂô®‰∏≠ÔºàÂÖ∂‰ªñÁî®Êà∑ÂèØ‰ª•ÊêúÁ¥¢ÊâæÂà∞Ôºâ„ÄÇÂÆÉÁöÑÂèÇÊï∞ÊåâÈ°∫Â∫èÂàÜÂà´Ë°®Á§∫ÔºåÈÄÇÈÖçÁöÑÂå∫ÂùóÈìæÔºàÊï∞ÁªÑÔºâÔºåÈ≠îÊ≥ïË°®ÁöÑÁ±ªÂûãÔºàÈ°πÁõÆÁ±ªÂûãËøòÊòØË°å‰∏öÁ±ªÂûãÔºâÔºåÈ°πÁõÆÊàñË°å‰∏öÁöÑÂëΩÂêçÔºåË¥°ÁåÆËÄÖÂàóË°®ÔºàÊï∞ÁªÑÔºâ„ÄÇÂÖ∑‰ΩìÂà∞Êàë‰ª¨Ëøô‰∏™È≠îÊ≥ïË°®ÔºåÂ∞±ÊòØbnbÂå∫ÂùóÈìæÔºåprojectÁ±ªÂûãÔºåÂêçÁß∞ÊòØspaceidÔºåË¥°ÁåÆËÄÖÂÜô‰Ω†Ëá™Â∑±ÁöÑgithubË¥¶Âè∑ÂêçÁß∞„ÄÇ
- ‰∏ª‰ΩìÈÉ®ÂàÜÂ∞±ÊòØ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑSELECTÊü•ËØ¢ËØ≠Âè•„ÄÇË∑üÊàë‰ª¨Âπ≥Â∏∏ÁºñÂÜôÁöÑÊü•ËØ¢ËØ≠Âè•ÁöÑ‰∏çÂêå‰πãÂ§ÑÂú®‰∫éÔºåÊàë‰ª¨ÈúÄË¶Å‰ΩøÁî®ÁâπÊÆäÁöÑJINJAÊ®°ÁâàËØ≠Ê≥ïÊù•ÂºïÁî®Êï∞ÊçÆÊ∫êË°®„ÄÇ‰æãÂ¶Ç`{{source('spaceid_bnb', 'BNBRegistrarControllerV9_evt_NameRegistered')}}` Â∞±ÊåáÂêëÊàë‰ª¨Âú®`spaceid_bnb_sources.yml`Êñá‰ª∂‰∏≠ÂÆö‰πâÁöÑ`BNBRegistrarControllerV9_evt_NameRegistered`Ë°®„ÄÇ
- Âú®Êèê‰∫§PRÁªôDune Review‰πãÂêéÔºåÊàë‰ª¨Êî∂Âà∞ÊµãËØïÂèçÈ¶àÔºåÂüüÂêç`name`Â≠óÊÆµÁöÑÂîØ‰∏ÄÊÄßÊ£ÄÊü•ÊµãËØïÂ§±Ë¥•„ÄÇÁªèËøáÊ£ÄÊü•Á°ÆËÆ§ÔºåÂèëÁé∞ÊòØV9ÁâàÊú¨ÁöÑË°®‰∏≠ÂåÖÂê´‰∫ÜÈÉ®ÂàÜV5‰∏≠ÁöÑËÆ∞ÂΩïÔºåÂπ∂‰∏îÊù•Ê∫ê‰∫éÁõ∏ÂêåÁöÑ‰∫§ÊòìËÆ∞ÂΩïÔºàevt_tx_hashÂÄºÁõ∏ÂêåÔºâ„ÄÇËøôÈáåÁöÑÂéüÂõ†Â∞öÊú™Á°ÆÂÆöÔºå‰∏çËøáÊàë‰ª¨Â∞±ÂØπV9ÈÉ®ÂàÜÁöÑÊü•ËØ¢ÂÅö‰∫ÜË∞ÉÊï¥ÔºåÊéíÈô§ÊéâÈÇ£‰∫õÂ∑≤ÁªèÂú®V5‰∏≠ÁöÑËÆ∞ÂΩï„ÄÇ

ÂèÇËÄÉÊñáÊ°£Ôºö
- [üé® ÈÖçÁΩÆÂà´ÂêçÂíåÁâ©ÂåñÁ≠ñÁï•](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/7-configure-alias-and-materialization-strategy/)
- [üñãÔ∏è Â∞ÜÊÇ®ÁöÑÈ≠îÊ≥ïË°®ÂÜôÊàê SELECT ËØ≠Âè•](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/6-write-your-spell-as-SELECT-statement/)

ÂÜôÂ•ΩÊü•ËØ¢ËØ≠Âè•ÂêéÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖà‰ΩøÁî®`dbt compile`Â∞ùËØïÁºñËØë„ÄÇÂ¶ÇÊûúËøîÂõûÈîôËØØÔºåËØ∑ÈíàÂØπÊÄß‰øÆÊîπÂêéÂÜçÊ¨°ÁºñËØëÔºåÁ°Æ‰øùÁºñËØëÊàêÂäü„ÄÇ

Âú®Êàë‰ª¨ÁöÑPRÊèê‰∫§Review‰πãÂêéÔºåÊî∂Âà∞‰∫ÜËØÑÂÆ°ÂèçÈ¶àÔºåÂª∫ËÆÆÂ∞ÜËßÜÂõæÁöÑÁâ©ÂåñÁ≠ñÁï•ËÆæÁΩÆ‰∏∫Â¢ûÈáèÊõ¥Êñ∞ÔºàincrementalÔºâÔºåÊâÄ‰ª•ÂØπ‰∫é‰∏äÈù¢ÁöÑÊü•ËØ¢SQLÔºåÂàÜÂà´ÂØπÂÖ∂Â§¥ÈÉ®ÁöÑ`config`ÈÉ®ÂàÜÂíåÊØè‰∏Ä‰∏™Â≠êÊü•ËØ¢ÈÉ®ÂàÜÂ¢ûÂä†ÊúâÂÖ≥Â¢ûÈáèÊõ¥Êñ∞ÁöÑË∞ÉÊï¥„ÄÇË∞ÉÊï¥ÂêéÁöÑÁ§∫‰æãÂ¶Ç‰∏ãÔºö

```sql
{{
    config(
        alias='registrations'
        ,materialized = 'incremental'
        ,file_format = 'delta'
        ,incremental_strategy = 'merge'
        ,unique_key = ['name']
        ,post_hook='{{ expose_spells(\'["bnb"]\',
                                    "project",
                                    "spaceid",
                                    \'["springzh"]\') }}'
    )
}}

SELECT 'v3'                    as version,
       evt_block_time          as block_time,
       name,
       label,
       owner,
       cast(cost as double)    as cost,
       cast(expires as bigint) as expires,
       contract_address,
       evt_tx_hash             as tx_hash,
       evt_block_number        as block_number,
       evt_index
FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV3_evt_NameRegistered')}}
{% if is_incremental() %}
WHERE evt_block_time >= date_trunc("day", now() - interval '1 week')
{% endif %}

UNION ALL

-- Ê≠§Â§ÑÁúÅÁï•
```

Ê∑ªÂä†‰∫ÜÂ¢ûÈáèÊõ¥Êñ∞Áõ∏ÂÖ≥ÁöÑÈÖçÁΩÆÂíåÊù°‰ª∂ÊéßÂà∂ÂêéÔºåÂú®Â¢ûÈáèÊõ¥Êñ∞Ê®°Âºè‰∏ãÔºàÂç≥`{% if is_incremental() %}`ÔºâÔºåÊØèÊ¨°Âè™‰ºöÂØπËøë‰∏ÄÂë®ÂÜÖÁöÑÊï∞ÊçÆËøõË°åÊü•ËØ¢ÔºåÊü•ËØ¢Âà∞ÁöÑÊñ∞Êï∞ÊçÆÂ∞Ü‰ºöË¢´ÂêàÂπ∂Âà∞‰øùÂ≠òËßÜÂõæÊï∞ÊçÆÁöÑÁâ©ÁêÜÊñá‰ª∂‰∏≠ÔºåÂõ†‰∏∫‰ΩøÁî®‰∫Ü`incremental_strategy = 'merge'`Á≠ñÁï•ÔºåÂ∑≤Â≠òÂú®ÁöÑËÆ∞ÂΩï‰ºöË¢´ÂøΩÁï•„ÄÇ

## Â∞ÜÊñ∞Ê®°ÂûãÊ∑ªÂä†Âà∞ dbt_project.yml Êñá‰ª∂

Êé•‰∏ãÊù•Êàë‰ª¨ÈúÄË¶Å‰øÆÊîπ‰Ωç‰∫éspellbookÊ†πÁõÆÂΩï‰∏ãÁöÑ`dbt_project.yml`Êñá‰ª∂ÔºåÂ∞ÜÊàë‰ª¨ÁöÑÈ≠îÊ≥ïË°®Âä†ÂÖ•ÂÖ∂‰∏≠„ÄÇ

```
    spaceid:
      +schema: spaceid
      bnb:
        +schema: spaceid_bnb
```

ËøôÈáåÊàë‰ª¨ÂàÜÂêßÊåáÂÆö‰∫ÜÈ°πÁõÆÂêçÁß∞ÂíåÈ°πÁõÆÁöÑÊ®°ÂºèÂêçÁß∞ÔºåÂ∑≤ÁªèÈ°πÁõÆÂØπÂ∫îÁöÑÂå∫ÂùóÈìæÂêçÁß∞ÂíåÂú®ËØ•Âå∫ÂùóÈìæ‰∏ãÁöÑÊ®°ÂºèÂêçÁß∞„ÄÇÈÄöËøáËøôÊ†∑ÁöÑÂ±ÇÁ∫ßÁªìÊûÑÔºåÊàë‰ª¨ÂèØ‰ª•ËøõË°åÂàÜÂ±ÇÊäΩË±°Â§ÑÁêÜÔºåÂÖàÈíàÂØπÊØè‰∏™ÈÉ®ÁΩ≤Âú®‰∏çÂêåÂå∫ÂùóÈìæ‰∏äÁöÑÈ°πÁõÆÊûÑÂª∫È≠îÊ≥ïË°®ÔºåÁÑ∂ÂêéÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Â∞ÜÂ§ö‰∏™Âå∫ÂùóÈìæ‰∏äÁöÑÁõ∏ÂêåÈ°πÁõÆÁöÑÈ≠îÊ≥ïË°®Ëøõ‰∏ÄÊ≠•ÊûÑÂª∫‰∏∫Êï¥‰∏™È°πÁõÆÂ±ÇÁ∫ßÁöÑÈ≠îÊ≥ïË°®„ÄÇÂÖ∑‰ΩìÁöÑ‰æãÂ≠êÂèØ‰ª•ÂèÇËÄÉopenseaÊàñËÄÖuniswapÁõ∏ÂÖ≥ÁöÑÈ≠îÊ≥ïË°®„ÄÇ

ÂèØ‰ª•ÂÜçÊ¨°‰ΩøÁî®`dbt compile`Â∞ùËØïÁºñËØëÔºåÁ°ÆËÆ§ÁºñËØëÊàêÂäü„ÄÇ

ÂèÇËÄÉÊñáÊ°£Ôºö
- [üé® ÈÖçÁΩÆÂà´ÂêçÂíåÁâ©ÂåñÁ≠ñÁï•](https://dune.com/docs/zh/spellbook/how-to-cast-a-spell/7-configure-alias-and-materialization-strategy/)

## ÁºñÂÜôÊµãËØï

Êàë‰ª¨ÈúÄË¶ÅÁ°Æ‰øùÁîüÊàêÁöÑÈ≠îÊ≥ïË°®Êï∞ÊçÆÊòØÂÆåÊï¥‰∏îÂáÜÁ°ÆÁöÑÔºåÈÄöËøáÁºñÂÜôÂêàÁêÜÁöÑÊµãËØïÂèØ‰ª•ËææÂà∞Ëøô‰∏™ÁõÆÁöÑ„ÄÇÂú®`spellbook/test`ÁõÆÂΩï‰∏ãÂàõÂª∫Êñ∞ÁöÑÁõÆÂΩïË∑ØÂæÑ`spaceid/bnb`ÔºåËøõÂÖ•bnbÂ≠êÁõÆÂΩïÔºåÂú®ÂÖ∂‰∏≠ÂàõÂª∫‰∏Ä‰∏™Êñá‰ª∂`spaceid_registrations_test.sql`ÔºåÊñá‰ª∂ÂÜÖÂÆπÂ¶Ç‰∏ãÔºö

```sql
WITH unit_tests AS (
    SELECT COUNT(*) as count_spell
    FROM {{ ref('spaceid_bnb_registrations') }} AS s
    WHERE version = 'v7'
),

spaceid_v7_registration as (
    SELECT COUNT(*) as count_event_table
    FROM {{source('spaceid_bnb', 'BNBRegistrarControllerV7_evt_NameRegistered')}}
)
SELECT 1
FROM unit_tests
JOIN spaceid_v7_registration ON TRUE
WHERE count_spell - count_event_table <> 0
```

Êàë‰ª¨Âú®Ëøô‰∏™ÊµãËØï‰∏≠Ôºå‰ΩøÁî®`{{ ref('spaceid_bnb_registrations') }}` ÁöÑÂΩ¢ÂºèÊù•ÂºïÁî®ÁîüÊàêÁöÑÈ≠îÊ≥ïË°®„ÄÇÈ¶ñÂÖàÔºå‰ªéÁîüÊàêÁöÑÈ≠îÊ≥ïË°®‰∏≠Êü•Âá∫V7ÁâàÊú¨ÁöÑÊâÄÊúâËÆ∞ÂΩïÊï∞„ÄÇÁÑ∂ÂêéÊàë‰ª¨ÂÜç‰ΩøÁî®`{{source('spaceid_bnb', 'BNBRegistrarControllerV7_evt_NameRegistered')}}Ôºå‰ªéÂØπÂ∫îÁöÑV7Ëß£ÊûêË°®Êü•ËØ¢ËÆ∞ÂΩïÊï∞Èáè„ÄÇÊúÄÂêéÊ£ÄÊü•Ëøô‰∏§‰∏™CTEËøîÂõûÁöÑËÆ∞ÂΩïÊï∞ÈáèÊòØÂê¶Áõ∏Âêå„ÄÇÂ¶ÇÊûú‰∏çÂêåÔºåÂàô‰ºöËøîÂõû‰∏ÄË°åÁªìÊûúËÆ∞ÂΩï„ÄÇ‰∏Ä‰∏™ÊàêÂäüÁöÑÊµãËØïÂøÖÈ°ª‰∏çËøîÂõû‰ªª‰ΩïÁªìÊûúÈõÜÔºåÊü•ËØ¢ËøîÂõû‰ªªÊÑèËÆ∞ÂΩïÂàôË°®Á§∫ÊµãËØïÂ§±Ë¥•„ÄÇ

ÂèÇËÄÉÊñáÊ°£Ôºö[Â¶Ç‰Ωï‰∏∫ÊÇ®ÁöÑÈ≠îÊ≥ïÁºñÂÜôÂçïÂÖÉÊµãËØïÔºü](https://dune.com/docs/zh/spellbook/getting-started/tests/)

## ÁºñËØë‰∏éË∞ÉËØï

ÂΩìÊàë‰ª¨ÁºñËæëÂπ∂‰øùÂ≠ò‰∫ÜÊµãËØïÊñá‰ª∂‰πãÂêéÔºåÈúÄË¶ÅÂÜçÊ¨°‰ΩøÁî®`dbt compile`ËøõË°åÁºñËØëÔºå‰øÆÊîπÊèêÁ§∫ÁöÑ‰ªª‰ΩïÈîôËØØÔºåÁ°ÆËÆ§ÁºñËØëÊàêÂäü„ÄÇ

Ê≠§Êó∂ÔºåÊàë‰ª¨ËøòÈúÄËøõË°å‰∏Ä‰∏™ÈùûÂ∏∏ÈáçË¶ÅÁöÑÊ≠•È™§ÔºåÂ§çÂà∂ÁºñËØëÁîüÊàêÁöÑÊü•ËØ¢‰ª£Á†ÅÔºåÂú®Dune‰∏äËøõË°åÂÆûÈôÖÁöÑÊµãËØïÈ™åËØÅ„ÄÇ

ÁºñËØëÊàêÂäüÊó∂ÔºåÂú®`spellbook`ÁõÆÂΩï‰∏ã‰ºöÁîüÊàê`target`Â≠êÁõÆÂΩïÔºåÊàë‰ª¨ÂèØ‰ª•Âú®ÂÖ∂‰∏≠ÊâæÂà∞`compiled/spellbook/models/spaceid/bnb`Â≠êÁõÆÂΩïÔºåÂÖ∂‰∏≠‰ºöÊúâ‰∏Ä‰∏™`spaceid_bnb_registrations.sql`Êñá‰ª∂„ÄÇËøô‰∏™Â∞±ÊòØÊàë‰ª¨Ê≠£Âú®ÊûÑÂª∫ÁöÑÈ≠îÊ≥ïË°®ËÉåÂêéÁöÑËßÜÂõæÂÆö‰πâSQL„ÄÇÁõÆÂΩï‰∏ãËøòÊúâ‰∏Ä‰∏™`spaceid_bnb_schema.yml`ÁöÑÂ≠êÁõÆÂΩïÔºåÈáåÈù¢‰øùÂ≠òÁöÑÊòØÊ†πÊçÆÊ®°ÂºèÂÆö‰πâËá™Âä®ÁîüÊàêÁöÑÊµãËØïÔºåËøôÈÉ®ÂàÜÊàë‰ª¨ÂèØ‰ª•ÂøΩÁï•„ÄÇ

Êàë‰ª¨ÂØπ`spaceid_bnb_registrations.sql`Êñá‰ª∂ËøõË°åÊâãÂä®ÊµãËØï„ÄÇÂõ†‰∏∫Êï∞ÊçÆÈáèÂæàÂ§ßÔºåÂπ∂‰∏çÈÄÇÂêàÁõ¥Êé•ËøêË°åÊñá‰ª∂ÈáåÈù¢ÁöÑSQLËøîÂõûÊâÄÊúâËÆ∞ÂΩï„ÄÇÊàë‰ª¨ÂèØ‰ª•Â§çÂà∂Êü•ËØ¢Êñá‰ª∂ÁöÑÂÖ®ÈÉ®ÂÜÖÂÆπÔºåÂ∞ÜÂÖ∂ÊîæÂà∞‰∏Ä‰∏™CTEÂÆö‰πâ‰∏≠ÔºåÁÑ∂ÂêéÈíàÂØπËØ•CTEËøõË°åÂè™ËøîÂõûÂ∞ëÈáèÊï∞ÊçÆÁöÑÊü•ËØ¢„ÄÇ

```sql
with view_registration as (
SELECT 'v3'                    as version,
       evt_block_time          as block_time,
       name,
       label,
       owner,
       cast(cost as double)    as cost,
       cast(expires as bigint) as expires,
       contract_address,
       evt_tx_hash             as tx_hash,
       evt_block_number        as block_number,
       evt_index
FROM spaceid_bnb.BNBRegistrarControllerV3_evt_NameRegistered

-- Ê≠§Â§ÑÁúÅÁï•ÂêéÁª≠‰ª£Á†Å

)

select * from view_registration
limit 1000
```

ÂÆåÊï¥ÁöÑÊâãÂä®ÊµãËØïÊü•ËØ¢‰ª£Á†ÅÔºö[https://dune.com/queries/2020131](https://dune.com/queries/2020131)

Ëøô‰∏ÄÊ≠•ÊµãËØïÁöÑ‰∏ªË¶ÅÁõÆÁöÑÊòØÁ°Æ‰øùÁºñËØëÁîüÊàêÁöÑSQLËØ≠Âè•Âú®Dune‰∏äÂèØ‰ª•Ê≠£Â∏∏ËøêË°å„ÄÇÂΩìÁÑ∂‰Ω†ÂèØ‰ª•‰øÆÊîπÊúÄÂêéÁöÑËæìÂá∫Êü•ËØ¢ËØ≠Âè•ÔºåÂÅöÊõ¥Â§öÁöÑÊâãÂä®ÊµãËØï„ÄÇ

## Êèê‰∫§PR

Áé∞Âú®Êàë‰ª¨Â∑≤ÁªèÂ§ÑÁêÜÂ•ΩÊñ∞ÁöÑÈ≠îÊ≥ïË°®Âπ∂‰∏îÂÆåÊàê‰∫ÜÊú¨Âú∞ÊµãËØï„ÄÇÂ∑≤ÁªèÂáÜÂ§áÂ•ΩÂ∞ÜÊñ∞Â¢ûÂíå‰øÆÊîπËøáÁöÑÊñá‰ª∂ÂÜÖÂÆπÊèê‰∫§Âà∞Github‰ª£Á†ÅÂ∫ì‰∏≠ÔºåÂêëDuneÊèê‰∫§PR„ÄÇ

Êàë‰ª¨È¶ñÂÖàÂ∞ÜÊú¨Âú∞Êñ∞Âª∫Âíå‰øÆÊîπÁöÑ‰ª£Á†ÅÊñá‰ª∂Ê∑ªÂä†Âπ∂Êèê‰∫§Âà∞Êú¨Âú∞git Â≠òË¥ÆÂ∫ìÔºåÁÑ∂ÂêéÂ∞ÜÊú¨Âú∞ÁöÑÂàÜÊîØÊé®ÈÄÅÂà∞ËøúÁ®ãGithubÂ≠òË¥ÆÂ∫ì‰∏≠Ôºö

```
# Êü•ÁúãÂπ∂Á°ÆËÆ§Êñ∞Â¢ûÊàñ‰øÆÊîπËøáÁöÑÊñá‰ª∂ÂèäÁõÆÂΩï
git status

# Â∞ÜÊâÄÊúâÊñ∞Â¢ûÂíå‰øÆÊîπËøáÁöÑÊñá‰ª∂Âä†ÂÖ•Êèê‰∫§
git add .

# Êèê‰∫§Âà∞Êú¨Âú∞gitÂ≠òË¥ÆÂ∫ì
git commit -m 'Add spaceid view'

# Â∞ÜÊú¨Âú∞Â≠òË¥ÆÂ∫ìÂàÜÊîØÊé®ÈÄÅÂà∞ËøúÁ®ãGithubÂ∫ì‰∏≠
git push -u origin add_bnb_spaceid

```

‰∏äÈù¢ÁöÑÊé®ÈÄÅÂëΩ‰ª§‰∏≠ÁöÑÂèÇÊï∞ÈÉ®ÂàÜ`-u origin add_bnb_spaceid`‰ªÖÂú®Á¨¨‰∏ÄÊ¨°Êé®ÈÄÅÊó∂ÊâçÈúÄË¶Å„ÄÇÂΩìÊàë‰ª¨ÂÆåÊàêÁ¨¨‰∏ÄÊ¨°Êé®ÈÄÅÂêéÔºåÂ¶ÇÊûúÂêéÁª≠ÂèàÂØπÁõ∏ÂÖ≥Êñá‰ª∂ÂÅö‰∫Ü‰øÆÊîπÔºåÂàôÂú®Êèê‰∫§Âà∞Êú¨Âú∞gitÂ∫ì‰∏≠ÂêéÔºåÊé®ÈÄÅÂà∞ËøúÁ®ãÊó∂‰ΩøÁî®ÁöÑÂëΩ‰ª§ÈúÄË¶ÅÊîπÊàêÔºö

```
git push
```

ÁÑ∂ÂêéÔºåÊàë‰ª¨ÊâìÂºÄgithubÁΩëÁ´ôÔºåËøõÂÖ•Êàë‰ª¨ÁöÑ‰∏™‰∫∫Ë¥¶Âè∑‰∏ãÁöÑ`spellbook`Â≠òË¥ÆÂ∫ìÈ°µÈù¢„ÄÇÂèØ‰ª•ÁúãÂà∞ÊèêÁ§∫‰ø°ÊÅØÔºåÂëäËØâÊàë‰ª¨ÊúâÊñ∞ÁöÑÂàÜÊîØ`add_bnb_spaceid`Êèê‰∫§‰∫ÜÊúÄÊñ∞‰øÆÊîπÔºåÂèØ‰ª•‰∏∫ÂÖ∂ÂàõÂª∫Pull RequestÔºàÂç≥PR)„ÄÇÁÇπÂáªÂàõÂª∫PRÊåâÈíÆÔºåÂàô‰ºöËøõÂÖ•PRÂàõÂª∫È°µÈù¢„ÄÇ

Âú®Ëøô‰∏™PRÈ°µÈù¢‰∏≠ÔºåÊàë‰ª¨ÈúÄË¶ÅÁºñËæëËæìÂÖ•‰∏Ä‰∏ãÂÜÖÂÆπÔºåÂêåÊó∂Á°ÆËÆ§Êàë‰ª¨Â∑≤ÁªèÊåâÁÖßÊñáÊ°£ÊåáÂØºÂÆåÊàê‰∫ÜÁõ∏Â∫îÁöÑÊ£ÄÊü•ÂíåÊµãËØïÂ∑•‰Ωú„ÄÇËøô‰∏™ÂÜÖÂÆπÁºñËæëÂô®ÊîØÊåÅMarkdownËØ≠Ê≥ïÔºå`[ ]`Â∞Ü‰ºöËæìÂá∫‰∏Ä‰∏™Êú™ÂãæÈÄâÁöÑcheckboxÔºå`[x]`Âàô‰ºöËæìÂá∫‰∏Ä‰∏™ÂãæÈÄâÁä∂ÊÄÅÁöÑcheckbox„ÄÇÊàë‰ª¨ÈÄê‰∏ÄË∞ÉÊï¥Ëøô‰∫õÈÄâÈ°πÔºåÁ°ÆËÆ§Â∑≤ÂÆåÊàê‰∫ÜÁõ∏Â∫îÁöÑÊ≠•È™§ÂíåÂ§ÑÁêÜ„ÄÇ

Êàë‰ª¨ËøòÈúÄË¶ÅÈíàÂØπËøô‰∏™PRÊâÄÊñ∞Â¢ûÊàñËÄÖ‰øÆÊîπÁöÑSpellÊèê‰æõ‰∏Ä‰∫õÁÆÄË¶ÅÁöÑËØ¥Êòé‰ø°ÊÅØÔºå‰ª•Êñπ‰æøÂÆ°Ê†∏‰∫∫ÂëòÂèØ‰ª•Êõ¥ÂÆπÊòì‰∫ÜËß£ÂÖ∂‰∏≠Ê∂âÂèäÁöÑÂÜÖÂÆπ„ÄÇ

![image_03.jpg](img/image_03.jpg)

Êèê‰∫§PRÂêéÔºåÊàë‰ª¨ÈúÄË¶ÅÁ≠âÂæÖÁõ∏ÂÖ≥‰∫∫ÂëòReviewÂπ∂Êèê‰æõÂèçÈ¶à„ÄÇÂêåÊó∂ÔºåÈúÄË¶ÅÁïôÊÑèÊù•Ëá™GithubÁöÑÈÇÆ‰ª∂ÈÄöÁü•„ÄÇÂÖ∂‰∏≠‰∏Ä‰∫õÈÄöÁü•‰ø°ÊÅØÂèØ‰ª•ÂøΩÁï•ÔºåÊØîÂ¶ÇÂÖ≥‰∫é`dbt slim ci (in beta) / dbt-test`ÁöÑ„ÄÇ‰∏ªË¶ÅÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØReview‰∫∫ÂëòÊèê‰æõÁöÑÂèçÈ¶àÁÇπËØÑ„ÄÇÂ¶ÇÊûúÊúâÈúÄË¶Å‰øÆÊîπÁöÑÂÜÖÂÆπÔºåÂ∞±Ë¶ÅÂèäÊó∂‰øÆÊîπ„ÄÅÊµãËØï„ÄÅÊèê‰∫§‰øÆÊîπ„ÄÅÊé®ÈÄÅÂà∞GithubÔºàÊ≠§Êó∂‰øÆÊîπ‰ºöËá™Âä®Âá∫Áé∞Âú®Â∑≤ÁªèÂàõÂª∫ÁöÑPR‰∏ãÔºåÊó†ÈúÄÂÜçÊ¨°ÂàõÂª∫Êñ∞ÁöÑPRÔºâÔºåÂπ∂Á≠âÂæÖÂÜçÊ¨°Review„ÄÇ

Â¶ÇÊûúÊâÄÊúâÁöÑ‰øÆÊîπÈÉΩÈ°∫Âà©ÈÄöËøá‰∫ÜReviewÔºåÈÇ£‰πàÊàë‰ª¨ÁöÑPRÂ∞±‰ºöË¢´ÂêàÂπ∂Âà∞spellbook‰∏ªÂàÜÊîØÔºåÂπ∂Ë¢´ÈÉ®ÁΩ≤Âà∞DuneÊ≠£ÂºèÁ´ôÁÇπ„ÄÇÈÉ®ÁΩ≤ÂÆåÊàêÂêéÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•Âú®Êü•ËØ¢ÁºñËæëÂô®‰∏≠ÊêúÁ¥¢ÊâæÂà∞Âπ∂‰ΩøÁî®Êàë‰ª¨Ëá™Â∑±ÊûÑÂª∫ÁöÑÈ≠îÊ≥ïË°®‰∫Ü„ÄÇÂ§ßÂäüÂëäÊàêÔºÅ

## Ë°•ÂÖÖËØ¥Êòé‰∏éÁâπÂà´È∏£Ë∞¢

Ê≥®ÊÑèÔºöÊà™Ê≠¢Âà∞Êú¨ÊñáÂèëÁ®øÊó∂ÔºåÊàë‰ª¨ÁöÑËøô‰∏™PRËøòÂú®ReviewËøáÁ®ã‰∏≠ÔºåÂ∞öÊú™Ë¢´ÊâπÂáÜÈÄöËøá„ÄÇÊâÄ‰ª•ÂêéÁª≠ÂèØËÉΩËøò‰ºöÊ†πÊçÆÂèçÈ¶àÂª∫ËÆÆËøõË°å‰øÆÊîπË∞ÉÊï¥„ÄÇËøô‰∏™PRÁöÑÁºñÂè∑ÊòØ2725ÔºåÂ§ßÂÆ∂ÂèØ‰ª•ÈÄöËøáPRÈ°µÈù¢Êù•‰∫ÜËß£Áõ∏ÂÖ≥ÁöÑÁªÜËäÇ„ÄÇ

PRÁöÑGithubÈìæÊé•Ôºö[Add BNB spaceid view](https://github.com/duneanalytics/spellbook/pull/2725)

ÁâπÂà´È∏£Ë∞¢Á§æÂå∫ÊàêÂëò @hosuke (Dune: [https://dune.com/hosuke](https://dune.com/hosuke)ÔºâÂèäÊó∂ÂçèÂä©PRÁöÑReviewÔºåÊèê‰æõÈóÆÈ¢òÂèçÈ¶àÂíåÂÆåÂñÑÂª∫ËÆÆÔºåÂπ∂Â∏ÆÂøô‰øÆÊîπ‰∫ÜÈ≠îÊ≥ïË°®ÁöÑÁâ©ÂåñÁ≠ñÁï•ÈÉ®ÂàÜ„ÄÇ

## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/ch24/ch23-how-to-build-app-use-dune-api.md">
# ‰ΩøÁî®Dune APIÂàõÂª∫Â∫îÁî®Á®ãÂ∫è

## È°πÁõÆÊ¶ÇËø∞

4Êúà25Êó•ÔºåDuneÊ≠£ÂºèÂêëÊâÄÊúâÁî®Êà∑Á≠âÁ∫ßÂºÄÊîæ‰∫ÜÊúüÂæÖÂ∑≤‰πÖÁöÑAPIËÆøÈóÆÊùÉÈôê„ÄÇÁé∞Âú®ÔºåÂÖçË¥πÁî®Êà∑‰πüÂèØ‰ª•ËÆøÈóÆDune API‰∫Ü„ÄÇÊú¨ÁØáÊïôÁ®ãÊèê‰æõ‰∏Ä‰∏™DemoÔºåËÆ≤Ëß£Â¶Ç‰ΩïÂõ¥ÁªïDune APIÊù•ÂºÄÂèëÂ∫îÁî®Á®ãÂ∫è„ÄÇ

DemoÁ®ãÂ∫èÈÉ®ÁΩ≤Âú®ËøôÈáåÔºö[Watcher Demo](https://dev.lentics.xyz/)„ÄÇ

Êú¨ÊïôÁ®ãÁöÑDemoÁ®ãÂ∫èÂú®3ÊúàÂàùÂ∑≤ÁªèÂÆåÊàêÔºåÁî±‰∫éÂêÑÁßçÂÖ∂‰ªñÂéüÂõ†ÔºåÊïôÁ®ãÊãñÂª∂Âà∞‰∫ÜÁé∞Âú®ÔºåÊä±Ê≠âËÆ©Â§ßÂÆ∂‰πÖÁ≠â‰∫Ü„ÄÇÈ°πÁõÆÁ®ãÂ∫è‰ª£Á†ÅÁî±ÊàëÂÖ¨Âè∏Âêå‰∫ãGeorgeÔºåKen Âíå Benny ÂçèÂêåÂÆåÊàêÔºåÂú®Ê≠§Ë°®Á§∫ÊÑüË∞¢„ÄÇ

Áî±‰∫éAPI Key ÊúâÈ¢ùÂ∫¶ÈôêÂà∂Ôºå‰ª•‰∏äDemoÁ®ãÂ∫èÊúâÂèØËÉΩÊó†Ê≥ï‰∏ÄÁõ¥Ê≠£Â∏∏Â∑•‰Ωú„ÄÇÂª∫ËÆÆÂ§ßÂÆ∂Fork‰πãÂêéËá™Ë°åÈÉ®ÁΩ≤Ôºå‰ΩøÁî®Ëá™Â∑±ÁöÑAPI KeyÊù•ÂÅöÊõ¥Â§öÂ∞ùËØï„ÄÇ

È°πÁõÆËøêË°åÁöÑÁïåÈù¢Â¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö

![wather01.jpg](./img/watcher01.jpg)

## Dune API ‰ΩøÁî®‰ªãÁªç

Dune APIÊòØÂü∫‰∫éQuery IDÊù•ÊâßË°åÂíåËé∑ÂèñÁªìÊûúÁöÑ„ÄÇÊØè‰∏Ä‰∏™Â∑≤‰øùÂ≠òÁöÑQueryÔºåÈÉΩÂèØ‰ª•Ëá™Âä®ËΩ¨Âåñ‰∏∫‰∏Ä‰∏™APIÁöÑËÆøÈóÆÁ´ØÁÇπ„ÄÇÂú®ÊúÄÊñ∞ÁâàÁöÑQuery Editor ÁïåÈù¢ÔºåÂè™ÈúÄÂÖàÁºñÂÜôÊü•ËØ¢ÔºåÊµãËØïÂ•ΩÂäüËÉΩÔºå‰øùÂ≠òÊü•ËØ¢ÔºåÁÑ∂ÂêéÁÇπÂáª‚ÄùAPI Endpoint‚ÄúÊåâÈíÆÔºåÂç≥ÂèØËé∑ÂèñËÆøÈóÆËØ•Êü•ËØ¢ÁªìÊûúÁöÑAPIÁ´ØÁÇπÁΩëÂùÄ„ÄÇ

```
https://api.dune.com/api/v1/query/2408388/results?api_key=<api_key>
```

ËøôÊòØÈÄöËøáAPIËÆøÈóÆÂ∑≤‰øùÂ≠òÁöÑÊü•ËØ¢ÁªìÊûúÈõÜÁöÑÊúÄÁÆÄ‰æøÁöÑÊñπÊ≥ï„ÄÇ

![wather02.jpg](./img/watcher02.jpg)

QueryÁöÑÊâßË°åÁªìÊûúÈªòËÆ§ÊòØÁºìÂ≠ò‰øùÂ≠òÁöÑÔºåÂ¶ÇÊûú‰∏çÂÜçÊ¨°‰∏ªÂä®ÊâßË°åËøô‰∏™QueryÔºåÈÇ£‰πà‰∏äÈù¢ÁöÑAPIÁ´ØÁÇπËé∑ÂèñÁöÑÂ∞ÜÊòØÂ∑≤‰øùÂ≠òÁöÑ‰∏äÊ¨°ÊâßË°åÁªìÊûúÈõÜ„ÄÇÈÄöÂ∏∏Êàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫èÈúÄË¶Å‰∏ªÂä®ÊâßË°åÊü•ËØ¢‰ª•Ëé∑ÂèñÊúÄÊñ∞Êª°Ë∂≥Êù°‰ª∂ÁöÑÊï∞ÊçÆËÄå‰∏çÊòØÈáçÂ§çËé∑ÂèñÁºìÂ≠òÁöÑÁªìÊûúÈõÜÔºåÂØπ‰∫éÁõëÊéßÁ±ªÂûãÁöÑÂ∫îÁî®Êõ¥ÊòØÂ¶ÇÊ≠§„ÄÇÊâÄ‰ª•Êàë‰ª¨ËøòÈúÄË¶ÅËÆøÈóÆÊâßË°åÊü•ËØ¢ÔºàExecuteÔºâÁöÑÁ´ØÁÇπÂíåËé∑ÂèñÊü•ËØ¢ÊâßË°åÁä∂ÊÄÅÔºàStatusÔºâÁöÑÁ´ØÁÇπÔºåÂú®Êé•Êî∂Âà∞Â∑≤ÊâßË°åÂÆåÊàêÁöÑÁä∂ÊÄÅ‰ø°ÊÅØÂêéÔºåËÆøÈóÆËé∑ÂèñÁªìÊûúÈõÜÔºàResultsÔºâÁöÑÁ´ØÁÇπËé∑ÂèñÊï∞ÊçÆ„ÄÇ

‰∏Ä‰∏™ÂÆåÊï¥ÁöÑAPIË∞ÉÁî®ÊµÅÁ®ãÂåÖÊã¨ÔºöÊâßË°åÊü•ËØ¢„ÄÅÊ£ÄÊü•Êü•ËØ¢ÊâßË°åÁä∂ÊÄÅ„ÄÅËé∑ÂèñÊü•ËØ¢ÁªìÊûúÈõÜ„ÄÇDune APIÁöÑÁõ∏ÂÖ≥ÊñáÊ°£Â∑≤ÁªèÊúâËØ¶ÁªÜÁöÑËØ¥ÊòéÔºåÊâÄ‰ª•ËøôÈáåÂ∞±‰∏çÂÜçÂ±ïÂºÄÊèèËø∞„ÄÇÂ§ßÂÆ∂ÂèØ‰ª•Áõ¥Êé•ÁúãAPIÊñáÊ°£Ôºö[Dune API](https://dune.com/docs/api/api-reference/#latest-results-endpoint)„ÄÇ


## È°πÁõÆÈúÄÊ±ÇËØ¥Êòé

‰∏∫‰∫ÜÂ∞ΩÂèØËÉΩÂÆåÊï¥Â±ïÁ§∫‰ΩøÁî®Dune APIÂºÄÂèëÈ°πÁõÆÁöÑÂÆåÊï¥ÊµÅÁ®ãÔºåÊàëÊï¥ÁêÜ‰∫Ü‰ª•‰∏ã‰∏ªË¶ÅÈúÄÊ±ÇÁÇπ„ÄÇ

Ëøô‰∏™Â∫îÁî®ÁöÑ‰∏ªË¶ÅÂäüËÉΩÊòØÂü∫‰∫éDune ÁöÑAPIÔºåÈíàÂØπUniswap V3ÔºåÊèê‰æõ‰∏Ä‰∏™Êñ∞Âª∫ÊµÅÂä®ËµÑÈáëÊ±†ÁõëÊéßÁöÑÁ∫ØÂâçÁ´ØÂ∫îÁî®„ÄÇ‰ΩøÁî®Êï∞ÊçÆÂ∫ìÊù•‰øùÂ≠òÁî®Êà∑ÈÄâÊã©ÁõëÊéßÁöÑËµÑÈáëÊ±†Âú∞ÂùÄ„ÄÇ‰ΩøÁî®ÁºìÂ≠ò‰ª•ÈÅøÂÖçÈáçÂ§çË∞ÉÁî®APIËØ∑Ê±ÇÂÆåÂÖ®Áõ∏ÂêåÁöÑÊï∞ÊçÆ„ÄÇ

ÂäüËÉΩÂåÖÊã¨‰∏â‰∏™ÊñπÈù¢Ôºö

1. New Pools Êñ∞Âª∫ËµÑÈáëÊ±†

ÊåâÈÄâÊã©ÁöÑÂå∫ÂùóÈìæ„ÄÅÊó•ÊúüËåÉÂõ¥ÔºåËøîÂõûÊª°Ë∂≥Êù°‰ª∂ÁöÑÊñ∞Âª∫ËµÑÈáëÊ±†ÂàóË°®„ÄÇ
Ë∞ÉÁî®APIÊó∂Ôºå‰º†ÂÖ•ÈÄâÊã©ÁöÑÂå∫ÂùóÈìæÂêçÁß∞ÔºàÂÖ®ÈÉ®Â∞èÂÜôÔºâÔºåÊó•ÊúüÂèÇÊï∞ÔºàYYYY-MM-DDÔºåÊú¨Âú∞Ê†πÊçÆÁî®Êà∑ÈÄâÊã©Êç¢ÁÆóÊàêÂÖ∑‰ΩìÊó•ÊúüÔºâ„ÄÇ

2. Latest Swaps ÊúÄÊñ∞‰∫§ÊòìËÆ∞ÂΩï

‰ªéËµÑÈáëÊ±†ÂàóË°®ÈÄâÊã©‰∏Ä‰∏™PoolÔºàÈìæÊé•ÔºâÔºåÂú®Êñ∞ÁöÑÁïåÈù¢‰∏≠ÂàóÂá∫ËØ•PoolÂΩìÂâçÂ∞èÊó∂ÂÜÖÁöÑÊúÄÊñ∞100Êù°SwapÂÖëÊç¢ËÆ∞ÂΩï„ÄÇ
Áî®Êà∑‰ªéÁ¨¨‰∏ÄÊ≠•ÁöÑÂêÑ‰∏™ÂàóË°®ÁÇπÂáªPool ÊóÅËæπÁöÑ‚ÄúLatest Swap‚ÄùÈìæÊé•ËøõÂÖ•Êú¨ÁïåÈù¢„ÄÇ
Ë∞ÉÁî®APIÊó∂Ôºå‰º†ÂÖ•Âå∫ÂùóÈìæÂêçÁß∞„ÄÅPoolÂú∞ÂùÄÂíåÂΩìÂâçÁöÑÂ∞èÊó∂ÂÄºÔºàYYYY-MM-DD HH:MI:SSÔºåÊú¨Âú∞Êç¢ÁÆóÊàêÂÖ∑‰ΩìÊó•Êúü+Â∞èÊó∂ÂÄºÔºåÂ¶Ç ‚Äú2023-02-27 09:00:00‚ÄùÔºâ„ÄÇ
APIË∞ÉÁî®ÂèÇÊï∞: blockchain, pool, current hour (Unix timestamp)
Áî®ÂàóË°®ÊñπÂºèÂ±ïÁ§∫APIË∞ÉÁî®ËøîÂõûÁªìÊûúÂç≥ÂèØ„ÄÇ

3. Large Swap Alerts Â§ßÈ¢ù‰∫§ÊòìÊèêÈÜí

ÂÖÅËÆ∏Áî®Êà∑ËæìÂÖ•‰∏Ä‰∏™Pool ÁöÑÂú∞ÂùÄÔºàÊèêÁ§∫Áî®Êà∑Ëá™Ë°å‰ªéËµÑÈáëÊ±†ÂàóË°®‰∏≠Â§çÂà∂ÔºâÔºåÂ§ßÈ¢ù‰∫§Êç¢ÁöÑÈòàÂÄºÔºàÊØîÂ¶Ç1000 USDÔºâ„ÄÇËÆæÁΩÆÂêéÊØèÈöî5ÂàÜÈíüË∞ÉÁî®Âõ†Ê≠§APIÔºåÂΩìÂá∫Áé∞Êª°Ë∂≥Êù°‰ª∂ÁöÑSwapËÆ∞ÂΩïÊó∂ÔºåÁîüÊàêÁ´ôÂÜÖÊèêÈÜí„ÄÇ
Áî®Êà∑ÂèØ‰ª•ËÆæÁΩÆË¶ÅÁõëÊéßÁöÑPool Âú∞ÂùÄÂíåÊúÄÂ∞è‰∫§Êç¢ÈáëÈ¢ùÔºàUSDÔºâÔºàÊöÇÊó∂Âè™Êèê‰æõ1000Ôºå10000Ôºå10000‰∏â‰∏™ÈÄâÊã©ÂÄºÔºâ„ÄÇ
Â¶ÇÊûúAPIÊúâËøîÂõûÊï∞ÊçÆÔºåÂàôÂä†ÂÖ•Á´ôÂÜÖÊèêÈÜí‰∏≠„ÄÇÂØºËà™Êù°Á∫¢Ëâ≤Êï∞Â≠óbadgeÊèêÈÜíÊú™ËØªÊèêÈÜí‰∏™Êï∞ÔºåÁÇπÂáªÂèØ‰ª•ÊòæÁ§∫ÂàóË°®„ÄÇÁÇπÂáªÂçïÊù°‰ø°ÊÅØÂêéÊîπÊàêÂ∑≤ËØªÁä∂ÊÄÅ„ÄÇ


## ÂºÄÂèëÁéØÂ¢ÉÈÖçÁΩÆ

```
yarn dev
```

ÂÖ∂‰ªñÂëΩ‰ª§ÂèØ‰ª•ÂèÇËÄÉÈ°πÁõÆÊ∫ê‰ª£Á†Å‰∏≠ÁöÑ readme.md Êñá‰ª∂ËØ¥Êòé„ÄÇ

## ÂºÄÂèëÊ¶ÇËßà

### ÂàõÂª∫È°πÁõÆ

Âü∫‰∫é Next.js, CSS framework ‰ΩøÁî® tailwindcssÔºåfetcher ‰ΩøÁî® AxiosÔºåÂâçÁ´ØÊï∞ÊçÆÊìç‰Ωú‰ΩøÁî® dexieÔºåÂêéÁ´ØÊï∞ÊçÆÊìç‰Ωú‰ΩøÁî® prisma„ÄÇ

``` bash
$ yarn create next-app
$ yarn add tailwindcss autoprefixer postcss prisma -D
$ yarn add axios dexie dexie-react-hooks @prisma/client
```

### ÂàùÂßãÂåñ Schema

``` bash
$ yarn prisma init --datasource-provider sqlite
$ vim prisma/schema.prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "sqlite"
  url      = env("DATABASE_URL")
}

model DuneQuery {
  id           String   @unique
  execution_id String
  createdAt    DateTime @default(now())
  updatedAt    DateTime @updatedAt
}

$ yarn prisma migrate dev --name init
$ yarn prisma generate
```

### Â∞ÅË£ÖAPIË∞ÉÁî®

Â¢ûÂä† lib/dune.ts, Â∞ÅË£Ö Dune API ÊâßË°åÁöÑ‰∏â‰∏™Ê≠•È™§Ôºö
``` javascript
export const executeQuery = async (id: string, parameters: any) => {
  // Áî® hash ÁîüÊàêÂΩìÂâçÊâßË°åÁöÑ query key, Ê£ÄÊü•Âπ∂Ëé∑Âèñ sqlite ‰∏≠ÊòØÂê¶ÊúâÂØπÂ∫î execution_id„ÄÇËÆ∞ÂæóÂÅöÂ•ΩÁºìÂ≠òËøáÊúüÂ§ÑÁêÜ
  // ...
};
export const executeStatus = async (id: string) => {
  // ...
};
export const executeResults = async (id: string) => {
  // ...
};
```

### ÂâçÁ´ØÊï∞ÊçÆÂ±ïÁ§∫

Âú® pages ÁõÆÂΩïÂ¢ûÂä†ÂØπÂ∫îÈ°µÈù¢‰∏≠Â¢ûÂä†‰∏™ÈÄíÂΩí functionÔºåÂà§Êñ≠ÊòØÂê¶Êúâ data.result ËäÇÁÇπËøîÂõûÁî®‰∫éÈÄíÂΩíË∞ÉÁî®ÔºåuseEffect ‰∏≠Ëß¶ÂèëÂç≥ÂèØ„ÄÇ


### ‰ª£Á†ÅÈÉ®ÁΩ≤

‰∏é Next.js È°πÁõÆÈÉ®ÁΩ≤ÊñπÂºè‰∏ÄËá¥ÔºåËøôÂÑøÂ∑≤Â∞Ü DB ÂàùÂßãÂåñÊîæÂà∞ package.json

``` json
  "scripts": {
    "dev": "prisma generate && prisma migrate dev && next dev",
    "build": "prisma generate && prisma migrate deploy && next build",
    "start": "next start"
  }
```

### ‰∏∫APIÁºñÂÜôSQLÊü•ËØ¢

API Ë∞ÉÁî®ÁöÑquery ‰ø°ÊÅØÔºö

New Pools:

https://dune.com/queries/2056212

Latest Swap:

https://dune.com/queries/2056310

Alerts:

https://dune.com/queries/2056547


### ÈáçË¶ÅÂäüËÉΩÁÇπËØ¥Êòé

1. Dune API ÈúÄË¶ÅÂÖà Execute Query IDÔºå Ëé∑ÂèñÂÖ∂ execution_idÔºåÊâçËÉΩÊâßË°åÂêéÈù¢ÁöÑ status/results„ÄÇÂÅöÂ•ΩÁºìÂ≠òËøáÊúüÂ§ÑÁêÜ„ÄÇ
2. ÂâçÁ´ØÈúÄË¶ÅÈÄíÂΩíË∞ÉÁî®Á≥ªÁªü API Êù•Ëé∑ÂèñÁªìÊûú


## Dune API ÊñáÊ°£
- ‰∏≠ÊñáÊñáÊ°£Ôºö https://dune.com/docs/zh/api/ 
- ÊúÄÊñ∞ÁâàÊú¨Ôºö https://dune.com/docs/api/


## È°πÁõÆ‰ª£Á†Å‰ªìÂ∫ì

È°πÁõÆÁöÑÊ∫ê‰ª£Á†ÅÂú®ËøôÈáåÔºö 
[Uniswap New Pools Watcher](https://github.com/codingtalent/watcher)


## SixdegreeLab‰ªãÁªç

SixdegreeLabÔºà[@SixdegreeLab](https://twitter.com/sixdegreelab)ÔºâÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

Ê¨¢ËøéËÆøÈóÆ[SixdegreeLabÁöÑDune‰∏ªÈ°µ](https://dune.com/sixdegree)„ÄÇ

Âõ†Ê∞¥Âπ≥ÊâÄÈôêÔºå‰∏çË∂≥‰πãÂ§ÑÂú®ÊâÄÈöæÂÖç„ÄÇÂ¶ÇÊúâÂèëÁé∞‰ªª‰ΩïÈîôËØØÔºåÊï¨ËØ∑ÊåáÊ≠£„ÄÇ
</file>

<file path="zh/readme.md">
<p align="center">
  <img src="assets/bookcover-zh.png" alt="book" width="60%"/>
</p>

Êú¨ÊïôÁ®ãÊòØ‰∏Ä‰∏™Èù¢ÂêëÂå∫ÂùóÈìæÁà±Â•ΩËÄÖÁöÑÁ≥ªÂàóÊïôÁ®ãÔºåÂ∏ÆÂä©Êñ∞ÊâãÁî®Êà∑‰ªéÈõ∂ÂºÄÂßãÂ≠¶‰π†Âå∫ÂùóÈìæÊï∞ÊçÆÂàÜÊûêÔºåÊàê‰∏∫‰∏ÄÂêçÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏à„ÄÇ

- Ëã±ÊñáÁâàÊú¨: [Mastering Onchain Analytics](https://tutorial.sixdegree.xyz)
- ‰∏≠ÊñáÁâàÊú¨: [Á≤æÈÄöÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê](https://tutorial.sixdegree.xyz/v/zh/)


> ÂèÇ‰∏éË¥°ÁåÆ: [https://github.com/SixdegreeLab/MasteringChainAnalytics](https://github.com/SixdegreeLab/MasteringChainAnalytics)

## ÁõÆÂΩï

- **ÁÆÄ‰ªã**
  - [ÁÆÄ‰ªã](readme.md)
  - [#0 Êàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏à](ch00/ch00-become-chain-analyst.md)

- **ÂÖ•Èó®ÊïôÁ®ã**
  - [#1 DuneÂπ≥Âè∞ÁÆÄ‰ªã](ch01/ch01-dune-platform-introduction.md)
  - [#2 Êï∞ÊçÆÂàÜÊûêÊñ∞Êâã‰∏äË∑Ø](ch02/ch02-quickstart.md)
  - [#3 ÂàõÂª∫Á¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùø](ch03/ch03-build-first-dashboard.md)
  - [#4 ÁÜüÊÇâÊï∞ÊçÆË°®](ch04/ch04-understanding-tables.md)
  - [#5 SQLÂü∫Á°ÄÔºà‰∏ÄÔºâ](ch05/ch05-sql-basics-part1.md)
  - [#6 SQLÂü∫Á°ÄÔºà‰∫åÔºâ](ch06/ch06-sql-basics-part2.md)
  - [#7 ÂÆûË∑µÊ°à‰æãÔºöÂà∂‰ΩúLensÁöÑÊï∞ÊçÆÁúãÊùøÔºà‰∏ÄÔºâ](ch07/ch07-practice-build-lens-dashboard-part1.md)
  - [#8 ÂÆûË∑µÊ°à‰æãÔºöÂà∂‰ΩúLensÁöÑÊï∞ÊçÆÁúãÊùøÔºà‰∫åÔºâ](ch08/ch08-practice-build-lens-dashboard-part2.md)

- **‰∏≠Á∫ßÊïôÁ®ã**
  - [#9 Â∏∏ËßÅÊü•ËØ¢‰∏ÄÔºöERC20‰ª£Â∏Å‰ª∑Ê†º](ch09/ch09-useful-queries-part1.md)
  - [#10 Â∏∏ËßÅÊü•ËØ¢‰∫åÔºö‰ª£Â∏ÅÁöÑÊåÅÊúâËÄÖ„ÄÅÊÄª‰æõÂ∫îÈáè„ÄÅË¥¶Êà∑‰ΩôÈ¢ù](ch10/ch10-useful-queries-part2.md)
  - [#11 Â∏∏ËßÅÊü•ËØ¢‰∏âÔºöËá™ÂÆö‰πâÊï∞ÊçÆ„ÄÅÊï∞Â≠óÂ∫èÂàó„ÄÅÊï∞ÁªÑ„ÄÅJSONÁ≠â](ch11/ch11-useful-queries-part3.md)
  - [#12 NFTÊï∞ÊçÆÂàÜÊûê](ch12/ch12-nft-analysis.md)
  - [#13 ÂÄüË¥∑ÂçèËÆÆÊï∞ÊçÆÂàÜÊûê](ch13/ch13-lending-analysis.md)
  - [#14 DeFiÊï∞ÊçÆÂàÜÊûê](ch14/ch14-defi-analysis.md)
  - [#15 Dune SQL Êü•ËØ¢ÂºïÊìéÂÖ•Èó®](ch15/ch15-dunesql-introduction.md)
  - [#16 PolygonÂå∫ÂùóÈìæÊ¶ÇÂÜµÂàÜÊûê](ch16/ch16-blockchain-analysis-polygon.md)
  - [#17 MEVÊï∞ÊçÆÂàÜÊûê‚Äî‚Äî‰ª•Uniswap‰∏∫‰æã](ch17/ch17-mev-analysis-uniswap.md)
  - [#18 UniswapÂ§öÈìæÊï∞ÊçÆÂØπÊØîÂàÜÊûê](ch18/ch18-uniswap-multichain-analysis.md)
  - [#19 ÂêÑÁ±ªÂ∏∏ËßÅÊåáÊ†áÂàÜÊûê](ch19/ch19-useful-metrics.md)

- **È´òÁ∫ßÊïôÁ®ã**
  - [#20 Âå∫ÂùóÈìæÁΩëÁªúÂàÜÊûê](ch20/ch20-network-analysis.md)
  - [#21 BTCÊï∞ÊçÆÂàÜÊûê-‰ª•ÊåáÊ†áCDD‰∏∫‰æã](ch21/ch21-btc-analysis.md)
  - [#22 Â¶Ç‰ΩïÊûÑÂª∫È≠îÊ≥ïË°®ÔºàSpellbookÔºâ](ch22/ch22-how-to-build-spellbook.md)
  - [#23 ‰ΩøÁî®Dune APIÂàõÂª∫Â∫îÁî®Á®ãÂ∫è](ch23/ch23-how-to-build-app-use-dune-api.md)

## ÂÖ≥‰∫éÊàë‰ª¨
`Sixdegree`ÊòØ‰∏ì‰∏öÁöÑÈìæ‰∏äÊï∞ÊçÆÂõ¢ÈòüÔºåÊàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØ‰∏∫Áî®Êà∑Êèê‰æõÂáÜÁ°ÆÁöÑÈìæ‰∏äÊï∞ÊçÆÂõæË°®„ÄÅÂàÜÊûê‰ª•ÂèäÊ¥ûËßÅÔºåÂπ∂Ëá¥Âäõ‰∫éÊôÆÂèäÈìæ‰∏äÊï∞ÊçÆÂàÜÊûê„ÄÇ
ÈÄöËøáÂª∫Á´ãÁ§æÂå∫„ÄÅÁºñÂÜôÊïôÁ®ãÁ≠âÊñπÂºèÔºåÂüπÂÖªÈìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåËæìÂá∫Êúâ‰ª∑ÂÄºÁöÑÂàÜÊûêÂÜÖÂÆπÔºåÊé®Âä®Á§æÂå∫ÊûÑÂª∫Âå∫ÂùóÈìæÁöÑÊï∞ÊçÆÂ±ÇÔºå‰∏∫Êú™Êù•ÂπøÈòîÁöÑÂå∫ÂùóÈìæÊï∞ÊçÆÂ∫îÁî®ÂüπÂÖª‰∫∫Êâç„ÄÇ

- Website: [sixdegree.xyz](https://sixdegree.xyz)
- Email: [contact@sixdegree.xyz](mailto:contact@sixdegree.xyz)
- Twitter: [twitter.com/SixdegreeLab](https://twitter.com/SixdegreeLab)
- Dune: [dune.com/sixdegree](https://dune.com/sixdegree)
- Github: [https://github.com/SixdegreeLab](https://github.com/SixdegreeLab)


## Ëá¥Ë∞¢

**ËµûÂä©**

Êú¨‰π¶ÂæóÂà∞‰ª•‰∏ãÊú∫ÊûÑËµûÂä©ÔºåÈùûÂ∏∏ÊÑüË∞¢‰ªñ‰ª¨Âú®Êí∞ÂÜôÊ≠§‰π¶ÊúüÈó¥Áªô‰∫àÁöÑÂ§ßÂäõÊîØÊîØÊåÅ„ÄÇ


- [Ethereum Fundation](https://ethereum.foundation/)
- [Dune Analytics](https://dune.com/)

**Ë¥°ÁåÆËÄÖ**

‰∏éÊ≠§ÂêåÊó∂ÔºåÊúâÈùûÂ∏∏Â§öÁöÑË¥°ÁåÆËÄÖ‰πüÂèÇ‰∏éÂà∞‰∫ÜÊ≠§‰π¶ÁöÑÁºñÂÜô‰∏≠ÔºåÈùûÂ∏∏ÊÑüË∞¢‰ªñ‰ª¨ÁöÑÂä™Âäõ‰ªòÂá∫„ÄÇ


- george-taotaome, chenxsan, Brendan, ËÇñÂÆÅ, g.c., ken, shell, yueyan, wodeche,Winkey
</file>

<file path="zh/SUMMARY.md">
- [ÁÆÄ‰ªã](readme.md)
- [#0 Êàê‰∏∫Èìæ‰∏äÊï∞ÊçÆÂàÜÊûêÂ∏à](ch00/ch00-become-chain-analyst.md)

## ÂÖ•Èó®ÊïôÁ®ã
- [#1 DuneÂπ≥Âè∞ÁÆÄ‰ªã](ch01/ch01-dune-platform-introduction.md)
- [#2 Êï∞ÊçÆÂàÜÊûêÊñ∞Êâã‰∏äË∑Ø](ch02/ch02-quickstart.md)
- [#3 ÂàõÂª∫Á¨¨‰∏Ä‰∏™DuneÊï∞ÊçÆÁúãÊùø](ch03/ch03-build-first-dashboard.md)
- [#4 ÁÜüÊÇâÊï∞ÊçÆË°®](ch04/ch04-understanding-tables.md)
- [#5 SQLÂü∫Á°ÄÔºà‰∏ÄÔºâ](ch05/ch05-sql-basics-part1.md)
- [#6 SQLÂü∫Á°ÄÔºà‰∫åÔºâ](ch06/ch06-sql-basics-part2.md)
- [#7 ÂÆûË∑µÊ°à‰æãÔºöÂà∂‰ΩúLensÁúãÊùøÔºà‰∏ÄÔºâ](ch07/ch07-practice-build-lens-dashboard-part1.md)
- [#8 ÂÆûË∑µÊ°à‰æãÔºöÂà∂‰ΩúLensÁúãÊùøÔºà‰∫åÔºâ](ch08/ch08-practice-build-lens-dashboard-part2.md)

## ‰∏≠Á∫ßÊïôÁ®ã
- [#9 Â∏∏ËßÅÊü•ËØ¢‰∏ÄÔºöERC20‰ª£Â∏Å‰ª∑Ê†º](ch09/ch09-useful-queries-part1.md)
- [#10 Â∏∏ËßÅÊü•ËØ¢‰∫åÔºö‰ª£Â∏ÅÁöÑÊåÅÊúâËÄÖ„ÄÅÊÄª‰æõÂ∫îÈáè„ÄÅË¥¶Êà∑‰ΩôÈ¢ù](ch10/ch10-useful-queries-part2.md)
- [#11 Â∏∏ËßÅÊü•ËØ¢‰∏âÔºöËá™ÂÆö‰πâÊï∞ÊçÆ„ÄÅÊï∞Â≠óÂ∫èÂàó„ÄÅÊï∞ÁªÑ„ÄÅJSONÁ≠â](ch11/ch11-useful-queries-part3.md)
- [#12 NFTÊï∞ÊçÆÂàÜÊûê](ch12/ch12-nft-analysis.md)
- [#13 ÂÄüË¥∑ÂçèËÆÆÊï∞ÊçÆÂàÜÊûê](ch13/ch13-lending-analysis.md)
- [#14 DeFiÊï∞ÊçÆÂàÜÊûê](ch14/ch14-defi-analysis.md)
- [#15 Dune SQL Êü•ËØ¢ÂºïÊìéÂÖ•Èó®](ch15/ch15-dunesql-introduction.md)
- [#16 PolygonÂå∫ÂùóÈìæÊ¶ÇÂÜµÂàÜÊûê](ch16/ch16-blockchain-analysis-polygon.md)
- [#17 MEVÊï∞ÊçÆÂàÜÊûê‚Äî‚Äî‰ª•Uniswap‰∏∫‰æã](ch17/ch17-mev-analysis-uniswap.md)
- [#18 UniswapÂ§öÈìæÊï∞ÊçÆÂØπÊØîÂàÜÊûê](ch18/ch18-uniswap-multichain-analysis.md)
- [#19 ÂêÑÁ±ªÂ∏∏ËßÅÊåáÊ†áÂàÜÊûê](ch19/ch19-useful-metrics.md)

## È´òÁ∫ßÊïôÁ®ã	
- [#20 Âå∫ÂùóÈìæÁΩëÁªúÂàÜÊûê](ch20/ch20-network-analysis.md)
- [#21 BTCÊï∞ÊçÆÂàÜÊûê-‰ª•ÊåáÊ†áCDD‰∏∫‰æã](ch21/ch21-btc-analysis.md)
- [#22 Â¶Ç‰ΩïÊûÑÂª∫È≠îÊ≥ïË°®ÔºàSpellbookÔºâ](ch22/ch22-how-to-build-spellbook.md)
- [#23 ‰ΩøÁî®Dune APIÂàõÂª∫Â∫îÁî®Á®ãÂ∫è](ch23/ch23-how-to-build-app-use-dune-api.md)
</file>

<file path=".gitignore">
*pxd
</file>

