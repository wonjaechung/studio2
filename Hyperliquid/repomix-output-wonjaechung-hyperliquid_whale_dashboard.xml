This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    scrape.yml
hyperliquid/
  utils/
    __init__.py
    constants.py
  __init__.py
app.py
requirements.txt
scrape_playwright.py
top30_wallets.csv
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/scrape.yml">
name: scrape-hyperliquid

permissions:
  contents: write   # Ïª§Î∞ã/Ìë∏Ïãú Í∂åÌïú

on:
  schedule:
    - cron: '*/5 * * * *'   # Îß§ 5Î∂ÑÎßàÎã§
  workflow_dispatch:       # ÏàòÎèô Ïã§ÌñâÎèÑ Í∞ÄÎä•

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install chromium

      - name: Run scraper
        run: |
          python scrape_playwright.py

      - name: Commit & Push CSV
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add top30_wallets.csv
          git diff --quiet && echo "No changes to commit" || git commit -m "chore: update top30_wallets.csv"
          git push
</file>

<file path="hyperliquid/utils/__init__.py">

</file>

<file path="hyperliquid/utils/constants.py">
# hyperliquid/utils/constants.py

MAINNET_API_URL = "https://api.hyperliquid.xyz"  # ‚Üê replace with the real endpoint
</file>

<file path="hyperliquid/__init__.py">

</file>

<file path="app.py">
# app.py
import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
from hyperliquid.utils import constants
from st_aggrid import AgGrid, GridOptionsBuilder, DataReturnMode, GridUpdateMode


# ‚îÄ‚îÄ Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CSV_PATH = "top30_wallets.csv"
BASE_URL = constants.MAINNET_API_URL


# ‚îÄ‚îÄ HTTP helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def info_http(payload: dict):
    r = requests.post(f"{BASE_URL}/info", json=payload)
    r.raise_for_status()
    return r.json()

def get_portfolio(wallet: str):
    return info_http({"type": "portfolio", "user": wallet})

def get_clearinghouse_state(wallet: str):
    return info_http({"type": "clearinghouseState", "user": wallet})


# ‚îÄ‚îÄ Load leaderboard with Unrealized PnL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data(ttl=600)
def load_leaderboard():
    df = pd.read_csv(CSV_PATH)
    df["Rank"] = df.index + 1
    unrealized = []
    for w in df["Wallet"]:
        try:
            stt = get_clearinghouse_state(w)
            up = sum(float(ap["position"].get("unrealizedPnl") or 0.0)
                     for ap in stt.get("assetPositions", []))
        except:
            up = 0.0
        unrealized.append(up)
    df["Unrealized PnL"] = unrealized
    return df[[
        "Rank","Wallet","Account Value","PNL",
        "ROI","Volume","Unrealized PnL"
    ]]


# ‚îÄ‚îÄ Top-10 summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄv
@st.cache_data(ttl=600)
def compute_top10_summary(wallets):
    periods = [("All-Time","allTime"),("24H","day"),
               ("7D","week"),("30D","month")]
    rows = []
    for label,key in periods:
        pnls,rois = [],[]
        for w in wallets:
            try:
                pf = get_portfolio(w)
                data = next(i[1] for i in pf if i[0]==key)
                hist = data.get("pnlHistory",[])
                delta = (float(hist[-1][1]) - float(hist[0][1])
                         if len(hist)>=2 else 0.0)
                pnls.append(delta)
                if label!="All-Time":
                    av = data.get("accountValueHistory",[])
                    if len(av)>=2:
                        start=float(av[0][1]); rois.append(delta/start if start else 0.0)
            except: pass
        avg_pnl = sum(pnls)/len(pnls) if pnls else 0.0
        if label=="All-Time":
            rows.append({"Period":label,"Avg P&L (USD)":avg_pnl,"Avg ROI (%)":"‚Äî"})
        else:
            avg_roi = sum(rois)/len(rois) if rois else 0.0
            rows.append({"Period":label,"Avg P&L (USD)":avg_pnl,"Avg ROI (%)":avg_roi*100})
    return pd.DataFrame(rows)

st.title("Hyperliquid Whale Dashboard")

# manage search_addr in session_state
if "search_addr" not in st.session_state:
    st.session_state.search_addr = ""
search_input = st.sidebar.text_input(
    "üîé Search Address (hex)",
    value=st.session_state.search_addr,
    key="search_addr"
).strip()

# load leaderboard
df_leader     = load_leaderboard()
top_n         = 10
wallets_top10 = df_leader["Wallet"].head(top_n).tolist()

#
# ‚îÄ‚îÄ Custom Report ÏÑπÏÖò (ÏßÅÏ†ë ÏûÖÎ†•) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#
st.sidebar.markdown("## üìã Custom Report")
raw_text = st.sidebar.text_area(
    "Enter wallet addresses (one per line or comma-separated):",
    height=100
).strip()

if st.sidebar.button("üñ®Ô∏è Generate Report"):
    # parse ÏûÖÎ†•
    custom_wallets = []
    if raw_text:
        custom_wallets = [
            w.strip()
            for part in raw_text.splitlines()
            for w in part.split(",")
            if w.strip()
        ]

    if not custom_wallets:
        st.sidebar.warning("ÌïòÎÇò Ïù¥ÏÉÅÏùò ÏßÄÍ∞ë Ï£ºÏÜåÎ•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
    else:
        # --- 1) Summary ---
        df_cust_summary = compute_top10_summary(custom_wallets)
        st.subheader(f"Custom Report: P&L Summary ({len(custom_wallets)} wallets)")
        st.table(df_cust_summary.style.format({
            "Avg P&L (USD)": "{:,.2f}",
            "Avg ROI (%)":   lambda x: f"{x:.2f}%" if isinstance(x,(int,float)) else x
        }))

        # --- 2) Aggregate Metrics ---
        unrealized_total = 0.0
        coin_counter     = Counter()
        coin_upnls       = defaultdict(float)
        coin_volumes     = defaultdict(float)
        coin_sentiment   = defaultdict(lambda: {"Long":0,"Short":0})

        for w in custom_wallets:
            try:
                state = get_clearinghouse_state(w)
                for ap in state.get("assetPositions", []):
                    p   = ap["position"]
                    amt = float(p.get("szi") or 0.0)
                    upnl= float(p.get("unrealizedPnl") or 0.0)
                    val = float(p.get("positionValue") or 0.0)
                    c   = p.get("coin")

                    unrealized_total += upnl
                    if c:
                        coin_counter[c]  += 1
                        coin_upnls[c]    += upnl
                        coin_volumes[c]  += val
                        side = "Long" if amt>0 else "Short"
                        coin_sentiment[c][side] += 1
            except:
                pass

        popular_coin  = coin_counter.most_common(1)[0][0] if coin_counter else "‚Äî"
        pop_long      = coin_sentiment[popular_coin]["Long"]
        pop_short     = coin_sentiment[popular_coin]["Short"]
        trending_coin = max(coin_volumes, key=coin_volumes.get) if coin_volumes else "‚Äî"
        top_coin, top_upnl     = max(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)
        worst_coin, worst_upnl = min(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)

        st.subheader("Custom Report: Aggregate Metrics")
        st.markdown(f"üí∞ **Unrealized PnL (USD):** ${unrealized_total:,.2f}")
        st.markdown(f"üêã **Popular Whale Position: {popular_coin}** ({pop_long} Long / {pop_short} Short)")
        st.markdown(f"üî• **Trending Coin (by Open Interest):** {trending_coin}")
        st.markdown(f"üèÜ **Top Unrealized PnL Coin:** {top_coin} (+${top_upnl:,.2f})")
        st.markdown(f"‚ö†Ô∏è **Worst Unrealized PnL Coin:** {worst_coin} (${worst_upnl:,.2f})")

        # Avg Entry/Liq table for custom report
        top_coins = [c for c,_ in coin_counter.most_common(10)]
        entries = defaultdict(list)
        liqs    = defaultdict(list)
        for w in custom_wallets:
            try:
                state = get_clearinghouse_state(w)
                for ap in state.get("assetPositions", []):
                    p = ap["position"]
                    c = p.get("coin")
                    if c in top_coins:
                        entries[c].append(float(p.get("entryPx") or 0.0))
                        liqs[c].append(float(p.get("liquidationPx") or 0.0))
            except:
                pass

        rows = []
        for c in top_coins:
            e = sum(entries[c])/len(entries[c]) if entries[c] else 0
            l = sum(liqs[c])/len(liqs[c]) if liqs[c] else 0
            rows.append({"Coin":c, "Avg Entry":e, "Avg Liq":l})
        df_eql = pd.DataFrame(rows)

        st.subheader("Custom Report: Avg Entry & Liq")
        st.table(df_eql.style.format({"Avg Entry":"{:,.2f}", "Avg Liq":"{:,.2f}"}))

        # show back button and stop further rendering
        st.button("‚Üê Back to Leaderboard", on_click=lambda: st.session_state.update({"search_addr": ""}))
        st.stop()
#
# ‚îÄ‚îÄ leaderboard vs individual wallet Î™®Îìú ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#
if search_input == "":
    # Top-10 P&L Summary
    st.markdown(
        "<h2 style='color:#0072C3; font-size:1rem;'>"
        f"Top {top_n} P&L Summary</h2>",
        unsafe_allow_html=True
    )
    df_summary = compute_top10_summary(wallets_top10)
    st.table(df_summary.style.format({
        "Avg P&L (USD)": "{:,.2f}",
        "Avg ROI (%)":   lambda x: f"{x:.2f}%" if isinstance(x,(int,float)) else x
    }))

    # Top-10 Aggregate Metrics (same logic)
    unrealized_total = 0.0
    coin_counter     = Counter()
    coin_upnls       = defaultdict(float)
    coin_volumes     = defaultdict(float)
    coin_sentiment   = defaultdict(lambda: {"Long":0,"Short":0})

    for w in wallets_top10:
        try:
            state = get_clearinghouse_state(w)
            for ap in state.get("assetPositions", []):
                p   = ap["position"]
                amt = float(p.get("szi") or 0.0)
                upnl= float(p.get("unrealizedPnl") or 0.0)
                val = float(p.get("positionValue") or 0.0)
                c   = p.get("coin")

                unrealized_total += upnl
                if c:
                    coin_counter[c]  += 1
                    coin_upnls[c]    += upnl
                    coin_volumes[c]  += val
                    side = "Long" if amt>0 else "Short"
                    coin_sentiment[c][side] += 1
        except:
            pass

    popular_coin  = coin_counter.most_common(1)[0][0] if coin_counter else "‚Äî"
    pop_long      = coin_sentiment[popular_coin]["Long"]
    pop_short     = coin_sentiment[popular_coin]["Short"]
    trending_coin = max(coin_volumes, key=coin_volumes.get) if coin_volumes else "‚Äî"
    top_coin, top_upnl     = max(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)
    worst_coin, worst_upnl = min(coin_upnls.items(), key=lambda kv:kv[1]) if coin_upnls else ("‚Äî",0.0)

    st.markdown(
        "<h2 style='color:#0072C3; font-size:1rem;'>"
        "Top-10 Aggregate Metrics</h2>",
        unsafe_allow_html=True
    )
    st.markdown(f"üí∞ **Unrealized PnL (USD):** ${unrealized_total:,.2f}")
    st.markdown(f"üêã **Popular Whale Position:** {popular_coin} ({pop_long} Long / {pop_short} Short)")
    st.markdown(f"üî• **Trending Coin (by Open Interest):** {trending_coin}")
    st.markdown(f"üèÜ **Top Unrealized PnL Coin:** {top_coin} (+${top_upnl:,.2f})")
    st.markdown(f"‚ö†Ô∏è **Worst Unrealized PnL Coin:** {worst_coin} (${worst_upnl:,.2f})")

    # Avg Entry/Liq table for top-10
    top_coins = [c for c,_ in coin_counter.most_common(10)]
    entries = defaultdict(list)
    liqs    = defaultdict(list)
    for w in wallets_top10:
        try:
            state = get_clearinghouse_state(w)
            for ap in state.get("assetPositions", []):
                p = ap["position"]; c = p.get("coin")
                if c in top_coins:
                    entries[c].append(float(p.get("entryPx") or 0.0))
                    liqs[c].append(float(p.get("liquidationPx") or 0.0))
        except:
            pass
    rows = []
    for c in top_coins:
        e = sum(entries[c])/len(entries[c]) if entries[c] else 0
        l = sum(liqs[c])/len(liqs[c]) if liqs[c] else 0
        rows.append({"Coin":c, "Avg Entry":e, "Avg Liq":l})
    df_eql = pd.DataFrame(rows)

    st.markdown(
        "<h2 style='color:#0072C3; font-size:1rem;'>"
        "Top-10 Avg Entry & Liq</h2>",
        unsafe_allow_html=True
    )
    st.table(df_eql.style.format({"Avg Entry":"{:,.2f}", "Avg Liq":"{:,.2f}"} ))

    st.markdown("---")
    st.markdown("**‚òëÔ∏è Ï≤¥ÌÅ¨Î∞ïÏä§Î•º ÌÅ¥Î¶≠ÌïòÏó¨ ÏßÄÍ∞ëÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.**")

    # Leaderboard Grid
    gb = GridOptionsBuilder.from_dataframe(df_leader)
    gb.configure_selection("multiple", use_checkbox=True)
    gb.configure_column("Rank", width=60)
    gb.configure_column("Wallet", width=250)
    grid_opts = gb.build()

    grid_resp = AgGrid(
        df_leader,
        gridOptions=grid_opts,
        update_mode=GridUpdateMode.SELECTION_CHANGED,
        data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
        fit_columns_on_grid_load=True
    )

    raw = grid_resp.get("selected_rows")
    if isinstance(raw, pd.DataFrame):
        wallets_to_show = raw.to_dict("records")
    elif isinstance(raw, list):
        wallets_to_show = raw
    else:
        wallets_to_show = []

else:
    # individual wallet mode
    def _reset_search():
        st.session_state.search_addr = ""
    st.button("‚Üê Back to Leaderboard", on_click=_reset_search)
    wallets_to_show = [{"Wallet": search_input}]

# ‚îÄ‚îÄ Wallet Details ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
for entry in wallets_to_show:
    wallet = entry["Wallet"]
    st.subheader(f"Address: {wallet}")

    # P&L Chart & Metrics
    try:
        pf       = get_portfolio(wallet)
        all_time = next(i[1] for i in pf if i[0] == "allTime")
        df_pnl   = pd.DataFrame(all_time["pnlHistory"], columns=["time","pnl"])
        df_pnl["pnl"]   = df_pnl["pnl"].astype(float)
        df_pnl["time"]  = pd.to_datetime(df_pnl["time"], unit="ms")

        total = df_pnl["pnl"].iloc[-1]
        now   = df_pnl["time"].iloc[-1]
        def delta(days):
            sl = df_pnl[df_pnl["time"] >= now - pd.Timedelta(days=days)]
            return (sl["pnl"].iloc[-1] - sl["pnl"].iloc[0]) if len(sl)>1 else 0.0

        c1,c2,c3,c4 = st.columns(4)
        c1.metric("Total P&L", f"{total:,.2f}")
        av_d = next(i[1] for i in pf if i[0]=="day")["accountValueHistory"]
        sd   = float(av_d[0][1]) if len(av_d)>=2 else None
        c2.metric("24H P&L", f"{delta(1):,.2f}", delta=f"{delta(1)/sd*100:.2f}%" if sd else None)
        av_w = next(i[1] for i in pf if i[0]=="week")["accountValueHistory"]
        sw   = float(av_w[0][1]) if len(av_w)>=2 else None
        c3.metric("7D P&L", f"{delta(7):,.2f}", delta=f"{delta(7)/sw*100:.2f}%" if sw else None)
        av_m = next(i[1] for i in pf if i[0]=="month")["accountValueHistory"]
        sm   = float(av_m[0][1]) if len(av_m)>=2 else None
        c4.metric("30D P&L", f"{delta(30):,.2f}", delta=f"{delta(30)/sm*100:.2f}%" if sm else None)

        fig, ax = plt.subplots(figsize=(8,3))
        ax.fill_between(df_pnl["time"], df_pnl["pnl"], step="mid", alpha=0.3)
        ax.plot(df_pnl["time"], df_pnl["pnl"], linewidth=2)
        ax.axhline(0, color="gray", linewidth=0.8)
        ax.set_xlabel("Time"); ax.set_ylabel("P&L (USD)")
        plt.xticks(rotation=30)
        st.pyplot(fig)
    except Exception as e:
        st.error(f"Error fetching P&L for {wallet}: {e}")
        continue

    # Positions + CSV export
    try:
        state = get_clearinghouse_state(wallet)
        pos   = []
        for ap in state.get("assetPositions", []):
            p   = ap["position"]
            val = float(p.get("positionValue") or 0.0)
            if val == 0: continue
            amt = float(p.get("szi") or 0.0)
            pnl = float(p.get("unrealizedPnl") or 0.0)
            pos.append({
                "Symbol":         p.get("coin",""),
                "Side":           "Long" if amt>0 else "Short",
                "Leverage":       f"{p['leverage']['value']}X {'Cross' if p['leverage']['type']=='cross' else 'Isolated'}",
                "Value (USD)":    val,
                "Amount":         amt,
                "Entry Price":    float(p.get("entryPx") or 0.0),
                "Unrealised PnL": pnl,
                "Funding Fee":    float((p.get("cumFunding") or {}).get("allTime") or 0.0),
                "Liq. Price":     float(p.get("liquidationPx") or 0.0),
            })
        df_pos = pd.DataFrame(pos)
        if not df_pos.empty:
            st.table(df_pos.style.format({
                "Value (USD)":    "{:,.2f}",
                "Amount":         "{:,.4f}",
                "Entry Price":    "{:,.2f}",
                "Unrealised PnL": "{:,.2f}",
                "Funding Fee":    "{:,.2f}",
                "Liq. Price":     "{:,.2f}"
            }))
            csv = df_pos.to_csv(index=False)
            st.download_button(
                label="üì• Export positions as CSV",
                data=csv,
                file_name=f"{wallet}_positions.csv",
                mime="text/csv"
            )
        else:
            st.info("No active positions.")
    except Exception as e:
        st.error(f"Error fetching positions for {wallet}: {e}")

    st.markdown("---")
</file>

<file path="requirements.txt">
streamlit
pandas
matplotlib
selenium
webdriver-manager
streamlit-aggrid
openai
streamlit-chat
playwright==1.43.0
</file>

<file path="scrape_playwright.py">
# scrape_playwright.py

import asyncio
import pandas as pd
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

async def main():
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-dev-shm-usage"]
        )
        page = await browser.new_page()
        await page.goto("https://app.hyperliquid.xyz/leaderboard", wait_until="networkidle")

        # All-time Î≥¥Í∏∞Î°ú Ï†ÑÌôò
        await page.click("div.variant_black", timeout=30000)
        await page.click("text=All-time", timeout=30000)
        await page.wait_for_selector("table > tbody > tr", timeout=60000)

        # Í∞ÄÏÉÅÌôîÎêú ÌÖåÏù¥Î∏îÏù¥Îùº ÏïÑÎûòÏ≤òÎüº ÌÇ§Î≥¥Îìú Ïä§ÌÅ¨Î°§ÏùÑ Ï∂©Î∂ÑÌûà ÎÇ¥Î†§Ïïº 30Í∞ú ÌñâÏù¥ Î°úÎìúÎê©ÎãàÎã§
        for _ in range(20):
            await page.keyboard.press("PageDown")
            await page.wait_for_timeout(300)

        records = []
        rows_locator = page.locator("table > tbody > tr")
        count = await rows_locator.count()
        total = min(count, 30)
        print(f"üîç Î°úÎìúÎêú Î°úÏö∞: {count}Í∞ú, Í∞ÄÏ†∏Ïò¨ Í∞úÏàò: {total}Í∞ú")

        for i in range(total):
            row = rows_locator.nth(i)
            cols = row.locator("td")
            ccount = await cols.count()

            trader = await cols.nth(1).inner_text() if ccount > 1 else "N/A"
            acct   = await cols.nth(2).inner_text() if ccount > 2 else "N/A"
            pnl    = await cols.nth(3).inner_text() if ccount > 3 else "N/A"
            roi    = await cols.nth(4).inner_text() if ccount > 4 else "N/A"
            vol    = await cols.nth(5).inner_text() if ccount > 5 else "N/A"

            # ÏßÄÍ∞ëÏ£ºÏÜåÎäî ÌÅ¥Î¶≠Ìï¥ÏÑú URL ÎßàÏßÄÎßâ segment Î°ú Ï∂îÏ∂ú
            try:
                await cols.nth(1).click()
                await page.wait_for_load_state("networkidle", timeout=30000)
                wallet = page.url.split("/")[-1]
            except PlaywrightTimeoutError:
                wallet = "N/A"

            await page.go_back(wait_until="networkidle", timeout=30000)
            await page.wait_for_selector("table > tbody > tr", timeout=30000)

            records.append({
                "Trader": trader,
                "Wallet": wallet,
                "Account Value": acct,
                "PNL": pnl,
                "ROI": roi,
                "Volume": vol
            })
            print(f"‚úÖ Row {i+1}: {trader} / {wallet}")

        df = pd.DataFrame(records)
        df.to_csv("top30_wallets.csv", index=False)
        print("‚úÖ Saved top30_wallets.csv")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="top30_wallets.csv">
Trader,Wallet,Account Value,PNL,ROI,Volume
0x77c3...5e45,0x77c3ea550d2da44b120e55071f57a108f8dd5e45,"$383,503,173.15","$191,531,322.95",93.47%,$114.89
thank you jefef,0xfae95f601f3a25ace60d19dbb929f2a5c57e3571,"$129,592,349.99","$132,830,483.88","3,089.41%","$4,655,922.47"
0x9794...333b,0x9794bbbc222b6b93c1417d01aa1ff06d42e5333b,"$125,027,291.46","$106,028,775.17",558.09%,"$26,418,280.98"
0xecb6...2b00,0xecb63caa47c7c4e77f60f1ce858cf28dc2b82b00,"$111,002,630.87","$94,106,370.44",93.23%,"$116,616,733,919.42"
0x20c2...44f5,0x20c2d95a3dfdca9e9ad12794d5fa6fad99da44f5,"$39,946,685.11","$84,218,333.39",81.37%,"$834,677,709.15"
0x5d83...4fb6,0x5d83bb3313240cab65e2e9200d3aaf3520474fb6,"$82,641,759.06","$79,803,886.88","2,812.10%",$0.00
jefe,0x51156f7002c4f74f4956c9e0f2b7bfb6e9dbfac2,"$83,778,381.40","$74,528,986.52",618.38%,"$11,881,334.74"
0x0d44...8c0b,0x0d446c3372a9ba9cddef0eef7a1afab6dc0e8c0b,"$70,355,294.60","$70,330,903.07","117,218.17%",$0.00
0x716b...1d95,0x716bd8d3337972db99995dda5c4b34d954a61d95,"$143,574,644.86","$65,672,743.06",53.27%,$0.00
0xbde2...60b1,0xbde2ddc49a2e6827300faa6afc93d572114a60b1,"$64,504,309.46","$62,253,837.66","2,766.26%","$2,045.92"
</file>

</files>
